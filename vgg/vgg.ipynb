{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MbtUcKfE_I4g"},"source":["**Installs**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":671},"colab_type":"code","id":"tzg4cO9xLvUG","outputId":"bd60267b-5ff1-432b-9d2c-c6d528130861","trusted":false},"outputs":[],"source":["!pip3 install 'torch==1.3.1'\n","!pip3 install 'torchvision==0.5.0'\n","!pip3 install 'Pillow-SIMD'\n","!pip3 install 'tqdm'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fxs_3zcG_NZd"},"source":["**Imports**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"C7N0hU-VLx8W","trusted":true},"outputs":[],"source":["import os\n","import logging\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset, DataLoader\n","from torch.backends import cudnn\n","\n","import torchvision\n","from torchvision import transforms\n","from torchvision.models import vgg19\n","from torchvision.models import vgg19_bn\n","from torchvision.models import vgg16\n","from torchvision.models import alexnet\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","\n","#NUM_CLASSES = 102\n","NUM_CLASSES = 6\n","DEVICE = 'cuda'\n","MOMENTUM = 0.9"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uvABcepY_Vfe"},"source":["**Model definition**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"vztVCv3fQXjR","trusted":true},"outputs":[],"source":["def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n","                                                         transforms.CenterCrop(224),\n","                                                         transforms.ToTensor()#,\n","                                                         #transforms.Normalize((75.29522728, 26.30439561, 70.34910019), (80.67869619, 35.54419227, 54.88938911))\n","                                                         ]):\n","    train_transform = transforms.Compose(compose)\n","    eval_transform = transforms.Compose([\n","          transforms.Resize(224),\n","          transforms.CenterCrop(224),\n","          transforms.ToTensor()\n","          ])\n","\n","    '''\n","    if not os.path.isdir('./Homework2-Caltech101'):\n","        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n","\n","    '''\n","    if not os.path.isdir('./AIML_project'):\n","        !git clone https://github.com/anphetamina/AIML_project.git\n","    \n","    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n","    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n","\n","    return train_dataset, test_dataset\n","\n","def test_network(net, test_dataset, batch_size):\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    net.train(False)\n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    sum_test_losses = 0.0\n","    running_corrects = 0\n","    for images, labels in test_dataloader:\n","      images = images.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      # Forward Pass\n","      outputs = net(images)\n","\n","      # Get predictions\n","      _, preds = torch.max(outputs.data, 1)\n","      test_loss = criterion(outputs, labels)\n","      sum_test_losses += test_loss.item()*images.size(0)\n","\n","      # Update Corrects\n","      running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","    # Calculate Accuracy\n","    accuracy = running_corrects / float(len(test_dataset))\n","\n","    # Calculate loss\n","    test_loss = sum_test_losses / float(len(test_dataset))\n","\n","    return accuracy, test_loss\n","\n","def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n","  \n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","    net = net.to(DEVICE)\n","    best_net = vgg19()\n","    best_net = best_net.to(DEVICE)\n","    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n","\n","    cudnn.benchmark\n","\n","    train_accuracies = []\n","    train_losses = []\n","    val_accuracies = []\n","    val_losses = []\n","\n","    current_step = 0\n","    best_val_accuracy = 0.0\n","    best_val_loss = 0.0\n","    for epoch in range(num_epochs):\n","\n","        train_running_corrects = 0\n","        sum_train_losses = 0.0\n","\n","        for images, labels in train_dataloader:\n","            images = images.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","            net.train()\n","            optimizer.zero_grad()\n","\n","            outputs = net(images)\n","            _, preds = torch.max(outputs.data, 1)\n","            train_running_corrects += torch.sum(preds == labels.data).data.item()\n","            loss = criterion(outputs, labels)\n","            sum_train_losses += loss.item()*images.size(0)\n","            loss.backward()\n","\n","            optimizer.step()\n","            current_step += 1\n","        \n","        if val_dataset is not None:\n","            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n","            if val_accuracy > best_val_accuracy:\n","                best_val_accuracy = val_accuracy\n","                best_val_loss = val_loss\n","                best_net.load_state_dict(net.state_dict())\n","            val_accuracies.append(val_accuracy)\n","            val_losses.append(val_loss)\n","\n","        # Calculate accuracy on train set\n","        train_accuracy = train_running_corrects / float(len(train_dataset))\n","        train_accuracies.append(train_accuracy)\n","\n","        # Calculate loss on training set\n","        train_loss = sum_train_losses/float(len(train_dataset))\n","        train_losses.append(loss)\n","\n","        if verbosity:\n","            if val_dataset is not None:\n","                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n","            else:\n","                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n","\n","        scheduler.step()\n","\n","    if plot:\n","\n","        fig, ax = plt.subplots()\n","        line1, = ax.plot(train_losses, label='Loss on training set')\n","        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n","        ax.legend()\n","        plt.xlabel(\"Epochs\")\n","        plt.show()\n","\n","        if val_dataset is not None:\n","            fig, ax = plt.subplots()\n","            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n","            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n","            ax.legend()\n","            plt.xlabel(\"Epochs\")\n","            plt.show()\n","        \n","            fig, ax = plt.subplots()\n","            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n","            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n","            ax.legend()\n","            plt.xlabel(\"Epochs\")\n","            plt.show()\n","\n","    \n","    return best_net, best_val_accuracy, best_val_loss\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"I6fTm2sD_BOt"},"source":["**Train + validation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596},"colab_type":"code","id":"XtBXC1cO_A6A","outputId":"a0064e1c-216a-48ad-b06d-bb7b7e0ec68b","trusted":false},"outputs":[],"source":["BATCH_SIZE = 16\n","LR = 0.001\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 5e-5\n","NUM_EPOCHS = 100\n","STEP_SIZE = 60\n","GAMMA = 0.1\n","\n","TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n","#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n","compose=[transforms.Resize(224),\n","         transforms.CenterCrop(224),\n","         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n","         transforms.ToTensor()\n","         ]\n","train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n","train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n","val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n","val_dataset = Subset(val_dataset, val_indexes)\n","train_dataset = Subset(train_dataset, train_indexes)\n","print('training set {}'.format(len(train_dataset)))\n","print('validation set {}'.format(len(val_dataset)))\n","\n","net = vgg19()\n","net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n","best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n","\n","print('val accuracy {}'.format(val_accuracy))\n","print('val loss {}'.format(val_loss))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kgj76dvQxIJ"},"source":["**Testing**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"_dKdDvgnQw7d","trusted":false},"outputs":[],"source":["# todo"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qxj7-SlSKb_3"},"source":["**Grid search**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"colab_type":"code","id":"aPmSObkPKbu3","outputId":"48ad0793-0ed9-4230-879d-0f61cf1a8843","trusted":false},"outputs":[],"source":["NUM_CLASSES = 6\n","DEVICE = 'cuda'\n","#BATCH_SIZE = 16\n","#LR = 0.001\n","MOMENTUM = 0.9\n","#WEIGHT_DECAY = 5e-5\n","NUM_EPOCHS = 100\n","STEP_SIZE = 60\n","#GAMMA = 0.1\n","\n","lr_range = [0.001, 0.05]\n","batch_size_range = [16, 32]\n","weight_decay_range = [1e-5, 1e-3]\n","gamma_range = [0.05, 0.1]\n","hyperparameters_sets = []\n","\n","for lr in lr_range:\n","  for batch_size in batch_size_range:\n","    for weight_decay in weight_decay_range:\n","      for gamma in gamma_range:\n","        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n","\n","for set in hyperparameters_sets:\n","  print(set)\n","\n","\n","TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n","compose=[transforms.Resize(224),\n","         transforms.CenterCrop(224),\n","         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n","         transforms.ToTensor()\n","         ]\n","train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n","\n","train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n","val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n","val_dataset = Subset(val_dataset, val_indexes)\n","train_dataset = Subset(train_dataset, train_indexes)\n","print('training set {}'.format(len(train_dataset)))\n","print('validation set {}'.format(len(val_dataset)))\n","\n","best_net = vgg19()\n","best_net = best_net.to(DEVICE)\n","best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n","best_set = {}\n","best_accuracy = 0.0\n","best_loss = 0.0\n","val_accuracies = []\n","val_losses = []\n","\n","for set in hyperparameters_sets:\n","\n","  net = vgg19()\n","  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n","  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset, verbosity=True)\n","  val_accuracies.append(val_accuracy)\n","  val_losses.append(val_loss)\n","\n","  if val_accuracy > best_accuracy:\n","    best_accuracy = val_accuracy\n","    best_loss = val_loss\n","    best_net = copy.deepcopy(current_net)\n","    best_set = copy.deepcopy(set)\n","  \n","  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n","\n","print(\"\\n({}), best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n","print(\"\\nval_accuracies\")\n","print(val_accuracies)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S1laZWm8Q0tm"},"source":["**Testing**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"TKl555WRQ1AF","trusted":false},"outputs":[],"source":["# todo"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jJGI06ylKePa"},"source":["**Mean / std computation**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"colab_type":"code","id":"YDJptx12L1OL","outputId":"c59e12bc-93f0-4450-8ade-b176122bb1bb","trusted":false},"outputs":[],"source":["TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n","pixel_mean = np.zeros(3)\n","pixel_std = np.zeros(3)\n","k = 1\n","dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n","for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n","    image = np.array(image)\n","    pixels = image.reshape((-1, image.shape[2]))\n","\n","    for pixel in pixels:\n","        diff = pixel - pixel_mean\n","        pixel_mean += diff / k\n","        pixel_std += diff * (pixel - pixel_mean)\n","        k += 1\n","\n","pixel_std = np.sqrt(pixel_std / (k - 2))\n","print(pixel_mean)\n","print(pixel_std)"]}],"metadata":{"colab":{"name":"vgg.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}