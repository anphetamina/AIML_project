{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 5\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          #transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg19()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            #acc_diff = train_accuracy-val_accuracy\n",
        "            #if acc_diff > 0.25:\n",
        "              #print(\"overfit -> train_accuracy {}, val_accuracy {}\".format(train_accuracy, val_accuracy))\n",
        "              #return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "        \n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        if train_accuracy < 0.25 and epoch > num_epochs*0.1 or train_accuracy < 0.35 and epoch > num_epochs*0.5:\n",
        "          print(\"underfit -> train_accuracy = {}\".format(train_accuracy))\n",
        "          return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "4a07379f-0940-4c83-aace-cbda239b6b9f",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        }
      },
      "source": [
        "# ({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7881773399014779, val loss 1.4585814757887365\n",
        "# lr 0.0017290126152359597, batch 11, decay 1.0506062245241487e-06, gamma 0.10515207194838522, val accuracy 0.6108374384236454, val loss 1.1022712842290625 [3 / 50]\n",
        "BATCH_SIZE = 11\n",
        "LR = 0.0017290126152359597\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1.0506062245241487e-06\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.10515207194838522\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 2]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 2]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg19()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 414\n",
            "validation set 414\n",
            "train_acc: 0.2318840579710145, val_acc: 0.2222222222222222, train_loss: 1.5968541238043044, val_loss: 1.5734839088099015 (1 / 100)\n",
            "train_acc: 0.2246376811594203, val_acc: 0.2222222222222222, train_loss: 1.5851994980360575, val_loss: 1.5602227325600702 (2 / 100)\n",
            "train_acc: 0.22946859903381642, val_acc: 0.24879227053140096, train_loss: 1.5821979924100609, val_loss: 1.564067614539234 (3 / 100)\n",
            "train_acc: 0.2463768115942029, val_acc: 0.2391304347826087, train_loss: 1.5706412527296278, val_loss: 1.5450032229584771 (4 / 100)\n",
            "train_acc: 0.26811594202898553, val_acc: 0.40096618357487923, train_loss: 1.5593176086743672, val_loss: 1.4996689350708672 (5 / 100)\n",
            "train_acc: 0.30676328502415456, val_acc: 0.2463768115942029, train_loss: 1.5293991703918015, val_loss: 1.5016534314063437 (6 / 100)\n",
            "train_acc: 0.28502415458937197, val_acc: 0.3888888888888889, train_loss: 1.5305622562694088, val_loss: 1.4488196583185795 (7 / 100)\n",
            "train_acc: 0.3502415458937198, val_acc: 0.39855072463768115, train_loss: 1.4563430697445707, val_loss: 1.4609544056913126 (8 / 100)\n",
            "train_acc: 0.2608695652173913, val_acc: 0.22946859903381642, train_loss: 1.5757264523690448, val_loss: 1.598708462887916 (9 / 100)\n",
            "train_acc: 0.2246376811594203, val_acc: 0.36231884057971014, train_loss: 1.586304745524402, val_loss: 1.5637879509856736 (10 / 100)\n",
            "train_acc: 0.2584541062801932, val_acc: 0.24396135265700483, train_loss: 1.5631541105860098, val_loss: 1.5679483825457845 (11 / 100)\n",
            "train_acc: 0.3333333333333333, val_acc: 0.39371980676328505, train_loss: 1.5165685654262413, val_loss: 1.4029710955089993 (12 / 100)\n",
            "train_acc: 0.30917874396135264, val_acc: 0.2222222222222222, train_loss: 1.531334010011332, val_loss: 1.5831850997491734 (13 / 100)\n",
            "train_acc: 0.28743961352657005, val_acc: 0.4468599033816425, train_loss: 1.534842800690932, val_loss: 1.3239303481751594 (14 / 100)\n",
            "train_acc: 0.3333333333333333, val_acc: 0.391304347826087, train_loss: 1.533255088156548, val_loss: 1.3678729306672506 (15 / 100)\n",
            "train_acc: 0.3888888888888889, val_acc: 0.47101449275362317, train_loss: 1.3793577757722513, val_loss: 1.235894647485392 (16 / 100)\n",
            "train_acc: 0.4227053140096618, val_acc: 0.4323671497584541, train_loss: 1.324609659432213, val_loss: 1.2316866067872532 (17 / 100)\n",
            "train_acc: 0.427536231884058, val_acc: 0.427536231884058, train_loss: 1.3219551328875592, val_loss: 1.2930346341524723 (18 / 100)\n",
            "train_acc: 0.41545893719806765, val_acc: 0.3695652173913043, train_loss: 1.2904468521403805, val_loss: 1.3261093949350182 (19 / 100)\n",
            "train_acc: 0.4227053140096618, val_acc: 0.46618357487922707, train_loss: 1.3408168744349824, val_loss: 1.151642089880607 (20 / 100)\n",
            "train_acc: 0.4613526570048309, val_acc: 0.46859903381642515, train_loss: 1.215882117189647, val_loss: 1.295760088496738 (21 / 100)\n",
            "train_acc: 0.42995169082125606, val_acc: 0.36231884057971014, train_loss: 1.29075521475451, val_loss: 1.3948230380597322 (22 / 100)\n",
            "train_acc: 0.4444444444444444, val_acc: 0.45169082125603865, train_loss: 1.2370510580747023, val_loss: 1.2450893180093903 (23 / 100)\n",
            "train_acc: 0.43719806763285024, val_acc: 0.41304347826086957, train_loss: 1.2030797726002291, val_loss: 1.2823696271808827 (24 / 100)\n",
            "train_acc: 0.4444444444444444, val_acc: 0.5, train_loss: 1.1728983462432732, val_loss: 1.1239293076565877 (25 / 100)\n",
            "train_acc: 0.4444444444444444, val_acc: 0.42028985507246375, train_loss: 1.1976676594807907, val_loss: 1.2114717801987838 (26 / 100)\n",
            "train_acc: 0.4855072463768116, val_acc: 0.4251207729468599, train_loss: 1.1624904067619988, val_loss: 1.281320209376478 (27 / 100)\n",
            "train_acc: 0.5120772946859904, val_acc: 0.5024154589371981, train_loss: 1.143983109993635, val_loss: 1.1049949641964862 (28 / 100)\n",
            "train_acc: 0.46859903381642515, val_acc: 0.4806763285024155, train_loss: 1.129451930378946, val_loss: 1.1038407255773959 (29 / 100)\n",
            "train_acc: 0.49033816425120774, val_acc: 0.49033816425120774, train_loss: 1.1132926097238698, val_loss: 1.0904550965569446 (30 / 100)\n",
            "train_acc: 0.4855072463768116, val_acc: 0.4468599033816425, train_loss: 1.1495740095486389, val_loss: 1.1764064768086309 (31 / 100)\n",
            "train_acc: 0.5144927536231884, val_acc: 0.5048309178743962, train_loss: 1.102316474425044, val_loss: 1.0407773849468875 (32 / 100)\n",
            "train_acc: 0.5096618357487923, val_acc: 0.4927536231884058, train_loss: 1.0835663838950909, val_loss: 1.1126571759797526 (33 / 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "from torchvision import datasets\n",
        "# Serve per il mapping fra label sul file con le labels per canzone di test e l'indice della label che la rete considera.\n",
        "LABELS_FROM_FILE = {'angry' : 0, 'calming' : 1, 'happy' : 2, 'normal' : 3, 'sad' : 4}\n",
        "NUM_CLASSES = 5\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "\n",
        "def test_network_with_songs_data_return(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "    net = net.to(DEVICE)\n",
        "\n",
        "    test_songs_data = dict()\n",
        "    for images, labels, paths in test_dataloader:\n",
        "      torch.cuda.empty_cache()\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      idx = 0;\n",
        "      for pred in preds:\n",
        "\n",
        "        image_name = paths[idx].split(\"/\")[-1]\n",
        "        song_idx = image_name.split(\"_\")[0]\n",
        "      \n",
        "        if song_idx not in test_songs_data:\n",
        "          test_songs_data[song_idx] = dict()\n",
        "          test_songs_data[song_idx][\"preds\"] = np.zeros(NUM_CLASSES, dtype=int)\n",
        "          # test_songs_data[song_idx][\"outputs\"] = []\n",
        "\n",
        "        test_songs_data[song_idx][\"preds\"][pred] += 1\n",
        "        # test_songs_data[song_idx][\"outputs\"].append(outputs[idx])\n",
        "\n",
        "        idx += 1\n",
        "\n",
        "      del labels\n",
        "      del images\n",
        "      del outputs\n",
        "\n",
        "    return test_songs_data\n",
        "\n",
        "def read_songs_labels(path):\n",
        "  f = open(path,\"r\")\n",
        "  lines = f.readlines()\n",
        "\n",
        "  song_labels = dict()\n",
        "\n",
        "  for line in lines:\n",
        "    names = line.split(\":\")\n",
        "\n",
        "    if names[0] not in song_labels:\n",
        "      song_labels[names[0]] = []\n",
        "\n",
        "    labels = names[1].replace(\" \", \"\").split(\",\")\n",
        "    labels[-1] = labels[-1][:-2]\n",
        "\n",
        "    for label in labels:\n",
        "      song_labels[names[0]].append(LABELS_FROM_FILE[label])\n",
        "  \n",
        "  return song_labels\n",
        "\n",
        "def major_voting_analyze(songs_data, songs_labels):\n",
        "\n",
        "  ordered_keys = sorted(songs_labels.keys())\n",
        "  print(ordered_keys)\n",
        "  prediction = dict()\n",
        "  avg_outputs = dict()\n",
        "  corrects = 0\n",
        "\n",
        "  for key in songs_data.keys():\n",
        "    num_slices = 0\n",
        "    for value in songs_data[key][\"preds\"]:\n",
        "      num_slices += value\n",
        "\n",
        "\n",
        "    for value in songs_data[key][\"preds\"]:\n",
        "      value = (float) (value/num_slices)\n",
        "      # if value > 0.5:\n",
        "      #   prediction[key] = idx_pred\n",
        "\n",
        "    max = 0\n",
        "    idx_pred = 0\n",
        "    idx_max = 0\n",
        "    for value in songs_data[key][\"preds\"]:\n",
        "      if value > max:\n",
        "        max = value\n",
        "        idx_max = idx_pred\n",
        "      idx_pred += 1\n",
        "\n",
        "    prediction[key] = idx_max\n",
        "\n",
        "    # for output in songs_data[key][\"outputs\"]:\n",
        "    #   if sum_outputs is None:\n",
        "    #     sum_outputs = output\n",
        "    #   else:\n",
        "    #     sum_outputs += output\n",
        "\n",
        "    # avg_ouputs = sum_outputs/num_slices\n",
        "\n",
        "  idx = 0\n",
        "  keys = sorted(prediction.keys(), key=int)\n",
        "  print(list(keys))\n",
        "  for song_idx in keys:\n",
        "    if prediction[song_idx] in songs_labels[ordered_keys[idx]]:\n",
        "      corrects += 1\n",
        "    print(\"Prediction for song {} - {}: {}; labels: {}\".format(song_idx, ordered_keys[idx], prediction[song_idx], list(songs_labels[ordered_keys[idx]])))\n",
        "    idx += 1\n",
        "\n",
        "  test_accuracy = (float) (corrects / idx)\n",
        "  print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "\n",
        "def get_test_dataset(test_data_dir):\n",
        "    eval_transform = transforms.Compose([\n",
        "          #transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "    \n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    test_dataset = ImageFolderWithPaths(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "TEST_DATA_DIR = 'AIML_project/CAL500_test_sliced_spectrograms'\n",
        "test_dataset = get_test_dataset(TEST_DATA_DIR)\n",
        "print('test set {}'.format(len(test_dataset)))\n",
        "\n",
        "# net extracted by training\n",
        "songs_data = test_network_with_songs_data_return(best_net, test_dataset, BATCH_SIZE)\n",
        "\n",
        "print(songs_data)\n",
        "\n",
        "songs_labels = read_songs_labels(\"AIML_project/songs_filtered_with_labels.txt\")\n",
        "\n",
        "print(songs_labels)\n",
        "\n",
        "major_voting_analyze(songs_data, songs_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUIpGmogDgOC",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eOsPQVDgG6",
        "colab_type": "code",
        "outputId": "e4945cf7-2254-4dec-d111-50c3cfeaf2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 10]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 10]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = vgg19()\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = random.uniform(0.0008, 0.003)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-5, -3)\n",
        "  NUM_EPOCHS = 100\n",
        "  STEP_SIZE = 60\n",
        "  GAMMA = 10**random.uniform(-2, -1)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"-------------------------------------\")\n",
        "  print(set)\n",
        "  net = vgg19()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "\n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 910\n",
            "validation set 102\n",
            "-------------------------------------\n",
            "{'lr': 0.00271621936500431, 'batch_size': 13, 'weight_decay': 0.00018308707592117277, 'gamma': 0.06393470426207985}\n",
            "train_acc: 0.17582417582417584, val_acc: 0.17647058823529413, train_loss: 1.776629032407488, val_loss: 1.7655110300755967 (1 / 100)\n",
            "train_acc: 0.2, val_acc: 0.27450980392156865, train_loss: 1.7512230464390346, val_loss: 1.6718381549797805 (2 / 100)\n",
            "train_acc: 0.1835164835164835, val_acc: 0.22549019607843138, train_loss: 1.759641420841217, val_loss: 1.756030163344215 (3 / 100)\n",
            "train_acc: 0.23076923076923078, val_acc: 0.3235294117647059, train_loss: 1.7647455028125218, val_loss: 1.7353674956396514 (4 / 100)\n",
            "train_acc: 0.23736263736263735, val_acc: 0.20588235294117646, train_loss: 1.7537101064409528, val_loss: 1.7741931232751584 (5 / 100)\n",
            "train_acc: 0.26483516483516484, val_acc: 0.22549019607843138, train_loss: 1.7133156946727208, val_loss: 1.6680528311168445 (6 / 100)\n",
            "train_acc: 0.3142857142857143, val_acc: 0.27450980392156865, train_loss: 1.638217568397522, val_loss: 1.5608780991797353 (7 / 100)\n",
            "train_acc: 0.31978021978021975, val_acc: 0.3431372549019608, train_loss: 1.57286821944373, val_loss: 1.5317199989861132 (8 / 100)\n",
            "train_acc: 0.33516483516483514, val_acc: 0.3333333333333333, train_loss: 1.5335504974637713, val_loss: 1.4480944264168834 (9 / 100)\n",
            "train_acc: 0.37252747252747254, val_acc: 0.29411764705882354, train_loss: 1.480773946217128, val_loss: 1.6039530412823546 (10 / 100)\n",
            "train_acc: 0.3769230769230769, val_acc: 0.4411764705882353, train_loss: 1.4574126873697553, val_loss: 1.401168263426014 (11 / 100)\n",
            "train_acc: 0.37362637362637363, val_acc: 0.47058823529411764, train_loss: 1.4127995840140752, val_loss: 1.3989268038787095 (12 / 100)\n",
            "train_acc: 0.3956043956043956, val_acc: 0.4019607843137255, train_loss: 1.3742786015783037, val_loss: 1.2522293796726303 (13 / 100)\n",
            "train_acc: 0.3945054945054945, val_acc: 0.45098039215686275, train_loss: 1.3558871226651328, val_loss: 1.3403532563471328 (14 / 100)\n",
            "train_acc: 0.4021978021978022, val_acc: 0.38235294117647056, train_loss: 1.400364191191537, val_loss: 1.311785736504723 (15 / 100)\n",
            "train_acc: 0.46153846153846156, val_acc: 0.46078431372549017, train_loss: 1.3158947212355478, val_loss: 1.3222332947394426 (16 / 100)\n",
            "train_acc: 0.45164835164835165, val_acc: 0.47058823529411764, train_loss: 1.2716284930706023, val_loss: 1.1885002606055315 (17 / 100)\n",
            "train_acc: 0.4824175824175824, val_acc: 0.49019607843137253, train_loss: 1.225695573432105, val_loss: 1.1645794960798002 (18 / 100)\n",
            "train_acc: 0.4912087912087912, val_acc: 0.4215686274509804, train_loss: 1.1881378386701857, val_loss: 1.372730980316798 (19 / 100)\n",
            "train_acc: 0.5054945054945055, val_acc: 0.5, train_loss: 1.179316622018814, val_loss: 1.1310799595187693 (20 / 100)\n",
            "train_acc: 0.4901098901098901, val_acc: 0.5392156862745098, train_loss: 1.2613177282469614, val_loss: 1.1481217817932952 (21 / 100)\n",
            "train_acc: 0.5197802197802198, val_acc: 0.5, train_loss: 1.1430995651653835, val_loss: 1.1302893436422534 (22 / 100)\n",
            "train_acc: 0.5516483516483517, val_acc: 0.46078431372549017, train_loss: 1.0796671092510224, val_loss: 1.2344100358439427 (23 / 100)\n",
            "train_acc: 0.5571428571428572, val_acc: 0.46078431372549017, train_loss: 1.1029968125479561, val_loss: 1.175735714973188 (24 / 100)\n",
            "train_acc: 0.5703296703296703, val_acc: 0.5, train_loss: 1.0524595447949001, val_loss: 1.120857127156912 (25 / 100)\n",
            "train_acc: 0.6131868131868132, val_acc: 0.5196078431372549, train_loss: 0.9500172602278846, val_loss: 1.1849217788845885 (26 / 100)\n",
            "train_acc: 0.643956043956044, val_acc: 0.47058823529411764, train_loss: 0.9118848604815347, val_loss: 1.1741300803773544 (27 / 100)\n",
            "train_acc: 0.6186813186813187, val_acc: 0.49019607843137253, train_loss: 0.9452331236430577, val_loss: 1.1641788850812351 (28 / 100)\n",
            "train_acc: 0.7, val_acc: 0.5588235294117647, train_loss: 0.7501984715461731, val_loss: 1.0082249886849348 (29 / 100)\n",
            "train_acc: 0.6901098901098901, val_acc: 0.5784313725490197, train_loss: 0.7809723441089903, val_loss: 1.0832497454157062 (30 / 100)\n",
            "train_acc: 0.7175824175824176, val_acc: 0.5588235294117647, train_loss: 0.7195851076926504, val_loss: 1.0560180895468767 (31 / 100)\n",
            "train_acc: 0.7527472527472527, val_acc: 0.5882352941176471, train_loss: 0.6507820052759988, val_loss: 1.1092572907606761 (32 / 100)\n",
            "train_acc: 0.7241758241758242, val_acc: 0.5098039215686274, train_loss: 0.6689426434891564, val_loss: 1.0426185353129518 (33 / 100)\n",
            "train_acc: 0.7923076923076923, val_acc: 0.5980392156862745, train_loss: 0.5528523340821266, val_loss: 1.03619009197927 (34 / 100)\n",
            "train_acc: 0.8043956043956044, val_acc: 0.5686274509803921, train_loss: 0.5219702174620969, val_loss: 1.3351203480771943 (35 / 100)\n",
            "overfit -> train_accuracy 0.8263736263736263, val_accuracy 0.5686274509803921\n",
            "lr 0.00271621936500431, batch 13, decay 0.00018308707592117277, gamma 0.06393470426207985, val accuracy 0.5980392156862745, val loss 1.03619009197927 [1 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0012755288318408756, 'batch_size': 15, 'weight_decay': 1.1833646558848458e-05, 'gamma': 0.026341788763606662}\n",
            "train_acc: 0.16593406593406593, val_acc: 0.18627450980392157, train_loss: 1.7875189892538301, val_loss: 1.7788648570285124 (1 / 100)\n",
            "train_acc: 0.189010989010989, val_acc: 0.18627450980392157, train_loss: 1.7725236271763896, val_loss: 1.755297162953545 (2 / 100)\n",
            "train_acc: 0.20549450549450549, val_acc: 0.2549019607843137, train_loss: 1.7601415259497506, val_loss: 1.745736805831685 (3 / 100)\n",
            "train_acc: 0.25384615384615383, val_acc: 0.28431372549019607, train_loss: 1.7281212086205955, val_loss: 1.644379436969757 (4 / 100)\n",
            "train_acc: 0.26593406593406593, val_acc: 0.3333333333333333, train_loss: 1.7389490073853797, val_loss: 1.6117912355591268 (5 / 100)\n",
            "train_acc: 0.27912087912087913, val_acc: 0.30392156862745096, train_loss: 1.6373400020075368, val_loss: 1.6655828356742859 (6 / 100)\n",
            "train_acc: 0.3362637362637363, val_acc: 0.28431372549019607, train_loss: 1.5667974627934969, val_loss: 1.646809830385096 (7 / 100)\n",
            "train_acc: 0.3131868131868132, val_acc: 0.37254901960784315, train_loss: 1.5317123512645343, val_loss: 1.3909529587801766 (8 / 100)\n",
            "train_acc: 0.35384615384615387, val_acc: 0.3137254901960784, train_loss: 1.4972936465190008, val_loss: 1.5796797310604769 (9 / 100)\n",
            "train_acc: 0.36043956043956044, val_acc: 0.39215686274509803, train_loss: 1.4696476944200285, val_loss: 1.3556760865099289 (10 / 100)\n",
            "train_acc: 0.3978021978021978, val_acc: 0.46078431372549017, train_loss: 1.4347221851348877, val_loss: 1.4451213198549606 (11 / 100)\n",
            "train_acc: 0.3868131868131868, val_acc: 0.45098039215686275, train_loss: 1.408931390269772, val_loss: 1.488965911023757 (12 / 100)\n",
            "train_acc: 0.4087912087912088, val_acc: 0.4803921568627451, train_loss: 1.4076120506276142, val_loss: 1.2607755661010742 (13 / 100)\n",
            "train_acc: 0.4098901098901099, val_acc: 0.4117647058823529, train_loss: 1.3946621005351727, val_loss: 1.3274798288064844 (14 / 100)\n",
            "train_acc: 0.42527472527472526, val_acc: 0.47058823529411764, train_loss: 1.3559669154685932, val_loss: 1.252638141898548 (15 / 100)\n",
            "train_acc: 0.42527472527472526, val_acc: 0.5, train_loss: 1.350989207134142, val_loss: 1.2159877279225517 (16 / 100)\n",
            "train_acc: 0.4175824175824176, val_acc: 0.4411764705882353, train_loss: 1.3476767962450509, val_loss: 1.3619780470343197 (17 / 100)\n",
            "train_acc: 0.45274725274725275, val_acc: 0.5294117647058824, train_loss: 1.2864861842040176, val_loss: 1.1813167158295126 (18 / 100)\n",
            "train_acc: 0.46483516483516485, val_acc: 0.43137254901960786, train_loss: 1.2847055799358493, val_loss: 1.3812114175628214 (19 / 100)\n",
            "train_acc: 0.46923076923076923, val_acc: 0.5098039215686274, train_loss: 1.286240232187313, val_loss: 1.1759291711975546 (20 / 100)\n",
            "train_acc: 0.4835164835164835, val_acc: 0.5098039215686274, train_loss: 1.2230681433127477, val_loss: 1.185610129552729 (21 / 100)\n",
            "train_acc: 0.49340659340659343, val_acc: 0.47058823529411764, train_loss: 1.213113091476671, val_loss: 1.2809797192321104 (22 / 100)\n",
            "train_acc: 0.4956043956043956, val_acc: 0.5882352941176471, train_loss: 1.206034318758891, val_loss: 1.1135902509969824 (23 / 100)\n",
            "train_acc: 0.5395604395604395, val_acc: 0.5686274509803921, train_loss: 1.1354016353795817, val_loss: 1.1706321730333216 (24 / 100)\n",
            "train_acc: 0.5307692307692308, val_acc: 0.5490196078431373, train_loss: 1.1504281333514623, val_loss: 1.0883677163544823 (25 / 100)\n",
            "train_acc: 0.5208791208791209, val_acc: 0.49019607843137253, train_loss: 1.1418652531209883, val_loss: 1.2051746249198914 (26 / 100)\n",
            "train_acc: 0.5582417582417583, val_acc: 0.5294117647058824, train_loss: 1.065355392930272, val_loss: 1.0632890305098366 (27 / 100)\n",
            "train_acc: 0.5769230769230769, val_acc: 0.6274509803921569, train_loss: 1.0319718273131402, val_loss: 0.9923160356633803 (28 / 100)\n",
            "train_acc: 0.6197802197802198, val_acc: 0.4803921568627451, train_loss: 0.9429955764131231, val_loss: 1.274824717465569 (29 / 100)\n",
            "train_acc: 0.6054945054945055, val_acc: 0.5882352941176471, train_loss: 1.000457491193499, val_loss: 1.074726304587196 (30 / 100)\n",
            "train_acc: 0.6472527472527473, val_acc: 0.5784313725490197, train_loss: 0.9045614110571998, val_loss: 1.0005477474016302 (31 / 100)\n",
            "train_acc: 0.6406593406593407, val_acc: 0.6176470588235294, train_loss: 0.9096988596758999, val_loss: 1.0370993035681106 (32 / 100)\n",
            "train_acc: 0.6241758241758242, val_acc: 0.6078431372549019, train_loss: 0.9333953037039264, val_loss: 1.071111617719426 (33 / 100)\n",
            "train_acc: 0.6406593406593407, val_acc: 0.5588235294117647, train_loss: 0.8625553982270943, val_loss: 1.0220933223471922 (34 / 100)\n",
            "train_acc: 0.7054945054945055, val_acc: 0.6372549019607843, train_loss: 0.7537721829427467, val_loss: 0.9742044648703407 (35 / 100)\n",
            "train_acc: 0.710989010989011, val_acc: 0.6176470588235294, train_loss: 0.7441299374286945, val_loss: 1.044766399790259 (36 / 100)\n",
            "train_acc: 0.7571428571428571, val_acc: 0.6470588235294118, train_loss: 0.6604753919355162, val_loss: 1.0249008799300474 (37 / 100)\n",
            "train_acc: 0.743956043956044, val_acc: 0.5882352941176471, train_loss: 0.6246708274542631, val_loss: 1.0795524996869705 (38 / 100)\n",
            "train_acc: 0.7846153846153846, val_acc: 0.5980392156862745, train_loss: 0.6018933233815235, val_loss: 1.0129166192868178 (39 / 100)\n",
            "train_acc: 0.8076923076923077, val_acc: 0.6862745098039216, train_loss: 0.5440053593899522, val_loss: 1.2153484492617495 (40 / 100)\n",
            "train_acc: 0.8362637362637363, val_acc: 0.6470588235294118, train_loss: 0.4979899800740756, val_loss: 1.1750224548227646 (41 / 100)\n",
            "train_acc: 0.8142857142857143, val_acc: 0.6666666666666666, train_loss: 0.476833035330196, val_loss: 1.0789171807906206 (42 / 100)\n",
            "train_acc: 0.8208791208791208, val_acc: 0.5882352941176471, train_loss: 0.48608823771496396, val_loss: 1.2324450945152956 (43 / 100)\n",
            "train_acc: 0.8384615384615385, val_acc: 0.7254901960784313, train_loss: 0.41600364463014916, val_loss: 0.9953072509344887 (44 / 100)\n",
            "train_acc: 0.8725274725274725, val_acc: 0.696078431372549, train_loss: 0.37117695460443967, val_loss: 1.123483352801379 (45 / 100)\n",
            "train_acc: 0.9043956043956044, val_acc: 0.7549019607843137, train_loss: 0.27824700994232854, val_loss: 1.2426655976211323 (46 / 100)\n",
            "train_acc: 0.8934065934065935, val_acc: 0.6666666666666666, train_loss: 0.29868697385933085, val_loss: 1.5060060585246366 (47 / 100)\n",
            "overfit -> train_accuracy 0.9010989010989011, val_accuracy 0.6372549019607843\n",
            "lr 0.0012755288318408756, batch 15, decay 1.1833646558848458e-05, gamma 0.026341788763606662, val accuracy 0.7549019607843137, val loss 1.2426655976211323 [2 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.001965256561700741, 'batch_size': 8, 'weight_decay': 0.0002764066446847852, 'gamma': 0.04749271196834699}\n",
            "train_acc: 0.18571428571428572, val_acc: 0.18627450980392157, train_loss: 1.769174363062932, val_loss: 1.7236811109617645 (1 / 100)\n",
            "train_acc: 0.22637362637362637, val_acc: 0.19607843137254902, train_loss: 1.74858144901611, val_loss: 1.6643324903413361 (2 / 100)\n",
            "train_acc: 0.27802197802197803, val_acc: 0.17647058823529413, train_loss: 1.6924547423373213, val_loss: 1.7820400911218979 (3 / 100)\n",
            "train_acc: 0.17362637362637362, val_acc: 0.22549019607843138, train_loss: 1.7698567932778662, val_loss: 1.7436198323380714 (4 / 100)\n",
            "train_acc: 0.2032967032967033, val_acc: 0.17647058823529413, train_loss: 1.7539054040070419, val_loss: 1.7243466096765854 (5 / 100)\n",
            "train_acc: 0.22967032967032966, val_acc: 0.3235294117647059, train_loss: 1.7332925723149226, val_loss: 1.697927107997969 (6 / 100)\n",
            "train_acc: 0.22637362637362637, val_acc: 0.28431372549019607, train_loss: 1.7563410111836024, val_loss: 1.7366159943973316 (7 / 100)\n",
            "train_acc: 0.2, val_acc: 0.19607843137254902, train_loss: 1.751451610994863, val_loss: 1.7659691805933035 (8 / 100)\n",
            "train_acc: 0.24835164835164836, val_acc: 0.2549019607843137, train_loss: 1.7212337577735985, val_loss: 1.6386491270626293 (9 / 100)\n",
            "train_acc: 0.22857142857142856, val_acc: 0.29411764705882354, train_loss: 1.7310722518753219, val_loss: 1.6252620056563734 (10 / 100)\n",
            "train_acc: 0.3054945054945055, val_acc: 0.23529411764705882, train_loss: 1.6330084454882277, val_loss: 1.7867151218302109 (11 / 100)\n",
            "train_acc: 0.24725274725274726, val_acc: 0.24509803921568626, train_loss: 1.7412601054369747, val_loss: 1.6765750997206743 (12 / 100)\n",
            "underfit -> train_accuracy = 0.24725274725274726\n",
            "lr 0.001965256561700741, batch 8, decay 0.0002764066446847852, gamma 0.04749271196834699, val accuracy 0.3235294117647059, val loss 1.697927107997969 [3 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0026255338284178462, 'batch_size': 9, 'weight_decay': 9.86134271466636e-05, 'gamma': 0.020775274374540884}\n",
            "train_acc: 0.17362637362637362, val_acc: 0.17647058823529413, train_loss: 1.7802660784878575, val_loss: 1.752064603216508 (1 / 100)\n",
            "train_acc: 0.1989010989010989, val_acc: 0.18627450980392157, train_loss: 1.7669337885720389, val_loss: 1.7490653360591215 (2 / 100)\n",
            "train_acc: 0.1978021978021978, val_acc: 0.2647058823529412, train_loss: 1.7604992038601048, val_loss: 1.7666034978978775 (3 / 100)\n",
            "train_acc: 0.23406593406593407, val_acc: 0.30392156862745096, train_loss: 1.7612553994734208, val_loss: 1.7421432347858654 (4 / 100)\n",
            "train_acc: 0.25824175824175827, val_acc: 0.3235294117647059, train_loss: 1.736691339330359, val_loss: 1.7404405264293445 (5 / 100)\n",
            "train_acc: 0.25274725274725274, val_acc: 0.17647058823529413, train_loss: 1.7298549029853318, val_loss: 1.7796716935494368 (6 / 100)\n",
            "train_acc: 0.2703296703296703, val_acc: 0.3137254901960784, train_loss: 1.6892060336175856, val_loss: 1.58041872697718 (7 / 100)\n",
            "train_acc: 0.2681318681318681, val_acc: 0.18627450980392157, train_loss: 1.6800099473733168, val_loss: 1.7916657854528988 (8 / 100)\n",
            "train_acc: 0.18461538461538463, val_acc: 0.18627450980392157, train_loss: 1.7770881952820243, val_loss: 1.7661704736597397 (9 / 100)\n",
            "train_acc: 0.17912087912087912, val_acc: 0.24509803921568626, train_loss: 1.770722934439942, val_loss: 1.7407646354506998 (10 / 100)\n",
            "train_acc: 0.26373626373626374, val_acc: 0.18627450980392157, train_loss: 1.6891727195991264, val_loss: 1.7763741051449495 (11 / 100)\n",
            "train_acc: 0.16263736263736264, val_acc: 0.30392156862745096, train_loss: 1.7720877887128474, val_loss: 1.7542477565653183 (12 / 100)\n",
            "underfit -> train_accuracy = 0.16263736263736264\n",
            "lr 0.0026255338284178462, batch 9, decay 9.86134271466636e-05, gamma 0.020775274374540884, val accuracy 0.3235294117647059, val loss 1.7404405264293445 [4 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0008240940187758286, 'batch_size': 9, 'weight_decay': 0.0006293398362618167, 'gamma': 0.06260271599519035}\n",
            "train_acc: 0.17142857142857143, val_acc: 0.2549019607843137, train_loss: 1.7779658938502216, val_loss: 1.7451476349550135 (1 / 100)\n",
            "train_acc: 0.17582417582417584, val_acc: 0.18627450980392157, train_loss: 1.7845601806273828, val_loss: 1.777064653003917 (2 / 100)\n",
            "train_acc: 0.17692307692307693, val_acc: 0.2647058823529412, train_loss: 1.7708478959052116, val_loss: 1.7463589135338278 (3 / 100)\n",
            "train_acc: 0.25054945054945055, val_acc: 0.29411764705882354, train_loss: 1.7491639674364865, val_loss: 1.7267788964159347 (4 / 100)\n",
            "train_acc: 0.26263736263736265, val_acc: 0.3235294117647059, train_loss: 1.7185690641403197, val_loss: 1.6881272337015938 (5 / 100)\n",
            "train_acc: 0.3021978021978022, val_acc: 0.37254901960784315, train_loss: 1.677737337547344, val_loss: 1.6394436815205742 (6 / 100)\n",
            "train_acc: 0.31648351648351647, val_acc: 0.3431372549019608, train_loss: 1.628853056195018, val_loss: 1.5775360850726856 (7 / 100)\n",
            "train_acc: 0.31978021978021975, val_acc: 0.2549019607843137, train_loss: 1.6032711249131424, val_loss: 1.662684777203728 (8 / 100)\n",
            "train_acc: 0.3648351648351648, val_acc: 0.37254901960784315, train_loss: 1.5248040728516632, val_loss: 1.4616110359921175 (9 / 100)\n",
            "train_acc: 0.3747252747252747, val_acc: 0.35294117647058826, train_loss: 1.4990963593944089, val_loss: 1.4533443030189066 (10 / 100)\n",
            "train_acc: 0.35934065934065934, val_acc: 0.38235294117647056, train_loss: 1.4876307609317068, val_loss: 1.4722699698279886 (11 / 100)\n",
            "train_acc: 0.3769230769230769, val_acc: 0.45098039215686275, train_loss: 1.4704470126183478, val_loss: 1.4125618794385124 (12 / 100)\n",
            "train_acc: 0.4054945054945055, val_acc: 0.4215686274509804, train_loss: 1.4077610486156338, val_loss: 1.3172649881419014 (13 / 100)\n",
            "train_acc: 0.367032967032967, val_acc: 0.4117647058823529, train_loss: 1.4022977815224573, val_loss: 1.4444249833331388 (14 / 100)\n",
            "train_acc: 0.4054945054945055, val_acc: 0.49019607843137253, train_loss: 1.3925298389497693, val_loss: 1.290573677595924 (15 / 100)\n",
            "train_acc: 0.4054945054945055, val_acc: 0.4803921568627451, train_loss: 1.3790224665468866, val_loss: 1.2916592569912182 (16 / 100)\n",
            "train_acc: 0.4307692307692308, val_acc: 0.47058823529411764, train_loss: 1.3178946700069931, val_loss: 1.1901190473752863 (17 / 100)\n",
            "train_acc: 0.4318681318681319, val_acc: 0.5, train_loss: 1.308016540519484, val_loss: 1.2063576999832601 (18 / 100)\n",
            "train_acc: 0.42857142857142855, val_acc: 0.4411764705882353, train_loss: 1.314052556176762, val_loss: 1.288542530115913 (19 / 100)\n",
            "train_acc: 0.45494505494505494, val_acc: 0.5392156862745098, train_loss: 1.2659539967447846, val_loss: 1.1607225397053886 (20 / 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-75811a0371d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mcurrent_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-9628b9dce2c0>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset, verbosity, plot)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mtrain_running_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0msum_train_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "4ee4e2f6-7038-49db-9ba6-667755ca46e8",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg19()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg19()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 24392 (delta 10), reused 13 (delta 5), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24392/24392), 2.15 GiB | 47.69 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (24636/24636), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.4876847290640394, val loss 1.3147739389259827\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6059113300492611, val loss 1.5047687838230226\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.3448275862068966, val loss 1.6433078479297056\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5812807881773399, val loss 2.414570222347241\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.2955665024630542, val loss 1.7655747535780733\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.4876847290640394, val loss 1.3504160378366856\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.18226600985221675, val loss 1.7624990276515191\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.270935960591133, val loss 1.7162450311219164\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6108374384236454, val loss 2.431815377597151\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6551724137931034, val loss 1.9367152525873608\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.528708166676789\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6600985221674877, val loss 1.645547920847174\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7536945812807881, val loss 1.4387520968620413\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6995073891625616, val loss 2.476622701278461\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6650246305418719, val loss 3.20528265466831\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6305418719211823, val loss 1.9122127376753708\n",
            "({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6502463054187192, val loss 1.084208725121221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}