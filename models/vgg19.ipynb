{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg19()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "428f80ba-3e28-4860-f031-48e3d0a775e2",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "# ({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7881773399014779, val loss 1.4585814757887365\n",
        "# lr 0.0017290126152359597, batch 11, decay 1.0506062245241487e-06, gamma 0.10515207194838522, val accuracy 0.6108374384236454, val loss 1.1022712842290625 [3 / 50]\n",
        "BATCH_SIZE = 11\n",
        "LR = 0.0017290126152359597\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1.0506062245241487e-06\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.10515207194838522\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg19()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/72)\u001b[K\rremote: Counting objects:   2% (2/72)\u001b[K\rremote: Counting objects:   4% (3/72)\u001b[K\rremote: Counting objects:   5% (4/72)\u001b[K\rremote: Counting objects:   6% (5/72)\u001b[K\rremote: Counting objects:   8% (6/72)\u001b[K\rremote: Counting objects:   9% (7/72)\u001b[K\rremote: Counting objects:  11% (8/72)\u001b[K\rremote: Counting objects:  12% (9/72)\u001b[K\rremote: Counting objects:  13% (10/72)\u001b[K\rremote: Counting objects:  15% (11/72)\u001b[K\rremote: Counting objects:  16% (12/72)\u001b[K\rremote: Counting objects:  18% (13/72)\u001b[K\rremote: Counting objects:  19% (14/72)\u001b[K\rremote: Counting objects:  20% (15/72)\u001b[K\rremote: Counting objects:  22% (16/72)\u001b[K\rremote: Counting objects:  23% (17/72)\u001b[K\rremote: Counting objects:  25% (18/72)\u001b[K\rremote: Counting objects:  26% (19/72)\u001b[K\rremote: Counting objects:  27% (20/72)\u001b[K\rremote: Counting objects:  29% (21/72)\u001b[K\rremote: Counting objects:  30% (22/72)\u001b[K\rremote: Counting objects:  31% (23/72)\u001b[K\rremote: Counting objects:  33% (24/72)\u001b[K\rremote: Counting objects:  34% (25/72)\u001b[K\rremote: Counting objects:  36% (26/72)\u001b[K\rremote: Counting objects:  37% (27/72)\u001b[K\rremote: Counting objects:  38% (28/72)\u001b[K\rremote: Counting objects:  40% (29/72)\u001b[K\rremote: Counting objects:  41% (30/72)\u001b[K\rremote: Counting objects:  43% (31/72)\u001b[K\rremote: Counting objects:  44% (32/72)\u001b[K\rremote: Counting objects:  45% (33/72)\u001b[K\rremote: Counting objects:  47% (34/72)\u001b[K\rremote: Counting objects:  48% (35/72)\u001b[K\rremote: Counting objects:  50% (36/72)\u001b[K\rremote: Counting objects:  51% (37/72)\u001b[K\rremote: Counting objects:  52% (38/72)\u001b[K\rremote: Counting objects:  54% (39/72)\u001b[K\rremote: Counting objects:  55% (40/72)\u001b[K\rremote: Counting objects:  56% (41/72)\u001b[K\rremote: Counting objects:  58% (42/72)\u001b[K\rremote: Counting objects:  59% (43/72)\u001b[K\rremote: Counting objects:  61% (44/72)\u001b[K\rremote: Counting objects:  62% (45/72)\u001b[K\rremote: Counting objects:  63% (46/72)\u001b[K\rremote: Counting objects:  65% (47/72)\u001b[K\rremote: Counting objects:  66% (48/72)\u001b[K\rremote: Counting objects:  68% (49/72)\u001b[K\rremote: Counting objects:  69% (50/72)\u001b[K\rremote: Counting objects:  70% (51/72)\u001b[K\rremote: Counting objects:  72% (52/72)\u001b[K\rremote: Counting objects:  73% (53/72)\u001b[K\rremote: Counting objects:  75% (54/72)\u001b[K\rremote: Counting objects:  76% (55/72)\u001b[K\rremote: Counting objects:  77% (56/72)\u001b[K\rremote: Counting objects:  79% (57/72)\u001b[K\rremote: Counting objects:  80% (58/72)\u001b[K\rremote: Counting objects:  81% (59/72)\u001b[K\rremote: Counting objects:  83% (60/72)\u001b[K\rremote: Counting objects:  84% (61/72)\u001b[K\rremote: Counting objects:  86% (62/72)\u001b[K\rremote: Counting objects:  87% (63/72)\u001b[K\rremote: Counting objects:  88% (64/72)\u001b[K\rremote: Counting objects:  90% (65/72)\u001b[K\rremote: Counting objects:  91% (66/72)\u001b[K\rremote: Counting objects:  93% (67/72)\u001b[K\rremote: Counting objects:  94% (68/72)\u001b[K\rremote: Counting objects:  95% (69/72)\u001b[K\rremote: Counting objects:  97% (70/72)\u001b[K\rremote: Counting objects:  98% (71/72)\u001b[K\rremote: Counting objects: 100% (72/72)\u001b[K\rremote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 24445 (delta 32), reused 52 (delta 15), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24445/24445), 2.15 GiB | 47.11 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Checking out files: 100% (24651/24651), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7775743001765756, val_loss: 1.760344133001243 (1 / 100)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.18226600985221675, train_loss: 1.7594681262085847, val_loss: 1.7497443935554016 (2 / 100)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.2857142857142857, train_loss: 1.7275618546088636, val_loss: 1.6521202813228364 (3 / 100)\n",
            "train_acc: 0.2546353522867738, val_acc: 0.270935960591133, train_loss: 1.7061701532642095, val_loss: 1.7345602248102574 (4 / 100)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.270935960591133, train_loss: 1.6600631518181235, val_loss: 1.6801588602841193 (5 / 100)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.33004926108374383, train_loss: 1.6044214196199245, val_loss: 1.6161292362682924 (6 / 100)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3251231527093596, train_loss: 1.6070170896162357, val_loss: 1.5891932613156698 (7 / 100)\n",
            "train_acc: 0.27564894932014833, val_acc: 0.3399014778325123, train_loss: 1.655619474807098, val_loss: 1.5853831779780647 (8 / 100)\n",
            "train_acc: 0.30284301606922126, val_acc: 0.31527093596059114, train_loss: 1.6047751689870808, val_loss: 1.6007195840328199 (9 / 100)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.2561576354679803, train_loss: 1.5697471052224026, val_loss: 1.6992436371413357 (10 / 100)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.3103448275862069, train_loss: 1.6289871564164886, val_loss: 1.61227196132021 (11 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.32019704433497537, train_loss: 1.5268859552364562, val_loss: 1.5947031505002176 (12 / 100)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.35467980295566504, train_loss: 1.5974188387320274, val_loss: 1.5683458779245762 (13 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3497536945812808, train_loss: 1.4891156376660681, val_loss: 1.7072339502755056 (14 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3694581280788177, train_loss: 1.517412869538306, val_loss: 1.5179547047967394 (15 / 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUIpGmogDgOC",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eOsPQVDgG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b8a63b0-821c-465e-ad89-b7f13b0dfd67"
      },
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = vgg19()\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = random.uniform(0.0008, 0.003)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-6, -3)\n",
        "  NUM_EPOCHS = 35\n",
        "  STEP_SIZE = 21\n",
        "  GAMMA = 10**random.uniform(-2, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"-------------------------------------\")\n",
        "  \n",
        "  net = vgg19()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "\n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "-------------------------------------\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7833453471345277, val_loss: 1.7584026781796234 (1 / 35)\n",
            "train_acc: 0.21755253399258342, val_acc: 0.21674876847290642, train_loss: 1.7654487995341033, val_loss: 1.7678945757485376 (2 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.26108374384236455, train_loss: 1.756191347968593, val_loss: 1.7623431295009668 (3 / 35)\n",
            "train_acc: 0.26081582200247216, val_acc: 0.2857142857142857, train_loss: 1.734042658646705, val_loss: 1.6665216772427112 (4 / 35)\n",
            "train_acc: 0.2546353522867738, val_acc: 0.31527093596059114, train_loss: 1.7096135972898883, val_loss: 1.6315629041840878 (5 / 35)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.19704433497536947, train_loss: 1.6419084664475638, val_loss: 2.0252758170583567 (6 / 35)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.28078817733990147, train_loss: 1.6528172840736115, val_loss: 1.6320640882247774 (7 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.35467980295566504, train_loss: 1.5736660683258208, val_loss: 1.4867718084692367 (8 / 35)\n",
            "train_acc: 0.315203955500618, val_acc: 0.32019704433497537, train_loss: 1.5578700756407786, val_loss: 1.5206400966409392 (9 / 35)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.37438423645320196, train_loss: 1.5289614577817976, val_loss: 1.4380428409341521 (10 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.3399014778325123, train_loss: 1.4701307338601433, val_loss: 1.4110833441682638 (11 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.42857142857142855, train_loss: 1.4436556367555862, val_loss: 1.4074968733811026 (12 / 35)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.42857142857142855, train_loss: 1.4087786228017254, val_loss: 1.3968137549649318 (13 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.4088669950738916, train_loss: 1.3729997429771092, val_loss: 1.3847408230081568 (14 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4630541871921182, train_loss: 1.3805803094423008, val_loss: 1.2913315795325293 (15 / 35)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.4088669950738916, train_loss: 1.3435060914573622, val_loss: 1.3236249732266505 (16 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.45320197044334976, train_loss: 1.3299902186847588, val_loss: 1.2210407116142987 (17 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4236453201970443, train_loss: 1.2850062036691108, val_loss: 1.300212679238155 (18 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.3793103448275862, train_loss: 1.325293100955902, val_loss: 1.3034379188650347 (19 / 35)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.4729064039408867, train_loss: 1.3520233100660062, val_loss: 1.2507865050156128 (20 / 35)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.45320197044334976, train_loss: 1.2327423823631296, val_loss: 1.329760540001498 (21 / 35)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.47783251231527096, train_loss: 1.1769844521992876, val_loss: 1.1690049884941778 (22 / 35)\n",
            "train_acc: 0.546353522867738, val_acc: 0.45320197044334976, train_loss: 1.1011883410888785, val_loss: 1.1708995097963681 (23 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.4630541871921182, train_loss: 1.07822609330874, val_loss: 1.1717132852582508 (24 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.46798029556650245, train_loss: 1.0900478505970375, val_loss: 1.1642372652227655 (25 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.46798029556650245, train_loss: 1.059271166881613, val_loss: 1.1688326849726034 (26 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.4729064039408867, train_loss: 1.0506461774757678, val_loss: 1.1674233407809818 (27 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.4876847290640394, train_loss: 1.0621751566015745, val_loss: 1.1620443448644553 (28 / 35)\n",
            "train_acc: 0.5859085290482077, val_acc: 0.4876847290640394, train_loss: 1.0399279105206503, val_loss: 1.1573336379868644 (29 / 35)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.4975369458128079, train_loss: 1.0457180159348345, val_loss: 1.1558651598216279 (30 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5024630541871922, train_loss: 1.050006878980158, val_loss: 1.1587991737967054 (31 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5024630541871922, train_loss: 1.0396714101468383, val_loss: 1.156752995963167 (32 / 35)\n",
            "train_acc: 0.580964153275649, val_acc: 0.5024630541871922, train_loss: 1.031938014278011, val_loss: 1.1539305254743604 (33 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5073891625615764, train_loss: 1.002797673747625, val_loss: 1.1506031137969106 (34 / 35)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.5024630541871922, train_loss: 0.9879823880378337, val_loss: 1.1559447722481977 (35 / 35)\n",
            "lr 0.0008592737619240511, batch 8, decay 1.2402220590044963e-06, gamma 0.031296463279691086, val accuracy 0.5073891625615764, val loss 1.1506031137969106 [1 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.784998740489757, val_loss: 1.7652970270570276 (1 / 35)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7628419216542663, val_loss: 1.74656337646428 (2 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.26108374384236455, train_loss: 1.7509447401032607, val_loss: 1.7229377571585143 (3 / 35)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.2955665024630542, train_loss: 1.721430346019778, val_loss: 1.7090269327163696 (4 / 35)\n",
            "train_acc: 0.2954264524103832, val_acc: 0.3497536945812808, train_loss: 1.6601095697641077, val_loss: 1.5440228155681066 (5 / 35)\n",
            "train_acc: 0.276885043263288, val_acc: 0.3251231527093596, train_loss: 1.6492937246270762, val_loss: 1.5314596292420561 (6 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.35467980295566504, train_loss: 1.5792157865130563, val_loss: 1.4600059525132767 (7 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.4187192118226601, train_loss: 1.5046078917122594, val_loss: 1.4283625900451773 (8 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3251231527093596, train_loss: 1.5196018217520602, val_loss: 1.4535698033318731 (9 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3694581280788177, train_loss: 1.4554073733216606, val_loss: 1.3678340277648324 (10 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.4187192118226601, train_loss: 1.4248324564861867, val_loss: 1.3950573893016196 (11 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.41379310344827586, train_loss: 1.400403109852257, val_loss: 1.3768539481562347 (12 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.43349753694581283, train_loss: 1.3941594175119483, val_loss: 1.2994043812375937 (13 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.4236453201970443, train_loss: 1.3832200043575726, val_loss: 1.2761586292330267 (14 / 35)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.45320197044334976, train_loss: 1.3995049169243339, val_loss: 1.3148615884369816 (15 / 35)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4729064039408867, train_loss: 1.3445379539532185, val_loss: 1.2796962648776953 (16 / 35)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.3842364532019704, train_loss: 1.3312793352695271, val_loss: 1.3437799354785769 (17 / 35)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.49261083743842365, train_loss: 1.3232785756567353, val_loss: 1.289827497428274 (18 / 35)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.4482758620689655, train_loss: 1.2993341113345143, val_loss: 1.3058600447741635 (19 / 35)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.47783251231527096, train_loss: 1.3066119379991359, val_loss: 1.2273511898341438 (20 / 35)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.46798029556650245, train_loss: 1.2951049526188665, val_loss: 1.2374564051040875 (21 / 35)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.47783251231527096, train_loss: 1.1681337196688422, val_loss: 1.120322334502131 (22 / 35)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.5073891625615764, train_loss: 1.1132453996849296, val_loss: 1.1150029398537622 (23 / 35)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.49261083743842365, train_loss: 1.1089116594994761, val_loss: 1.1094409661927247 (24 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.4876847290640394, train_loss: 1.0979990830969604, val_loss: 1.1066149800575424 (25 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.46798029556650245, train_loss: 1.09121658385021, val_loss: 1.1279466068509765 (26 / 35)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.4827586206896552, train_loss: 1.0626310603727664, val_loss: 1.0984390275231724 (27 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.49261083743842365, train_loss: 1.0602248493024828, val_loss: 1.0982913813861133 (28 / 35)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.49261083743842365, train_loss: 1.0799883938542991, val_loss: 1.0933186711348923 (29 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5073891625615764, train_loss: 1.0551336568277168, val_loss: 1.0931581624329383 (30 / 35)\n",
            "train_acc: 0.588380716934487, val_acc: 0.5123152709359606, train_loss: 1.0364468624476892, val_loss: 1.0883142357976565 (31 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.5221674876847291, train_loss: 1.067088345441005, val_loss: 1.1084869468740641 (32 / 35)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5073891625615764, train_loss: 1.0043716287730797, val_loss: 1.081624325566691 (33 / 35)\n",
            "train_acc: 0.588380716934487, val_acc: 0.5320197044334976, train_loss: 1.0047161489982983, val_loss: 1.091591693938072 (34 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5320197044334976, train_loss: 0.9913622929964431, val_loss: 1.0806318285136387 (35 / 35)\n",
            "lr 0.001417452569253381, batch 15, decay 0.00033775431376678616, gamma 0.07881282747568351, val accuracy 0.5320197044334976, val loss 1.091591693938072 [2 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.782908953164505, val_loss: 1.7641630313666583 (1 / 35)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7653637835652336, val_loss: 1.7565951505905302 (2 / 35)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.18226600985221675, train_loss: 1.75919376418676, val_loss: 1.758113853156273 (3 / 35)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.2512315270935961, train_loss: 1.7386182204754597, val_loss: 1.7382530596455916 (4 / 35)\n",
            "train_acc: 0.2694684796044499, val_acc: 0.3497536945812808, train_loss: 1.7098816095382823, val_loss: 1.5720954581434503 (5 / 35)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3645320197044335, train_loss: 1.6159348761932222, val_loss: 1.672365885062758 (6 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.4187192118226601, train_loss: 1.5878409525962047, val_loss: 1.499142132956406 (7 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.42857142857142855, train_loss: 1.5184324693915576, val_loss: 1.5831796553334578 (8 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.458128078817734, train_loss: 1.4839686634219327, val_loss: 1.3523263179609928 (9 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3251231527093596, train_loss: 1.4123893162818126, val_loss: 1.505330020277371 (10 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3793103448275862, train_loss: 1.4539891939670104, val_loss: 1.415662311568049 (11 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.4088669950738916, train_loss: 1.4119332370121487, val_loss: 1.3074527981833284 (12 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.458128078817734, train_loss: 1.391279340011375, val_loss: 1.317761846363838 (13 / 35)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.46798029556650245, train_loss: 1.3551130566667715, val_loss: 1.2474958181674844 (14 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.41379310344827586, train_loss: 1.3044423589158265, val_loss: 1.2946179606057153 (15 / 35)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.42857142857142855, train_loss: 1.3084047657744993, val_loss: 1.3392309754940088 (16 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.3448275862068966, train_loss: 1.244842497173729, val_loss: 1.3758618047671953 (17 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4876847290640394, train_loss: 1.2423220888351185, val_loss: 1.1687002337624874 (18 / 35)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4827586206896552, train_loss: 1.247321095322207, val_loss: 1.1838248856549192 (19 / 35)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5221674876847291, train_loss: 1.1677877094748583, val_loss: 1.2224410361257092 (20 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.458128078817734, train_loss: 1.2041830088211078, val_loss: 1.2592143130126259 (21 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5517241379310345, train_loss: 1.0442402958133166, val_loss: 1.0885106131361035 (22 / 35)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5812807881773399, train_loss: 0.94695918547503, val_loss: 1.072718378505096 (23 / 35)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.5714285714285714, train_loss: 0.9143353661589039, val_loss: 1.0891051699815713 (24 / 35)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.5517241379310345, train_loss: 0.8408954338399677, val_loss: 1.1074048506802525 (25 / 35)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.5615763546798029, train_loss: 0.8817447350626381, val_loss: 1.0718833317457162 (26 / 35)\n",
            "train_acc: 0.6736711990111248, val_acc: 0.5566502463054187, train_loss: 0.8316547481621741, val_loss: 1.096935268840179 (27 / 35)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.5665024630541872, train_loss: 0.8139518723352288, val_loss: 1.0634183242843656 (28 / 35)\n",
            "train_acc: 0.6835599505562423, val_acc: 0.5911330049261084, train_loss: 0.7801462574338147, val_loss: 1.0839345436818495 (29 / 35)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.5763546798029556, train_loss: 0.7636081315530983, val_loss: 1.056638160509429 (30 / 35)\n",
            "train_acc: 0.7404202719406675, val_acc: 0.5960591133004927, train_loss: 0.6871177986430002, val_loss: 1.0919225392817276 (31 / 35)\n",
            "train_acc: 0.7033374536464772, val_acc: 0.6009852216748769, train_loss: 0.7186874224538414, val_loss: 1.0876557567143088 (32 / 35)\n",
            "train_acc: 0.7589616810877626, val_acc: 0.6108374384236454, train_loss: 0.6307297549745798, val_loss: 1.1022712842290625 (33 / 35)\n",
            "train_acc: 0.7441285537700866, val_acc: 0.5911330049261084, train_loss: 0.6605644385768987, val_loss: 1.1219058488977367 (34 / 35)\n",
            "train_acc: 0.757725587144623, val_acc: 0.6059113300492611, train_loss: 0.6382181133950596, val_loss: 1.0874798685459082 (35 / 35)\n",
            "lr 0.0017290126152359597, batch 11, decay 1.0506062245241487e-06, gamma 0.10515207194838522, val accuracy 0.6108374384236454, val loss 1.1022712842290625 [3 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.7853594452547938, val_loss: 1.779347866626796 (1 / 35)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.77100047133909, val_loss: 1.8324217214960183 (2 / 35)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18719211822660098, train_loss: 1.7613666271249797, val_loss: 1.8068276109366581 (3 / 35)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.2955665024630542, train_loss: 1.723949943838367, val_loss: 1.684229075615042 (4 / 35)\n",
            "train_acc: 0.26328800988875156, val_acc: 0.2660098522167488, train_loss: 1.6950470085344445, val_loss: 1.6520581961852576 (5 / 35)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.3448275862068966, train_loss: 1.6553002473597769, val_loss: 1.6378230279302362 (6 / 35)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.3251231527093596, train_loss: 1.6102682565729167, val_loss: 1.5955992420318679 (7 / 35)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.33497536945812806, train_loss: 1.6145606565534405, val_loss: 1.5675799529540715 (8 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.31527093596059114, train_loss: 1.5820340108223103, val_loss: 1.5953746752198694 (9 / 35)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.789014906022693, val_loss: 1.7378116734509397 (10 / 35)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.21182266009852216, train_loss: 1.7665607130571703, val_loss: 1.7557692768538526 (11 / 35)\n",
            "train_acc: 0.2546353522867738, val_acc: 0.2955665024630542, train_loss: 1.7087351789580583, val_loss: 1.6676158805198857 (12 / 35)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7831285606945402, val_loss: 1.7719811071903246 (13 / 35)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.773501841335273, val_loss: 1.7699649134292978 (14 / 35)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.21182266009852216, train_loss: 1.7657694227173832, val_loss: 1.7504330368464804 (15 / 35)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7702290588904666, val_loss: 1.756778768717949 (16 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18226600985221675, train_loss: 1.7563316080861981, val_loss: 1.7635201756002867 (17 / 35)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.270935960591133, train_loss: 1.7148581060991888, val_loss: 1.6978456545345888 (18 / 35)\n",
            "train_acc: 0.24351050679851668, val_acc: 0.3497536945812808, train_loss: 1.704714948373613, val_loss: 1.5366941050355658 (19 / 35)\n",
            "train_acc: 0.2694684796044499, val_acc: 0.23645320197044334, train_loss: 1.673700040291502, val_loss: 1.7156022211600994 (20 / 35)\n",
            "train_acc: 0.315203955500618, val_acc: 0.3399014778325123, train_loss: 1.6120956555579884, val_loss: 1.470374871944559 (21 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3793103448275862, train_loss: 1.5051753547489275, val_loss: 1.4184628349219637 (22 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3793103448275862, train_loss: 1.439550523852241, val_loss: 1.411239880059153 (23 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.3793103448275862, train_loss: 1.4457183069882198, val_loss: 1.396751143662213 (24 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3891625615763547, train_loss: 1.443189540074399, val_loss: 1.3902705866715004 (25 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3842364532019704, train_loss: 1.4279351585138271, val_loss: 1.3842740587413018 (26 / 35)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.4236453201970443, train_loss: 1.4508815115255538, val_loss: 1.382980490552968 (27 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.41379310344827586, train_loss: 1.4320264278147807, val_loss: 1.3776474639112726 (28 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.4433497536945813, train_loss: 1.4407634061700187, val_loss: 1.3782594591525976 (29 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.45320197044334976, train_loss: 1.421421835537452, val_loss: 1.3768559641438751 (30 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.4630541871921182, train_loss: 1.4349399600247075, val_loss: 1.3698895089144778 (31 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.458128078817734, train_loss: 1.403156551354011, val_loss: 1.3663259004724437 (32 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.43349753694581283, train_loss: 1.4184943324113806, val_loss: 1.363735196625658 (33 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.43349753694581283, train_loss: 1.418048720424638, val_loss: 1.3671435904620317 (34 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.43842364532019706, train_loss: 1.4208669190943168, val_loss: 1.365477886693231 (35 / 35)\n",
            "lr 0.002360069796703086, batch 8, decay 9.276125589091475e-06, gamma 0.011109406101242607, val accuracy 0.4630541871921182, val loss 1.3698895089144778 [4 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7696616935494214, val_loss: 1.7563290249537953 (1 / 35)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.22167487684729065, train_loss: 1.7469613510834419, val_loss: 1.6886115361904275 (2 / 35)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7523633200394355, val_loss: 1.743223210860943 (3 / 35)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.26108374384236455, train_loss: 1.7443693815851389, val_loss: 1.7448893121897882 (4 / 35)\n",
            "train_acc: 0.24351050679851668, val_acc: 0.18226600985221675, train_loss: 1.7443987387514528, val_loss: 1.7883415251529862 (5 / 35)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7828476381832354, val_loss: 1.7711140117034536 (6 / 35)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.32019704433497537, train_loss: 1.7616308659351947, val_loss: 1.708327390877484 (7 / 35)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.18226600985221675, train_loss: 1.7316633866655518, val_loss: 1.7715101077638824 (8 / 35)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.3103448275862069, train_loss: 1.746739610016567, val_loss: 1.650739458981406 (9 / 35)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.3448275862068966, train_loss: 1.6838744024116412, val_loss: 1.56517542465567 (10 / 35)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.32019704433497537, train_loss: 1.621758993682814, val_loss: 1.5686986135144538 (11 / 35)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3251231527093596, train_loss: 1.538932115392131, val_loss: 1.4805493733565795 (12 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3645320197044335, train_loss: 1.496902430602735, val_loss: 1.3984453657577778 (13 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.43842364532019706, train_loss: 1.4968570192311101, val_loss: 1.448506118922398 (14 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3645320197044335, train_loss: 1.4924653658760787, val_loss: 1.413311183746225 (15 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.41379310344827586, train_loss: 1.4484427555824535, val_loss: 1.3160738492834156 (16 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.43349753694581283, train_loss: 1.3587996181657789, val_loss: 1.3647678998009911 (17 / 35)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4236453201970443, train_loss: 1.4039877059285808, val_loss: 1.2552445423720506 (18 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3251231527093596, train_loss: 1.4302982488285625, val_loss: 1.5798759087553165 (19 / 35)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.4482758620689655, train_loss: 1.3820366402639004, val_loss: 1.432939387747807 (20 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.39408866995073893, train_loss: 1.2897850274302904, val_loss: 1.3235368847553366 (21 / 35)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.4827586206896552, train_loss: 1.2532829162658956, val_loss: 1.2281002924947315 (22 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.4630541871921182, train_loss: 1.203493421982481, val_loss: 1.2668668544791601 (23 / 35)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.49261083743842365, train_loss: 1.1952503417124707, val_loss: 1.1867519731592076 (24 / 35)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.4827586206896552, train_loss: 1.1678469922250811, val_loss: 1.145351533525683 (25 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.5024630541871922, train_loss: 1.123994039811369, val_loss: 1.1427430366647655 (26 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4236453201970443, train_loss: 1.0827330513701894, val_loss: 1.406034889479576 (27 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.49261083743842365, train_loss: 1.1058174131532534, val_loss: 1.2137846741183052 (28 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.4975369458128079, train_loss: 1.023620363071616, val_loss: 1.212173136877896 (29 / 35)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5369458128078818, train_loss: 0.9678724574659604, val_loss: 1.223845001511973 (30 / 35)\n",
            "train_acc: 0.6365883807169345, val_acc: 0.5221674876847291, train_loss: 0.8945631079090246, val_loss: 1.2104561273834389 (31 / 35)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.5566502463054187, train_loss: 0.9159830454621828, val_loss: 1.0548159365583523 (32 / 35)\n",
            "train_acc: 0.6687268232385661, val_acc: 0.5221674876847291, train_loss: 0.8670678933338712, val_loss: 1.1730266512908372 (33 / 35)\n",
            "train_acc: 0.7045735475896168, val_acc: 0.5566502463054187, train_loss: 0.8155627603031355, val_loss: 1.0807410855892257 (34 / 35)\n",
            "train_acc: 0.7021013597033374, val_acc: 0.5763546798029556, train_loss: 0.788096663867882, val_loss: 1.029365658393047 (35 / 35)\n",
            "lr 0.0026840711798288416, batch 11, decay 5.520398454190368e-06, gamma 0.760533597169735, val accuracy 0.5763546798029556, val loss 1.029365658393047 [5 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7857435890122308, val_loss: 1.7698631997178929 (1 / 35)\n",
            "train_acc: 0.16563658838071693, val_acc: 0.18226600985221675, train_loss: 1.7738349508443485, val_loss: 1.7615640081208328 (2 / 35)\n",
            "train_acc: 0.207663782447466, val_acc: 0.1921182266009852, train_loss: 1.74808456723858, val_loss: 1.725644729994788 (3 / 35)\n",
            "train_acc: 0.2373300370828183, val_acc: 0.3251231527093596, train_loss: 1.7313687379928986, val_loss: 1.7034518272418695 (4 / 35)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.2857142857142857, train_loss: 1.7032493016923167, val_loss: 1.6657423391717996 (5 / 35)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.22167487684729065, train_loss: 1.6778904999731792, val_loss: 1.798351798738752 (6 / 35)\n",
            "train_acc: 0.2694684796044499, val_acc: 0.29064039408866993, train_loss: 1.7072688342614286, val_loss: 1.6133626394083935 (7 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.2315270935960591, train_loss: 1.6196199771942403, val_loss: 1.7055222318677479 (8 / 35)\n",
            "train_acc: 0.30284301606922126, val_acc: 0.33497536945812806, train_loss: 1.6265027396316434, val_loss: 1.5609313760484969 (9 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3497536945812808, train_loss: 1.526211079472517, val_loss: 1.5073757576824995 (10 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.3694581280788177, train_loss: 1.4929976918641363, val_loss: 1.513549790593791 (11 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3793103448275862, train_loss: 1.4884489780598136, val_loss: 1.3799070974288903 (12 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.2660098522167488, train_loss: 1.4501033907915075, val_loss: 1.498666577444875 (13 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.42857142857142855, train_loss: 1.42645573925471, val_loss: 1.3378850929255557 (14 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.3645320197044335, train_loss: 1.404501652098704, val_loss: 1.3872118524729913 (15 / 35)\n",
            "train_acc: 0.41409147095179233, val_acc: 0.4482758620689655, train_loss: 1.3889161159729928, val_loss: 1.2767769626795953 (16 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.4236453201970443, train_loss: 1.3767522045207408, val_loss: 1.2824261405785096 (17 / 35)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4827586206896552, train_loss: 1.3196484111295494, val_loss: 1.3190704243523734 (18 / 35)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.458128078817734, train_loss: 1.2957620625884925, val_loss: 1.2751878969775046 (19 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.4630541871921182, train_loss: 1.327668133639582, val_loss: 1.3152365702126414 (20 / 35)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.4433497536945813, train_loss: 1.2628140176182476, val_loss: 1.2950667923894421 (21 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4827586206896552, train_loss: 1.1877720482711887, val_loss: 1.1812139541057531 (22 / 35)\n",
            "train_acc: 0.515451174289246, val_acc: 0.47783251231527096, train_loss: 1.161631149473532, val_loss: 1.1744200816295418 (23 / 35)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.47783251231527096, train_loss: 1.1442761331317746, val_loss: 1.1704068222069388 (24 / 35)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.4729064039408867, train_loss: 1.1432436230892893, val_loss: 1.1699638886404742 (25 / 35)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.4827586206896552, train_loss: 1.1636338267102377, val_loss: 1.165452754262633 (26 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.46798029556650245, train_loss: 1.1395923311100313, val_loss: 1.169870659635572 (27 / 35)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.46798029556650245, train_loss: 1.1283361054174095, val_loss: 1.1675470747383945 (28 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.46798029556650245, train_loss: 1.116696364800037, val_loss: 1.1637477287517979 (29 / 35)\n",
            "train_acc: 0.522867737948084, val_acc: 0.46798029556650245, train_loss: 1.1265409446617287, val_loss: 1.1614325657266702 (30 / 35)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.4729064039408867, train_loss: 1.1254560973941912, val_loss: 1.1606190683219233 (31 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4729064039408867, train_loss: 1.127844471719268, val_loss: 1.1584237896162888 (32 / 35)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.4729064039408867, train_loss: 1.111310649345478, val_loss: 1.1603085222502647 (33 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.4729064039408867, train_loss: 1.1165313885002701, val_loss: 1.159788293204284 (34 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4729064039408867, train_loss: 1.1258596341748468, val_loss: 1.1545166012101573 (35 / 35)\n",
            "lr 0.0014043505609652512, batch 15, decay 1.428049274093578e-06, gamma 0.015364319269522017, val accuracy 0.4827586206896552, val loss 1.3190704243523734 [6 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.16563658838071693, val_acc: 0.18719211822660098, train_loss: 1.7857277565745104, val_loss: 1.7659570859570808 (1 / 35)\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.7761318950334792, val_loss: 1.7621916168428995 (2 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.3497536945812808, train_loss: 1.7449826566486335, val_loss: 1.6621820938411018 (3 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.1724137931034483, train_loss: 1.7314377402787744, val_loss: 1.768336066471532 (4 / 35)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7696248110204162, val_loss: 1.7715088927687095 (5 / 35)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2660098522167488, train_loss: 1.769158305284856, val_loss: 1.7554847788928178 (6 / 35)\n",
            "train_acc: 0.2311495673671199, val_acc: 0.18226600985221675, train_loss: 1.7579873617558899, val_loss: 1.7699250840201166 (7 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18226600985221675, train_loss: 1.7635622611004578, val_loss: 1.7672146570506355 (8 / 35)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.3645320197044335, train_loss: 1.7315095838421797, val_loss: 1.6190784200658939 (9 / 35)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.31527093596059114, train_loss: 1.6878270036063177, val_loss: 1.5722677713544497 (10 / 35)\n",
            "train_acc: 0.23980222496909764, val_acc: 0.21674876847290642, train_loss: 1.7526369824250343, val_loss: 1.6272847805117152 (11 / 35)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.27586206896551724, train_loss: 1.6137993763050131, val_loss: 1.6213019064494543 (12 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.39408866995073893, train_loss: 1.5242025610543004, val_loss: 1.4075595046499092 (13 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3793103448275862, train_loss: 1.529117067016394, val_loss: 1.4736563213940324 (14 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3497536945812808, train_loss: 1.491452192051891, val_loss: 1.4119044125373728 (15 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.39901477832512317, train_loss: 1.468690577779329, val_loss: 1.3203401914958297 (16 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3891625615763547, train_loss: 1.45933792440794, val_loss: 1.3619939464653654 (17 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3793103448275862, train_loss: 1.4181876586305786, val_loss: 1.4121054763277177 (18 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4187192118226601, train_loss: 1.3808860678607955, val_loss: 1.5159180035144824 (19 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.41379310344827586, train_loss: 1.398242296777638, val_loss: 1.317127140284759 (20 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.42857142857142855, train_loss: 1.3892632899679271, val_loss: 1.2714648663704031 (21 / 35)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.47783251231527096, train_loss: 1.244158545589565, val_loss: 1.1838939600977405 (22 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.5221674876847291, train_loss: 1.240406791565592, val_loss: 1.1711795429878047 (23 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.46798029556650245, train_loss: 1.1968711775224494, val_loss: 1.2152431871503444 (24 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.5123152709359606, train_loss: 1.1469192151233498, val_loss: 1.1966156149145417 (25 / 35)\n",
            "train_acc: 0.515451174289246, val_acc: 0.4827586206896552, train_loss: 1.1292737440950937, val_loss: 1.171780337253815 (26 / 35)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.4975369458128079, train_loss: 1.1175697670584115, val_loss: 1.3530508362013718 (27 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.5467980295566502, train_loss: 1.130793226516733, val_loss: 1.1397834857696383 (28 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.5123152709359606, train_loss: 1.066390846214719, val_loss: 1.1414657931022456 (29 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.5369458128078818, train_loss: 1.0530330997757034, val_loss: 1.152784775924213 (30 / 35)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.5467980295566502, train_loss: 0.9778007146601918, val_loss: 1.1577722086695028 (31 / 35)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.49261083743842365, train_loss: 0.9913475165703093, val_loss: 1.2005011935539434 (32 / 35)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.5073891625615764, train_loss: 0.9604336393188929, val_loss: 1.167829044346739 (33 / 35)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5665024630541872, train_loss: 0.9077580717791733, val_loss: 1.184184802283207 (34 / 35)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.4975369458128079, train_loss: 0.9352530864319489, val_loss: 1.1750603150851622 (35 / 35)\n",
            "lr 0.002751138304687399, batch 8, decay 0.0005025503388048997, gamma 0.24778550033858615, val accuracy 0.5665024630541872, val loss 1.184184802283207 [7 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17181705809641531, val_acc: 0.1921182266009852, train_loss: 1.7896585849071167, val_loss: 1.780920702835609 (1 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.1921182266009852, train_loss: 1.7724254340559649, val_loss: 1.753977524823156 (2 / 35)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.2019704433497537, train_loss: 1.7570357897373006, val_loss: 1.7407782324429215 (3 / 35)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.2512315270935961, train_loss: 1.7494910881752137, val_loss: 1.73419163144868 (4 / 35)\n",
            "train_acc: 0.24598269468479605, val_acc: 0.3251231527093596, train_loss: 1.7154799634947617, val_loss: 1.639417372900864 (5 / 35)\n",
            "train_acc: 0.30284301606922126, val_acc: 0.33004926108374383, train_loss: 1.6504886708831314, val_loss: 1.5800525772160496 (6 / 35)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.2561576354679803, train_loss: 1.6176379378263381, val_loss: 1.6831673507032723 (7 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.3694581280788177, train_loss: 1.6306470069661276, val_loss: 1.5062445278825431 (8 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3054187192118227, train_loss: 1.5344608622811486, val_loss: 1.614267629796061 (9 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3399014778325123, train_loss: 1.5618498208938334, val_loss: 1.5534899029238471 (10 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.32019704433497537, train_loss: 1.4697804894523951, val_loss: 1.4956956361902172 (11 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.43842364532019706, train_loss: 1.4953986034994515, val_loss: 1.3822330483074845 (12 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.43349753694581283, train_loss: 1.4262560314242123, val_loss: 1.355299633124779 (13 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3842364532019704, train_loss: 1.4116804297686507, val_loss: 1.4255247938221898 (14 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.37438423645320196, train_loss: 1.3850290266928185, val_loss: 1.4494758145562534 (15 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.43842364532019706, train_loss: 1.3958688244978783, val_loss: 1.2855287255911991 (16 / 35)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.42857142857142855, train_loss: 1.354450464690719, val_loss: 1.3296437756768589 (17 / 35)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4482758620689655, train_loss: 1.3641363749250641, val_loss: 1.307270518664656 (18 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.41379310344827586, train_loss: 1.3506914751491381, val_loss: 1.4687044003914143 (19 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.47783251231527096, train_loss: 1.3815186496718115, val_loss: 1.2600714852069985 (20 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.4630541871921182, train_loss: 1.3031730536919441, val_loss: 1.244438549567913 (21 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4876847290640394, train_loss: 1.2422353297435162, val_loss: 1.201539578108952 (22 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.47783251231527096, train_loss: 1.2148828493207877, val_loss: 1.1993263610478104 (23 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4975369458128079, train_loss: 1.199550478508505, val_loss: 1.1877606120602837 (24 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.5172413793103449, train_loss: 1.178055937490593, val_loss: 1.1789921008307358 (25 / 35)\n",
            "train_acc: 0.5043263288009888, val_acc: 0.5172413793103449, train_loss: 1.1865538257014177, val_loss: 1.1846205694922085 (26 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.5024630541871922, train_loss: 1.162553514332058, val_loss: 1.2042260683816055 (27 / 35)\n",
            "train_acc: 0.484548825710754, val_acc: 0.5123152709359606, train_loss: 1.1943906896341274, val_loss: 1.168786918294841 (28 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4876847290640394, train_loss: 1.1711630918481588, val_loss: 1.1498531555307323 (29 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.5172413793103449, train_loss: 1.1545601521787892, val_loss: 1.151168132650441 (30 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.5123152709359606, train_loss: 1.1720477252719723, val_loss: 1.1630551075113231 (31 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4827586206896552, train_loss: 1.1408155631960102, val_loss: 1.1653933648405403 (32 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5123152709359606, train_loss: 1.1178207514607272, val_loss: 1.1484981282003994 (33 / 35)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5024630541871922, train_loss: 1.122300963613984, val_loss: 1.18690268130138 (34 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.46798029556650245, train_loss: 1.1183215509386382, val_loss: 1.1667122717561393 (35 / 35)\n",
            "lr 0.0008177304807509773, batch 14, decay 0.00015407752677908, gamma 0.1346498507741459, val accuracy 0.5172413793103449, val loss 1.1789921008307358 [8 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18719211822660098, train_loss: 1.7825956640785792, val_loss: 1.7631537315293486 (1 / 35)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7631400212074535, val_loss: 1.750663649272449 (2 / 35)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.22660098522167488, train_loss: 1.7576802991081963, val_loss: 1.7481958507904278 (3 / 35)\n",
            "train_acc: 0.2546353522867738, val_acc: 0.31527093596059114, train_loss: 1.721870509302071, val_loss: 1.6646534691890473 (4 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.2512315270935961, train_loss: 1.6891107380905905, val_loss: 1.6644167882468313 (5 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.28078817733990147, train_loss: 1.5792841756594342, val_loss: 1.5872138327565686 (6 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3793103448275862, train_loss: 1.5888504470676663, val_loss: 1.5619714371676516 (7 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.31527093596059114, train_loss: 1.5147973726352744, val_loss: 1.4865099473539831 (8 / 35)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.37438423645320196, train_loss: 1.4808015144062867, val_loss: 1.4458007648073394 (9 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.3399014778325123, train_loss: 1.5282746354493282, val_loss: 1.406974049624551 (10 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.39901477832512317, train_loss: 1.4081949481858016, val_loss: 1.3752524356536677 (11 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.3793103448275862, train_loss: 1.4156142490903292, val_loss: 1.3750097393402325 (12 / 35)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.32019704433497537, train_loss: 1.435500304542749, val_loss: 1.5792362842653773 (13 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.4236453201970443, train_loss: 1.4125434459360922, val_loss: 1.342544036839396 (14 / 35)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.41379310344827586, train_loss: 1.3519119439814677, val_loss: 1.2875182766632494 (15 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.4433497536945813, train_loss: 1.3782951274819957, val_loss: 1.3332197043696061 (16 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.458128078817734, train_loss: 1.363482596110944, val_loss: 1.2727973243873107 (17 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4729064039408867, train_loss: 1.3619543029587113, val_loss: 1.302809408732823 (18 / 35)\n",
            "train_acc: 0.446229913473424, val_acc: 0.45320197044334976, train_loss: 1.318755305004945, val_loss: 1.2944302030384833 (19 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.4827586206896552, train_loss: 1.3106197444411232, val_loss: 1.1994472260545628 (20 / 35)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.42857142857142855, train_loss: 1.2643523466749156, val_loss: 1.3082281891348326 (21 / 35)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.4729064039408867, train_loss: 1.2117350945808685, val_loss: 1.1668489425640387 (22 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4876847290640394, train_loss: 1.1756128424914423, val_loss: 1.1570513521509218 (23 / 35)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4827586206896552, train_loss: 1.1649723878160247, val_loss: 1.15345149145925 (24 / 35)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5024630541871922, train_loss: 1.1596868415403425, val_loss: 1.137354738900227 (25 / 35)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.4975369458128079, train_loss: 1.1438565208531724, val_loss: 1.1338660737563824 (26 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.5024630541871922, train_loss: 1.1256437145440628, val_loss: 1.1276619995168864 (27 / 35)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.5024630541871922, train_loss: 1.132965159504611, val_loss: 1.1314343613356792 (28 / 35)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.4975369458128079, train_loss: 1.1144609219948352, val_loss: 1.1208641907851684 (29 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.5073891625615764, train_loss: 1.1284478192571068, val_loss: 1.121868499100502 (30 / 35)\n",
            "train_acc: 0.522867737948084, val_acc: 0.49261083743842365, train_loss: 1.13640793071247, val_loss: 1.1281322496277946 (31 / 35)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.5123152709359606, train_loss: 1.1261758972304714, val_loss: 1.1159073046862786 (32 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.5024630541871922, train_loss: 1.141450172228041, val_loss: 1.1165493142428657 (33 / 35)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.5270935960591133, train_loss: 1.096681682229484, val_loss: 1.1107552653463015 (34 / 35)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5270935960591133, train_loss: 1.1099039817180563, val_loss: 1.1084408836411725 (35 / 35)\n",
            "lr 0.0009044635141860893, batch 12, decay 0.0003915636725694811, gamma 0.045028926951079996, val accuracy 0.5270935960591133, val loss 1.1107552653463015 [9 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7820779228092567, val_loss: 1.7573637110846383 (1 / 35)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.23645320197044334, train_loss: 1.7648033565290189, val_loss: 1.741812863960642 (2 / 35)\n",
            "train_acc: 0.22126081582200247, val_acc: 0.18226600985221675, train_loss: 1.7444495992695888, val_loss: 1.7633042887513861 (3 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.19704433497536947, train_loss: 1.7435469954505987, val_loss: 1.676845522936929 (4 / 35)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.2660098522167488, train_loss: 1.7113427438016875, val_loss: 1.73262371276987 (5 / 35)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.28078817733990147, train_loss: 1.6921269887752084, val_loss: 1.6022151215323086 (6 / 35)\n",
            "train_acc: 0.242274412855377, val_acc: 0.21182266009852216, train_loss: 1.684510267267121, val_loss: 1.7469392868098368 (7 / 35)\n",
            "train_acc: 0.2830655129789864, val_acc: 0.37438423645320196, train_loss: 1.6653311987889858, val_loss: 1.5813904677705812 (8 / 35)\n",
            "train_acc: 0.2892459826946848, val_acc: 0.3645320197044335, train_loss: 1.6447348408999638, val_loss: 1.550099438634412 (9 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.23645320197044334, train_loss: 1.595142692364338, val_loss: 1.7417400934426068 (10 / 35)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.35960591133004927, train_loss: 1.5954337996811743, val_loss: 1.524142544845055 (11 / 35)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.3448275862068966, train_loss: 1.5644785898135531, val_loss: 1.598744990203181 (12 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.35960591133004927, train_loss: 1.5611169492947894, val_loss: 1.5200240095260695 (13 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.31527093596059114, train_loss: 1.6312134130334088, val_loss: 1.5710192002686374 (14 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3694581280788177, train_loss: 1.5263786936277808, val_loss: 1.5000771060953 (15 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.37438423645320196, train_loss: 1.5030447022139806, val_loss: 1.467592355652983 (16 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.39901477832512317, train_loss: 1.482089122087316, val_loss: 1.4588408845986052 (17 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.4088669950738916, train_loss: 1.4616562159011333, val_loss: 1.4361123797928759 (18 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.4039408866995074, train_loss: 1.4540737485708795, val_loss: 1.452495862110495 (19 / 35)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.43349753694581283, train_loss: 1.445601165368324, val_loss: 1.4344755199742434 (20 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.39901477832512317, train_loss: 1.4229853670440882, val_loss: 1.3820714756773023 (21 / 35)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.47783251231527096, train_loss: 1.3373374526373978, val_loss: 1.3806143828800745 (22 / 35)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.43842364532019706, train_loss: 1.2961192931174053, val_loss: 1.3420823460142013 (23 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.4187192118226601, train_loss: 1.29327588352491, val_loss: 1.3377927858841243 (24 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.42857142857142855, train_loss: 1.270721911647264, val_loss: 1.3095069700861213 (25 / 35)\n",
            "train_acc: 0.4758961681087763, val_acc: 0.4236453201970443, train_loss: 1.2276309585689171, val_loss: 1.3038202265800514 (26 / 35)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.43349753694581283, train_loss: 1.236198165360723, val_loss: 1.2987853723206544 (27 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.43349753694581283, train_loss: 1.2100234488474277, val_loss: 1.332593702330378 (28 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4876847290640394, train_loss: 1.2129377154690963, val_loss: 1.2400133286790895 (29 / 35)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.458128078817734, train_loss: 1.1743712754567857, val_loss: 1.3406885680306722 (30 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.49261083743842365, train_loss: 1.1859360983404152, val_loss: 1.2387617867568443 (31 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.49261083743842365, train_loss: 1.1208031868610453, val_loss: 1.3086257485920572 (32 / 35)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.4827586206896552, train_loss: 1.115302858084477, val_loss: 1.2254866872514998 (33 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.458128078817734, train_loss: 1.0636098003210626, val_loss: 1.3217131850754686 (34 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.4433497536945813, train_loss: 1.0710555799811967, val_loss: 1.3116561579586836 (35 / 35)\n",
            "lr 0.0020643464500784124, batch 12, decay 0.00013238295654226893, gamma 0.15715451324785862, val accuracy 0.49261083743842365, val loss 1.2387617867568443 [10 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7775980011641759, val_loss: 1.7605069957930466 (1 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.3399014778325123, train_loss: 1.7469141782435262, val_loss: 1.718785856744926 (2 / 35)\n",
            "train_acc: 0.2323856613102596, val_acc: 0.17733990147783252, train_loss: 1.7236914384202993, val_loss: 1.7795016982872498 (3 / 35)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.19704433497536947, train_loss: 1.773862909622334, val_loss: 1.766212669499402 (4 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.2413793103448276, train_loss: 1.7645915141064392, val_loss: 1.7483245240056455 (5 / 35)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.1921182266009852, train_loss: 1.760424197088508, val_loss: 1.7531008232990508 (6 / 35)\n",
            "train_acc: 0.24721878862793573, val_acc: 0.18226600985221675, train_loss: 1.7475963340259453, val_loss: 1.7740861441701503 (7 / 35)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.27586206896551724, train_loss: 1.7603527416552247, val_loss: 1.7580290363339954 (8 / 35)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.35960591133004927, train_loss: 1.72074509875294, val_loss: 1.5392093822873871 (9 / 35)\n",
            "train_acc: 0.276885043263288, val_acc: 0.37438423645320196, train_loss: 1.6507860158370953, val_loss: 1.4416314845014675 (10 / 35)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.33004926108374383, train_loss: 1.5848593196114444, val_loss: 1.6225122718388223 (11 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3645320197044335, train_loss: 1.5315980323312899, val_loss: 1.4802352642190868 (12 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.3793103448275862, train_loss: 1.4730872091168379, val_loss: 1.3496801380453438 (13 / 35)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.4187192118226601, train_loss: 1.471414158164497, val_loss: 1.3499242178912234 (14 / 35)\n",
            "train_acc: 0.3164400494437577, val_acc: 0.29064039408866993, train_loss: 1.5886952101963265, val_loss: 1.635406508821572 (15 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3448275862068966, train_loss: 1.4685650773631922, val_loss: 1.592864054177195 (16 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3497536945812808, train_loss: 1.4476006184284413, val_loss: 1.4114538087633444 (17 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3645320197044335, train_loss: 1.4081152599438453, val_loss: 1.4198359227532824 (18 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.4039408866995074, train_loss: 1.3542581550565138, val_loss: 1.3717476481874589 (19 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.4433497536945813, train_loss: 1.319939613636993, val_loss: 1.3492313412022707 (20 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.3891625615763547, train_loss: 1.3157921326617228, val_loss: 1.5119394439781828 (21 / 35)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.42857142857142855, train_loss: 1.2108969850504796, val_loss: 1.2855140972020003 (22 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.43842364532019706, train_loss: 1.1379070013798358, val_loss: 1.2412773831724533 (23 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.47783251231527096, train_loss: 1.1384293470158713, val_loss: 1.2402857565527479 (24 / 35)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.43349753694581283, train_loss: 1.1070073623445036, val_loss: 1.2349988920935269 (25 / 35)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.458128078817734, train_loss: 1.0857179707148756, val_loss: 1.212993962717761 (26 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4433497536945813, train_loss: 1.0128384679740086, val_loss: 1.1890637390132022 (27 / 35)\n",
            "train_acc: 0.5859085290482077, val_acc: 0.4433497536945813, train_loss: 1.0036399641496732, val_loss: 1.2303650414415181 (28 / 35)\n",
            "train_acc: 0.588380716934487, val_acc: 0.49261083743842365, train_loss: 1.0002556392377329, val_loss: 1.2202933016668986 (29 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5073891625615764, train_loss: 0.9851643096089215, val_loss: 1.2188479970828654 (30 / 35)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.4630541871921182, train_loss: 0.9716233346606656, val_loss: 1.203503361770085 (31 / 35)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.4630541871921182, train_loss: 0.8883984430758709, val_loss: 1.3959503267786186 (32 / 35)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.4827586206896552, train_loss: 0.8796567610374045, val_loss: 1.4515841459405834 (33 / 35)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.45320197044334976, train_loss: 0.8594956969743311, val_loss: 1.4823910350282792 (34 / 35)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5467980295566502, train_loss: 0.9834705175663838, val_loss: 1.2194182875708406 (35 / 35)\n",
            "lr 0.002628231587505414, batch 8, decay 1.6710565146641975e-06, gamma 0.15578762585695832, val accuracy 0.5467980295566502, val loss 1.2194182875708406 [11 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7824287159628567, val_loss: 1.755638496629123 (1 / 35)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2857142857142857, train_loss: 1.7620164052812366, val_loss: 1.7420011799910973 (2 / 35)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.33497536945812806, train_loss: 1.7404049542100526, val_loss: 1.7079792803731457 (3 / 35)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.32019704433497537, train_loss: 1.737533358619888, val_loss: 1.6778643953389134 (4 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.2561576354679803, train_loss: 1.6772213584855107, val_loss: 1.6676999412733933 (5 / 35)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.3448275862068966, train_loss: 1.6575652412489996, val_loss: 1.5951767173306695 (6 / 35)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.29064039408866993, train_loss: 1.6145532333069885, val_loss: 1.5476775621545726 (7 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.3448275862068966, train_loss: 1.5992133521621101, val_loss: 1.5093542995124027 (8 / 35)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.3694581280788177, train_loss: 1.5677894810663608, val_loss: 1.4761385013317239 (9 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.35467980295566504, train_loss: 1.5240540255427508, val_loss: 1.4494649747322346 (10 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.37438423645320196, train_loss: 1.462921496080085, val_loss: 1.4447403652914639 (11 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.4482758620689655, train_loss: 1.4742891406836114, val_loss: 1.3805184816492015 (12 / 35)\n",
            "train_acc: 0.377008652657602, val_acc: 0.27586206896551724, train_loss: 1.4806508621562398, val_loss: 1.6692875418169746 (13 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3694581280788177, train_loss: 1.4397656558028553, val_loss: 1.391435064118484 (14 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.4187192118226601, train_loss: 1.4035929572596981, val_loss: 1.37401302724049 (15 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4433497536945813, train_loss: 1.3606138067280849, val_loss: 1.432768176341879 (16 / 35)\n",
            "train_acc: 0.415327564894932, val_acc: 0.42857142857142855, train_loss: 1.3615065505094965, val_loss: 1.286197339666301 (17 / 35)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.458128078817734, train_loss: 1.3046687004445363, val_loss: 1.2542073521120796 (18 / 35)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.4827586206896552, train_loss: 1.3076952575016376, val_loss: 1.261034052947472 (19 / 35)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.46798029556650245, train_loss: 1.2860211643801336, val_loss: 1.2926154342190972 (20 / 35)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.49261083743842365, train_loss: 1.2425615799294414, val_loss: 1.2541528631900918 (21 / 35)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.5221674876847291, train_loss: 1.2292668690492845, val_loss: 1.199357754197614 (22 / 35)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.47783251231527096, train_loss: 1.18236931174883, val_loss: 1.185053708224461 (23 / 35)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.4975369458128079, train_loss: 1.1236902101078199, val_loss: 1.1796178098382621 (24 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4975369458128079, train_loss: 1.142993251089702, val_loss: 1.1751409501864993 (25 / 35)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.49261083743842365, train_loss: 1.129845357353814, val_loss: 1.1730832478095745 (26 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.4876847290640394, train_loss: 1.1311377588986467, val_loss: 1.1712634707319325 (27 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.4876847290640394, train_loss: 1.1126099429996994, val_loss: 1.1701432630933564 (28 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.49261083743842365, train_loss: 1.1351549936313416, val_loss: 1.1684346527888858 (29 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.47783251231527096, train_loss: 1.1142551132716119, val_loss: 1.1649450269238701 (30 / 35)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.49261083743842365, train_loss: 1.118388369292647, val_loss: 1.1648185931403061 (31 / 35)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.49261083743842365, train_loss: 1.1101274661286946, val_loss: 1.1617980866596616 (32 / 35)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.4975369458128079, train_loss: 1.130493666981295, val_loss: 1.160774446766952 (33 / 35)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.5024630541871922, train_loss: 1.083390647312914, val_loss: 1.1596755179865608 (34 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.5024630541871922, train_loss: 1.1195163377577944, val_loss: 1.1585422857054348 (35 / 35)\n",
            "lr 0.0010917650269079559, batch 14, decay 6.975925845968681e-06, gamma 0.011396041262752815, val accuracy 0.5221674876847291, val loss 1.199357754197614 [12 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7828603492236992, val_loss: 1.7645734055288906 (1 / 35)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.22660098522167488, train_loss: 1.7784042759200993, val_loss: 1.7729339123946692 (2 / 35)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18719211822660098, train_loss: 1.7671609873824714, val_loss: 1.7567195804248303 (3 / 35)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.2019704433497537, train_loss: 1.7448697910910043, val_loss: 1.726203759315566 (4 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.28078817733990147, train_loss: 1.757231684491425, val_loss: 1.7481280923476947 (5 / 35)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.26108374384236455, train_loss: 1.6950005886728596, val_loss: 1.7046878367222 (6 / 35)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.3054187192118227, train_loss: 1.7281405751873153, val_loss: 1.6685195703224596 (7 / 35)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.2857142857142857, train_loss: 1.664753386647209, val_loss: 1.5756872316886639 (8 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.31527093596059114, train_loss: 1.584013502146906, val_loss: 1.6962782708294872 (9 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.39901477832512317, train_loss: 1.5648740310456755, val_loss: 1.4242128186625214 (10 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.39408866995073893, train_loss: 1.492461650274298, val_loss: 1.3627004737924473 (11 / 35)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.3694581280788177, train_loss: 1.4790279544033433, val_loss: 1.5042235105495734 (12 / 35)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.35960591133004927, train_loss: 1.5189851073016343, val_loss: 1.3467621263024843 (13 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.39901477832512317, train_loss: 1.4585947692762642, val_loss: 1.4921259880065918 (14 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.33497536945812806, train_loss: 1.4357229233966917, val_loss: 1.4588231447295015 (15 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.4187192118226601, train_loss: 1.400562615270815, val_loss: 1.328195957127463 (16 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.4630541871921182, train_loss: 1.395745391309335, val_loss: 1.3142662418299709 (17 / 35)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.4433497536945813, train_loss: 1.3290609144899252, val_loss: 1.3021934613805686 (18 / 35)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.4433497536945813, train_loss: 1.2796761792139306, val_loss: 1.3995187391201263 (19 / 35)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4433497536945813, train_loss: 1.2712709690053914, val_loss: 1.343935523714338 (20 / 35)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.43349753694581283, train_loss: 1.233891905017188, val_loss: 1.3358758632185423 (21 / 35)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.5073891625615764, train_loss: 1.092242958519161, val_loss: 1.1749444868177028 (22 / 35)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5024630541871922, train_loss: 1.0342474861993778, val_loss: 1.1941672880661311 (23 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5221674876847291, train_loss: 1.0343326216722448, val_loss: 1.2084028867665182 (24 / 35)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5369458128078818, train_loss: 0.9894086910856079, val_loss: 1.1556285179307308 (25 / 35)\n",
            "train_acc: 0.6118665018541409, val_acc: 0.4975369458128079, train_loss: 0.9581411235559414, val_loss: 1.1884955109046598 (26 / 35)\n",
            "train_acc: 0.622991347342398, val_acc: 0.4975369458128079, train_loss: 0.9306067237158494, val_loss: 1.2435286967037933 (27 / 35)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5123152709359606, train_loss: 0.8481807251943204, val_loss: 1.260012876517667 (28 / 35)\n",
            "train_acc: 0.6563658838071693, val_acc: 0.4975369458128079, train_loss: 0.864886132836784, val_loss: 1.225146497411681 (29 / 35)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5172413793103449, train_loss: 0.8486201391821296, val_loss: 1.2074721617064452 (30 / 35)\n",
            "train_acc: 0.6823238566131026, val_acc: 0.5221674876847291, train_loss: 0.784050970053938, val_loss: 1.1745528170627912 (31 / 35)\n",
            "train_acc: 0.6872682323856613, val_acc: 0.5369458128078818, train_loss: 0.7846876905934036, val_loss: 1.2145285811917534 (32 / 35)\n",
            "train_acc: 0.688504326328801, val_acc: 0.5320197044334976, train_loss: 0.7434277185256166, val_loss: 1.2208035550094003 (33 / 35)\n",
            "train_acc: 0.7268232385661311, val_acc: 0.47783251231527096, train_loss: 0.6868160696347948, val_loss: 1.3396621002939535 (34 / 35)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5369458128078818, train_loss: 0.6734746640043884, val_loss: 1.2711333829193867 (35 / 35)\n",
            "lr 0.0018138076264542424, batch 8, decay 0.0003907788622265566, gamma 0.17985827569386414, val accuracy 0.5369458128078818, val loss 1.1556285179307308 [13 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.15822002472187885, val_acc: 0.18226600985221675, train_loss: 1.7818168790732385, val_loss: 1.7634254558920273 (1 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.19704433497536947, train_loss: 1.7594361327339898, val_loss: 1.7563993378813043 (2 / 35)\n",
            "train_acc: 0.25092707045735474, val_acc: 0.18719211822660098, train_loss: 1.754788729699492, val_loss: 1.750018678862473 (3 / 35)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.29064039408866993, train_loss: 1.700075549896627, val_loss: 1.6162779739337603 (4 / 35)\n",
            "train_acc: 0.2373300370828183, val_acc: 0.31527093596059114, train_loss: 1.7447676897343658, val_loss: 1.6503460636279854 (5 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.3645320197044335, train_loss: 1.6408243686955408, val_loss: 1.4843246461135413 (6 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.29064039408866993, train_loss: 1.653599819382572, val_loss: 1.516543340800431 (7 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3497536945812808, train_loss: 1.5387105549811138, val_loss: 1.4528883980412788 (8 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.39408866995073893, train_loss: 1.5361307933097716, val_loss: 1.46949553504366 (9 / 35)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.33497536945812806, train_loss: 1.5426647872358965, val_loss: 1.4168614491159692 (10 / 35)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.2512315270935961, train_loss: 1.5883480620619983, val_loss: 1.5235914256185146 (11 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3842364532019704, train_loss: 1.4449795421917446, val_loss: 1.3267834961707956 (12 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.43842364532019706, train_loss: 1.4702715338823675, val_loss: 1.4200908400742291 (13 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.39901477832512317, train_loss: 1.438699821311847, val_loss: 1.4933272770472936 (14 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.4630541871921182, train_loss: 1.378776902247713, val_loss: 1.327006254877363 (15 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.4236453201970443, train_loss: 1.4447576965772915, val_loss: 1.4237842853433393 (16 / 35)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.4236453201970443, train_loss: 1.3373762201172459, val_loss: 1.3246242703475388 (17 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.3793103448275862, train_loss: 1.3131439105247242, val_loss: 1.4375370848061415 (18 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.4482758620689655, train_loss: 1.317778321072846, val_loss: 1.3884078919006686 (19 / 35)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.4039408866995074, train_loss: 1.2636926613278383, val_loss: 1.340846515054186 (20 / 35)\n",
            "train_acc: 0.449938195302843, val_acc: 0.43349753694581283, train_loss: 1.266790678386193, val_loss: 1.3544257929172423 (21 / 35)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.4827586206896552, train_loss: 1.215189821787906, val_loss: 1.2320213590936708 (22 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5073891625615764, train_loss: 1.1291390546172746, val_loss: 1.1949756304031522 (23 / 35)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.5123152709359606, train_loss: 1.1288059009020348, val_loss: 1.180686286517552 (24 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.5073891625615764, train_loss: 1.120816176179313, val_loss: 1.172951097558872 (25 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5073891625615764, train_loss: 1.0820286363105396, val_loss: 1.1702884920124936 (26 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.4975369458128079, train_loss: 1.1021635598688397, val_loss: 1.1655169690183818 (27 / 35)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.5073891625615764, train_loss: 1.1025675664136672, val_loss: 1.1634426058219571 (28 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5123152709359606, train_loss: 1.0724592354742646, val_loss: 1.1635545120744282 (29 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.5123152709359606, train_loss: 1.1002222855099937, val_loss: 1.1616154616983065 (30 / 35)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.5123152709359606, train_loss: 1.0760265401620948, val_loss: 1.1633803906111881 (31 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.5073891625615764, train_loss: 1.0635974318046948, val_loss: 1.1619745234550514 (32 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5073891625615764, train_loss: 1.0433005258827774, val_loss: 1.1624309232669512 (33 / 35)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5073891625615764, train_loss: 1.0603972998331446, val_loss: 1.1594002459730421 (34 / 35)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5073891625615764, train_loss: 1.065378133608178, val_loss: 1.1584016158075756 (35 / 35)\n",
            "lr 0.0023866231379973952, batch 13, decay 0.00023462746885540795, gamma 0.012174873019500636, val accuracy 0.5123152709359606, val loss 1.180686286517552 [14 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.173053152039555, val_acc: 0.2512315270935961, train_loss: 1.7810410399666823, val_loss: 1.749632306874092 (1 / 35)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.2561576354679803, train_loss: 1.7506311959477674, val_loss: 1.7542052163279116 (2 / 35)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7732680076721719, val_loss: 1.762461401558862 (3 / 35)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18719211822660098, train_loss: 1.7677728658258842, val_loss: 1.749583461014508 (4 / 35)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.22167487684729065, train_loss: 1.7577427341263139, val_loss: 1.6985341028626917 (5 / 35)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.18226600985221675, train_loss: 1.7340088329739565, val_loss: 1.77477874192111 (6 / 35)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18719211822660098, train_loss: 1.7640691898367167, val_loss: 1.755174312098273 (7 / 35)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.2413793103448276, train_loss: 1.733485669229175, val_loss: 1.7232690755956865 (8 / 35)\n",
            "train_acc: 0.24351050679851668, val_acc: 0.18226600985221675, train_loss: 1.7471680927040845, val_loss: 1.7728434413524683 (9 / 35)\n",
            "train_acc: 0.2558714462299135, val_acc: 0.3497536945812808, train_loss: 1.7042093481799434, val_loss: 1.563880985593561 (10 / 35)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.27586206896551724, train_loss: 1.6356741682118627, val_loss: 1.7089358403764923 (11 / 35)\n",
            "train_acc: 0.23856613102595797, val_acc: 0.31527093596059114, train_loss: 1.7307147157501674, val_loss: 1.618795658567269 (12 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.31527093596059114, train_loss: 1.6333580017089844, val_loss: 1.5798613731497027 (13 / 35)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.29064039408866993, train_loss: 1.5585978925596504, val_loss: 1.8660824768648947 (14 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.43842364532019706, train_loss: 1.5311533756397564, val_loss: 1.4141158147398474 (15 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.33497536945812806, train_loss: 1.4492265506197408, val_loss: 1.6002531239551863 (16 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3694581280788177, train_loss: 1.432564514971192, val_loss: 1.3615441386922826 (17 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3891625615763547, train_loss: 1.478372231549474, val_loss: 1.3774949347444356 (18 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3694581280788177, train_loss: 1.4348790545398726, val_loss: 1.4029625325367368 (19 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.4482758620689655, train_loss: 1.3544640122591638, val_loss: 1.355695186577407 (20 / 35)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.3645320197044335, train_loss: 1.3291676819545524, val_loss: 1.3240848585889844 (21 / 35)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.4187192118226601, train_loss: 1.241150719273665, val_loss: 1.287801401074884 (22 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.42857142857142855, train_loss: 1.2020595901828761, val_loss: 1.271978306946496 (23 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.45320197044334976, train_loss: 1.1964980249646568, val_loss: 1.2609488652844734 (24 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4729064039408867, train_loss: 1.1924044041167967, val_loss: 1.2615928550071904 (25 / 35)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.49261083743842365, train_loss: 1.1773446410783879, val_loss: 1.273363036768777 (26 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.46798029556650245, train_loss: 1.187291025304971, val_loss: 1.2602341430527824 (27 / 35)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4827586206896552, train_loss: 1.1477936283767003, val_loss: 1.2619086738877696 (28 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.47783251231527096, train_loss: 1.193990678884485, val_loss: 1.252499442676018 (29 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4729064039408867, train_loss: 1.1516378465188006, val_loss: 1.251045204442123 (30 / 35)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.47783251231527096, train_loss: 1.142249087320712, val_loss: 1.2451779404884489 (31 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.458128078817734, train_loss: 1.1513966756639138, val_loss: 1.242895689797519 (32 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.49261083743842365, train_loss: 1.1363931192897896, val_loss: 1.249784382399667 (33 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.49261083743842365, train_loss: 1.127149450764226, val_loss: 1.247393246061109 (34 / 35)\n",
            "train_acc: 0.522867737948084, val_acc: 0.47783251231527096, train_loss: 1.121609530578585, val_loss: 1.2350269109744745 (35 / 35)\n",
            "lr 0.0026295048422407016, batch 12, decay 0.00020477892104017582, gamma 0.035289948852451535, val accuracy 0.49261083743842365, val loss 1.273363036768777 [15 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.780409494053448, val_loss: 1.7601068624721958 (1 / 35)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7674035427744221, val_loss: 1.7412427775378299 (2 / 35)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.2561576354679803, train_loss: 1.7563744392913705, val_loss: 1.739530656725315 (3 / 35)\n",
            "train_acc: 0.2484548825710754, val_acc: 0.1921182266009852, train_loss: 1.737771486175075, val_loss: 1.7763892418058047 (4 / 35)\n",
            "train_acc: 0.273176761433869, val_acc: 0.2019704433497537, train_loss: 1.7068627702880406, val_loss: 1.690884008783425 (5 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.1921182266009852, train_loss: 1.6704232701559738, val_loss: 1.7408100425316195 (6 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.37438423645320196, train_loss: 1.6165696345684113, val_loss: 1.5108636312296826 (7 / 35)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.3694581280788177, train_loss: 1.5795316573863272, val_loss: 1.4472781501967331 (8 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3793103448275862, train_loss: 1.5141646747094002, val_loss: 1.356889550321795 (9 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.4088669950738916, train_loss: 1.4950307119909412, val_loss: 1.41473561202364 (10 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4236453201970443, train_loss: 1.397953474182723, val_loss: 1.2917526044281833 (11 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.4482758620689655, train_loss: 1.3787937582791663, val_loss: 1.381097039565664 (12 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.41379310344827586, train_loss: 1.3580047474213968, val_loss: 1.3743647228320832 (13 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.3842364532019704, train_loss: 1.3321186939187633, val_loss: 1.4894152154476183 (14 / 35)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.45320197044334976, train_loss: 1.2766347013975692, val_loss: 1.246648561778327 (15 / 35)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.4827586206896552, train_loss: 1.2346039917619325, val_loss: 1.273278637472632 (16 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4482758620689655, train_loss: 1.2127688371648895, val_loss: 1.2561038494697345 (17 / 35)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.39901477832512317, train_loss: 1.248542078787965, val_loss: 1.270439156170549 (18 / 35)\n",
            "train_acc: 0.484548825710754, val_acc: 0.47783251231527096, train_loss: 1.1861427116158276, val_loss: 1.613210312251387 (19 / 35)\n",
            "train_acc: 0.515451174289246, val_acc: 0.5073891625615764, train_loss: 1.164068420236868, val_loss: 1.170529866747081 (20 / 35)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.5024630541871922, train_loss: 1.1230431142342547, val_loss: 1.1775321373211338 (21 / 35)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5369458128078818, train_loss: 1.0298882750851852, val_loss: 1.119924227592393 (22 / 35)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.5320197044334976, train_loss: 0.9943751451848316, val_loss: 1.1034489770240972 (23 / 35)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5467980295566502, train_loss: 0.9812895730045729, val_loss: 1.101068928911181 (24 / 35)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5517241379310345, train_loss: 0.9519668294413864, val_loss: 1.0972938575768119 (25 / 35)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5467980295566502, train_loss: 0.9379421698000876, val_loss: 1.0984355067384655 (26 / 35)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5566502463054187, train_loss: 0.9360774308995646, val_loss: 1.0966506019014444 (27 / 35)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5566502463054187, train_loss: 0.9263753227898748, val_loss: 1.0933446194150764 (28 / 35)\n",
            "train_acc: 0.630407911001236, val_acc: 0.5467980295566502, train_loss: 0.9312544437804534, val_loss: 1.1021940998843152 (29 / 35)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.5517241379310345, train_loss: 0.9102077518022252, val_loss: 1.0933777695806155 (30 / 35)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5467980295566502, train_loss: 0.8905031751790654, val_loss: 1.093630265426166 (31 / 35)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.5467980295566502, train_loss: 0.8604285758269584, val_loss: 1.1032093064538364 (32 / 35)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.5517241379310345, train_loss: 0.8886519866467112, val_loss: 1.1052549449093823 (33 / 35)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.541871921182266, train_loss: 0.8815253110986999, val_loss: 1.1058232276310473 (34 / 35)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.5369458128078818, train_loss: 0.8564247485291678, val_loss: 1.111414728493526 (35 / 35)\n",
            "lr 0.0015179814277084618, batch 8, decay 4.481170380811817e-06, gamma 0.012186141653678885, val accuracy 0.5566502463054187, val loss 1.0966506019014444 [16 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7860405807589423, val_loss: 1.7670101361908936 (1 / 35)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7663660131956649, val_loss: 1.7425508992425327 (2 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.2955665024630542, train_loss: 1.7522847634752836, val_loss: 1.7124281669485157 (3 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18719211822660098, train_loss: 1.761283779026404, val_loss: 1.7720965299700282 (4 / 35)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.270935960591133, train_loss: 1.763470488219385, val_loss: 1.7479288378372568 (5 / 35)\n",
            "train_acc: 0.276885043263288, val_acc: 0.270935960591133, train_loss: 1.7229097999070573, val_loss: 1.6829653432216551 (6 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.3891625615763547, train_loss: 1.6281520567364687, val_loss: 1.5019566173036698 (7 / 35)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3399014778325123, train_loss: 1.5494943771727743, val_loss: 1.4866750498710595 (8 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3694581280788177, train_loss: 1.607152692172377, val_loss: 1.6285590902337888 (9 / 35)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.42857142857142855, train_loss: 1.4976441279624684, val_loss: 1.375124259828934 (10 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.2857142857142857, train_loss: 1.4585741750978864, val_loss: 1.5392693968242026 (11 / 35)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.3891625615763547, train_loss: 1.4214646902455683, val_loss: 1.4685640382062037 (12 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3645320197044335, train_loss: 1.4542503706899061, val_loss: 1.476798229029613 (13 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.4236453201970443, train_loss: 1.3664714005143739, val_loss: 1.3103576387677873 (14 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.3842364532019704, train_loss: 1.3468337406776154, val_loss: 1.3629518054389014 (15 / 35)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.4827586206896552, train_loss: 1.3198427557945251, val_loss: 1.2249715281237523 (16 / 35)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4039408866995074, train_loss: 1.3283375200294005, val_loss: 1.2574730900120852 (17 / 35)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.4482758620689655, train_loss: 1.303273918454815, val_loss: 1.2554701927847463 (18 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4630541871921182, train_loss: 1.2899333353537712, val_loss: 1.243403620026969 (19 / 35)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.458128078817734, train_loss: 1.2042983579547208, val_loss: 1.2149202574062816 (20 / 35)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.45320197044334976, train_loss: 1.2423882485909574, val_loss: 1.2308703308622237 (21 / 35)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.4827586206896552, train_loss: 1.1304571333862794, val_loss: 1.1828638259413207 (22 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5172413793103449, train_loss: 1.0856382046700703, val_loss: 1.1622583965949824 (23 / 35)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.5320197044334976, train_loss: 1.0478744594511498, val_loss: 1.1521670893201688 (24 / 35)\n",
            "train_acc: 0.5686032138442522, val_acc: 0.5467980295566502, train_loss: 1.0590883206820163, val_loss: 1.1427837030347345 (25 / 35)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.5221674876847291, train_loss: 1.0234751264450723, val_loss: 1.1413224772573105 (26 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5369458128078818, train_loss: 1.0317051400360278, val_loss: 1.136361003509296 (27 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5221674876847291, train_loss: 1.0255618068137482, val_loss: 1.1338397127947784 (28 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5369458128078818, train_loss: 1.0331341898338167, val_loss: 1.1309863353891325 (29 / 35)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5369458128078818, train_loss: 0.9970107011506231, val_loss: 1.1292095447115122 (30 / 35)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.5369458128078818, train_loss: 1.0202904202145315, val_loss: 1.1269336579174831 (31 / 35)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5320197044334976, train_loss: 0.9804517220065679, val_loss: 1.1267321531114907 (32 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5467980295566502, train_loss: 0.9849574198239519, val_loss: 1.1246318774563926 (33 / 35)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.541871921182266, train_loss: 0.9755078699297015, val_loss: 1.123448864579788 (34 / 35)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.5320197044334976, train_loss: 0.9777564823406442, val_loss: 1.1261608885426826 (35 / 35)\n",
            "lr 0.0017163790974761063, batch 9, decay 0.0005061452305054841, gamma 0.013705898650736906, val accuracy 0.5467980295566502, val loss 1.1427837030347345 [17 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7844688358943455, val_loss: 1.7654725518719903 (1 / 35)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7632630883689568, val_loss: 1.7453258695273564 (2 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7564326887225044, val_loss: 1.7238553721329262 (3 / 35)\n",
            "train_acc: 0.22249690976514216, val_acc: 0.32019704433497537, train_loss: 1.7389155839960124, val_loss: 1.7171220286139126 (4 / 35)\n",
            "train_acc: 0.24351050679851668, val_acc: 0.32019704433497537, train_loss: 1.7104670311818164, val_loss: 1.695545036217262 (5 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.23645320197044334, train_loss: 1.666012343429075, val_loss: 1.6935786296581399 (6 / 35)\n",
            "train_acc: 0.26081582200247216, val_acc: 0.270935960591133, train_loss: 1.6704049875179239, val_loss: 1.6829169084285867 (7 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.27586206896551724, train_loss: 1.6281006069501633, val_loss: 1.6462366580963135 (8 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.35960591133004927, train_loss: 1.604456498537429, val_loss: 1.584333374582488 (9 / 35)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.35960591133004927, train_loss: 1.586377685385375, val_loss: 1.5427724904027478 (10 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3891625615763547, train_loss: 1.5522080300322865, val_loss: 1.5193788923066238 (11 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.3793103448275862, train_loss: 1.5638708943047541, val_loss: 1.520177039606818 (12 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.3448275862068966, train_loss: 1.556066986951604, val_loss: 1.6237049369976437 (13 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.39408866995073893, train_loss: 1.547466985080092, val_loss: 1.4884646802112973 (14 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.3103448275862069, train_loss: 1.4805893369009822, val_loss: 1.5923683396701156 (15 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3891625615763547, train_loss: 1.5057145127259903, val_loss: 1.4450932371205296 (16 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.37438423645320196, train_loss: 1.4777142815890507, val_loss: 1.4408049583435059 (17 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.3842364532019704, train_loss: 1.4229679285964212, val_loss: 1.4588815631537602 (18 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.37438423645320196, train_loss: 1.516363988700697, val_loss: 1.4293444567713245 (19 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4039408866995074, train_loss: 1.4116431401008729, val_loss: 1.4047836147505661 (20 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.4039408866995074, train_loss: 1.400869729050305, val_loss: 1.4100853698006992 (21 / 35)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.39901477832512317, train_loss: 1.3284876259649345, val_loss: 1.3544003593510594 (22 / 35)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.3842364532019704, train_loss: 1.3182414239652371, val_loss: 1.3405519518358955 (23 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4187192118226601, train_loss: 1.3086194700304745, val_loss: 1.3347665030380775 (24 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4088669950738916, train_loss: 1.2944353712798637, val_loss: 1.324327041362894 (25 / 35)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.4039408866995074, train_loss: 1.2772482277731076, val_loss: 1.321790152582629 (26 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4088669950738916, train_loss: 1.3001167783041672, val_loss: 1.3211387354752113 (27 / 35)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.41379310344827586, train_loss: 1.2907394463995332, val_loss: 1.3178614460188767 (28 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4187192118226601, train_loss: 1.2825855679800837, val_loss: 1.3169119316956093 (29 / 35)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.42857142857142855, train_loss: 1.2883045263726574, val_loss: 1.3111550561312972 (30 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.43349753694581283, train_loss: 1.273357442047157, val_loss: 1.3082252165366863 (31 / 35)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.43349753694581283, train_loss: 1.287179517068144, val_loss: 1.3082229844455062 (32 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4482758620689655, train_loss: 1.260131646882471, val_loss: 1.3088031102871072 (33 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.43842364532019706, train_loss: 1.264081924895863, val_loss: 1.3077983321814701 (34 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.45320197044334976, train_loss: 1.2729343872871917, val_loss: 1.3070222180465172 (35 / 35)\n",
            "lr 0.0014675121262497802, batch 14, decay 2.2421597387681695e-05, gamma 0.014478440271304833, val accuracy 0.45320197044334976, val loss 1.3070222180465172 [18 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.783968668785614, val_loss: 1.759783768301527 (1 / 35)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.19704433497536947, train_loss: 1.7581964580915472, val_loss: 1.740070547963598 (2 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.31527093596059114, train_loss: 1.7455982274855908, val_loss: 1.699184049526459 (3 / 35)\n",
            "train_acc: 0.2669962917181706, val_acc: 0.18226600985221675, train_loss: 1.6864729667328786, val_loss: 1.7762921666864104 (4 / 35)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.18226600985221675, train_loss: 1.69240740615741, val_loss: 1.7868423303359835 (5 / 35)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.20689655172413793, train_loss: 1.7803402680843812, val_loss: 1.7658807861393895 (6 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.2315270935960591, train_loss: 1.763083317371175, val_loss: 1.7439709837213526 (7 / 35)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.2315270935960591, train_loss: 1.7538640110100745, val_loss: 1.7434777162345172 (8 / 35)\n",
            "train_acc: 0.2620519159456119, val_acc: 0.2512315270935961, train_loss: 1.7365494726320132, val_loss: 1.7007260780616347 (9 / 35)\n",
            "train_acc: 0.2880098887515451, val_acc: 0.2660098522167488, train_loss: 1.6765278723684907, val_loss: 1.6059351654475547 (10 / 35)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.31527093596059114, train_loss: 1.5768652635687508, val_loss: 1.5407383007369018 (11 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3842364532019704, train_loss: 1.5398606590935857, val_loss: 1.5195304860035186 (12 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.37438423645320196, train_loss: 1.5212641423948026, val_loss: 1.4748723101733354 (13 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.3842364532019704, train_loss: 1.46614976792754, val_loss: 1.492722003917976 (14 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.37438423645320196, train_loss: 1.4844937172749428, val_loss: 1.4409950079001816 (15 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.43349753694581283, train_loss: 1.4032045965289008, val_loss: 1.3137117034108767 (16 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.3793103448275862, train_loss: 1.3783596867536585, val_loss: 1.359689775946105 (17 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4630541871921182, train_loss: 1.3541803306937954, val_loss: 1.2967511274544476 (18 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.47783251231527096, train_loss: 1.325826077290312, val_loss: 1.253167976886768 (19 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.41379310344827586, train_loss: 1.3597612546017792, val_loss: 1.3314496877745454 (20 / 35)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4827586206896552, train_loss: 1.2703340111026362, val_loss: 1.2867380034160145 (21 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4827586206896552, train_loss: 1.2439406090525378, val_loss: 1.2091478373616786 (22 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.46798029556650245, train_loss: 1.1792186647469387, val_loss: 1.1893515492894966 (23 / 35)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.5024630541871922, train_loss: 1.1554598527579432, val_loss: 1.1878360962045604 (24 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.5073891625615764, train_loss: 1.1611875252906412, val_loss: 1.1898647317745414 (25 / 35)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.47783251231527096, train_loss: 1.1708485387606438, val_loss: 1.1676507935735392 (26 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4827586206896552, train_loss: 1.1424289271327561, val_loss: 1.1645036254610335 (27 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.4876847290640394, train_loss: 1.1582482177925346, val_loss: 1.1588547893345649 (28 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4975369458128079, train_loss: 1.1510743032427153, val_loss: 1.1606348805826874 (29 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5221674876847291, train_loss: 1.1404590584586372, val_loss: 1.162307824407305 (30 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4876847290640394, train_loss: 1.1089474070352145, val_loss: 1.155813621769985 (31 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4975369458128079, train_loss: 1.1275640667884694, val_loss: 1.1499514556283434 (32 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.5221674876847291, train_loss: 1.1277840542704862, val_loss: 1.157044266832286 (33 / 35)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.5123152709359606, train_loss: 1.1192541791423143, val_loss: 1.1476636062114698 (34 / 35)\n",
            "train_acc: 0.5142150803461063, val_acc: 0.5221674876847291, train_loss: 1.115928856197777, val_loss: 1.1547508926814414 (35 / 35)\n",
            "lr 0.0018413999432852234, batch 12, decay 1.3181751308788781e-06, gamma 0.02930125024302994, val accuracy 0.5221674876847291, val loss 1.162307824407305 [19 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7779990520111857, val_loss: 1.7505988704747166 (1 / 35)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.18226600985221675, train_loss: 1.753045355433734, val_loss: 1.733755730643061 (2 / 35)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.3054187192118227, train_loss: 1.6924155974122885, val_loss: 1.6218330314006713 (3 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.32019704433497537, train_loss: 1.6470619320722093, val_loss: 1.5952379045815304 (4 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3399014778325123, train_loss: 1.6318432685029227, val_loss: 1.5750041013867984 (5 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3497536945812808, train_loss: 1.604558128361649, val_loss: 1.5635248880668227 (6 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.33004926108374383, train_loss: 1.594866551928526, val_loss: 1.575426946719879 (7 / 35)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7774529188908221, val_loss: 1.7914501434476504 (8 / 35)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7782052803982615, val_loss: 1.765860574586051 (9 / 35)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7712961059565597, val_loss: 1.749138973616614 (10 / 35)\n",
            "train_acc: 0.22620519159456118, val_acc: 0.1921182266009852, train_loss: 1.764567678437392, val_loss: 1.7548023515146942 (11 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.2512315270935961, train_loss: 1.7429239089763062, val_loss: 1.7025859978398665 (12 / 35)\n",
            "train_acc: 0.2373300370828183, val_acc: 0.18226600985221675, train_loss: 1.7293732384374028, val_loss: 1.7714198551741727 (13 / 35)\n",
            "train_acc: 0.26081582200247216, val_acc: 0.32019704433497537, train_loss: 1.7004446735782883, val_loss: 1.6163292985244337 (14 / 35)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.27586206896551724, train_loss: 1.6758605853294117, val_loss: 1.7582066528902853 (15 / 35)\n",
            "train_acc: 0.25092707045735474, val_acc: 0.3497536945812808, train_loss: 1.7039590382900167, val_loss: 1.5578594151976073 (16 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.28078817733990147, train_loss: 1.634997018924897, val_loss: 1.7087163009079807 (17 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.3694581280788177, train_loss: 1.5467760330077598, val_loss: 1.4661980432829833 (18 / 35)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3891625615763547, train_loss: 1.5017072425047753, val_loss: 1.5117532983789304 (19 / 35)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.3645320197044335, train_loss: 1.4803604309726852, val_loss: 1.4582654378684283 (20 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.4088669950738916, train_loss: 1.4571761446918634, val_loss: 1.3744917981730307 (21 / 35)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.4433497536945813, train_loss: 1.3795828114923352, val_loss: 1.3313714030928212 (22 / 35)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4433497536945813, train_loss: 1.3213879201556609, val_loss: 1.2896618111967453 (23 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4729064039408867, train_loss: 1.2912509053835026, val_loss: 1.2642181474587013 (24 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.45320197044334976, train_loss: 1.2848991211618865, val_loss: 1.2693621950783753 (25 / 35)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.4729064039408867, train_loss: 1.2781717120790659, val_loss: 1.2530485027529337 (26 / 35)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.46798029556650245, train_loss: 1.2813063454716402, val_loss: 1.2723418207004153 (27 / 35)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.45320197044334976, train_loss: 1.265535096081874, val_loss: 1.2341577263888468 (28 / 35)\n",
            "train_acc: 0.4758961681087763, val_acc: 0.45320197044334976, train_loss: 1.2467300566960913, val_loss: 1.2511069158027912 (29 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4876847290640394, train_loss: 1.2478410540464044, val_loss: 1.2185765220026665 (30 / 35)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.5024630541871922, train_loss: 1.2310538398762716, val_loss: 1.2083124820821978 (31 / 35)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.5073891625615764, train_loss: 1.2468772347100143, val_loss: 1.2150857974155782 (32 / 35)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4876847290640394, train_loss: 1.2155586026507639, val_loss: 1.200895645935547 (33 / 35)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.49261083743842365, train_loss: 1.2242844031089906, val_loss: 1.1879710864844581 (34 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4876847290640394, train_loss: 1.193635918153968, val_loss: 1.20238830773114 (35 / 35)\n",
            "lr 0.002582664822853346, batch 13, decay 6.304927921665847e-06, gamma 0.09936179133503131, val accuracy 0.5073891625615764, val loss 1.2150857974155782 [20 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1841779975278121, val_acc: 0.28078817733990147, train_loss: 1.7796663695713792, val_loss: 1.7606313175755768 (1 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18226600985221675, train_loss: 1.7616123818643898, val_loss: 1.7264046710113 (2 / 35)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.27586206896551724, train_loss: 1.7703641082801393, val_loss: 1.7584881518274693 (3 / 35)\n",
            "train_acc: 0.22126081582200247, val_acc: 0.3448275862068966, train_loss: 1.7432159288557263, val_loss: 1.6786762358519831 (4 / 35)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.1921182266009852, train_loss: 1.6747852723000223, val_loss: 2.279945199125506 (5 / 35)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7968562543760567, val_loss: 1.7738496241311135 (6 / 35)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7699378535832992, val_loss: 1.7551007670134746 (7 / 35)\n",
            "train_acc: 0.23485784919653893, val_acc: 0.22167487684729065, train_loss: 1.7463447652729538, val_loss: 1.708012498071041 (8 / 35)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7656992875748718, val_loss: 1.7757013630984453 (9 / 35)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7741413428845305, val_loss: 1.7679772283056099 (10 / 35)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.2512315270935961, train_loss: 1.7691815964813138, val_loss: 1.7576303300011922 (11 / 35)\n",
            "train_acc: 0.2373300370828183, val_acc: 0.2315270935960591, train_loss: 1.734950779984407, val_loss: 1.6960197270210153 (12 / 35)\n",
            "train_acc: 0.2867737948084054, val_acc: 0.33497536945812806, train_loss: 1.6755332705116979, val_loss: 1.564437941964624 (13 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.30049261083743845, train_loss: 1.6326861548040648, val_loss: 1.5426158523324676 (14 / 35)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.39901477832512317, train_loss: 1.5375810936738004, val_loss: 1.438125992643422 (15 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3645320197044335, train_loss: 1.5043231863321274, val_loss: 1.4420483502848396 (16 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.27586206896551724, train_loss: 1.48887103007662, val_loss: 1.596839432645901 (17 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.41379310344827586, train_loss: 1.5367324903367918, val_loss: 1.3442228926813662 (18 / 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "4ee4e2f6-7038-49db-9ba6-667755ca46e8",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg19()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg19()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 24392 (delta 10), reused 13 (delta 5), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24392/24392), 2.15 GiB | 47.69 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (24636/24636), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.4876847290640394, val loss 1.3147739389259827\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6059113300492611, val loss 1.5047687838230226\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.3448275862068966, val loss 1.6433078479297056\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5812807881773399, val loss 2.414570222347241\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.2955665024630542, val loss 1.7655747535780733\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.4876847290640394, val loss 1.3504160378366856\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.18226600985221675, val loss 1.7624990276515191\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.270935960591133, val loss 1.7162450311219164\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6108374384236454, val loss 2.431815377597151\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6551724137931034, val loss 1.9367152525873608\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.528708166676789\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6600985221674877, val loss 1.645547920847174\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7536945812807881, val loss 1.4387520968620413\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6995073891625616, val loss 2.476622701278461\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6650246305418719, val loss 3.20528265466831\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6305418719211823, val loss 1.9122127376753708\n",
            "({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6502463054187192, val loss 1.084208725121221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}