

{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 1}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 1}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.05}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.05}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}
{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 1}
training set 809
validation set 203
train_acc: 0.20148331273176762, val_acc: 0.18719211822660098, train_loss: 1.7846523278723245, val_loss: 1.771295857546952 (1 / 100)
train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.770473012376038, val_loss: 1.755620509532872 (2 / 100)
train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.762690275797001, val_loss: 1.745736573717277 (3 / 100)
train_acc: 0.20519159456118666, val_acc: 0.29064039408866993, train_loss: 1.741083622862883, val_loss: 1.735056434946107 (4 / 100)
train_acc: 0.28182941903584674, val_acc: 0.18719211822660098, train_loss: 1.713869026476432, val_loss: 1.7381697317649578 (5 / 100)
train_acc: 0.2892459826946848, val_acc: 0.28078817733990147, train_loss: 1.6716446287110356, val_loss: 1.648497969646172 (6 / 100)
train_acc: 0.3164400494437577, val_acc: 0.27586206896551724, train_loss: 1.618611656396439, val_loss: 1.5296889332127688 (7 / 100)
train_acc: 0.3164400494437577, val_acc: 0.32019704433497537, train_loss: 1.5826222385257962, val_loss: 1.5383024233315379 (8 / 100)
train_acc: 0.34363411619283063, val_acc: 0.33004926108374383, train_loss: 1.5499994613331534, val_loss: 1.5018623268663003 (9 / 100)
train_acc: 0.34981458590852904, val_acc: 0.3645320197044335, train_loss: 1.4890236761720277, val_loss: 1.4076737682220384 (10 / 100)
train_acc: 0.3621755253399258, val_acc: 0.39408866995073893, train_loss: 1.4918878679664527, val_loss: 1.4242649736075566 (11 / 100)
train_acc: 0.4079110012360939, val_acc: 0.41379310344827586, train_loss: 1.4276630871080793, val_loss: 1.3674884899496444 (12 / 100)
train_acc: 0.377008652657602, val_acc: 0.3793103448275862, train_loss: 1.4281412597345038, val_loss: 1.4358766513505006 (13 / 100)
train_acc: 0.29913473423980225, val_acc: 0.26108374384236455, train_loss: 1.6700593738532332, val_loss: 1.6849985028722603 (14 / 100)
train_acc: 0.34857849196538937, val_acc: 0.3103448275862069, train_loss: 1.529677912684984, val_loss: 1.64809743230566 (15 / 100)
train_acc: 0.36093943139678614, val_acc: 0.270935960591133, train_loss: 1.5072463042067066, val_loss: 1.7498927465800582 (16 / 100)
train_acc: 0.3720642768850433, val_acc: 0.32019704433497537, train_loss: 1.4524943744591052, val_loss: 1.5132048546974295 (17 / 100)
train_acc: 0.3621755253399258, val_acc: 0.41379310344827586, train_loss: 1.4540730265368638, val_loss: 1.3225465402227317 (18 / 100)
train_acc: 0.38442521631644005, val_acc: 0.43349753694581283, train_loss: 1.4244053779337993, val_loss: 1.373814660927345 (19 / 100)
train_acc: 0.39060568603213847, val_acc: 0.35960591133004927, train_loss: 1.3842594754710629, val_loss: 1.4064045704057064 (20 / 100)
train_acc: 0.3794808405438813, val_acc: 0.4187192118226601, train_loss: 1.4324970186419776, val_loss: 1.3580065548713571 (21 / 100)
train_acc: 0.4079110012360939, val_acc: 0.39901477832512317, train_loss: 1.3732545723579133, val_loss: 1.3782458980682448 (22 / 100)
train_acc: 0.4252163164400494, val_acc: 0.39408866995073893, train_loss: 1.3381676222986285, val_loss: 1.49858721019012 (23 / 100)
train_acc: 0.4215080346106304, val_acc: 0.4827586206896552, train_loss: 1.3678005969126528, val_loss: 1.232147831047697 (24 / 100)
train_acc: 0.43757725587144625, val_acc: 0.49261083743842365, train_loss: 1.2927020315186792, val_loss: 1.209989441439436 (25 / 100)
train_acc: 0.44870210135970334, val_acc: 0.46798029556650245, train_loss: 1.2852420923294332, val_loss: 1.2176786156123496 (26 / 100)
train_acc: 0.45982694684796044, val_acc: 0.4729064039408867, train_loss: 1.2582683063702766, val_loss: 1.2172952021284056 (27 / 100)
train_acc: 0.4758961681087763, val_acc: 0.49261083743842365, train_loss: 1.2589306079855072, val_loss: 1.216126994546411 (28 / 100)
train_acc: 0.5006180469715699, val_acc: 0.5221674876847291, train_loss: 1.2435942313579753, val_loss: 1.2120068278805962 (29 / 100)
train_acc: 0.49443757725587145, val_acc: 0.5123152709359606, train_loss: 1.1985865443834416, val_loss: 1.1786975760765264 (30 / 100)
train_acc: 0.5030902348578492, val_acc: 0.47783251231527096, train_loss: 1.190513773518528, val_loss: 1.2296033334262266 (31 / 100)
train_acc: 0.4932014833127318, val_acc: 0.5221674876847291, train_loss: 1.177742185345097, val_loss: 1.2160658337212549 (32 / 100)
train_acc: 0.5278121137206427, val_acc: 0.5369458128078818, train_loss: 1.1512120229794156, val_loss: 1.1644849172366665 (33 / 100)
train_acc: 0.5339925834363412, val_acc: 0.4729064039408867, train_loss: 1.1157716969477085, val_loss: 1.212376438338181 (34 / 100)
train_acc: 0.553770086526576, val_acc: 0.45320197044334976, train_loss: 1.0775252349297106, val_loss: 1.2723687619998538 (35 / 100)
train_acc: 0.5784919653893696, val_acc: 0.5073891625615764, train_loss: 1.0831043319442806, val_loss: 1.1675690656225082 (36 / 100)
train_acc: 0.5784919653893696, val_acc: 0.541871921182266, train_loss: 1.0106015155282981, val_loss: 1.1442109616519196 (37 / 100)
train_acc: 0.5661310259579728, val_acc: 0.4975369458128079, train_loss: 1.0439231323518035, val_loss: 1.1978560539301981 (38 / 100)
train_acc: 0.6217552533992583, val_acc: 0.5665024630541872, train_loss: 0.9616557337592353, val_loss: 1.0984095763690367 (39 / 100)
train_acc: 0.6378244746600742, val_acc: 0.5320197044334976, train_loss: 0.9166134965729212, val_loss: 1.3681423123834169 (40 / 100)
train_acc: 0.6341161928306551, val_acc: 0.5467980295566502, train_loss: 0.9356465917287857, val_loss: 1.1275413611839558 (41 / 100)
train_acc: 0.622991347342398, val_acc: 0.5665024630541872, train_loss: 0.9485804268397271, val_loss: 1.094537656442285 (42 / 100)
train_acc: 0.695920889987639, val_acc: 0.6059113300492611, train_loss: 0.7810975358866349, val_loss: 1.2223694383217196 (43 / 100)
train_acc: 0.7095179233621756, val_acc: 0.6354679802955665, train_loss: 0.7563180630227692, val_loss: 1.0204299309570801 (44 / 100)
train_acc: 0.7255871446229913, val_acc: 0.49261083743842365, train_loss: 0.7251225098396555, val_loss: 1.3389981143873901 (45 / 100)
train_acc: 0.7428924598269468, val_acc: 0.6059113300492611, train_loss: 0.6894739153063931, val_loss: 1.1384396987595582 (46 / 100)
train_acc: 0.7688504326328801, val_acc: 0.6206896551724138, train_loss: 0.6199289299501625, val_loss: 1.106202503143273 (47 / 100)
train_acc: 0.7626699629171817, val_acc: 0.5714285714285714, train_loss: 0.6276600020482896, val_loss: 1.1855774454295342 (48 / 100)
train_acc: 0.765142150803461, val_acc: 0.5320197044334976, train_loss: 0.5811903849520407, val_loss: 1.3918250592177726 (49 / 100)
train_acc: 0.8195302843016069, val_acc: 0.5517241379310345, train_loss: 0.4559266788261046, val_loss: 1.2837828814322725 (50 / 100)
train_acc: 0.8368355995055624, val_acc: 0.625615763546798, train_loss: 0.4458173536989096, val_loss: 1.1641926954092063 (51 / 100)
train_acc: 0.8170580964153276, val_acc: 0.6206896551724138, train_loss: 0.5018481637992435, val_loss: 1.4143247064111268 (52 / 100)
train_acc: 0.8405438813349815, val_acc: 0.6108374384236454, train_loss: 0.4192745432128718, val_loss: 1.4397434272936411 (53 / 100)
train_acc: 0.8467243510506799, val_acc: 0.6403940886699507, train_loss: 0.4209695193911954, val_loss: 1.314115210560155 (54 / 100)
train_acc: 0.8776266996291718, val_acc: 0.5517241379310345, train_loss: 0.3261669782831878, val_loss: 1.4651242383007932 (55 / 100)
train_acc: 0.8850432632880099, val_acc: 0.6157635467980296, train_loss: 0.33607612227922024, val_loss: 1.261197113344822 (56 / 100)
train_acc: 0.8974042027194067, val_acc: 0.625615763546798, train_loss: 0.29895521875364967, val_loss: 1.149796444757525 (57 / 100)
train_acc: 0.8776266996291718, val_acc: 0.5566502463054187, train_loss: 0.3144294904690001, val_loss: 1.4508782267166769 (58 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5862068965517241, train_loss: 0.32623690609878897, val_loss: 1.8958760681997966 (59 / 100)
train_acc: 0.8813349814585909, val_acc: 0.6157635467980296, train_loss: 0.30632985920192873, val_loss: 1.582964019748965 (60 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6650246305418719, train_loss: 0.16110153162877255, val_loss: 1.350961731132028 (61 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.09579297992296065, val_loss: 1.4021153918334417 (62 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6600985221674877, train_loss: 0.12877923301772223, val_loss: 1.4032429816394016 (63 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6748768472906403, train_loss: 0.10917304870666768, val_loss: 1.4977097076735473 (64 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.08628666784029514, val_loss: 1.461474534913237 (65 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6650246305418719, train_loss: 0.08881436496494137, val_loss: 1.507705717985266 (66 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6847290640394089, train_loss: 0.08418719199738191, val_loss: 1.5235966332440305 (67 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6847290640394089, train_loss: 0.05872689881931866, val_loss: 1.5819440406237917 (68 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6896551724137931, train_loss: 0.0632476737384301, val_loss: 1.6254350657533543 (69 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6896551724137931, train_loss: 0.08329657998456354, val_loss: 1.592039326582049 (70 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6896551724137931, train_loss: 0.06522140632601102, val_loss: 1.6379939700875963 (71 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.042329181699434525, val_loss: 1.7408821667943681 (72 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6699507389162561, train_loss: 0.06707940275501115, val_loss: 1.72185030843824 (73 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6798029556650246, train_loss: 0.03790702483857371, val_loss: 1.8063944475404148 (74 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6699507389162561, train_loss: 0.04689016639817925, val_loss: 1.794878368013598 (75 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6847290640394089, train_loss: 0.03541297965645053, val_loss: 1.8559380866623865 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6847290640394089, train_loss: 0.05320910779743171, val_loss: 1.8426982640045617 (77 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6847290640394089, train_loss: 0.03165657101809168, val_loss: 1.9318973580604704 (78 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6847290640394089, train_loss: 0.060489077797926255, val_loss: 1.8916374800240465 (79 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6896551724137931, train_loss: 0.03958811202951061, val_loss: 1.8726468064221256 (80 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6847290640394089, train_loss: 0.052141608944340015, val_loss: 1.8970764684559676 (81 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.03945834571852525, val_loss: 1.9266482058710652 (82 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6798029556650246, train_loss: 0.04536235288282849, val_loss: 1.9839103304106613 (83 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6847290640394089, train_loss: 0.03149326062762398, val_loss: 1.953515360508059 (84 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6748768472906403, train_loss: 0.03299798717899582, val_loss: 1.9587377562311483 (85 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6945812807881774, train_loss: 0.040221495887699764, val_loss: 2.044234804038344 (86 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6798029556650246, train_loss: 0.043781126238064946, val_loss: 2.033209960448918 (87 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6847290640394089, train_loss: 0.0581943642518429, val_loss: 1.9890052411943822 (88 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6945812807881774, train_loss: 0.030604020184727916, val_loss: 2.020433465835496 (89 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6847290640394089, train_loss: 0.05794573198584897, val_loss: 2.015761215992162 (90 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6798029556650246, train_loss: 0.037414426414574625, val_loss: 2.0902163991199925 (91 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6551724137931034, train_loss: 0.0654483939278111, val_loss: 2.0587359264566394 (92 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6748768472906403, train_loss: 0.03401942011452429, val_loss: 2.0561035771675296 (93 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6847290640394089, train_loss: 0.0377545067936882, val_loss: 2.0651958429167423 (94 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6896551724137931, train_loss: 0.027827624779549164, val_loss: 2.13892070706842 (95 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6847290640394089, train_loss: 0.0451092369329502, val_loss: 2.1509391233838837 (96 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6896551724137931, train_loss: 0.025758693480521108, val_loss: 2.19567796602625 (97 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6748768472906403, train_loss: 0.03419968047454419, val_loss: 2.1407214247534427 (98 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6748768472906403, train_loss: 0.027064158094238733, val_loss: 2.201522688266679 (99 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6945812807881774, train_loss: 0.026081521667272994, val_loss: 2.211726987596803 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.05}), val accuracy 0.6945812807881774, val loss 2.044234804038344
train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.7889496279588, val_loss: 1.7800333223906644 (1 / 100)
train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7748192591484457, val_loss: 1.7531231800323637 (2 / 100)
train_acc: 0.19530284301606923, val_acc: 0.270935960591133, train_loss: 1.747836526156356, val_loss: 1.7366105817221655 (3 / 100)
train_acc: 0.23485784919653893, val_acc: 0.270935960591133, train_loss: 1.7376674032034478, val_loss: 1.7089036327277498 (4 / 100)
train_acc: 0.27441285537700866, val_acc: 0.3251231527093596, train_loss: 1.7236348256487193, val_loss: 1.6755186507267317 (5 / 100)
train_acc: 0.2620519159456119, val_acc: 0.26108374384236455, train_loss: 1.6988744387962615, val_loss: 1.6584452461139323 (6 / 100)
train_acc: 0.27812113720642767, val_acc: 0.35467980295566504, train_loss: 1.6757261935801087, val_loss: 1.632284534975813 (7 / 100)
train_acc: 0.29666254635352285, val_acc: 0.24630541871921183, train_loss: 1.6801014871915574, val_loss: 1.7764696064840984 (8 / 100)
train_acc: 0.32138442521631644, val_acc: 0.33004926108374383, train_loss: 1.6491533056619878, val_loss: 1.6721160024257715 (9 / 100)
train_acc: 0.3300370828182942, val_acc: 0.3448275862068966, train_loss: 1.6319639149348728, val_loss: 1.5286328616400657 (10 / 100)
train_acc: 0.3473423980222497, val_acc: 0.3399014778325123, train_loss: 1.5911004382688714, val_loss: 1.498300528291411 (11 / 100)
train_acc: 0.35599505562422745, val_acc: 0.33497536945812806, train_loss: 1.5623125502441368, val_loss: 1.7457385750239707 (12 / 100)
train_acc: 0.3819530284301607, val_acc: 0.4236453201970443, train_loss: 1.5298005002096056, val_loss: 1.446173087129452 (13 / 100)
train_acc: 0.38442521631644005, val_acc: 0.3645320197044335, train_loss: 1.5142464761533607, val_loss: 1.4684999529364073 (14 / 100)
train_acc: 0.4054388133498146, val_acc: 0.32019704433497537, train_loss: 1.4517237011375475, val_loss: 1.5355336466446299 (15 / 100)
train_acc: 0.3794808405438813, val_acc: 0.3399014778325123, train_loss: 1.4445522899828087, val_loss: 1.4477795074725974 (16 / 100)
train_acc: 0.377008652657602, val_acc: 0.39901477832512317, train_loss: 1.4308560304205555, val_loss: 1.3171497078364707 (17 / 100)
train_acc: 0.40914709517923364, val_acc: 0.41379310344827586, train_loss: 1.3701100240384398, val_loss: 1.3340382722798239 (18 / 100)
train_acc: 0.40914709517923364, val_acc: 0.4433497536945813, train_loss: 1.380042527161069, val_loss: 1.319663649122116 (19 / 100)
train_acc: 0.40667490729295425, val_acc: 0.458128078817734, train_loss: 1.3812059392445757, val_loss: 1.278676225634044 (20 / 100)
train_acc: 0.4326328800988875, val_acc: 0.43349753694581283, train_loss: 1.3447421758224996, val_loss: 1.2431240627918336 (21 / 100)
train_acc: 0.42027194066749074, val_acc: 0.43842364532019706, train_loss: 1.3137700021340615, val_loss: 1.263827929355828 (22 / 100)
train_acc: 0.4326328800988875, val_acc: 0.46798029556650245, train_loss: 1.3034550256575879, val_loss: 1.2621520634355217 (23 / 100)
train_acc: 0.44870210135970334, val_acc: 0.4630541871921182, train_loss: 1.2771644104543811, val_loss: 1.270727871967654 (24 / 100)
train_acc: 0.44870210135970334, val_acc: 0.45320197044334976, train_loss: 1.259386179031636, val_loss: 1.19984301234701 (25 / 100)
train_acc: 0.4573547589616811, val_acc: 0.47783251231527096, train_loss: 1.244576970490596, val_loss: 1.2311734654046045 (26 / 100)
train_acc: 0.4561186650185414, val_acc: 0.46798029556650245, train_loss: 1.2380005508771785, val_loss: 1.2946494298028242 (27 / 100)
train_acc: 0.4820766378244747, val_acc: 0.4729064039408867, train_loss: 1.2144952168128693, val_loss: 1.2106932736382696 (28 / 100)
train_acc: 0.4919653893695921, val_acc: 0.4482758620689655, train_loss: 1.2311013951731848, val_loss: 1.2215823554640333 (29 / 100)
train_acc: 0.5018541409147095, val_acc: 0.49261083743842365, train_loss: 1.1833498251010814, val_loss: 1.1803533605166845 (30 / 100)
train_acc: 0.5327564894932015, val_acc: 0.49261083743842365, train_loss: 1.1121592722068758, val_loss: 1.6036221012106082 (31 / 100)
train_acc: 0.49938195302843014, val_acc: 0.5320197044334976, train_loss: 1.1574276091878581, val_loss: 1.1040639313570972 (32 / 100)
train_acc: 0.546353522867738, val_acc: 0.4876847290640394, train_loss: 1.0970585045620007, val_loss: 1.0959452299648904 (33 / 100)
train_acc: 0.5525339925834364, val_acc: 0.5320197044334976, train_loss: 1.0829835829540295, val_loss: 1.111041525901832 (34 / 100)
train_acc: 0.553770086526576, val_acc: 0.5221674876847291, train_loss: 1.061016086300165, val_loss: 1.2004921301245102 (35 / 100)
train_acc: 0.5970333745364648, val_acc: 0.4729064039408867, train_loss: 0.9948812745262872, val_loss: 1.3215184076666244 (36 / 100)
train_acc: 0.5760197775030902, val_acc: 0.4975369458128079, train_loss: 1.0154522801801211, val_loss: 1.166816625101813 (37 / 100)
train_acc: 0.6118665018541409, val_acc: 0.5221674876847291, train_loss: 0.9592080083854119, val_loss: 1.2887088694595938 (38 / 100)
train_acc: 0.6390605686032138, val_acc: 0.5024630541871922, train_loss: 0.9104339062651834, val_loss: 1.1302996703556605 (39 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5517241379310345, train_loss: 0.9651780266991652, val_loss: 1.1694407046134836 (40 / 100)
train_acc: 0.630407911001236, val_acc: 0.5467980295566502, train_loss: 0.8918682335333712, val_loss: 1.1655441763365797 (41 / 100)
train_acc: 0.6477132262051916, val_acc: 0.5517241379310345, train_loss: 0.8664556778552948, val_loss: 1.2363171448261279 (42 / 100)
train_acc: 0.6996291718170581, val_acc: 0.5320197044334976, train_loss: 0.7773836641877484, val_loss: 1.1245587697170052 (43 / 100)
train_acc: 0.7169344870210136, val_acc: 0.5172413793103449, train_loss: 0.7561611212670287, val_loss: 1.4636281681765477 (44 / 100)
train_acc: 0.7021013597033374, val_acc: 0.5763546798029556, train_loss: 0.729866217181768, val_loss: 1.6157425677247823 (45 / 100)
train_acc: 0.7144622991347342, val_acc: 0.5812807881773399, train_loss: 0.6866971155621655, val_loss: 1.1598355229852235 (46 / 100)
train_acc: 0.7255871446229913, val_acc: 0.6108374384236454, train_loss: 0.7169032515347814, val_loss: 1.44140797530489 (47 / 100)
train_acc: 0.761433868974042, val_acc: 0.5862068965517241, train_loss: 0.6301876626291735, val_loss: 1.2537730121847444 (48 / 100)
train_acc: 0.7935723114956736, val_acc: 0.5812807881773399, train_loss: 0.554832505207274, val_loss: 1.4372420793977276 (49 / 100)
train_acc: 0.792336217552534, val_acc: 0.6305418719211823, train_loss: 0.562624884624269, val_loss: 1.3481287307339935 (50 / 100)
train_acc: 0.7985166872682324, val_acc: 0.6945812807881774, train_loss: 0.5788733430197566, val_loss: 1.1138744528951317 (51 / 100)
train_acc: 0.8603213844252163, val_acc: 0.6650246305418719, train_loss: 0.39347097723386787, val_loss: 1.2390679270763116 (52 / 100)
train_acc: 0.8257107540173053, val_acc: 0.6896551724137931, train_loss: 0.45077589828387477, val_loss: 1.3054344957978854 (53 / 100)
train_acc: 0.8479604449938195, val_acc: 0.6896551724137931, train_loss: 0.3871512124211296, val_loss: 0.8811898483651612 (54 / 100)
train_acc: 0.8133498145859085, val_acc: 0.7192118226600985, train_loss: 0.47643648266644945, val_loss: 0.8887551628016486 (55 / 100)
train_acc: 0.8145859085290482, val_acc: 0.7044334975369458, train_loss: 0.5140024846504881, val_loss: 1.1341201789365174 (56 / 100)
train_acc: 0.8850432632880099, val_acc: 0.7044334975369458, train_loss: 0.3205979477489834, val_loss: 1.2970165995000105 (57 / 100)
train_acc: 0.8677379480840544, val_acc: 0.7241379310344828, train_loss: 0.3576968093442976, val_loss: 0.9480068249068236 (58 / 100)
train_acc: 0.9097651421508035, val_acc: 0.729064039408867, train_loss: 0.24201117163093483, val_loss: 0.9602165140138177 (59 / 100)
train_acc: 0.899876390605686, val_acc: 0.729064039408867, train_loss: 0.2737009121549439, val_loss: 1.1889483858211873 (60 / 100)
train_acc: 0.9480840543881335, val_acc: 0.7389162561576355, train_loss: 0.14380855672291684, val_loss: 1.0749129908471344 (61 / 100)
train_acc: 0.965389369592089, val_acc: 0.7635467980295566, train_loss: 0.09907617350885983, val_loss: 1.144101327275995 (62 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7339901477832512, train_loss: 0.084343418497385, val_loss: 1.2040418133901185 (63 / 100)
train_acc: 0.969097651421508, val_acc: 0.7536945812807881, train_loss: 0.10664961349831523, val_loss: 1.1659016456555924 (64 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7586206896551724, train_loss: 0.07659363275110648, val_loss: 1.3449772919328618 (65 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7536945812807881, train_loss: 0.06806657606061221, val_loss: 1.321014214034096 (66 / 100)
train_acc: 0.9752781211372065, val_acc: 0.7487684729064039, train_loss: 0.08000877982164342, val_loss: 1.2880198239105676 (67 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7339901477832512, train_loss: 0.06375121510367752, val_loss: 1.5233858935351443 (68 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7536945812807881, train_loss: 0.058353457963658206, val_loss: 1.397391493092727 (69 / 100)
train_acc: 0.9777503090234858, val_acc: 0.7635467980295566, train_loss: 0.06079511943057971, val_loss: 1.3441705233956518 (70 / 100)
train_acc: 0.9826946847960445, val_acc: 0.7438423645320197, train_loss: 0.06528389512829491, val_loss: 1.3807267907782104 (71 / 100)
train_acc: 0.9789864029666254, val_acc: 0.7733990147783252, train_loss: 0.05599593011056832, val_loss: 1.3772794389971097 (72 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7586206896551724, train_loss: 0.041741705058679, val_loss: 1.4461388282582228 (73 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7389162561576355, train_loss: 0.05133129904974524, val_loss: 1.4364201494038398 (74 / 100)
train_acc: 0.969097651421508, val_acc: 0.7684729064039408, train_loss: 0.07606843640689355, val_loss: 1.4596071442901133 (75 / 100)
train_acc: 0.9826946847960445, val_acc: 0.7635467980295566, train_loss: 0.05512058558069142, val_loss: 1.3893434942557747 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.7733990147783252, train_loss: 0.04447895796838296, val_loss: 1.4430352290885826 (77 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7635467980295566, train_loss: 0.05665326221616955, val_loss: 1.468949444775511 (78 / 100)
train_acc: 0.9826946847960445, val_acc: 0.7635467980295566, train_loss: 0.042996695074074345, val_loss: 1.5528474770178973 (79 / 100)
train_acc: 0.9888751545117429, val_acc: 0.7536945812807881, train_loss: 0.03600116109081782, val_loss: 1.6141879781713626 (80 / 100)
train_acc: 0.9851668726823238, val_acc: 0.7586206896551724, train_loss: 0.049370659885948756, val_loss: 1.6297817488632216 (81 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7536945812807881, train_loss: 0.046560564795589565, val_loss: 1.6274351768259858 (82 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7635467980295566, train_loss: 0.05520885320764832, val_loss: 1.5210980053605705 (83 / 100)
train_acc: 0.9740420271940667, val_acc: 0.7684729064039408, train_loss: 0.06961189168050645, val_loss: 1.4223297288253665 (84 / 100)
train_acc: 0.9888751545117429, val_acc: 0.7635467980295566, train_loss: 0.04245850108609948, val_loss: 1.5603749317482911 (85 / 100)
train_acc: 0.9864029666254636, val_acc: 0.7536945812807881, train_loss: 0.04388283430719552, val_loss: 1.5842882612057196 (86 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7487684729064039, train_loss: 0.05000313516010902, val_loss: 1.6023584445709078 (87 / 100)
train_acc: 0.9864029666254636, val_acc: 0.7586206896551724, train_loss: 0.054288118967167086, val_loss: 1.5072848691141665 (88 / 100)
train_acc: 0.9864029666254636, val_acc: 0.7881773399014779, train_loss: 0.03999518036694992, val_loss: 1.4585814757887365 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.7438423645320197, train_loss: 0.040695895665360915, val_loss: 1.622004133139925 (90 / 100)
train_acc: 0.9901112484548825, val_acc: 0.7586206896551724, train_loss: 0.03303995444836516, val_loss: 1.696470892487789 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.7586206896551724, train_loss: 0.028714560607749837, val_loss: 1.650479727777368 (92 / 100)
train_acc: 0.9901112484548825, val_acc: 0.7536945812807881, train_loss: 0.031218970809200934, val_loss: 1.6241967173051226 (93 / 100)
train_acc: 0.9851668726823238, val_acc: 0.7487684729064039, train_loss: 0.04413421663866644, val_loss: 1.6703620473742415 (94 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7684729064039408, train_loss: 0.0497997165168319, val_loss: 1.6266447710873457 (95 / 100)
train_acc: 0.992583436341162, val_acc: 0.7684729064039408, train_loss: 0.025648481324222976, val_loss: 1.6730464925908362 (96 / 100)
train_acc: 0.9950556242274413, val_acc: 0.7586206896551724, train_loss: 0.018307454211750195, val_loss: 1.7491484393039947 (97 / 100)
train_acc: 0.9888751545117429, val_acc: 0.7487684729064039, train_loss: 0.038959158660454865, val_loss: 1.6877418198609717 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.7536945812807881, train_loss: 0.022920505520145146, val_loss: 1.7289325897329546 (99 / 100)
train_acc: 0.9876390605686032, val_acc: 0.7536945812807881, train_loss: 0.03307222362207099, val_loss: 1.7269403288511358 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7881773399014779, val loss 1.4585814757887365
train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.788083481552869, val_loss: 1.7794052362442017 (1 / 100)
train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7739495609245726, val_loss: 1.7567571530788404 (2 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7661358731049395, val_loss: 1.7451883413521527 (3 / 100)
train_acc: 0.20519159456118666, val_acc: 0.1921182266009852, train_loss: 1.7480334948255636, val_loss: 1.7207185646583294 (4 / 100)
train_acc: 0.2657601977750309, val_acc: 0.24630541871921183, train_loss: 1.728045602958783, val_loss: 1.6936405773820549 (5 / 100)
train_acc: 0.2954264524103832, val_acc: 0.3497536945812808, train_loss: 1.656259303187263, val_loss: 1.5592437148681415 (6 / 100)
train_acc: 0.32756489493201485, val_acc: 0.2512315270935961, train_loss: 1.604930846888586, val_loss: 1.8252836876902088 (7 / 100)
train_acc: 0.25339925834363414, val_acc: 0.32019704433497537, train_loss: 1.7550809328871397, val_loss: 1.6349977489762706 (8 / 100)
train_acc: 0.33250927070457353, val_acc: 0.3694581280788177, train_loss: 1.6046350795052697, val_loss: 1.5011434813438378 (9 / 100)
train_acc: 0.3547589616810878, val_acc: 0.35960591133004927, train_loss: 1.5574194189939274, val_loss: 1.4550898732810185 (10 / 100)
train_acc: 0.34981458590852904, val_acc: 0.3645320197044335, train_loss: 1.4938443361312999, val_loss: 1.4640404960792053 (11 / 100)
train_acc: 0.36341161928306553, val_acc: 0.3793103448275862, train_loss: 1.4734424454320052, val_loss: 1.536668906070916 (12 / 100)
train_acc: 0.34610630407911, val_acc: 0.33497536945812806, train_loss: 1.4723004059974283, val_loss: 1.4708837329460482 (13 / 100)
train_acc: 0.3943139678615575, val_acc: 0.3891625615763547, train_loss: 1.4485957351396936, val_loss: 1.3464317257181178 (14 / 100)
train_acc: 0.3584672435105068, val_acc: 0.4039408866995074, train_loss: 1.4681017672912446, val_loss: 1.4385286041081244 (15 / 100)
train_acc: 0.35970333745364647, val_acc: 0.3891625615763547, train_loss: 1.418681764484778, val_loss: 1.3267535505623653 (16 / 100)
train_acc: 0.3943139678615575, val_acc: 0.41379310344827586, train_loss: 1.4326139333368968, val_loss: 1.2973465743323265 (17 / 100)
train_acc: 0.41656365883807167, val_acc: 0.39901477832512317, train_loss: 1.3726817400405376, val_loss: 1.4327064599896886 (18 / 100)
train_acc: 0.4042027194066749, val_acc: 0.4236453201970443, train_loss: 1.3946013108761555, val_loss: 1.2935544513716486 (19 / 100)
train_acc: 0.40914709517923364, val_acc: 0.43349753694581283, train_loss: 1.3554971400827942, val_loss: 1.2856645537127416 (20 / 100)
train_acc: 0.40173053152039556, val_acc: 0.4039408866995074, train_loss: 1.3489083856233708, val_loss: 1.343585417775685 (21 / 100)
train_acc: 0.4388133498145859, val_acc: 0.39901477832512317, train_loss: 1.301369465178406, val_loss: 1.3239540877600608 (22 / 100)
train_acc: 0.4326328800988875, val_acc: 0.4236453201970443, train_loss: 1.3161172412971336, val_loss: 1.3433749775581172 (23 / 100)
train_acc: 0.4227441285537701, val_acc: 0.47783251231527096, train_loss: 1.316234576245321, val_loss: 1.2776202280533138 (24 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4236453201970443, train_loss: 1.2728601885667101, val_loss: 1.2876566360736716 (25 / 100)
train_acc: 0.4363411619283066, val_acc: 0.43349753694581283, train_loss: 1.2976937565137487, val_loss: 1.243563350198304 (26 / 100)
train_acc: 0.46971569839307786, val_acc: 0.45320197044334976, train_loss: 1.2442362760878611, val_loss: 1.2662556793889388 (27 / 100)
train_acc: 0.5092707045735476, val_acc: 0.4187192118226601, train_loss: 1.2060098771848549, val_loss: 1.266482593684361 (28 / 100)
train_acc: 0.4894932014833127, val_acc: 0.4827586206896552, train_loss: 1.207207947048475, val_loss: 1.2328671845309254 (29 / 100)
train_acc: 0.5018541409147095, val_acc: 0.41379310344827586, train_loss: 1.1943746371970632, val_loss: 1.3309064234418821 (30 / 100)
train_acc: 0.4684796044499382, val_acc: 0.45320197044334976, train_loss: 1.1930965543235335, val_loss: 1.2274563318402896 (31 / 100)
train_acc: 0.5142150803461063, val_acc: 0.5024630541871922, train_loss: 1.1510804088507653, val_loss: 1.1953109957901715 (32 / 100)
train_acc: 0.5006180469715699, val_acc: 0.45320197044334976, train_loss: 1.1362055376522031, val_loss: 1.1740729151100948 (33 / 100)
train_acc: 0.5327564894932015, val_acc: 0.47783251231527096, train_loss: 1.1088294057527786, val_loss: 1.168557384918476 (34 / 100)
train_acc: 0.5278121137206427, val_acc: 0.4630541871921182, train_loss: 1.1379133252189835, val_loss: 1.3773210430380158 (35 / 100)
train_acc: 0.5599505562422744, val_acc: 0.47783251231527096, train_loss: 1.0674920481421302, val_loss: 1.217021585978898 (36 / 100)
train_acc: 0.5624227441285538, val_acc: 0.4482758620689655, train_loss: 1.0482463509544306, val_loss: 1.1538682480163762 (37 / 100)
train_acc: 0.5871446229913473, val_acc: 0.5024630541871922, train_loss: 1.0274114119549764, val_loss: 1.191228659575796 (38 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5073891625615764, train_loss: 0.9751249958469782, val_loss: 1.2490725552507222 (39 / 100)
train_acc: 0.5784919653893696, val_acc: 0.4975369458128079, train_loss: 1.0448611232052627, val_loss: 1.1747870724189458 (40 / 100)
train_acc: 0.6044499381953028, val_acc: 0.5172413793103449, train_loss: 0.962414650304061, val_loss: 1.1069483351824907 (41 / 100)
train_acc: 0.6205191594561187, val_acc: 0.5221674876847291, train_loss: 0.939365976083706, val_loss: 1.1358367706754524 (42 / 100)
train_acc: 0.6291718170580964, val_acc: 0.49261083743842365, train_loss: 0.9271619166667735, val_loss: 1.2149256955226655 (43 / 100)
train_acc: 0.6847960444993819, val_acc: 0.458128078817734, train_loss: 0.8568331144648812, val_loss: 1.2447290960791075 (44 / 100)
train_acc: 0.6563658838071693, val_acc: 0.5123152709359606, train_loss: 0.8480493382853542, val_loss: 1.4516727225533848 (45 / 100)
train_acc: 0.6266996291718171, val_acc: 0.4827586206896552, train_loss: 0.8744054107347731, val_loss: 1.2037064312714074 (46 / 100)
train_acc: 0.7107540173053152, val_acc: 0.5615763546798029, train_loss: 0.7231251966525951, val_loss: 1.1970558022630626 (47 / 100)
train_acc: 0.6983930778739185, val_acc: 0.5270935960591133, train_loss: 0.7429420299671489, val_loss: 1.198431631027184 (48 / 100)
train_acc: 0.7206427688504327, val_acc: 0.5369458128078818, train_loss: 0.7258271475510191, val_loss: 1.2853256560898767 (49 / 100)
train_acc: 0.7292954264524104, val_acc: 0.5320197044334976, train_loss: 0.6655470527736159, val_loss: 1.3545145424715992 (50 / 100)
train_acc: 0.7441285537700866, val_acc: 0.541871921182266, train_loss: 0.6568220536994698, val_loss: 1.2007778407317664 (51 / 100)
train_acc: 0.7713226205191595, val_acc: 0.5467980295566502, train_loss: 0.6381576618246448, val_loss: 1.261301846339785 (52 / 100)
train_acc: 0.7676143386897404, val_acc: 0.5369458128078818, train_loss: 0.5913115750137159, val_loss: 1.2279667560690142 (53 / 100)
train_acc: 0.8244746600741656, val_acc: 0.5714285714285714, train_loss: 0.5051581186181388, val_loss: 1.3932442823654325 (54 / 100)
train_acc: 0.8108776266996292, val_acc: 0.5911330049261084, train_loss: 0.48850205374883926, val_loss: 1.3493724080729368 (55 / 100)
train_acc: 0.8207663782447466, val_acc: 0.5517241379310345, train_loss: 0.46454045990636234, val_loss: 1.2099139044437501 (56 / 100)
train_acc: 0.826946847960445, val_acc: 0.5862068965517241, train_loss: 0.4903829071224104, val_loss: 1.2668307174015514 (57 / 100)
train_acc: 0.8702101359703337, val_acc: 0.5812807881773399, train_loss: 0.351862191711869, val_loss: 1.5940282262604812 (58 / 100)
train_acc: 0.8529048207663782, val_acc: 0.5517241379310345, train_loss: 0.3841112302466582, val_loss: 1.469462747020381 (59 / 100)
train_acc: 0.8665018541409147, val_acc: 0.5369458128078818, train_loss: 0.34729567136988504, val_loss: 1.7992617884292978 (60 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5024630541871922, train_loss: 0.34682737307436534, val_loss: 1.5870454757671637 (61 / 100)
train_acc: 0.8739184177997528, val_acc: 0.5960591133004927, train_loss: 0.33284193638376014, val_loss: 1.811870755233201 (62 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5517241379310345, train_loss: 0.3509829707434505, val_loss: 1.2761704795466269 (63 / 100)
train_acc: 0.92336217552534, val_acc: 0.5665024630541872, train_loss: 0.2101727435261711, val_loss: 1.7328616175158271 (64 / 100)
train_acc: 0.9147095179233622, val_acc: 0.5665024630541872, train_loss: 0.24552160670937065, val_loss: 1.7538727163681256 (65 / 100)
train_acc: 0.9110012360939431, val_acc: 0.5714285714285714, train_loss: 0.22989320298207852, val_loss: 1.3481312091714643 (66 / 100)
train_acc: 0.9208899876390606, val_acc: 0.5862068965517241, train_loss: 0.25582591815401506, val_loss: 1.6102089206573411 (67 / 100)
train_acc: 0.9320148331273177, val_acc: 0.5714285714285714, train_loss: 0.1879903221012488, val_loss: 1.6359603278742636 (68 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6059113300492611, train_loss: 0.17250519777257894, val_loss: 1.7618624330154193 (69 / 100)
train_acc: 0.9283065512978986, val_acc: 0.6009852216748769, train_loss: 0.19590604010559573, val_loss: 1.545312479799017 (70 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6059113300492611, train_loss: 0.20260634115806175, val_loss: 1.6867671849692396 (71 / 100)
train_acc: 0.9208899876390606, val_acc: 0.5714285714285714, train_loss: 0.24691771576814214, val_loss: 1.4878473343520329 (72 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6157635467980296, train_loss: 0.14709577734302384, val_loss: 2.4393440866705234 (73 / 100)
train_acc: 0.9357231149567367, val_acc: 0.6059113300492611, train_loss: 0.1691479131818849, val_loss: 1.95808719414323 (74 / 100)
train_acc: 0.9604449938195303, val_acc: 0.5665024630541872, train_loss: 0.12111381856708503, val_loss: 2.796833932106131 (75 / 100)
train_acc: 0.9332509270704573, val_acc: 0.6108374384236454, train_loss: 0.17284953962592467, val_loss: 2.566387555869342 (76 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6354679802955665, train_loss: 0.14333126232562166, val_loss: 1.9400904360663127 (77 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6108374384236454, train_loss: 0.1715308342345418, val_loss: 1.9909913986187262 (78 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6551724137931034, train_loss: 0.081003662534933, val_loss: 2.16831288314218 (79 / 100)
train_acc: 0.9456118665018541, val_acc: 0.5467980295566502, train_loss: 0.16362609600991343, val_loss: 1.9574636285528173 (80 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6206896551724138, train_loss: 0.12790579347881606, val_loss: 2.2849272072608837 (81 / 100)
train_acc: 0.9777503090234858, val_acc: 0.625615763546798, train_loss: 0.07051708435982797, val_loss: 2.606735123789369 (82 / 100)
train_acc: 0.9443757725587144, val_acc: 0.6354679802955665, train_loss: 0.18710586771240045, val_loss: 1.9042406058663806 (83 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6157635467980296, train_loss: 0.1329956047319806, val_loss: 2.10610840473269 (84 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6305418719211823, train_loss: 0.1260688520037789, val_loss: 2.14588014252961 (85 / 100)
train_acc: 0.9555006180469716, val_acc: 0.5566502463054187, train_loss: 0.12658566921691516, val_loss: 2.5848834831726375 (86 / 100)
train_acc: 0.969097651421508, val_acc: 0.5812807881773399, train_loss: 0.09051838793477553, val_loss: 2.747852241024008 (87 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6009852216748769, train_loss: 0.13416881805886738, val_loss: 1.7155116861089696 (88 / 100)
train_acc: 0.9777503090234858, val_acc: 0.5665024630541872, train_loss: 0.08109358199889345, val_loss: 2.2980349451450293 (89 / 100)
train_acc: 0.969097651421508, val_acc: 0.6108374384236454, train_loss: 0.08704806081444136, val_loss: 2.7168934773929014 (90 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6305418719211823, train_loss: 0.05998926374909315, val_loss: 2.6145910652987476 (91 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6354679802955665, train_loss: 0.09205765246755555, val_loss: 2.4295268634269975 (92 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6108374384236454, train_loss: 0.10443388590559234, val_loss: 2.206275883272951 (93 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.0578558671901783, val_loss: 2.326340368815831 (94 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6403940886699507, train_loss: 0.09521429087823931, val_loss: 2.251922747478109 (95 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6206896551724138, train_loss: 0.09223244113592047, val_loss: 2.0020730636389974 (96 / 100)
train_acc: 0.9666254635352287, val_acc: 0.5862068965517241, train_loss: 0.093542801582327, val_loss: 2.6832896283107437 (97 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6354679802955665, train_loss: 0.08887104389841388, val_loss: 2.6229788164787107 (98 / 100)
train_acc: 0.9715698393077874, val_acc: 0.5615763546798029, train_loss: 0.0856619140568416, val_loss: 2.62710353203595 (99 / 100)
train_acc: 0.957972805933251, val_acc: 0.6650246305418719, train_loss: 0.130927194476275, val_loss: 1.4194094899839955 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.6650246305418719, val loss 1.4194094899839955
train_acc: 0.1792336217552534, val_acc: 0.21182266009852216, train_loss: 1.7866980400309427, val_loss: 1.7739119177381393 (1 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7706165101531115, val_loss: 1.7576087096641804 (2 / 100)
train_acc: 0.20642768850432633, val_acc: 0.2955665024630542, train_loss: 1.7602222705506276, val_loss: 1.7399543124466694 (3 / 100)
train_acc: 0.2521631644004944, val_acc: 0.3054187192118227, train_loss: 1.7478216680224952, val_loss: 1.7204288426291179 (4 / 100)
train_acc: 0.29913473423980225, val_acc: 0.3399014778325123, train_loss: 1.6925727597567886, val_loss: 1.6155736393529205 (5 / 100)
train_acc: 0.32014833127317677, val_acc: 0.32019704433497537, train_loss: 1.6526040494515664, val_loss: 1.5802088089177173 (6 / 100)
train_acc: 0.32014833127317677, val_acc: 0.32019704433497537, train_loss: 1.5744687530991468, val_loss: 1.4983807802200317 (7 / 100)
train_acc: 0.36711990111248455, val_acc: 0.3497536945812808, train_loss: 1.5327776232814907, val_loss: 1.4564790062129205 (8 / 100)
train_acc: 0.3522867737948084, val_acc: 0.3793103448275862, train_loss: 1.5457691117771182, val_loss: 1.488527959790723 (9 / 100)
train_acc: 0.34239802224969096, val_acc: 0.3448275862068966, train_loss: 1.4820476496322783, val_loss: 1.4104032751374644 (10 / 100)
train_acc: 0.37082818294190356, val_acc: 0.37438423645320196, train_loss: 1.4526021591075713, val_loss: 1.3693528010927398 (11 / 100)
train_acc: 0.3695920889987639, val_acc: 0.42857142857142855, train_loss: 1.4357297180314883, val_loss: 1.375034924798411 (12 / 100)
train_acc: 0.4079110012360939, val_acc: 0.43842364532019706, train_loss: 1.4014298002268977, val_loss: 1.3358411618641444 (13 / 100)
train_acc: 0.4103831891223733, val_acc: 0.4482758620689655, train_loss: 1.4025159663116682, val_loss: 1.3794128407398467 (14 / 100)
train_acc: 0.40173053152039556, val_acc: 0.4039408866995074, train_loss: 1.4130325610617036, val_loss: 1.283212755113987 (15 / 100)
train_acc: 0.41409147095179233, val_acc: 0.43349753694581283, train_loss: 1.3373288253623858, val_loss: 1.331716464070851 (16 / 100)
train_acc: 0.4252163164400494, val_acc: 0.46798029556650245, train_loss: 1.3844429633231334, val_loss: 1.3198502662733858 (17 / 100)
train_acc: 0.4177997527812114, val_acc: 0.45320197044334976, train_loss: 1.3360571417731908, val_loss: 1.2806498757724105 (18 / 100)
train_acc: 0.42398022249690975, val_acc: 0.458128078817734, train_loss: 1.345201506455543, val_loss: 1.2671842081793423 (19 / 100)
train_acc: 0.45241038318912236, val_acc: 0.4482758620689655, train_loss: 1.2912411731017388, val_loss: 1.2620063456408497 (20 / 100)
train_acc: 0.449938195302843, val_acc: 0.458128078817734, train_loss: 1.317021275038183, val_loss: 1.222269278441744 (21 / 100)
train_acc: 0.453646477132262, val_acc: 0.458128078817734, train_loss: 1.2782389965870766, val_loss: 1.194553988320487 (22 / 100)
train_acc: 0.4635352286773795, val_acc: 0.4975369458128079, train_loss: 1.2974042855617585, val_loss: 1.2383620060723404 (23 / 100)
train_acc: 0.48702101359703337, val_acc: 0.4876847290640394, train_loss: 1.2645314687262064, val_loss: 1.2533184190101812 (24 / 100)
train_acc: 0.4919653893695921, val_acc: 0.4876847290640394, train_loss: 1.2553545800952888, val_loss: 1.2131791041402393 (25 / 100)
train_acc: 0.46971569839307786, val_acc: 0.458128078817734, train_loss: 1.2481957693182493, val_loss: 1.1994104285545537 (26 / 100)
train_acc: 0.48825710754017304, val_acc: 0.458128078817734, train_loss: 1.181926818506974, val_loss: 1.131723033383562 (27 / 100)
train_acc: 0.5290482076637825, val_acc: 0.47783251231527096, train_loss: 1.1466830988012815, val_loss: 1.1849357606154944 (28 / 100)
train_acc: 0.49938195302843014, val_acc: 0.541871921182266, train_loss: 1.2085756023675756, val_loss: 1.12311108388337 (29 / 100)
train_acc: 0.519159456118665, val_acc: 0.4876847290640394, train_loss: 1.1663778351322829, val_loss: 1.1395077937342264 (30 / 100)
train_acc: 0.5525339925834364, val_acc: 0.5073891625615764, train_loss: 1.1238093585402178, val_loss: 1.1510139451238321 (31 / 100)
train_acc: 0.5377008652657602, val_acc: 0.5024630541871922, train_loss: 1.1393061630216017, val_loss: 1.2189995294134017 (32 / 100)
train_acc: 0.5550061804697157, val_acc: 0.5270935960591133, train_loss: 1.0991925674551644, val_loss: 1.20103268141817 (33 / 100)
train_acc: 0.5834363411619283, val_acc: 0.4729064039408867, train_loss: 1.0374502895494326, val_loss: 1.2118811484040886 (34 / 100)
train_acc: 0.5723114956736712, val_acc: 0.5320197044334976, train_loss: 1.0253033741148205, val_loss: 1.0642565553411474 (35 / 100)
train_acc: 0.6316440049443758, val_acc: 0.541871921182266, train_loss: 0.9528940932270328, val_loss: 1.0891713068403046 (36 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5172413793103449, train_loss: 0.977291912319339, val_loss: 1.1590453486137202 (37 / 100)
train_acc: 0.6143386897404203, val_acc: 0.5172413793103449, train_loss: 0.9514729207466796, val_loss: 1.1857811529648128 (38 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5123152709359606, train_loss: 0.9101444195463277, val_loss: 1.1193950076408574 (39 / 100)
train_acc: 0.6711990111248455, val_acc: 0.5812807881773399, train_loss: 0.8563360227789956, val_loss: 1.06278532185578 (40 / 100)
train_acc: 0.6909765142150803, val_acc: 0.5270935960591133, train_loss: 0.8335702397177924, val_loss: 1.4123526118659033 (41 / 100)
train_acc: 0.681087762669963, val_acc: 0.5763546798029556, train_loss: 0.840991710702922, val_loss: 1.0921685898245261 (42 / 100)
train_acc: 0.7082818294190358, val_acc: 0.5566502463054187, train_loss: 0.7595577265040394, val_loss: 1.2118460961750575 (43 / 100)
train_acc: 0.695920889987639, val_acc: 0.5517241379310345, train_loss: 0.7499677032711185, val_loss: 1.1288850489508342 (44 / 100)
train_acc: 0.723114956736712, val_acc: 0.5517241379310345, train_loss: 0.7233508210836441, val_loss: 1.1951284934147237 (45 / 100)
train_acc: 0.761433868974042, val_acc: 0.5615763546798029, train_loss: 0.6114767399352914, val_loss: 1.0833232341141537 (46 / 100)
train_acc: 0.7725587144622992, val_acc: 0.6059113300492611, train_loss: 0.5984330961229775, val_loss: 1.2505386010766617 (47 / 100)
train_acc: 0.799752781211372, val_acc: 0.5812807881773399, train_loss: 0.5724857890856428, val_loss: 1.4523735886136886 (48 / 100)
train_acc: 0.7873918417799752, val_acc: 0.5960591133004927, train_loss: 0.5017431760747884, val_loss: 1.2238115597828267 (49 / 100)
train_acc: 0.8281829419035847, val_acc: 0.5320197044334976, train_loss: 0.47763825685927835, val_loss: 1.6466735762915587 (50 / 100)
train_acc: 0.6625463535228677, val_acc: 0.6009852216748769, train_loss: 0.9550370505477943, val_loss: 1.1353334435101212 (51 / 100)
train_acc: 0.8108776266996292, val_acc: 0.6108374384236454, train_loss: 0.515754567677954, val_loss: 1.097847932077981 (52 / 100)
train_acc: 0.8566131025957973, val_acc: 0.5270935960591133, train_loss: 0.4032821842412866, val_loss: 1.5982975401901847 (53 / 100)
train_acc: 0.7441285537700866, val_acc: 0.6108374384236454, train_loss: 0.6663224655853951, val_loss: 1.128196856952066 (54 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5714285714285714, train_loss: 0.3366371294476635, val_loss: 1.4552115323801933 (55 / 100)
train_acc: 0.865265760197775, val_acc: 0.5566502463054187, train_loss: 0.3580690697480191, val_loss: 1.2524637436044628 (56 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6206896551724138, train_loss: 0.2898669026248682, val_loss: 1.5209604473830445 (57 / 100)
train_acc: 0.9035846724351051, val_acc: 0.5665024630541872, train_loss: 0.25432710712418716, val_loss: 1.7099188771741143 (58 / 100)
train_acc: 0.907292954264524, val_acc: 0.5714285714285714, train_loss: 0.25606105472013, val_loss: 1.4662507044270707 (59 / 100)
train_acc: 0.9184177997527813, val_acc: 0.5911330049261084, train_loss: 0.22295241936470286, val_loss: 1.4926254167932596 (60 / 100)
train_acc: 0.9493201483312732, val_acc: 0.5960591133004927, train_loss: 0.16356250897915608, val_loss: 1.5538581979685817 (61 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6009852216748769, train_loss: 0.12998017525054026, val_loss: 1.6107402493801024 (62 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6009852216748769, train_loss: 0.10752237550407759, val_loss: 1.6556320830518976 (63 / 100)
train_acc: 0.965389369592089, val_acc: 0.6009852216748769, train_loss: 0.0991528241979177, val_loss: 1.7970600339579466 (64 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6059113300492611, train_loss: 0.11526800793387244, val_loss: 1.834287433788694 (65 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6059113300492611, train_loss: 0.11593285287708523, val_loss: 1.8681436389537867 (66 / 100)
train_acc: 0.965389369592089, val_acc: 0.5862068965517241, train_loss: 0.11256707215633321, val_loss: 1.8896186839183564 (67 / 100)
train_acc: 0.969097651421508, val_acc: 0.6108374384236454, train_loss: 0.07721348466036199, val_loss: 1.9091710838778266 (68 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6206896551724138, train_loss: 0.08556908361696637, val_loss: 1.957100389038988 (69 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6059113300492611, train_loss: 0.07606889408804725, val_loss: 1.9845382421474738 (70 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6206896551724138, train_loss: 0.09211806652719806, val_loss: 2.004260938743065 (71 / 100)
train_acc: 0.969097651421508, val_acc: 0.6157635467980296, train_loss: 0.08722790902565672, val_loss: 2.043281590410054 (72 / 100)
train_acc: 0.965389369592089, val_acc: 0.6305418719211823, train_loss: 0.08151553440447644, val_loss: 2.0875267583161152 (73 / 100)
train_acc: 0.9839307787391842, val_acc: 0.625615763546798, train_loss: 0.05225414398721476, val_loss: 2.0769996895578693 (74 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6206896551724138, train_loss: 0.06254363693619246, val_loss: 2.106550321790385 (75 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6305418719211823, train_loss: 0.0765827238486046, val_loss: 2.0996410647049326 (76 / 100)
train_acc: 0.9740420271940667, val_acc: 0.645320197044335, train_loss: 0.06950069431616143, val_loss: 2.1155947699335407 (77 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6206896551724138, train_loss: 0.07812785483408623, val_loss: 2.1472688719556836 (78 / 100)
train_acc: 0.9728059332509271, val_acc: 0.625615763546798, train_loss: 0.07861048123155742, val_loss: 2.083090516146768 (79 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6206896551724138, train_loss: 0.08051879503228904, val_loss: 2.0977206823273833 (80 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6354679802955665, train_loss: 0.06099306225629318, val_loss: 2.1610156297683716 (81 / 100)
train_acc: 0.969097651421508, val_acc: 0.6157635467980296, train_loss: 0.07737963809660545, val_loss: 2.215587658835162 (82 / 100)
train_acc: 0.9765142150803461, val_acc: 0.625615763546798, train_loss: 0.07123023691519229, val_loss: 2.157601706500124 (83 / 100)
train_acc: 0.9802224969097652, val_acc: 0.625615763546798, train_loss: 0.050670606538892826, val_loss: 2.190193798154446 (84 / 100)
train_acc: 0.9802224969097652, val_acc: 0.625615763546798, train_loss: 0.060779014682887655, val_loss: 2.208410425726416 (85 / 100)
train_acc: 0.969097651421508, val_acc: 0.625615763546798, train_loss: 0.07363038054208083, val_loss: 2.2183727812884477 (86 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6305418719211823, train_loss: 0.07652119962482429, val_loss: 2.1629047211755084 (87 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6354679802955665, train_loss: 0.06474231686374018, val_loss: 2.1821188885590126 (88 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6305418719211823, train_loss: 0.07035674698125889, val_loss: 2.1535142936142795 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.625615763546798, train_loss: 0.048523172901941025, val_loss: 2.2339903069247167 (90 / 100)
train_acc: 0.969097651421508, val_acc: 0.6354679802955665, train_loss: 0.07738092464333854, val_loss: 2.276072575540965 (91 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6403940886699507, train_loss: 0.05694232882911107, val_loss: 2.400708122793677 (92 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6305418719211823, train_loss: 0.05917488084587974, val_loss: 2.304788974705588 (93 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6206896551724138, train_loss: 0.0635368824005127, val_loss: 2.2922068757963885 (94 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6354679802955665, train_loss: 0.06253500686145684, val_loss: 2.3021975127346996 (95 / 100)
train_acc: 0.9864029666254636, val_acc: 0.625615763546798, train_loss: 0.03818650431332394, val_loss: 2.329102596625906 (96 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.0684506426046157, val_loss: 2.36494965682476 (97 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6206896551724138, train_loss: 0.05115126517264009, val_loss: 2.3795724425997054 (98 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6108374384236454, train_loss: 0.06095972520901335, val_loss: 2.374785201890128 (99 / 100)
train_acc: 0.9814585908529048, val_acc: 0.625615763546798, train_loss: 0.05205594285014828, val_loss: 2.3623501755333884 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.05}), val accuracy 0.645320197044335, val loss 2.1155947699335407
train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7869124704297306, val_loss: 1.7794802676280732 (1 / 100)
train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.773596531086416, val_loss: 1.7593273176935507 (2 / 100)
train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7630550594648118, val_loss: 1.7480828474307883 (3 / 100)
train_acc: 0.21755253399258342, val_acc: 0.18226600985221675, train_loss: 1.755222012292322, val_loss: 1.7347424517711396 (4 / 100)
train_acc: 0.23485784919653893, val_acc: 0.22167487684729065, train_loss: 1.7379675693948131, val_loss: 1.7082222359521049 (5 / 100)
train_acc: 0.24351050679851668, val_acc: 0.33497536945812806, train_loss: 1.7132355904549692, val_loss: 1.666670712931403 (6 / 100)
train_acc: 0.29295426452410384, val_acc: 0.32019704433497537, train_loss: 1.6787960072530361, val_loss: 1.626487662639524 (7 / 100)
train_acc: 0.3337453646477132, val_acc: 0.33004926108374383, train_loss: 1.6048054587561063, val_loss: 1.533985801518257 (8 / 100)
train_acc: 0.31025957972805934, val_acc: 0.2955665024630542, train_loss: 1.6193587924405581, val_loss: 1.5822504682493914 (9 / 100)
train_acc: 0.32014833127317677, val_acc: 0.2512315270935961, train_loss: 1.5607170808153188, val_loss: 1.7123981461736368 (10 / 100)
train_acc: 0.34363411619283063, val_acc: 0.32019704433497537, train_loss: 1.5385714141635871, val_loss: 1.5428904024838226 (11 / 100)
train_acc: 0.35599505562422745, val_acc: 0.2857142857142857, train_loss: 1.4603054987632742, val_loss: 1.61329757844286 (12 / 100)
train_acc: 0.35599505562422745, val_acc: 0.4088669950738916, train_loss: 1.4818316001090486, val_loss: 1.352716711941611 (13 / 100)
train_acc: 0.3535228677379481, val_acc: 0.4088669950738916, train_loss: 1.4373639701176044, val_loss: 1.3859694714616673 (14 / 100)
train_acc: 0.38442521631644005, val_acc: 0.3793103448275862, train_loss: 1.430198955889538, val_loss: 1.3631596697375106 (15 / 100)
train_acc: 0.38442521631644005, val_acc: 0.43349753694581283, train_loss: 1.448474900389484, val_loss: 1.340765742832804 (16 / 100)
train_acc: 0.411619283065513, val_acc: 0.43842364532019706, train_loss: 1.3919739664264015, val_loss: 1.4130502575136759 (17 / 100)
train_acc: 0.40296662546353523, val_acc: 0.33497536945812806, train_loss: 1.383072898768082, val_loss: 1.522788278575014 (18 / 100)
train_acc: 0.4079110012360939, val_acc: 0.4236453201970443, train_loss: 1.363873432534292, val_loss: 1.296919466826716 (19 / 100)
train_acc: 0.3695920889987639, val_acc: 0.4187192118226601, train_loss: 1.5566769854542057, val_loss: 1.3512605528526118 (20 / 100)
train_acc: 0.4252163164400494, val_acc: 0.46798029556650245, train_loss: 1.345607307991669, val_loss: 1.2877084510079746 (21 / 100)
train_acc: 0.43139678615574784, val_acc: 0.4482758620689655, train_loss: 1.3304243334586305, val_loss: 1.2484883099353958 (22 / 100)
train_acc: 0.4103831891223733, val_acc: 0.4433497536945813, train_loss: 1.3436687365450581, val_loss: 1.2366104037890882 (23 / 100)
train_acc: 0.43757725587144625, val_acc: 0.4236453201970443, train_loss: 1.3072845732473177, val_loss: 1.2620248031146422 (24 / 100)
train_acc: 0.47095179233621753, val_acc: 0.4827586206896552, train_loss: 1.2579395664931816, val_loss: 1.2192934669297317 (25 / 100)
train_acc: 0.4622991347342398, val_acc: 0.4827586206896552, train_loss: 1.2934347569426736, val_loss: 1.2037759250020745 (26 / 100)
train_acc: 0.4907292954264524, val_acc: 0.5073891625615764, train_loss: 1.2590191875606296, val_loss: 1.239940696749194 (27 / 100)
train_acc: 0.5006180469715699, val_acc: 0.4827586206896552, train_loss: 1.2138866712195322, val_loss: 1.20789910184926 (28 / 100)
train_acc: 0.48331273176761436, val_acc: 0.43349753694581283, train_loss: 1.227568596048909, val_loss: 1.2354595752185202 (29 / 100)
train_acc: 0.48825710754017304, val_acc: 0.49261083743842365, train_loss: 1.192839022472556, val_loss: 1.1542301724109743 (30 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5270935960591133, train_loss: 1.1635743923328716, val_loss: 1.1285381601949043 (31 / 100)
train_acc: 0.5018541409147095, val_acc: 0.5517241379310345, train_loss: 1.145660074149133, val_loss: 1.1199828970608452 (32 / 100)
train_acc: 0.519159456118665, val_acc: 0.4876847290640394, train_loss: 1.128341598770085, val_loss: 1.2742697904849876 (33 / 100)
train_acc: 0.5414091470951793, val_acc: 0.5270935960591133, train_loss: 1.164923594525482, val_loss: 1.24987371743019 (34 / 100)
train_acc: 0.5426452410383189, val_acc: 0.541871921182266, train_loss: 1.0853634966613335, val_loss: 1.1142559042705105 (35 / 100)
train_acc: 0.5587144622991347, val_acc: 0.5024630541871922, train_loss: 1.0238713174874172, val_loss: 1.148946313435221 (36 / 100)
train_acc: 0.5587144622991347, val_acc: 0.541871921182266, train_loss: 1.0497459706623562, val_loss: 1.0937792608890626 (37 / 100)
train_acc: 0.6081582200247219, val_acc: 0.4827586206896552, train_loss: 0.9872299269191709, val_loss: 1.1980580578883882 (38 / 100)
train_acc: 0.6205191594561187, val_acc: 0.5369458128078818, train_loss: 0.9410817906057879, val_loss: 1.1390149701992278 (39 / 100)
train_acc: 0.6440049443757726, val_acc: 0.5665024630541872, train_loss: 0.9061973566472604, val_loss: 1.0436564902660295 (40 / 100)
train_acc: 0.6711990111248455, val_acc: 0.5467980295566502, train_loss: 0.821823381522972, val_loss: 1.2258209935550033 (41 / 100)
train_acc: 0.6637824474660075, val_acc: 0.5714285714285714, train_loss: 0.8287979734253382, val_loss: 1.0563801529959504 (42 / 100)
train_acc: 0.6823238566131026, val_acc: 0.5862068965517241, train_loss: 0.8183329364720028, val_loss: 1.0572070681990073 (43 / 100)
train_acc: 0.7132262051915945, val_acc: 0.5369458128078818, train_loss: 0.7534675904640603, val_loss: 1.2379502149051047 (44 / 100)
train_acc: 0.7095179233621756, val_acc: 0.5615763546798029, train_loss: 0.7708885260064463, val_loss: 1.3876987296372212 (45 / 100)
train_acc: 0.7391841779975278, val_acc: 0.5467980295566502, train_loss: 0.6943037767787504, val_loss: 1.1304418054120293 (46 / 100)
train_acc: 0.7824474660074165, val_acc: 0.5862068965517241, train_loss: 0.6082504886042497, val_loss: 1.1469514305368433 (47 / 100)
train_acc: 0.7564894932014833, val_acc: 0.5862068965517241, train_loss: 0.6449234933582019, val_loss: 1.255113984270049 (48 / 100)
train_acc: 0.7812113720642769, val_acc: 0.5714285714285714, train_loss: 0.5493097944813694, val_loss: 1.2069603093151975 (49 / 100)
train_acc: 0.8009888751545118, val_acc: 0.6108374384236454, train_loss: 0.5268574668686233, val_loss: 1.1763451830506912 (50 / 100)
train_acc: 0.8121137206427689, val_acc: 0.5862068965517241, train_loss: 0.4740670092763064, val_loss: 1.2562560036851855 (51 / 100)
train_acc: 0.8158220024721878, val_acc: 0.645320197044335, train_loss: 0.46436393540928184, val_loss: 1.2549538856069442 (52 / 100)
train_acc: 0.8640296662546354, val_acc: 0.6009852216748769, train_loss: 0.41698370330560636, val_loss: 1.4409185524644523 (53 / 100)
train_acc: 0.8776266996291718, val_acc: 0.625615763546798, train_loss: 0.33565008316110767, val_loss: 1.2698011368953537 (54 / 100)
train_acc: 0.8825710754017305, val_acc: 0.5714285714285714, train_loss: 0.3260173499952583, val_loss: 1.3938808229756472 (55 / 100)
train_acc: 0.8702101359703337, val_acc: 0.6009852216748769, train_loss: 0.33396945777723314, val_loss: 1.3937042123578451 (56 / 100)
train_acc: 0.861557478368356, val_acc: 0.5221674876847291, train_loss: 0.3645185080387978, val_loss: 1.4743546908124914 (57 / 100)
train_acc: 0.8825710754017305, val_acc: 0.5812807881773399, train_loss: 0.33607853726197234, val_loss: 1.197775911521442 (58 / 100)
train_acc: 0.934487021013597, val_acc: 0.6305418719211823, train_loss: 0.24328002131029466, val_loss: 1.3314626563358776 (59 / 100)
train_acc: 0.9110012360939431, val_acc: 0.6157635467980296, train_loss: 0.24696442812718036, val_loss: 1.758120040588191 (60 / 100)
train_acc: 0.9530284301606922, val_acc: 0.5911330049261084, train_loss: 0.11095570206494797, val_loss: 1.6031726692697685 (61 / 100)
train_acc: 0.9715698393077874, val_acc: 0.5960591133004927, train_loss: 0.09053465094053553, val_loss: 1.7353471317901987 (62 / 100)
train_acc: 0.9715698393077874, val_acc: 0.5960591133004927, train_loss: 0.08287731619788925, val_loss: 1.8039172782099306 (63 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6009852216748769, train_loss: 0.06863949384323893, val_loss: 1.8660052991265734 (64 / 100)
train_acc: 0.9728059332509271, val_acc: 0.625615763546798, train_loss: 0.07100584922526469, val_loss: 1.899662966798679 (65 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6157635467980296, train_loss: 0.07902335752220767, val_loss: 1.8192526160789828 (66 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6157635467980296, train_loss: 0.05587584524425794, val_loss: 1.924111419123382 (67 / 100)
train_acc: 0.9752781211372065, val_acc: 0.625615763546798, train_loss: 0.07427373524796682, val_loss: 1.8673137602547707 (68 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6354679802955665, train_loss: 0.07713022957036758, val_loss: 1.8477856461050475 (69 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6403940886699507, train_loss: 0.05635953730499494, val_loss: 1.8669576779962174 (70 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.05381034375415891, val_loss: 1.9614274730823311 (71 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6502463054187192, train_loss: 0.06843508203480536, val_loss: 1.888003379253331 (72 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6403940886699507, train_loss: 0.05921346207042265, val_loss: 1.9353911794465164 (73 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6403940886699507, train_loss: 0.06518050914052391, val_loss: 1.923524358002423 (74 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6403940886699507, train_loss: 0.05200133527017789, val_loss: 1.9608919256426431 (75 / 100)
train_acc: 0.9864029666254636, val_acc: 0.645320197044335, train_loss: 0.04208685293775259, val_loss: 2.0336032060566795 (76 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6650246305418719, train_loss: 0.05274546249540539, val_loss: 2.0542166051019 (77 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6551724137931034, train_loss: 0.03499801123540098, val_loss: 2.0805439614310055 (78 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6354679802955665, train_loss: 0.06788019683069292, val_loss: 2.0654023034232005 (79 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.04739051460483018, val_loss: 2.0677528727818006 (80 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6502463054187192, train_loss: 0.05986047881495378, val_loss: 2.056670405007348 (81 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6650246305418719, train_loss: 0.03643018766150928, val_loss: 2.107788314373035 (82 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.04964418950570086, val_loss: 2.143489781271648 (83 / 100)
train_acc: 0.9826946847960445, val_acc: 0.645320197044335, train_loss: 0.04619652438075345, val_loss: 2.0798249966992532 (84 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6699507389162561, train_loss: 0.04163150999543104, val_loss: 2.107171937162653 (85 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6403940886699507, train_loss: 0.03663861235817814, val_loss: 2.1890276999309144 (86 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.053130314582947306, val_loss: 2.195418787707249 (87 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6502463054187192, train_loss: 0.034912620987674066, val_loss: 2.240079913233301 (88 / 100)
train_acc: 0.9802224969097652, val_acc: 0.645320197044335, train_loss: 0.04793737786367296, val_loss: 2.202258536968325 (89 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6551724137931034, train_loss: 0.0441710195965761, val_loss: 2.2174732808409066 (90 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6502463054187192, train_loss: 0.03598170183202982, val_loss: 2.238557137292007 (91 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6354679802955665, train_loss: 0.05757345699409325, val_loss: 2.1266441445045285 (92 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6551724137931034, train_loss: 0.03779233297694599, val_loss: 2.1363505964795944 (93 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6600985221674877, train_loss: 0.04658201554207631, val_loss: 2.1514119068390043 (94 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.04381996518454534, val_loss: 2.304173370887493 (95 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6551724137931034, train_loss: 0.040676064043316175, val_loss: 2.227174406568405 (96 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6502463054187192, train_loss: 0.02468913417811447, val_loss: 2.319161052774326 (97 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6600985221674877, train_loss: 0.03591703690763457, val_loss: 2.317980657657379 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.6600985221674877, train_loss: 0.03408419290196026, val_loss: 2.3416625337647687 (99 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6551724137931034, train_loss: 0.030351054093746378, val_loss: 2.334578060751478 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6699507389162561, val loss 2.107171937162653
train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.786197695360785, val_loss: 1.7771795254035536 (1 / 100)
train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7731900278511095, val_loss: 1.7594707757968622 (2 / 100)
train_acc: 0.2027194066749073, val_acc: 0.2512315270935961, train_loss: 1.7646228592239588, val_loss: 1.7468475937256085 (3 / 100)
train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7526454536522864, val_loss: 1.7563717048156438 (4 / 100)
train_acc: 0.24351050679851668, val_acc: 0.28078817733990147, train_loss: 1.7300337376199635, val_loss: 1.7006181190753806 (5 / 100)
train_acc: 0.27812113720642767, val_acc: 0.26108374384236455, train_loss: 1.7104909408225117, val_loss: 1.6819662724809694 (6 / 100)
train_acc: 0.3374536464771323, val_acc: 0.3054187192118227, train_loss: 1.622471097520609, val_loss: 1.5974222920798316 (7 / 100)
train_acc: 0.311495673671199, val_acc: 0.3251231527093596, train_loss: 1.655641259015417, val_loss: 1.5655334201352349 (8 / 100)
train_acc: 0.33250927070457353, val_acc: 0.32019704433497537, train_loss: 1.5473115326300244, val_loss: 1.5710057296189182 (9 / 100)
train_acc: 0.37330037082818296, val_acc: 0.33497536945812806, train_loss: 1.496813357244758, val_loss: 1.4407365498284401 (10 / 100)
train_acc: 0.3683559950556242, val_acc: 0.3891625615763547, train_loss: 1.489613559543718, val_loss: 1.4255859922305705 (11 / 100)
train_acc: 0.37453646477132263, val_acc: 0.3103448275862069, train_loss: 1.4640849463282468, val_loss: 1.5800804616195228 (12 / 100)
train_acc: 0.3584672435105068, val_acc: 0.3842364532019704, train_loss: 1.4661831051221736, val_loss: 1.3575017607858029 (13 / 100)
train_acc: 0.3658838071693449, val_acc: 0.3399014778325123, train_loss: 1.4518695803006882, val_loss: 1.5501999496826397 (14 / 100)
train_acc: 0.37082818294190356, val_acc: 0.43349753694581283, train_loss: 1.4832133203560696, val_loss: 1.3579545138504705 (15 / 100)
train_acc: 0.41409147095179233, val_acc: 0.45320197044334976, train_loss: 1.4182057162592525, val_loss: 1.3962192611741315 (16 / 100)
train_acc: 0.40173053152039556, val_acc: 0.35467980295566504, train_loss: 1.3580905041382252, val_loss: 1.3347698485322774 (17 / 100)
train_acc: 0.380716934487021, val_acc: 0.42857142857142855, train_loss: 1.4101835054579124, val_loss: 1.380632543798738 (18 / 100)
train_acc: 0.40296662546353523, val_acc: 0.4187192118226601, train_loss: 1.3809255003487078, val_loss: 1.3385759932654244 (19 / 100)
train_acc: 0.446229913473424, val_acc: 0.4187192118226601, train_loss: 1.3259146209110877, val_loss: 1.306850849114028 (20 / 100)
train_acc: 0.41285537700865266, val_acc: 0.458128078817734, train_loss: 1.3234661723244177, val_loss: 1.2507827293696663 (21 / 100)
train_acc: 0.43757725587144625, val_acc: 0.458128078817734, train_loss: 1.3098584783386684, val_loss: 1.2570544727917374 (22 / 100)
train_acc: 0.44252163164400493, val_acc: 0.4729064039408867, train_loss: 1.3078474087827139, val_loss: 1.3168494296191362 (23 / 100)
train_acc: 0.4400494437577256, val_acc: 0.43842364532019706, train_loss: 1.3024738940084526, val_loss: 1.321410416675906 (24 / 100)
train_acc: 0.4622991347342398, val_acc: 0.46798029556650245, train_loss: 1.2814611822771937, val_loss: 1.2410843196173607 (25 / 100)
train_acc: 0.4622991347342398, val_acc: 0.5073891625615764, train_loss: 1.2955697785201856, val_loss: 1.2016513785117953 (26 / 100)
train_acc: 0.45488257107540175, val_acc: 0.4630541871921182, train_loss: 1.322124203144399, val_loss: 1.3792654322873195 (27 / 100)
train_acc: 0.45982694684796044, val_acc: 0.4729064039408867, train_loss: 1.280703400209896, val_loss: 1.2349704245628395 (28 / 100)
train_acc: 0.49814585908529047, val_acc: 0.45320197044334976, train_loss: 1.2468637356209962, val_loss: 1.3149813017234426 (29 / 100)
train_acc: 0.47342398022249693, val_acc: 0.4729064039408867, train_loss: 1.2527487832035211, val_loss: 1.2315461770654312 (30 / 100)
train_acc: 0.5315203955500618, val_acc: 0.4729064039408867, train_loss: 1.1553771713902836, val_loss: 1.24728591982367 (31 / 100)
train_acc: 0.5105067985166872, val_acc: 0.46798029556650245, train_loss: 1.2226559367256495, val_loss: 1.201691540884854 (32 / 100)
train_acc: 0.5389369592088998, val_acc: 0.4975369458128079, train_loss: 1.127053832683634, val_loss: 1.177755974783686 (33 / 100)
train_acc: 0.5426452410383189, val_acc: 0.4827586206896552, train_loss: 1.1148754250723294, val_loss: 1.1616279174541604 (34 / 100)
train_acc: 0.5488257107540173, val_acc: 0.5320197044334976, train_loss: 1.1292721170135422, val_loss: 1.1359739271290783 (35 / 100)
train_acc: 0.5723114956736712, val_acc: 0.5172413793103449, train_loss: 1.0613978654698772, val_loss: 1.1915687883428752 (36 / 100)
train_acc: 0.5587144622991347, val_acc: 0.5763546798029556, train_loss: 1.06406305702714, val_loss: 1.0824388923316166 (37 / 100)
train_acc: 0.5859085290482077, val_acc: 0.5073891625615764, train_loss: 1.0643842497331693, val_loss: 1.2746804594406353 (38 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5270935960591133, train_loss: 1.006101595014518, val_loss: 1.1785502078497938 (39 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5320197044334976, train_loss: 0.9802945438215258, val_loss: 1.1704826472428045 (40 / 100)
train_acc: 0.6131025957972805, val_acc: 0.5172413793103449, train_loss: 0.9986356501231529, val_loss: 1.1321981813520046 (41 / 100)
train_acc: 0.6365883807169345, val_acc: 0.47783251231527096, train_loss: 0.9259563629942565, val_loss: 1.3440391359658077 (42 / 100)
train_acc: 0.657601977750309, val_acc: 0.5467980295566502, train_loss: 0.8661454336899614, val_loss: 1.205056503048084 (43 / 100)
train_acc: 0.657601977750309, val_acc: 0.5615763546798029, train_loss: 0.8541679520836867, val_loss: 1.1054989152353973 (44 / 100)
train_acc: 0.6983930778739185, val_acc: 0.4975369458128079, train_loss: 0.796294931133539, val_loss: 1.2568260763079075 (45 / 100)
train_acc: 0.688504326328801, val_acc: 0.5172413793103449, train_loss: 0.8111088367268829, val_loss: 1.264134787573603 (46 / 100)
train_acc: 0.6897404202719407, val_acc: 0.5615763546798029, train_loss: 0.8050395511136803, val_loss: 1.0605621198421629 (47 / 100)
train_acc: 0.7404202719406675, val_acc: 0.5812807881773399, train_loss: 0.6548525155401053, val_loss: 1.113235910537795 (48 / 100)
train_acc: 0.7552533992583437, val_acc: 0.5615763546798029, train_loss: 0.637652127350806, val_loss: 1.1463372720579796 (49 / 100)
train_acc: 0.7911001236093943, val_acc: 0.5763546798029556, train_loss: 0.582515965433439, val_loss: 1.3010490751031585 (50 / 100)
train_acc: 0.8059332509270705, val_acc: 0.6108374384236454, train_loss: 0.5712485163114569, val_loss: 1.0947959517023247 (51 / 100)
train_acc: 0.7861557478368356, val_acc: 0.5763546798029556, train_loss: 0.5369677660049702, val_loss: 1.2018354364803858 (52 / 100)
train_acc: 0.8257107540173053, val_acc: 0.5566502463054187, train_loss: 0.4973380085269659, val_loss: 1.650314204358115 (53 / 100)
train_acc: 0.796044499381953, val_acc: 0.6206896551724138, train_loss: 0.49896658262599386, val_loss: 1.3345918339755147 (54 / 100)
train_acc: 0.8318912237330037, val_acc: 0.5172413793103449, train_loss: 0.418652397593108, val_loss: 2.0497737987829474 (55 / 100)
train_acc: 0.7750309023485785, val_acc: 0.5812807881773399, train_loss: 0.5828892512728169, val_loss: 1.1569323668926221 (56 / 100)
train_acc: 0.8529048207663782, val_acc: 0.6206896551724138, train_loss: 0.40210560653059385, val_loss: 1.5453255866548699 (57 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6502463054187192, train_loss: 0.36650489876679937, val_loss: 1.4016748657954738 (58 / 100)
train_acc: 0.8739184177997528, val_acc: 0.5960591133004927, train_loss: 0.33286428068417995, val_loss: 1.247331420776292 (59 / 100)
train_acc: 0.8726823238566132, val_acc: 0.5862068965517241, train_loss: 0.3256665163193409, val_loss: 1.5294801507677351 (60 / 100)
train_acc: 0.8182941903584673, val_acc: 0.5812807881773399, train_loss: 0.5300079597383553, val_loss: 1.3810158316871803 (61 / 100)
train_acc: 0.9060568603213844, val_acc: 0.5665024630541872, train_loss: 0.2879163051859852, val_loss: 1.4695628864020842 (62 / 100)
train_acc: 0.9011124845488258, val_acc: 0.5960591133004927, train_loss: 0.266658670970035, val_loss: 1.5114271499106449 (63 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6059113300492611, train_loss: 0.27829203764794047, val_loss: 1.467753047132727 (64 / 100)
train_acc: 0.92336217552534, val_acc: 0.6206896551724138, train_loss: 0.21050098166330194, val_loss: 1.5197464750134593 (65 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6157635467980296, train_loss: 0.25753201232999745, val_loss: 2.1815449003809193 (66 / 100)
train_acc: 0.9258343634116193, val_acc: 0.5665024630541872, train_loss: 0.1931936705510313, val_loss: 2.683658081028849 (67 / 100)
train_acc: 0.9171817058096415, val_acc: 0.6403940886699507, train_loss: 0.2722077578932452, val_loss: 1.6885842525313053 (68 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6699507389162561, train_loss: 0.19367087815689069, val_loss: 1.4312670207375964 (69 / 100)
train_acc: 0.9258343634116193, val_acc: 0.6059113300492611, train_loss: 0.19818950716143632, val_loss: 1.4522419858154991 (70 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6009852216748769, train_loss: 0.13735312407626799, val_loss: 2.1013679011114714 (71 / 100)
train_acc: 0.9567367119901112, val_acc: 0.5911330049261084, train_loss: 0.11812230594668018, val_loss: 1.939389306042582 (72 / 100)
train_acc: 0.9221260815822002, val_acc: 0.6502463054187192, train_loss: 0.24544114633307912, val_loss: 1.7364999261395684 (73 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6108374384236454, train_loss: 0.16999472469570315, val_loss: 1.9626569653966743 (74 / 100)
train_acc: 0.9604449938195303, val_acc: 0.625615763546798, train_loss: 0.12204172658389814, val_loss: 1.6620149342297332 (75 / 100)
train_acc: 0.9480840543881335, val_acc: 0.5911330049261084, train_loss: 0.14847402121728961, val_loss: 2.3158532322333953 (76 / 100)
train_acc: 0.9171817058096415, val_acc: 0.6748768472906403, train_loss: 0.2195678314260853, val_loss: 1.4093926531340688 (77 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6354679802955665, train_loss: 0.12828385432070058, val_loss: 1.9455834879663778 (78 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6403940886699507, train_loss: 0.13411195964836808, val_loss: 1.7100067373567027 (79 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6305418719211823, train_loss: 0.07006465858228422, val_loss: 2.0087579647216742 (80 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6403940886699507, train_loss: 0.07922780793735801, val_loss: 1.7818858494312304 (81 / 100)
train_acc: 0.9406674907292955, val_acc: 0.6551724137931034, train_loss: 0.18010991008673669, val_loss: 2.0312645470475768 (82 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6059113300492611, train_loss: 0.0901484642688954, val_loss: 2.3675240483777276 (83 / 100)
train_acc: 0.9542645241038319, val_acc: 0.5862068965517241, train_loss: 0.14385236738933474, val_loss: 1.7739383927707015 (84 / 100)
train_acc: 0.965389369592089, val_acc: 0.6206896551724138, train_loss: 0.0939819170311738, val_loss: 2.8372053824034817 (85 / 100)
train_acc: 0.9480840543881335, val_acc: 0.5566502463054187, train_loss: 0.14083023315896503, val_loss: 1.8676757336837317 (86 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6600985221674877, train_loss: 0.1366857506878149, val_loss: 1.8913396925761783 (87 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6305418719211823, train_loss: 0.04234918911465903, val_loss: 2.3065861222779223 (88 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6157635467980296, train_loss: 0.11025762425364906, val_loss: 1.9449627411189339 (89 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6403940886699507, train_loss: 0.0691664226270282, val_loss: 2.2526894064959633 (90 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.06347134543585099, val_loss: 2.283718156128241 (91 / 100)
train_acc: 0.9851668726823238, val_acc: 0.5960591133004927, train_loss: 0.04556321744129006, val_loss: 2.6507188278466023 (92 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6009852216748769, train_loss: 0.057229049126208936, val_loss: 2.996700646401626 (93 / 100)
train_acc: 0.965389369592089, val_acc: 0.6650246305418719, train_loss: 0.11134351743903237, val_loss: 2.056939384620178 (94 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6009852216748769, train_loss: 0.06396596835481812, val_loss: 2.128026794036621 (95 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6600985221674877, train_loss: 0.05442884855423634, val_loss: 2.1174305653924423 (96 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6798029556650246, train_loss: 0.04246172062104064, val_loss: 2.3692075959567367 (97 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.03482924639368234, val_loss: 2.863363665312969 (98 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6403940886699507, train_loss: 0.04803227317347957, val_loss: 2.275129447434226 (99 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6600985221674877, train_loss: 0.04377706767012663, val_loss: 2.3628317305607163 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 1}), val accuracy 0.6798029556650246, val loss 2.3692075959567367
train_acc: 0.15203955500618047, val_acc: 0.1921182266009852, train_loss: 1.7905304962389255, val_loss: 1.7874081363818917 (1 / 100)
train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7841965073560755, val_loss: 1.7790159685858364 (2 / 100)
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7760809573019096, val_loss: 1.765710439000811 (3 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7622129896515233, val_loss: 1.7497040321087014 (4 / 100)
train_acc: 0.20642768850432633, val_acc: 0.1921182266009852, train_loss: 1.7513646974846517, val_loss: 1.7389152913257993 (5 / 100)
train_acc: 0.22373300370828184, val_acc: 0.18226600985221675, train_loss: 1.743294757435142, val_loss: 1.7224128581032965 (6 / 100)
train_acc: 0.22373300370828184, val_acc: 0.26108374384236455, train_loss: 1.7207172165989728, val_loss: 1.6993804694396522 (7 / 100)
train_acc: 0.29295426452410384, val_acc: 0.24630541871921183, train_loss: 1.6903115472628543, val_loss: 1.662625506006438 (8 / 100)
train_acc: 0.3003708281829419, val_acc: 0.27586206896551724, train_loss: 1.6452489134997166, val_loss: 1.7075924432923641 (9 / 100)
train_acc: 0.2954264524103832, val_acc: 0.2512315270935961, train_loss: 1.6578596062654323, val_loss: 1.6356254140731736 (10 / 100)
train_acc: 0.33868974042027195, val_acc: 0.35467980295566504, train_loss: 1.5796911387862027, val_loss: 1.5323577473316286 (11 / 100)
train_acc: 0.33127317676143386, val_acc: 0.3448275862068966, train_loss: 1.5519078897752043, val_loss: 1.53631286609349 (12 / 100)
train_acc: 0.34239802224969096, val_acc: 0.3694581280788177, train_loss: 1.5813530018951454, val_loss: 1.4797856696133542 (13 / 100)
train_acc: 0.33498145859085293, val_acc: 0.37438423645320196, train_loss: 1.5320719536509002, val_loss: 1.4860579092514339 (14 / 100)
train_acc: 0.3658838071693449, val_acc: 0.37438423645320196, train_loss: 1.4777358583231055, val_loss: 1.3966677494236988 (15 / 100)
train_acc: 0.3522867737948084, val_acc: 0.4187192118226601, train_loss: 1.4799135400279344, val_loss: 1.4720306143972086 (16 / 100)
train_acc: 0.40296662546353523, val_acc: 0.3645320197044335, train_loss: 1.424788995343174, val_loss: 1.3989978635252402 (17 / 100)
train_acc: 0.40173053152039556, val_acc: 0.39901477832512317, train_loss: 1.434141154489647, val_loss: 1.3877007421014345 (18 / 100)
train_acc: 0.3683559950556242, val_acc: 0.3645320197044335, train_loss: 1.4468673081568941, val_loss: 1.4701698343154832 (19 / 100)
train_acc: 0.377008652657602, val_acc: 0.33497536945812806, train_loss: 1.4430014986190278, val_loss: 1.560751522703124 (20 / 100)
train_acc: 0.3992583436341162, val_acc: 0.43349753694581283, train_loss: 1.4038586022679973, val_loss: 1.4214464972171876 (21 / 100)
train_acc: 0.39060568603213847, val_acc: 0.4039408866995074, train_loss: 1.4190205295831517, val_loss: 1.349909060107076 (22 / 100)
train_acc: 0.38936959208899874, val_acc: 0.4187192118226601, train_loss: 1.3985551592740788, val_loss: 1.336094983399208 (23 / 100)
train_acc: 0.415327564894932, val_acc: 0.41379310344827586, train_loss: 1.3781869040136727, val_loss: 1.3760758221443063 (24 / 100)
train_acc: 0.41656365883807167, val_acc: 0.33004926108374383, train_loss: 1.3558859670412702, val_loss: 1.4608662609983547 (25 / 100)
train_acc: 0.40296662546353523, val_acc: 0.4236453201970443, train_loss: 1.3548760922494423, val_loss: 1.2920734001497918 (26 / 100)
train_acc: 0.4511742892459827, val_acc: 0.42857142857142855, train_loss: 1.3303160620266192, val_loss: 1.312100414572091 (27 / 100)
train_acc: 0.4264524103831891, val_acc: 0.4236453201970443, train_loss: 1.3386716509631598, val_loss: 1.3084623854735802 (28 / 100)
train_acc: 0.4326328800988875, val_acc: 0.4482758620689655, train_loss: 1.3142942023660402, val_loss: 1.327098425973225 (29 / 100)
train_acc: 0.43757725587144625, val_acc: 0.4630541871921182, train_loss: 1.2932757313083512, val_loss: 1.2427210258732875 (30 / 100)
train_acc: 0.4672435105067985, val_acc: 0.4630541871921182, train_loss: 1.2682714049689408, val_loss: 1.243977724331353 (31 / 100)
train_acc: 0.4276885043263288, val_acc: 0.46798029556650245, train_loss: 1.3378053492462385, val_loss: 1.2548160059698696 (32 / 100)
train_acc: 0.47095179233621753, val_acc: 0.47783251231527096, train_loss: 1.2469273152840594, val_loss: 1.295487168387239 (33 / 100)
train_acc: 0.45982694684796044, val_acc: 0.45320197044334976, train_loss: 1.2461431067717827, val_loss: 1.2948181200497255 (34 / 100)
train_acc: 0.45982694684796044, val_acc: 0.4630541871921182, train_loss: 1.2707791912688313, val_loss: 1.2133243101570994 (35 / 100)
train_acc: 0.5018541409147095, val_acc: 0.43349753694581283, train_loss: 1.2257993729653847, val_loss: 1.3461245122214256 (36 / 100)
train_acc: 0.5067985166872683, val_acc: 0.4827586206896552, train_loss: 1.2048218731385079, val_loss: 1.2471016604324867 (37 / 100)
train_acc: 0.48702101359703337, val_acc: 0.45320197044334976, train_loss: 1.2364440506556715, val_loss: 1.2074806290894307 (38 / 100)
train_acc: 0.5006180469715699, val_acc: 0.4729064039408867, train_loss: 1.1916922053831027, val_loss: 1.2318572275744284 (39 / 100)
train_acc: 0.4647713226205192, val_acc: 0.43842364532019706, train_loss: 1.2580830782688739, val_loss: 1.275062615648279 (40 / 100)
train_acc: 0.5241038318912238, val_acc: 0.4975369458128079, train_loss: 1.1704403551016809, val_loss: 1.2498757199113593 (41 / 100)
train_acc: 0.5142150803461063, val_acc: 0.45320197044334976, train_loss: 1.1913016425222342, val_loss: 1.2561328328888992 (42 / 100)
train_acc: 0.522867737948084, val_acc: 0.46798029556650245, train_loss: 1.1366934920712954, val_loss: 1.2076358078735803 (43 / 100)
train_acc: 0.5414091470951793, val_acc: 0.541871921182266, train_loss: 1.1444645620541756, val_loss: 1.1114913598070004 (44 / 100)
train_acc: 0.5426452410383189, val_acc: 0.5467980295566502, train_loss: 1.1202956402699644, val_loss: 1.18278923469224 (45 / 100)
train_acc: 0.5451174289245982, val_acc: 0.5123152709359606, train_loss: 1.1032189154359702, val_loss: 1.1873151797966417 (46 / 100)
train_acc: 0.5995055624227441, val_acc: 0.5714285714285714, train_loss: 1.03545864712912, val_loss: 1.0780601536699117 (47 / 100)
train_acc: 0.5735475896168108, val_acc: 0.46798029556650245, train_loss: 1.0108676675813013, val_loss: 1.2531039491662839 (48 / 100)
train_acc: 0.5822002472187886, val_acc: 0.5270935960591133, train_loss: 1.0202347354040158, val_loss: 1.164540581221651 (49 / 100)
train_acc: 0.584672435105068, val_acc: 0.4876847290640394, train_loss: 1.0411325471362902, val_loss: 1.1659355712641637 (50 / 100)
train_acc: 0.5896168108776267, val_acc: 0.5467980295566502, train_loss: 0.9624302617109602, val_loss: 1.0743771066219348 (51 / 100)
train_acc: 0.6254635352286774, val_acc: 0.5517241379310345, train_loss: 0.94733055855052, val_loss: 1.0997976023575355 (52 / 100)
train_acc: 0.630407911001236, val_acc: 0.4876847290640394, train_loss: 0.9422971063255527, val_loss: 1.2144635733712483 (53 / 100)
train_acc: 0.6514215080346106, val_acc: 0.5812807881773399, train_loss: 0.9143567951706932, val_loss: 1.105960439872272 (54 / 100)
train_acc: 0.6353522867737948, val_acc: 0.5369458128078818, train_loss: 0.8986242490881601, val_loss: 1.0780711450013034 (55 / 100)
train_acc: 0.6353522867737948, val_acc: 0.5862068965517241, train_loss: 0.8959649511703897, val_loss: 1.0725056537853672 (56 / 100)
train_acc: 0.69221260815822, val_acc: 0.5467980295566502, train_loss: 0.7789943551250972, val_loss: 1.0619062273373157 (57 / 100)
train_acc: 0.6773794808405439, val_acc: 0.541871921182266, train_loss: 0.7950319126893033, val_loss: 1.2134381838032764 (58 / 100)
train_acc: 0.6946847960444994, val_acc: 0.6009852216748769, train_loss: 0.7655958339516695, val_loss: 1.0663537744230824 (59 / 100)
train_acc: 0.7033374536464772, val_acc: 0.5960591133004927, train_loss: 0.7777340163111834, val_loss: 1.0271231772864393 (60 / 100)
train_acc: 0.7824474660074165, val_acc: 0.5566502463054187, train_loss: 0.570037642721782, val_loss: 1.0687828657075102 (61 / 100)
train_acc: 0.7948084054388134, val_acc: 0.5960591133004927, train_loss: 0.5590317027530505, val_loss: 1.0500709117926987 (62 / 100)
train_acc: 0.7935723114956736, val_acc: 0.5911330049261084, train_loss: 0.5410367111561473, val_loss: 1.064974430746633 (63 / 100)
train_acc: 0.788627935723115, val_acc: 0.6009852216748769, train_loss: 0.5388343494813728, val_loss: 1.0619177997405893 (64 / 100)
train_acc: 0.8133498145859085, val_acc: 0.5812807881773399, train_loss: 0.5048488343159849, val_loss: 1.0880806707396296 (65 / 100)
train_acc: 0.8281829419035847, val_acc: 0.5862068965517241, train_loss: 0.4548426588769307, val_loss: 1.095220744022595 (66 / 100)
train_acc: 0.8331273176761433, val_acc: 0.5812807881773399, train_loss: 0.4750707739657908, val_loss: 1.082181609322872 (67 / 100)
train_acc: 0.7985166872682324, val_acc: 0.6009852216748769, train_loss: 0.4938238190190017, val_loss: 1.0786374129098037 (68 / 100)
train_acc: 0.8281829419035847, val_acc: 0.5862068965517241, train_loss: 0.4675321381525292, val_loss: 1.1241390094381247 (69 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5960591133004927, train_loss: 0.4361744145177793, val_loss: 1.119722579793977 (70 / 100)
train_acc: 0.8318912237330037, val_acc: 0.5911330049261084, train_loss: 0.4418682524536095, val_loss: 1.1307707898722494 (71 / 100)
train_acc: 0.8318912237330037, val_acc: 0.5911330049261084, train_loss: 0.4379702599072191, val_loss: 1.1232480465484957 (72 / 100)
train_acc: 0.8491965389369592, val_acc: 0.5911330049261084, train_loss: 0.4151424765586853, val_loss: 1.1429054575600648 (73 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5960591133004927, train_loss: 0.43222487694842854, val_loss: 1.1389476621679484 (74 / 100)
train_acc: 0.8603213844252163, val_acc: 0.5714285714285714, train_loss: 0.392759049594476, val_loss: 1.1597265442603915 (75 / 100)
train_acc: 0.8504326328800988, val_acc: 0.5911330049261084, train_loss: 0.37848923614131214, val_loss: 1.1698826049348992 (76 / 100)
train_acc: 0.8516687268232386, val_acc: 0.5812807881773399, train_loss: 0.3926532649802336, val_loss: 1.1580320849207235 (77 / 100)
train_acc: 0.8442521631644005, val_acc: 0.5960591133004927, train_loss: 0.39011239865506975, val_loss: 1.186161965572188 (78 / 100)
train_acc: 0.8665018541409147, val_acc: 0.5812807881773399, train_loss: 0.35344230583483266, val_loss: 1.1980821827949562 (79 / 100)
train_acc: 0.8726823238566132, val_acc: 0.5911330049261084, train_loss: 0.3690041823978035, val_loss: 1.1930881277680985 (80 / 100)
train_acc: 0.8689740420271941, val_acc: 0.5911330049261084, train_loss: 0.3568520985810807, val_loss: 1.217711475975995 (81 / 100)
train_acc: 0.8541409147095179, val_acc: 0.6108374384236454, train_loss: 0.3584281557569987, val_loss: 1.2500558013986485 (82 / 100)
train_acc: 0.8689740420271941, val_acc: 0.6009852216748769, train_loss: 0.3763384692306424, val_loss: 1.2076491273095455 (83 / 100)
train_acc: 0.8912237330037083, val_acc: 0.5960591133004927, train_loss: 0.32329420773001627, val_loss: 1.2036124558871604 (84 / 100)
train_acc: 0.8689740420271941, val_acc: 0.5911330049261084, train_loss: 0.34345570906573086, val_loss: 1.2627468076832775 (85 / 100)
train_acc: 0.892459826946848, val_acc: 0.5960591133004927, train_loss: 0.3284519508720476, val_loss: 1.2594667080000703 (86 / 100)
train_acc: 0.8912237330037083, val_acc: 0.5862068965517241, train_loss: 0.3288709097651233, val_loss: 1.2759334148444565 (87 / 100)
train_acc: 0.8689740420271941, val_acc: 0.6009852216748769, train_loss: 0.32031089419266495, val_loss: 1.2847906204280009 (88 / 100)
train_acc: 0.8763906056860321, val_acc: 0.6059113300492611, train_loss: 0.3354709481426753, val_loss: 1.2847690218187906 (89 / 100)
train_acc: 0.8838071693448702, val_acc: 0.5911330049261084, train_loss: 0.32479269325512156, val_loss: 1.239562876412434 (90 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6009852216748769, train_loss: 0.27299244770013503, val_loss: 1.3351420883474678 (91 / 100)
train_acc: 0.8974042027194067, val_acc: 0.6206896551724138, train_loss: 0.2799109537683989, val_loss: 1.3300500752890638 (92 / 100)
train_acc: 0.8936959208899876, val_acc: 0.5960591133004927, train_loss: 0.3131255516678795, val_loss: 1.3498518646057016 (93 / 100)
train_acc: 0.8862793572311496, val_acc: 0.6108374384236454, train_loss: 0.29802454387301713, val_loss: 1.2890016915175715 (94 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6108374384236454, train_loss: 0.27643855278954665, val_loss: 1.3128027854294613 (95 / 100)
train_acc: 0.8813349814585909, val_acc: 0.6157635467980296, train_loss: 0.2985169027088157, val_loss: 1.3283893051993083 (96 / 100)
train_acc: 0.9171817058096415, val_acc: 0.6009852216748769, train_loss: 0.24123984464756196, val_loss: 1.3511122638368842 (97 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6108374384236454, train_loss: 0.27342218643213234, val_loss: 1.3587401779414399 (98 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6157635467980296, train_loss: 0.2784591559573953, val_loss: 1.3524430499875486 (99 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6009852216748769, train_loss: 0.24978249333108163, val_loss: 1.3797036782274106 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.05}), val accuracy 0.6206896551724138, val loss 1.3300500752890638
train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.787126222853313, val_loss: 1.7792050280594474 (1 / 100)
train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7674261928341444, val_loss: 1.7492488076534178 (2 / 100)
train_acc: 0.1965389369592089, val_acc: 0.18719211822660098, train_loss: 1.756366558216411, val_loss: 1.7371086058358254 (3 / 100)
train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7466010711396434, val_loss: 1.7230589536610494 (4 / 100)
train_acc: 0.22373300370828184, val_acc: 0.2512315270935961, train_loss: 1.732044529119145, val_loss: 1.6947432521528798 (5 / 100)
train_acc: 0.26452410383189123, val_acc: 0.3497536945812808, train_loss: 1.692613044686901, val_loss: 1.6573764355899079 (6 / 100)
train_acc: 0.311495673671199, val_acc: 0.3054187192118227, train_loss: 1.6660018516854096, val_loss: 1.6322195024913169 (7 / 100)
train_acc: 0.29666254635352285, val_acc: 0.3251231527093596, train_loss: 1.6750951153680922, val_loss: 1.6385149697364845 (8 / 100)
train_acc: 0.3374536464771323, val_acc: 0.35467980295566504, train_loss: 1.6134738382803937, val_loss: 1.5829068939086839 (9 / 100)
train_acc: 0.3016069221260816, val_acc: 0.29064039408866993, train_loss: 1.6417418716864474, val_loss: 1.5826150560613923 (10 / 100)
train_acc: 0.3695920889987639, val_acc: 0.3645320197044335, train_loss: 1.5595183403441875, val_loss: 1.5505846016512717 (11 / 100)
train_acc: 0.3646477132262052, val_acc: 0.2857142857142857, train_loss: 1.5623214820996203, val_loss: 1.5303122873963981 (12 / 100)
train_acc: 0.31396786155747836, val_acc: 0.2561576354679803, train_loss: 1.6150621520574073, val_loss: 1.5937005698387259 (13 / 100)
train_acc: 0.3522867737948084, val_acc: 0.28078817733990147, train_loss: 1.5673012565476048, val_loss: 1.5764722477626332 (14 / 100)
train_acc: 0.3584672435105068, val_acc: 0.35467980295566504, train_loss: 1.518779908918185, val_loss: 1.4215903687359663 (15 / 100)
train_acc: 0.39184177997527814, val_acc: 0.3251231527093596, train_loss: 1.4675575587599181, val_loss: 1.4614124626948917 (16 / 100)
train_acc: 0.37824474660074164, val_acc: 0.4039408866995074, train_loss: 1.457206516831708, val_loss: 1.441058377327003 (17 / 100)
train_acc: 0.3992583436341162, val_acc: 0.43842364532019706, train_loss: 1.448002156427381, val_loss: 1.3916058833963179 (18 / 100)
train_acc: 0.37824474660074164, val_acc: 0.39901477832512317, train_loss: 1.4800308580304253, val_loss: 1.3630456930310855 (19 / 100)
train_acc: 0.4227441285537701, val_acc: 0.30049261083743845, train_loss: 1.3943422346091536, val_loss: 1.4417008977805452 (20 / 100)
train_acc: 0.40914709517923364, val_acc: 0.4236453201970443, train_loss: 1.3898219808807184, val_loss: 1.3549303083584225 (21 / 100)
train_acc: 0.39555006180469715, val_acc: 0.4827586206896552, train_loss: 1.3952498094113117, val_loss: 1.2816179902682752 (22 / 100)
train_acc: 0.43016069221260816, val_acc: 0.43842364532019706, train_loss: 1.3502870472458885, val_loss: 1.3379988899371895 (23 / 100)
train_acc: 0.4573547589616811, val_acc: 0.4729064039408867, train_loss: 1.309731453399281, val_loss: 1.2508034309730154 (24 / 100)
train_acc: 0.45488257107540175, val_acc: 0.43349753694581283, train_loss: 1.3327517376841957, val_loss: 1.2532195956836194 (25 / 100)
train_acc: 0.43139678615574784, val_acc: 0.4433497536945813, train_loss: 1.3072197294353112, val_loss: 1.23979178907836 (26 / 100)
train_acc: 0.4622991347342398, val_acc: 0.39901477832512317, train_loss: 1.3054503037402008, val_loss: 1.3639952880995614 (27 / 100)
train_acc: 0.47713226205191595, val_acc: 0.4729064039408867, train_loss: 1.2708847658301166, val_loss: 1.2214730243964735 (28 / 100)
train_acc: 0.45241038318912236, val_acc: 0.41379310344827586, train_loss: 1.2607455564517762, val_loss: 1.2774712637140246 (29 / 100)
train_acc: 0.46600741656365885, val_acc: 0.4482758620689655, train_loss: 1.2700872486100356, val_loss: 1.2541096797717617 (30 / 100)
train_acc: 0.484548825710754, val_acc: 0.5024630541871922, train_loss: 1.2062752043508334, val_loss: 1.1523603794022734 (31 / 100)
train_acc: 0.484548825710754, val_acc: 0.458128078817734, train_loss: 1.2228049661674074, val_loss: 1.2931262812590951 (32 / 100)
train_acc: 0.4684796044499382, val_acc: 0.5320197044334976, train_loss: 1.2121554576274933, val_loss: 1.1976005056221497 (33 / 100)
train_acc: 0.49814585908529047, val_acc: 0.5073891625615764, train_loss: 1.2005779279766624, val_loss: 1.1298988849071447 (34 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5221674876847291, train_loss: 1.1527306199515852, val_loss: 1.3154821724727237 (35 / 100)
train_acc: 0.511742892459827, val_acc: 0.46798029556650245, train_loss: 1.1830651216365498, val_loss: 1.1698605611993762 (36 / 100)
train_acc: 0.5500618046971569, val_acc: 0.541871921182266, train_loss: 1.1113797924279871, val_loss: 1.2594316246474317 (37 / 100)
train_acc: 0.5241038318912238, val_acc: 0.5369458128078818, train_loss: 1.1113609751900577, val_loss: 1.1614335258606032 (38 / 100)
train_acc: 0.546353522867738, val_acc: 0.5270935960591133, train_loss: 1.108041583902314, val_loss: 1.1091724466807737 (39 / 100)
train_acc: 0.5747836835599506, val_acc: 0.4876847290640394, train_loss: 1.0339474952117769, val_loss: 1.110909357153136 (40 / 100)
train_acc: 0.519159456118665, val_acc: 0.5320197044334976, train_loss: 1.0585573479919999, val_loss: 1.0199857894422972 (41 / 100)
train_acc: 0.5920889987639061, val_acc: 0.5221674876847291, train_loss: 1.024563286006819, val_loss: 1.168785167151484 (42 / 100)
train_acc: 0.6266996291718171, val_acc: 0.5024630541871922, train_loss: 0.9426460457673326, val_loss: 1.0286735827699671 (43 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5665024630541872, train_loss: 0.9643261493062796, val_loss: 1.3320026597365957 (44 / 100)
train_acc: 0.5945611866501854, val_acc: 0.5467980295566502, train_loss: 1.0019995476613086, val_loss: 1.2010073250737683 (45 / 100)
train_acc: 0.6279357231149567, val_acc: 0.5467980295566502, train_loss: 0.9083423058977823, val_loss: 1.2589145881201833 (46 / 100)
train_acc: 0.6341161928306551, val_acc: 0.5615763546798029, train_loss: 0.9132967410777202, val_loss: 1.0443165140786195 (47 / 100)
train_acc: 0.6625463535228677, val_acc: 0.5467980295566502, train_loss: 0.8634108111943833, val_loss: 1.158231526760045 (48 / 100)
train_acc: 0.6687268232385661, val_acc: 0.5517241379310345, train_loss: 0.7921239208379399, val_loss: 1.1232722621833162 (49 / 100)
train_acc: 0.6971569839307787, val_acc: 0.5221674876847291, train_loss: 0.7766769192422129, val_loss: 1.2736751927530825 (50 / 100)
train_acc: 0.6983930778739185, val_acc: 0.5665024630541872, train_loss: 0.7433048428873197, val_loss: 1.0080061299460275 (51 / 100)
train_acc: 0.723114956736712, val_acc: 0.5812807881773399, train_loss: 0.7137691738136914, val_loss: 1.3321715194016255 (52 / 100)
train_acc: 0.7292954264524104, val_acc: 0.5665024630541872, train_loss: 0.7122195749848675, val_loss: 1.0107819073893167 (53 / 100)
train_acc: 0.7255871446229913, val_acc: 0.5123152709359606, train_loss: 0.7018585262914523, val_loss: 1.2780472712563764 (54 / 100)
train_acc: 0.7589616810877626, val_acc: 0.5665024630541872, train_loss: 0.6554709887327753, val_loss: 1.0692007001397645 (55 / 100)
train_acc: 0.7527812113720643, val_acc: 0.625615763546798, train_loss: 0.6350844122276024, val_loss: 1.3089323026206106 (56 / 100)
train_acc: 0.7713226205191595, val_acc: 0.5714285714285714, train_loss: 0.627007820844945, val_loss: 1.2395906833005068 (57 / 100)
train_acc: 0.796044499381953, val_acc: 0.6206896551724138, train_loss: 0.5152220437199577, val_loss: 1.1078832589934025 (58 / 100)
train_acc: 0.8034610630407911, val_acc: 0.6059113300492611, train_loss: 0.5188231636184107, val_loss: 1.1310713945938449 (59 / 100)
train_acc: 0.7812113720642769, val_acc: 0.6551724137931034, train_loss: 0.5776140907933597, val_loss: 1.2215278007714032 (60 / 100)
train_acc: 0.8850432632880099, val_acc: 0.6551724137931034, train_loss: 0.33630215303859545, val_loss: 1.1596341414991858 (61 / 100)
train_acc: 0.9097651421508035, val_acc: 0.6403940886699507, train_loss: 0.2693434246114659, val_loss: 1.160844730332567 (62 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6600985221674877, train_loss: 0.2557554394559306, val_loss: 1.186059846666646 (63 / 100)
train_acc: 0.9332509270704573, val_acc: 0.6600985221674877, train_loss: 0.21086305107032635, val_loss: 1.271480909122035 (64 / 100)
train_acc: 0.934487021013597, val_acc: 0.6748768472906403, train_loss: 0.19348189334197452, val_loss: 1.3154534553659374 (65 / 100)
train_acc: 0.9443757725587144, val_acc: 0.6650246305418719, train_loss: 0.19215599977041795, val_loss: 1.3633472872485082 (66 / 100)
train_acc: 0.9357231149567367, val_acc: 0.6600985221674877, train_loss: 0.17494179544180669, val_loss: 1.4947676840674113 (67 / 100)
train_acc: 0.9369592088998764, val_acc: 0.6847290640394089, train_loss: 0.1886445791708082, val_loss: 1.3873805001451465 (68 / 100)
train_acc: 0.957972805933251, val_acc: 0.6699507389162561, train_loss: 0.1453329225903094, val_loss: 1.408503317480604 (69 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6748768472906403, train_loss: 0.13972173499493723, val_loss: 1.475767044011008 (70 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6699507389162561, train_loss: 0.12426312498020743, val_loss: 1.4482250266474457 (71 / 100)
train_acc: 0.9431396786155748, val_acc: 0.6699507389162561, train_loss: 0.1688065398277252, val_loss: 1.4331500007601208 (72 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6748768472906403, train_loss: 0.14636625952060864, val_loss: 1.4549866908876767 (73 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6600985221674877, train_loss: 0.13508103734483234, val_loss: 1.6511906655551178 (74 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6600985221674877, train_loss: 0.15663665485175784, val_loss: 1.5879683805803948 (75 / 100)
train_acc: 0.957972805933251, val_acc: 0.6699507389162561, train_loss: 0.1295119221558235, val_loss: 1.5104679526953861 (76 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6699507389162561, train_loss: 0.12757645173479512, val_loss: 1.6273170316160606 (77 / 100)
train_acc: 0.957972805933251, val_acc: 0.6699507389162561, train_loss: 0.13159653401676893, val_loss: 1.5520172647654717 (78 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6551724137931034, train_loss: 0.14088981289172497, val_loss: 1.5823986512686818 (79 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6551724137931034, train_loss: 0.11240098646603644, val_loss: 1.7064294562551188 (80 / 100)
train_acc: 0.965389369592089, val_acc: 0.6502463054187192, train_loss: 0.1303846813618621, val_loss: 1.679764785790091 (81 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6699507389162561, train_loss: 0.1063674723796261, val_loss: 1.666327441267192 (82 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6699507389162561, train_loss: 0.09039273998977522, val_loss: 1.7188494851436522 (83 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.07942855971484308, val_loss: 1.8147715230293462 (84 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6699507389162561, train_loss: 0.084042462341865, val_loss: 1.8250499722992846 (85 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6748768472906403, train_loss: 0.08415984608260604, val_loss: 1.8456261046414304 (86 / 100)
train_acc: 0.9740420271940667, val_acc: 0.645320197044335, train_loss: 0.08248837725967353, val_loss: 2.01716100934691 (87 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6748768472906403, train_loss: 0.06385379637348637, val_loss: 1.915037789368277 (88 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6650246305418719, train_loss: 0.08875871604890995, val_loss: 1.9237265093573208 (89 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.0697557054211389, val_loss: 1.9952929630655374 (90 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6551724137931034, train_loss: 0.09237730060560152, val_loss: 1.8643207908263935 (91 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6699507389162561, train_loss: 0.07591331859806504, val_loss: 1.8926749499560578 (92 / 100)
train_acc: 0.965389369592089, val_acc: 0.6699507389162561, train_loss: 0.09792508477833219, val_loss: 1.9848427079581275 (93 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.07032593234691985, val_loss: 2.1911994800191796 (94 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6551724137931034, train_loss: 0.06732812343333354, val_loss: 1.9693509099518725 (95 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6600985221674877, train_loss: 0.08050257815750332, val_loss: 2.0054014680420824 (96 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6502463054187192, train_loss: 0.07396985485468276, val_loss: 1.8832919116090672 (97 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6502463054187192, train_loss: 0.062255272464492854, val_loss: 1.9714988769568833 (98 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6600985221674877, train_loss: 0.06936393091535686, val_loss: 2.0160775912806317 (99 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.07339881441575488, val_loss: 2.1677388440212004 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6847290640394089, val loss 1.3873805001451465
train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7895656277429042, val_loss: 1.7843824589780986 (1 / 100)
train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7819312298106322, val_loss: 1.7737277910627167 (2 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7703347621653667, val_loss: 1.7575726415136177 (3 / 100)
train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7565336831567904, val_loss: 1.7451080342231713 (4 / 100)
train_acc: 0.20519159456118666, val_acc: 0.2315270935960591, train_loss: 1.751777475048202, val_loss: 1.7368023665667756 (5 / 100)
train_acc: 0.21755253399258342, val_acc: 0.29064039408866993, train_loss: 1.740650770396031, val_loss: 1.7195685168205224 (6 / 100)
train_acc: 0.27935723114956734, val_acc: 0.27586206896551724, train_loss: 1.7155933020583485, val_loss: 1.68379957570231 (7 / 100)
train_acc: 0.32014833127317677, val_acc: 0.3399014778325123, train_loss: 1.676922640340732, val_loss: 1.602881089807144 (8 / 100)
train_acc: 0.3300370828182942, val_acc: 0.33004926108374383, train_loss: 1.6232355698961558, val_loss: 1.6070518182416267 (9 / 100)
train_acc: 0.3399258343634116, val_acc: 0.3251231527093596, train_loss: 1.5774220371128456, val_loss: 1.5119462136564583 (10 / 100)
train_acc: 0.3473423980222497, val_acc: 0.3103448275862069, train_loss: 1.5530331974713263, val_loss: 1.5458180875026535 (11 / 100)
train_acc: 0.34857849196538937, val_acc: 0.33004926108374383, train_loss: 1.567847564577025, val_loss: 1.4967693260737829 (12 / 100)
train_acc: 0.33498145859085293, val_acc: 0.33497536945812806, train_loss: 1.5817193831737315, val_loss: 1.5276196337685797 (13 / 100)
train_acc: 0.3399258343634116, val_acc: 0.3251231527093596, train_loss: 1.503472362961551, val_loss: 1.51079405587295 (14 / 100)
train_acc: 0.377008652657602, val_acc: 0.3842364532019704, train_loss: 1.4910053069276186, val_loss: 1.4297067502449299 (15 / 100)
train_acc: 0.38936959208899874, val_acc: 0.39901477832512317, train_loss: 1.4662392848206982, val_loss: 1.373579502105713 (16 / 100)
train_acc: 0.37453646477132263, val_acc: 0.3793103448275862, train_loss: 1.4632530371544534, val_loss: 1.3942953119137016 (17 / 100)
train_acc: 0.3930778739184178, val_acc: 0.4039408866995074, train_loss: 1.4372932488013552, val_loss: 1.425979144467509 (18 / 100)
train_acc: 0.4079110012360939, val_acc: 0.4039408866995074, train_loss: 1.4224498681585926, val_loss: 1.3451713441040716 (19 / 100)
train_acc: 0.38936959208899874, val_acc: 0.35467980295566504, train_loss: 1.410583389998956, val_loss: 1.3569413767072367 (20 / 100)
train_acc: 0.377008652657602, val_acc: 0.4039408866995074, train_loss: 1.4147767537309155, val_loss: 1.4310786600770622 (21 / 100)
train_acc: 0.415327564894932, val_acc: 0.3497536945812808, train_loss: 1.3839698250420456, val_loss: 1.4789028349768352 (22 / 100)
train_acc: 0.4042027194066749, val_acc: 0.458128078817734, train_loss: 1.3650471282977845, val_loss: 1.3337311909116547 (23 / 100)
train_acc: 0.4264524103831891, val_acc: 0.43842364532019706, train_loss: 1.3708062166041879, val_loss: 1.3929271651019017 (24 / 100)
train_acc: 0.41903584672435107, val_acc: 0.46798029556650245, train_loss: 1.3787219325455806, val_loss: 1.2648597697319068 (25 / 100)
train_acc: 0.45859085290482077, val_acc: 0.43842364532019706, train_loss: 1.3589645952759921, val_loss: 1.316983621695946 (26 / 100)
train_acc: 0.4326328800988875, val_acc: 0.45320197044334976, train_loss: 1.3165379603507346, val_loss: 1.2491979546147614 (27 / 100)
train_acc: 0.4511742892459827, val_acc: 0.3497536945812808, train_loss: 1.3188506215994968, val_loss: 1.5402298226145101 (28 / 100)
train_acc: 0.4610630407911001, val_acc: 0.4827586206896552, train_loss: 1.3153830592800277, val_loss: 1.2540826973656716 (29 / 100)
train_acc: 0.44499381953028433, val_acc: 0.4729064039408867, train_loss: 1.3240169814254799, val_loss: 1.2597395528126232 (30 / 100)
train_acc: 0.4622991347342398, val_acc: 0.49261083743842365, train_loss: 1.277814000881794, val_loss: 1.2607346767275205 (31 / 100)
train_acc: 0.4783683559950556, val_acc: 0.45320197044334976, train_loss: 1.2935156041229021, val_loss: 1.2419425947912808 (32 / 100)
train_acc: 0.4721878862793572, val_acc: 0.5024630541871922, train_loss: 1.2548828326874817, val_loss: 1.1882085823660413 (33 / 100)
train_acc: 0.47095179233621753, val_acc: 0.46798029556650245, train_loss: 1.2485652378079917, val_loss: 1.2191683785081497 (34 / 100)
train_acc: 0.46971569839307786, val_acc: 0.4975369458128079, train_loss: 1.22750819539847, val_loss: 1.1833435523098912 (35 / 100)
train_acc: 0.5129789864029666, val_acc: 0.49261083743842365, train_loss: 1.2281762790326283, val_loss: 1.1921937609541005 (36 / 100)
train_acc: 0.4969097651421508, val_acc: 0.4729064039408867, train_loss: 1.2223661968528268, val_loss: 1.1650893500285784 (37 / 100)
train_acc: 0.4956736711990111, val_acc: 0.4630541871921182, train_loss: 1.2059647755510874, val_loss: 1.176586408920476 (38 / 100)
train_acc: 0.5105067985166872, val_acc: 0.5221674876847291, train_loss: 1.1706808954293118, val_loss: 1.1759833860867128 (39 / 100)
train_acc: 0.5092707045735476, val_acc: 0.541871921182266, train_loss: 1.180487024621999, val_loss: 1.125724995958394 (40 / 100)
train_acc: 0.5142150803461063, val_acc: 0.4482758620689655, train_loss: 1.1520034278131681, val_loss: 1.2645265797676124 (41 / 100)
train_acc: 0.5216316440049443, val_acc: 0.5221674876847291, train_loss: 1.1456347991273783, val_loss: 1.107082738958556 (42 / 100)
train_acc: 0.5574783683559951, val_acc: 0.5320197044334976, train_loss: 1.0866500211439851, val_loss: 1.0991408085000927 (43 / 100)
train_acc: 0.5438813349814586, val_acc: 0.5123152709359606, train_loss: 1.1062163317896085, val_loss: 1.120169894155023 (44 / 100)
train_acc: 0.5624227441285538, val_acc: 0.4827586206896552, train_loss: 1.0682390689555146, val_loss: 1.1593418984577573 (45 / 100)
train_acc: 0.5735475896168108, val_acc: 0.5517241379310345, train_loss: 1.0850119643806675, val_loss: 1.0523519395607446 (46 / 100)
train_acc: 0.5859085290482077, val_acc: 0.5123152709359606, train_loss: 1.045369939839442, val_loss: 1.2025857335828207 (47 / 100)
train_acc: 0.5859085290482077, val_acc: 0.47783251231527096, train_loss: 1.0540366488127833, val_loss: 1.209336851030735 (48 / 100)
train_acc: 0.6019777503090235, val_acc: 0.46798029556650245, train_loss: 1.0048518849833787, val_loss: 1.2589439701270588 (49 / 100)
train_acc: 0.6007416563658838, val_acc: 0.5073891625615764, train_loss: 0.9888495270195055, val_loss: 1.2428431217306353 (50 / 100)
train_acc: 0.6279357231149567, val_acc: 0.5812807881773399, train_loss: 0.955213721956694, val_loss: 1.063156910424162 (51 / 100)
train_acc: 0.6341161928306551, val_acc: 0.5763546798029556, train_loss: 0.904357996579301, val_loss: 1.0587162757154756 (52 / 100)
train_acc: 0.6291718170580964, val_acc: 0.49261083743842365, train_loss: 0.9209998293477024, val_loss: 1.140599835388766 (53 / 100)
train_acc: 0.6415327564894932, val_acc: 0.5221674876847291, train_loss: 0.8768872963483313, val_loss: 1.3052036139765397 (54 / 100)
train_acc: 0.6835599505562423, val_acc: 0.5615763546798029, train_loss: 0.8238998138713012, val_loss: 1.0688501517173692 (55 / 100)
train_acc: 0.6711990111248455, val_acc: 0.5073891625615764, train_loss: 0.8107074986871594, val_loss: 1.2583565306780962 (56 / 100)
train_acc: 0.7107540173053152, val_acc: 0.541871921182266, train_loss: 0.7746881514750835, val_loss: 1.2451372240564507 (57 / 100)
train_acc: 0.6613102595797281, val_acc: 0.5172413793103449, train_loss: 0.8365898881618703, val_loss: 1.2628378782953535 (58 / 100)
train_acc: 0.7008652657601978, val_acc: 0.5615763546798029, train_loss: 0.796515135741499, val_loss: 1.2489537348594573 (59 / 100)
train_acc: 0.7194066749072929, val_acc: 0.5763546798029556, train_loss: 0.7021612368054384, val_loss: 1.0623816797885988 (60 / 100)
train_acc: 0.7552533992583437, val_acc: 0.5714285714285714, train_loss: 0.6630932771231247, val_loss: 1.182679180588041 (61 / 100)
train_acc: 0.7354758961681088, val_acc: 0.541871921182266, train_loss: 0.6914198768448329, val_loss: 1.3496642993588752 (62 / 100)
train_acc: 0.7762669962917181, val_acc: 0.4876847290640394, train_loss: 0.6275610116636208, val_loss: 1.3375410481626764 (63 / 100)
train_acc: 0.7626699629171817, val_acc: 0.5320197044334976, train_loss: 0.6237328917488032, val_loss: 1.164870146166515 (64 / 100)
train_acc: 0.7849196538936959, val_acc: 0.6502463054187192, train_loss: 0.5617382905833949, val_loss: 1.0741609851715013 (65 / 100)
train_acc: 0.823238566131026, val_acc: 0.5566502463054187, train_loss: 0.5135305512452449, val_loss: 1.1941093561684557 (66 / 100)
train_acc: 0.8046971569839307, val_acc: 0.6108374384236454, train_loss: 0.5169643526171577, val_loss: 1.1079555529678984 (67 / 100)
train_acc: 0.8022249690976514, val_acc: 0.541871921182266, train_loss: 0.5259098650056441, val_loss: 1.1468498096090232 (68 / 100)
train_acc: 0.8257107540173053, val_acc: 0.6009852216748769, train_loss: 0.4372872077711433, val_loss: 1.2800262215102247 (69 / 100)
train_acc: 0.8343634116192831, val_acc: 0.5960591133004927, train_loss: 0.46725488582117153, val_loss: 1.3025000192261682 (70 / 100)
train_acc: 0.8430160692212608, val_acc: 0.6108374384236454, train_loss: 0.4015993684419743, val_loss: 1.3195769170234943 (71 / 100)
train_acc: 0.8207663782447466, val_acc: 0.5911330049261084, train_loss: 0.4900442066387134, val_loss: 1.3162332984614256 (72 / 100)
train_acc: 0.8862793572311496, val_acc: 0.6600985221674877, train_loss: 0.33133404674779793, val_loss: 1.2496881414516805 (73 / 100)
train_acc: 0.8850432632880099, val_acc: 0.6403940886699507, train_loss: 0.3260001221254965, val_loss: 1.273976126768319 (74 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6502463054187192, train_loss: 0.33488636052210635, val_loss: 1.334957519481922 (75 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6108374384236454, train_loss: 0.3025168651813924, val_loss: 1.3509053978426704 (76 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6600985221674877, train_loss: 0.26404501252769685, val_loss: 1.3523094724551799 (77 / 100)
train_acc: 0.8788627935723115, val_acc: 0.645320197044335, train_loss: 0.31091344945952387, val_loss: 1.5673157475852026 (78 / 100)
train_acc: 0.8850432632880099, val_acc: 0.6157635467980296, train_loss: 0.30723719601835986, val_loss: 1.2437914292800603 (79 / 100)
train_acc: 0.9023485784919654, val_acc: 0.6206896551724138, train_loss: 0.2594727085090538, val_loss: 1.3068392085911604 (80 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6206896551724138, train_loss: 0.27312422192877683, val_loss: 1.3489740558445746 (81 / 100)
train_acc: 0.9110012360939431, val_acc: 0.6108374384236454, train_loss: 0.24922614479241767, val_loss: 1.6710186122086248 (82 / 100)
train_acc: 0.9060568603213844, val_acc: 0.5714285714285714, train_loss: 0.25982301707099775, val_loss: 1.5061808771687775 (83 / 100)
train_acc: 0.8899876390605687, val_acc: 0.6009852216748769, train_loss: 0.2783560052200949, val_loss: 1.5162383276840736 (84 / 100)
train_acc: 0.930778739184178, val_acc: 0.6600985221674877, train_loss: 0.1957876722044018, val_loss: 1.7007396696823571 (85 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6551724137931034, train_loss: 0.19643960320315934, val_loss: 1.65316422819504 (86 / 100)
train_acc: 0.9110012360939431, val_acc: 0.6847290640394089, train_loss: 0.21447988598617843, val_loss: 1.2969620803306843 (87 / 100)
train_acc: 0.9245982694684796, val_acc: 0.5911330049261084, train_loss: 0.22468791623474346, val_loss: 1.3399235243574152 (88 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6600985221674877, train_loss: 0.18954696585234296, val_loss: 1.3999948804014422 (89 / 100)
train_acc: 0.957972805933251, val_acc: 0.6502463054187192, train_loss: 0.15732464610658844, val_loss: 1.8260137371241754 (90 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6305418719211823, train_loss: 0.11443327774370851, val_loss: 1.9806129304059032 (91 / 100)
train_acc: 0.957972805933251, val_acc: 0.6009852216748769, train_loss: 0.12785035850680507, val_loss: 2.4426121147982593 (92 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6206896551724138, train_loss: 0.20951748008486368, val_loss: 1.5777117982873776 (93 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6699507389162561, train_loss: 0.15292878607368587, val_loss: 1.5437035836609714 (94 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6157635467980296, train_loss: 0.148504941218863, val_loss: 1.7789051955556634 (95 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6600985221674877, train_loss: 0.21017993923981199, val_loss: 1.417665024549503 (96 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6650246305418719, train_loss: 0.11257091705423719, val_loss: 1.762967722462903 (97 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6600985221674877, train_loss: 0.1432461405474559, val_loss: 2.389323148234137 (98 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6403940886699507, train_loss: 0.15877343020753013, val_loss: 1.7215871282398993 (99 / 100)
train_acc: 0.9629171817058096, val_acc: 0.645320197044335, train_loss: 0.11827396300456709, val_loss: 1.6345074746409074 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.6847290640394089, val loss 1.2969620803306843
train_acc: 0.14091470951792337, val_acc: 0.18226600985221675, train_loss: 1.791294159052251, val_loss: 1.7856890509281251 (1 / 100)
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7838531165246763, val_loss: 1.7758172433364567 (2 / 100)
train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7710073826781605, val_loss: 1.7563982556018922 (3 / 100)
train_acc: 0.1903584672435105, val_acc: 0.21674876847290642, train_loss: 1.7571616673793722, val_loss: 1.744096124113487 (4 / 100)
train_acc: 0.2200247218788628, val_acc: 0.22660098522167488, train_loss: 1.7501779772589912, val_loss: 1.7269557326885279 (5 / 100)
train_acc: 0.24351050679851668, val_acc: 0.270935960591133, train_loss: 1.7283283735824604, val_loss: 1.6998896181877023 (6 / 100)
train_acc: 0.26452410383189123, val_acc: 0.35467980295566504, train_loss: 1.7022912082330257, val_loss: 1.638359405137048 (7 / 100)
train_acc: 0.3003708281829419, val_acc: 0.33004926108374383, train_loss: 1.6495071039506326, val_loss: 1.6046459610239039 (8 / 100)
train_acc: 0.30902348578491967, val_acc: 0.3251231527093596, train_loss: 1.6376942970844075, val_loss: 1.6064492088233309 (9 / 100)
train_acc: 0.34610630407911, val_acc: 0.33497536945812806, train_loss: 1.5821018407607108, val_loss: 1.5480838996436208 (10 / 100)
train_acc: 0.3263288009888752, val_acc: 0.3399014778325123, train_loss: 1.5854351567691571, val_loss: 1.532668587609465 (11 / 100)
train_acc: 0.3473423980222497, val_acc: 0.3251231527093596, train_loss: 1.5635378614196966, val_loss: 1.4815107225784527 (12 / 100)
train_acc: 0.3584672435105068, val_acc: 0.29064039408866993, train_loss: 1.5360408091574576, val_loss: 1.4856429928042032 (13 / 100)
train_acc: 0.3374536464771323, val_acc: 0.32019704433497537, train_loss: 1.4939916035153515, val_loss: 1.5447272361792954 (14 / 100)
train_acc: 0.38442521631644005, val_acc: 0.3645320197044335, train_loss: 1.4757643802499005, val_loss: 1.4335653059588278 (15 / 100)
train_acc: 0.3868974042027194, val_acc: 0.3497536945812808, train_loss: 1.454032203028317, val_loss: 1.497194044695699 (16 / 100)
train_acc: 0.3683559950556242, val_acc: 0.4433497536945813, train_loss: 1.4484076830011658, val_loss: 1.4242459212617922 (17 / 100)
train_acc: 0.3819530284301607, val_acc: 0.3497536945812808, train_loss: 1.4022493651240364, val_loss: 1.417704433643172 (18 / 100)
train_acc: 0.38442521631644005, val_acc: 0.3842364532019704, train_loss: 1.420765985075122, val_loss: 1.3758241995214828 (19 / 100)
train_acc: 0.3794808405438813, val_acc: 0.4187192118226601, train_loss: 1.4113877053903265, val_loss: 1.389653323319158 (20 / 100)
train_acc: 0.43139678615574784, val_acc: 0.41379310344827586, train_loss: 1.361423467381481, val_loss: 1.3156501501064581 (21 / 100)
train_acc: 0.4004944375772559, val_acc: 0.41379310344827586, train_loss: 1.378735009760438, val_loss: 1.324101837691415 (22 / 100)
train_acc: 0.411619283065513, val_acc: 0.43842364532019706, train_loss: 1.3664403216653171, val_loss: 1.3745990416099285 (23 / 100)
train_acc: 0.4004944375772559, val_acc: 0.4088669950738916, train_loss: 1.357305859753169, val_loss: 1.309857511168043 (24 / 100)
train_acc: 0.43757725587144625, val_acc: 0.3694581280788177, train_loss: 1.3395040558354079, val_loss: 1.4501065109750908 (25 / 100)
train_acc: 0.4079110012360939, val_acc: 0.4729064039408867, train_loss: 1.3584715919235286, val_loss: 1.269415849828955 (26 / 100)
train_acc: 0.47342398022249693, val_acc: 0.4729064039408867, train_loss: 1.3146694614212358, val_loss: 1.2565735863347358 (27 / 100)
train_acc: 0.449938195302843, val_acc: 0.46798029556650245, train_loss: 1.3054873090149888, val_loss: 1.256828457557509 (28 / 100)
train_acc: 0.4622991347342398, val_acc: 0.4729064039408867, train_loss: 1.2761226930783323, val_loss: 1.2303392273451894 (29 / 100)
train_acc: 0.48084054388133496, val_acc: 0.4630541871921182, train_loss: 1.2704660779024084, val_loss: 1.237574181826831 (30 / 100)
train_acc: 0.4511742892459827, val_acc: 0.32019704433497537, train_loss: 1.288208446632357, val_loss: 1.5590556466520713 (31 / 100)
train_acc: 0.44746600741656367, val_acc: 0.46798029556650245, train_loss: 1.2984098987320003, val_loss: 1.234881951010286 (32 / 100)
train_acc: 0.4820766378244747, val_acc: 0.45320197044334976, train_loss: 1.2742917723355098, val_loss: 1.2920776852245988 (33 / 100)
train_acc: 0.4956736711990111, val_acc: 0.4630541871921182, train_loss: 1.2432049807570922, val_loss: 1.3039067290686621 (34 / 100)
train_acc: 0.49443757725587145, val_acc: 0.4729064039408867, train_loss: 1.2336689616899996, val_loss: 1.2150707949558501 (35 / 100)
train_acc: 0.4783683559950556, val_acc: 0.5172413793103449, train_loss: 1.2437192662832026, val_loss: 1.1995024995263575 (36 / 100)
train_acc: 0.5129789864029666, val_acc: 0.4729064039408867, train_loss: 1.217973482181469, val_loss: 1.1633788323754748 (37 / 100)
train_acc: 0.5018541409147095, val_acc: 0.4630541871921182, train_loss: 1.1843927889436079, val_loss: 1.244516109010856 (38 / 100)
train_acc: 0.46600741656365885, val_acc: 0.5024630541871922, train_loss: 1.2342778232100573, val_loss: 1.1500749723077408 (39 / 100)
train_acc: 0.49814585908529047, val_acc: 0.49261083743842365, train_loss: 1.1811523349087671, val_loss: 1.1757532399276207 (40 / 100)
train_acc: 0.5352286773794809, val_acc: 0.5517241379310345, train_loss: 1.1476211404918297, val_loss: 1.1410538066784148 (41 / 100)
train_acc: 0.5265760197775031, val_acc: 0.5221674876847291, train_loss: 1.1297751189162322, val_loss: 1.1861977007588729 (42 / 100)
train_acc: 0.5636588380716935, val_acc: 0.5123152709359606, train_loss: 1.108999546437682, val_loss: 1.1774528097049357 (43 / 100)
train_acc: 0.5599505562422744, val_acc: 0.5270935960591133, train_loss: 1.0773269473695932, val_loss: 1.1244172621243105 (44 / 100)
train_acc: 0.5426452410383189, val_acc: 0.5270935960591133, train_loss: 1.1246809823846051, val_loss: 1.1189549935275112 (45 / 100)
train_acc: 0.5920889987639061, val_acc: 0.5911330049261084, train_loss: 1.0533257243954501, val_loss: 1.0797894696883967 (46 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5270935960591133, train_loss: 1.1153218974583818, val_loss: 1.1712244640430207 (47 / 100)
train_acc: 0.5661310259579728, val_acc: 0.5123152709359606, train_loss: 1.0216501803863771, val_loss: 1.12032379422869 (48 / 100)
train_acc: 0.6044499381953028, val_acc: 0.5221674876847291, train_loss: 0.9799170722478105, val_loss: 1.1418867199291736 (49 / 100)
train_acc: 0.6044499381953028, val_acc: 0.541871921182266, train_loss: 0.9599678216522792, val_loss: 1.0892631960619847 (50 / 100)
train_acc: 0.6514215080346106, val_acc: 0.5911330049261084, train_loss: 0.9186559318759385, val_loss: 1.0702875923053385 (51 / 100)
train_acc: 0.6254635352286774, val_acc: 0.5566502463054187, train_loss: 0.9251570896843013, val_loss: 1.1286910044148637 (52 / 100)
train_acc: 0.6291718170580964, val_acc: 0.5270935960591133, train_loss: 0.9233109116996322, val_loss: 1.0942713606533745 (53 / 100)
train_acc: 0.6897404202719407, val_acc: 0.5517241379310345, train_loss: 0.8226803490346383, val_loss: 1.0944889082109988 (54 / 100)
train_acc: 0.6724351050679852, val_acc: 0.541871921182266, train_loss: 0.8547660380565044, val_loss: 1.1237143137184857 (55 / 100)
train_acc: 0.646477132262052, val_acc: 0.5763546798029556, train_loss: 0.918862882591738, val_loss: 1.0600052569887322 (56 / 100)
train_acc: 0.7008652657601978, val_acc: 0.5960591133004927, train_loss: 0.8064259915475644, val_loss: 1.0262623097508998 (57 / 100)
train_acc: 0.7119901112484549, val_acc: 0.5615763546798029, train_loss: 0.7391564549857518, val_loss: 1.1134782395339364 (58 / 100)
train_acc: 0.715698393077874, val_acc: 0.5714285714285714, train_loss: 0.7436045433299061, val_loss: 1.1746442408984519 (59 / 100)
train_acc: 0.7132262051915945, val_acc: 0.541871921182266, train_loss: 0.7416450042365066, val_loss: 1.2157294876469766 (60 / 100)
train_acc: 0.761433868974042, val_acc: 0.5911330049261084, train_loss: 0.6213897829518478, val_loss: 1.112928833280291 (61 / 100)
train_acc: 0.8145859085290482, val_acc: 0.6108374384236454, train_loss: 0.5129322957786259, val_loss: 1.1453368610936432 (62 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5960591133004927, train_loss: 0.4644290309753937, val_loss: 1.145680699148789 (63 / 100)
train_acc: 0.8343634116192831, val_acc: 0.5960591133004927, train_loss: 0.4288809378671705, val_loss: 1.1687016619250106 (64 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5960591133004927, train_loss: 0.46597738418502477, val_loss: 1.1324591384145426 (65 / 100)
train_acc: 0.8529048207663782, val_acc: 0.6206896551724138, train_loss: 0.4576504990108523, val_loss: 1.150812673744897 (66 / 100)
train_acc: 0.8763906056860321, val_acc: 0.5911330049261084, train_loss: 0.38563511371428355, val_loss: 1.1714329185156986 (67 / 100)
train_acc: 0.8504326328800988, val_acc: 0.6059113300492611, train_loss: 0.408092130320918, val_loss: 1.1606929657494494 (68 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5911330049261084, train_loss: 0.43580702768710106, val_loss: 1.148800951213085 (69 / 100)
train_acc: 0.8640296662546354, val_acc: 0.5960591133004927, train_loss: 0.3897200055484866, val_loss: 1.1841476800406507 (70 / 100)
train_acc: 0.8627935723114957, val_acc: 0.5960591133004927, train_loss: 0.367383913605558, val_loss: 1.2143340627548143 (71 / 100)
train_acc: 0.8739184177997528, val_acc: 0.5911330049261084, train_loss: 0.3482085689165536, val_loss: 1.199965964397186 (72 / 100)
train_acc: 0.8714462299134734, val_acc: 0.6009852216748769, train_loss: 0.34579105621804707, val_loss: 1.227967707981617 (73 / 100)
train_acc: 0.8825710754017305, val_acc: 0.6009852216748769, train_loss: 0.32178651722900947, val_loss: 1.24599793098243 (74 / 100)
train_acc: 0.8838071693448702, val_acc: 0.6157635467980296, train_loss: 0.33069798888175833, val_loss: 1.2549198695591517 (75 / 100)
train_acc: 0.8590852904820766, val_acc: 0.6059113300492611, train_loss: 0.36023260334366186, val_loss: 1.2353764790032298 (76 / 100)
train_acc: 0.8850432632880099, val_acc: 0.625615763546798, train_loss: 0.3116276555939846, val_loss: 1.2677218279815072 (77 / 100)
train_acc: 0.8739184177997528, val_acc: 0.6157635467980296, train_loss: 0.3233868316165891, val_loss: 1.2708893248013087 (78 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6009852216748769, train_loss: 0.30060738494575984, val_loss: 1.2997527298668923 (79 / 100)
train_acc: 0.892459826946848, val_acc: 0.6157635467980296, train_loss: 0.2880501508418061, val_loss: 1.3087395244631275 (80 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6009852216748769, train_loss: 0.2816758754056486, val_loss: 1.328224072021804 (81 / 100)
train_acc: 0.8875154511742892, val_acc: 0.6009852216748769, train_loss: 0.29497219653447865, val_loss: 1.277940048960042 (82 / 100)
train_acc: 0.8986402966625463, val_acc: 0.5960591133004927, train_loss: 0.28888198193646186, val_loss: 1.2707910693337765 (83 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6206896551724138, train_loss: 0.295491452546438, val_loss: 1.3042474474225725 (84 / 100)
train_acc: 0.9110012360939431, val_acc: 0.625615763546798, train_loss: 0.26358768266564686, val_loss: 1.3512168027497278 (85 / 100)
train_acc: 0.9011124845488258, val_acc: 0.625615763546798, train_loss: 0.2766386267760186, val_loss: 1.322425175770163 (86 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6157635467980296, train_loss: 0.26497308705439526, val_loss: 1.3922505319999356 (87 / 100)
train_acc: 0.9097651421508035, val_acc: 0.6009852216748769, train_loss: 0.2762993184759826, val_loss: 1.3597363597653769 (88 / 100)
train_acc: 0.892459826946848, val_acc: 0.6059113300492611, train_loss: 0.2900573155935969, val_loss: 1.3493042925895729 (89 / 100)
train_acc: 0.9085290482076638, val_acc: 0.6059113300492611, train_loss: 0.2439820463820942, val_loss: 1.3503521924535629 (90 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6009852216748769, train_loss: 0.2494236217956755, val_loss: 1.3818531741062408 (91 / 100)
train_acc: 0.9011124845488258, val_acc: 0.5960591133004927, train_loss: 0.2773110391330365, val_loss: 1.3727837137400811 (92 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6108374384236454, train_loss: 0.23714682929521733, val_loss: 1.3826608343664648 (93 / 100)
train_acc: 0.9147095179233622, val_acc: 0.625615763546798, train_loss: 0.22977707191739963, val_loss: 1.4182873523881283 (94 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6108374384236454, train_loss: 0.22026657711884884, val_loss: 1.4856042433254824 (95 / 100)
train_acc: 0.9097651421508035, val_acc: 0.6059113300492611, train_loss: 0.2419714397199369, val_loss: 1.4266644290515356 (96 / 100)
train_acc: 0.9221260815822002, val_acc: 0.625615763546798, train_loss: 0.23482434799703591, val_loss: 1.4783330207387801 (97 / 100)
train_acc: 0.9171817058096415, val_acc: 0.6206896551724138, train_loss: 0.21130082105160938, val_loss: 1.4586229189276108 (98 / 100)
train_acc: 0.9245982694684796, val_acc: 0.5862068965517241, train_loss: 0.22028412304275263, val_loss: 1.492980381244509 (99 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6206896551724138, train_loss: 0.1746680787378837, val_loss: 1.4525768069798135 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.05}), val accuracy 0.625615763546798, val loss 1.2677218279815072
train_acc: 0.14956736711990112, val_acc: 0.18226600985221675, train_loss: 1.7912535533327403, val_loss: 1.7849295033609927 (1 / 100)
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7828870591775448, val_loss: 1.7739724584400947 (2 / 100)
train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7694401382957903, val_loss: 1.7550625900916865 (3 / 100)
train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.766495667517701, val_loss: 1.7514261130628914 (4 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.755589942554903, val_loss: 1.7413058509967598 (5 / 100)
train_acc: 0.19530284301606923, val_acc: 0.18719211822660098, train_loss: 1.7487414581666623, val_loss: 1.7268438303999125 (6 / 100)
train_acc: 0.21631644004944375, val_acc: 0.2413793103448276, train_loss: 1.740178592714892, val_loss: 1.7091447925332732 (7 / 100)
train_acc: 0.3003708281829419, val_acc: 0.3251231527093596, train_loss: 1.701603465528217, val_loss: 1.6410148613558615 (8 / 100)
train_acc: 0.3362175525339926, val_acc: 0.29064039408866993, train_loss: 1.6605457820467955, val_loss: 1.6614848991920208 (9 / 100)
train_acc: 0.315203955500618, val_acc: 0.32019704433497537, train_loss: 1.6410240628958044, val_loss: 1.6667075415550194 (10 / 100)
train_acc: 0.3510506798516687, val_acc: 0.33004926108374383, train_loss: 1.5821969821514983, val_loss: 1.5261505918549787 (11 / 100)
train_acc: 0.3127317676143387, val_acc: 0.33004926108374383, train_loss: 1.571248523384443, val_loss: 1.5747166079253399 (12 / 100)
train_acc: 0.3522867737948084, val_acc: 0.3054187192118227, train_loss: 1.5495749442332754, val_loss: 1.4995301286575242 (13 / 100)
train_acc: 0.34981458590852904, val_acc: 0.3103448275862069, train_loss: 1.4970530135964581, val_loss: 1.4673484698892227 (14 / 100)
train_acc: 0.37082818294190356, val_acc: 0.35467980295566504, train_loss: 1.5011443041163706, val_loss: 1.4505731360665683 (15 / 100)
train_acc: 0.3856613102595797, val_acc: 0.39901477832512317, train_loss: 1.4555499264866814, val_loss: 1.3901912293997891 (16 / 100)
train_acc: 0.3856613102595797, val_acc: 0.4088669950738916, train_loss: 1.4228203234772747, val_loss: 1.4077405612456975 (17 / 100)
train_acc: 0.411619283065513, val_acc: 0.3448275862068966, train_loss: 1.4241501400880376, val_loss: 1.4856988009560872 (18 / 100)
train_acc: 0.3992583436341162, val_acc: 0.3694581280788177, train_loss: 1.4344050257992833, val_loss: 1.5153814953536235 (19 / 100)
train_acc: 0.3794808405438813, val_acc: 0.3891625615763547, train_loss: 1.4262827559660922, val_loss: 1.4177842692201361 (20 / 100)
train_acc: 0.4004944375772559, val_acc: 0.3645320197044335, train_loss: 1.3719882935617114, val_loss: 1.347497416834526 (21 / 100)
train_acc: 0.3868974042027194, val_acc: 0.4236453201970443, train_loss: 1.4105425081382723, val_loss: 1.4068816906125674 (22 / 100)
train_acc: 0.40914709517923364, val_acc: 0.4187192118226601, train_loss: 1.4066101104868358, val_loss: 1.307065139850372 (23 / 100)
train_acc: 0.4227441285537701, val_acc: 0.4433497536945813, train_loss: 1.3770764358848222, val_loss: 1.3032484271843445 (24 / 100)
train_acc: 0.4215080346106304, val_acc: 0.43842364532019706, train_loss: 1.3264572445040728, val_loss: 1.2891055369024793 (25 / 100)
train_acc: 0.41285537700865266, val_acc: 0.4482758620689655, train_loss: 1.3585213416881112, val_loss: 1.3353940412915986 (26 / 100)
train_acc: 0.4054388133498146, val_acc: 0.42857142857142855, train_loss: 1.402238633488253, val_loss: 1.2840831097710896 (27 / 100)
train_acc: 0.43510506798516685, val_acc: 0.4975369458128079, train_loss: 1.3362215104592303, val_loss: 1.2630057376006554 (28 / 100)
train_acc: 0.4622991347342398, val_acc: 0.4630541871921182, train_loss: 1.3105073023785472, val_loss: 1.303453783096351 (29 / 100)
train_acc: 0.45859085290482077, val_acc: 0.4482758620689655, train_loss: 1.3067813819212142, val_loss: 1.2589984750512786 (30 / 100)
train_acc: 0.4388133498145859, val_acc: 0.43842364532019706, train_loss: 1.3077585871051651, val_loss: 1.2917096136238775 (31 / 100)
train_acc: 0.43510506798516685, val_acc: 0.46798029556650245, train_loss: 1.3050923399047003, val_loss: 1.2495456660909605 (32 / 100)
train_acc: 0.4610630407911001, val_acc: 0.4039408866995074, train_loss: 1.3254163848749638, val_loss: 1.3321671104196258 (33 / 100)
train_acc: 0.4338689740420272, val_acc: 0.49261083743842365, train_loss: 1.2899331980199542, val_loss: 1.1876874122713588 (34 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4729064039408867, train_loss: 1.2820512809329039, val_loss: 1.2619510777478147 (35 / 100)
train_acc: 0.4796044499381953, val_acc: 0.47783251231527096, train_loss: 1.2265695122764786, val_loss: 1.191205382347107 (36 / 100)
train_acc: 0.45241038318912236, val_acc: 0.46798029556650245, train_loss: 1.2591352421509467, val_loss: 1.226238576649445 (37 / 100)
train_acc: 0.47713226205191595, val_acc: 0.43842364532019706, train_loss: 1.2396425307902181, val_loss: 1.2650480505280894 (38 / 100)
train_acc: 0.48084054388133496, val_acc: 0.4630541871921182, train_loss: 1.2297000913007003, val_loss: 1.223502686458268 (39 / 100)
train_acc: 0.4969097651421508, val_acc: 0.46798029556650245, train_loss: 1.2098722939732933, val_loss: 1.249930997787438 (40 / 100)
train_acc: 0.5018541409147095, val_acc: 0.458128078817734, train_loss: 1.1953491224494057, val_loss: 1.1733727378798235 (41 / 100)
train_acc: 0.4857849196538937, val_acc: 0.5172413793103449, train_loss: 1.1861374342102644, val_loss: 1.173161331655944 (42 / 100)
train_acc: 0.5179233621755254, val_acc: 0.4975369458128079, train_loss: 1.1421501754388232, val_loss: 1.223595717564005 (43 / 100)
train_acc: 0.5315203955500618, val_acc: 0.4433497536945813, train_loss: 1.1338655169873657, val_loss: 1.2211049207912876 (44 / 100)
train_acc: 0.5550061804697157, val_acc: 0.5024630541871922, train_loss: 1.1153738520790826, val_loss: 1.1165450050913055 (45 / 100)
train_acc: 0.5550061804697157, val_acc: 0.5320197044334976, train_loss: 1.1236217596622273, val_loss: 1.147510748485039 (46 / 100)
train_acc: 0.5401730531520396, val_acc: 0.5123152709359606, train_loss: 1.107157355333288, val_loss: 1.1313736095217062 (47 / 100)
train_acc: 0.546353522867738, val_acc: 0.5270935960591133, train_loss: 1.1219445795594394, val_loss: 1.1429993498501518 (48 / 100)
train_acc: 0.5599505562422744, val_acc: 0.5517241379310345, train_loss: 1.0601242523552903, val_loss: 1.070506243870176 (49 / 100)
train_acc: 0.5698393077873919, val_acc: 0.5221674876847291, train_loss: 1.0520018811426293, val_loss: 1.0988712398876697 (50 / 100)
train_acc: 0.6032138442521632, val_acc: 0.5566502463054187, train_loss: 1.009988401669949, val_loss: 1.070004145206489 (51 / 100)
train_acc: 0.5970333745364648, val_acc: 0.5320197044334976, train_loss: 1.023633415236314, val_loss: 1.083001425113584 (52 / 100)
train_acc: 0.5920889987639061, val_acc: 0.5566502463054187, train_loss: 0.996577741262792, val_loss: 1.0844966816197474 (53 / 100)
train_acc: 0.6032138442521632, val_acc: 0.5615763546798029, train_loss: 0.974743203268063, val_loss: 1.0686004983967747 (54 / 100)
train_acc: 0.6254635352286774, val_acc: 0.5566502463054187, train_loss: 0.9526860543028238, val_loss: 1.0709464937595312 (55 / 100)
train_acc: 0.6291718170580964, val_acc: 0.5073891625615764, train_loss: 0.9214658124190473, val_loss: 1.1123579323585397 (56 / 100)
train_acc: 0.6440049443757726, val_acc: 0.5369458128078818, train_loss: 0.9191288062462258, val_loss: 1.0306149638932327 (57 / 100)
train_acc: 0.6402966625463535, val_acc: 0.5172413793103449, train_loss: 0.9115238821845414, val_loss: 1.1786995829619797 (58 / 100)
train_acc: 0.6637824474660075, val_acc: 0.5024630541871922, train_loss: 0.8848138120766771, val_loss: 1.22143308209081 (59 / 100)
train_acc: 0.6650185414091471, val_acc: 0.5763546798029556, train_loss: 0.8471358502456373, val_loss: 1.120824455040429 (60 / 100)
train_acc: 0.7379480840543882, val_acc: 0.5911330049261084, train_loss: 0.6987563651630698, val_loss: 1.043343244808648 (61 / 100)
train_acc: 0.7453646477132262, val_acc: 0.6108374384236454, train_loss: 0.6582851138780969, val_loss: 1.0609759758845927 (62 / 100)
train_acc: 0.7787391841779975, val_acc: 0.5714285714285714, train_loss: 0.5914203734937203, val_loss: 1.0699876179836068 (63 / 100)
train_acc: 0.7663782447466008, val_acc: 0.5517241379310345, train_loss: 0.5815011459611108, val_loss: 1.1162344781048779 (64 / 100)
train_acc: 0.7836835599505563, val_acc: 0.5615763546798029, train_loss: 0.5882458656805261, val_loss: 1.1340518573234821 (65 / 100)
train_acc: 0.7824474660074165, val_acc: 0.5812807881773399, train_loss: 0.5692592029665839, val_loss: 1.0838666807841786 (66 / 100)
train_acc: 0.792336217552534, val_acc: 0.5665024630541872, train_loss: 0.5560017010779552, val_loss: 1.114659612695572 (67 / 100)
train_acc: 0.8022249690976514, val_acc: 0.5615763546798029, train_loss: 0.5295383288480148, val_loss: 1.1092141003444278 (68 / 100)
train_acc: 0.8133498145859085, val_acc: 0.5517241379310345, train_loss: 0.5011873457797231, val_loss: 1.1790444671814078 (69 / 100)
train_acc: 0.8009888751545118, val_acc: 0.5763546798029556, train_loss: 0.5040140384059901, val_loss: 1.153499395682894 (70 / 100)
train_acc: 0.8170580964153276, val_acc: 0.5714285714285714, train_loss: 0.5004348173571753, val_loss: 1.1359402446324014 (71 / 100)
train_acc: 0.8220024721878862, val_acc: 0.5517241379310345, train_loss: 0.49158132658311254, val_loss: 1.165147479825419 (72 / 100)
train_acc: 0.8343634116192831, val_acc: 0.5615763546798029, train_loss: 0.4520726564935465, val_loss: 1.1938867483820235 (73 / 100)
train_acc: 0.8207663782447466, val_acc: 0.5517241379310345, train_loss: 0.44270294978385805, val_loss: 1.1810517883653124 (74 / 100)
train_acc: 0.8294190358467244, val_acc: 0.5566502463054187, train_loss: 0.44758998207536116, val_loss: 1.223370660995615 (75 / 100)
train_acc: 0.8405438813349815, val_acc: 0.5615763546798029, train_loss: 0.41955617162294234, val_loss: 1.263092601534181 (76 / 100)
train_acc: 0.8566131025957973, val_acc: 0.541871921182266, train_loss: 0.404264256302889, val_loss: 1.3121873921361462 (77 / 100)
train_acc: 0.8294190358467244, val_acc: 0.5517241379310345, train_loss: 0.4289512523761933, val_loss: 1.2498608486992973 (78 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5566502463054187, train_loss: 0.3618149679287697, val_loss: 1.2855543091966601 (79 / 100)
train_acc: 0.8627935723114957, val_acc: 0.5615763546798029, train_loss: 0.35852942150661765, val_loss: 1.294647626395296 (80 / 100)
train_acc: 0.8553770086526576, val_acc: 0.5714285714285714, train_loss: 0.39930319159817784, val_loss: 1.246500746663568 (81 / 100)
train_acc: 0.8788627935723115, val_acc: 0.5615763546798029, train_loss: 0.3474968834624744, val_loss: 1.309751286882485 (82 / 100)
train_acc: 0.8875154511742892, val_acc: 0.5714285714285714, train_loss: 0.32278504626933663, val_loss: 1.3206738236502473 (83 / 100)
train_acc: 0.8788627935723115, val_acc: 0.5665024630541872, train_loss: 0.33464897872490995, val_loss: 1.3492105758836117 (84 / 100)
train_acc: 0.8838071693448702, val_acc: 0.5517241379310345, train_loss: 0.31209576651177684, val_loss: 1.414507480090475 (85 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5665024630541872, train_loss: 0.3317629594738021, val_loss: 1.491944714426407 (86 / 100)
train_acc: 0.8813349814585909, val_acc: 0.5566502463054187, train_loss: 0.3338530239717038, val_loss: 1.4256298427511318 (87 / 100)
train_acc: 0.8813349814585909, val_acc: 0.5714285714285714, train_loss: 0.30924605844342073, val_loss: 1.4472682070849565 (88 / 100)
train_acc: 0.907292954264524, val_acc: 0.5615763546798029, train_loss: 0.2673692201875491, val_loss: 1.593813112803868 (89 / 100)
train_acc: 0.8986402966625463, val_acc: 0.5714285714285714, train_loss: 0.2710324415317719, val_loss: 1.4822948892128291 (90 / 100)
train_acc: 0.8850432632880099, val_acc: 0.5665024630541872, train_loss: 0.3027949975653838, val_loss: 1.5178217071617766 (91 / 100)
train_acc: 0.9208899876390606, val_acc: 0.5665024630541872, train_loss: 0.2510701693106346, val_loss: 1.5360998593527695 (92 / 100)
train_acc: 0.8986402966625463, val_acc: 0.5714285714285714, train_loss: 0.2543535267908877, val_loss: 1.6733410314386115 (93 / 100)
train_acc: 0.9147095179233622, val_acc: 0.5763546798029556, train_loss: 0.25054071233947434, val_loss: 1.5676622989729707 (94 / 100)
train_acc: 0.9208899876390606, val_acc: 0.5665024630541872, train_loss: 0.22328291120576327, val_loss: 1.5925623287121062 (95 / 100)
train_acc: 0.8887515451174289, val_acc: 0.5763546798029556, train_loss: 0.2714614199914213, val_loss: 1.5697553410318685 (96 / 100)
train_acc: 0.927070457354759, val_acc: 0.5665024630541872, train_loss: 0.21318633005262452, val_loss: 1.6415278855802977 (97 / 100)
train_acc: 0.9035846724351051, val_acc: 0.5763546798029556, train_loss: 0.2672241924857843, val_loss: 1.6157184178606043 (98 / 100)
train_acc: 0.9097651421508035, val_acc: 0.5763546798029556, train_loss: 0.2263814733261231, val_loss: 1.6901830517012497 (99 / 100)
train_acc: 0.9122373300370828, val_acc: 0.5665024630541872, train_loss: 0.21982567876172154, val_loss: 1.6098851532184433 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6108374384236454, val loss 1.0609759758845927
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7910026692047403, val_loss: 1.7878807031462345 (1 / 100)
train_acc: 0.1903584672435105, val_acc: 0.21674876847290642, train_loss: 1.7859994066955132, val_loss: 1.7811731317360413 (2 / 100)
train_acc: 0.22744128553770088, val_acc: 0.18226600985221675, train_loss: 1.7772904008221715, val_loss: 1.7695591625908913 (3 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.770571891987427, val_loss: 1.7565752068176645 (4 / 100)
train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.759857417479139, val_loss: 1.7491220658635858 (5 / 100)
train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7530969175036963, val_loss: 1.7411743431842972 (6 / 100)
train_acc: 0.23362175525339926, val_acc: 0.22167487684729065, train_loss: 1.7393734559729899, val_loss: 1.7239773737385942 (7 / 100)
train_acc: 0.26823238566131025, val_acc: 0.22660098522167488, train_loss: 1.7172164810897392, val_loss: 1.6854756747560549 (8 / 100)
train_acc: 0.2657601977750309, val_acc: 0.2660098522167488, train_loss: 1.7081626266130558, val_loss: 1.6702542410695493 (9 / 100)
train_acc: 0.29666254635352285, val_acc: 0.3103448275862069, train_loss: 1.6512202980786526, val_loss: 1.582671719231629 (10 / 100)
train_acc: 0.3053152039555006, val_acc: 0.3103448275862069, train_loss: 1.6196044359277884, val_loss: 1.6118339458709867 (11 / 100)
train_acc: 0.3300370828182942, val_acc: 0.3497536945812808, train_loss: 1.5767442158921834, val_loss: 1.496836674624476 (12 / 100)
train_acc: 0.33868974042027195, val_acc: 0.35960591133004927, train_loss: 1.560014270292077, val_loss: 1.502376587520092 (13 / 100)
train_acc: 0.32756489493201485, val_acc: 0.29064039408866993, train_loss: 1.5415114252764746, val_loss: 1.5815671136226561 (14 / 100)
train_acc: 0.37824474660074164, val_acc: 0.37438423645320196, train_loss: 1.4963446547575434, val_loss: 1.4309930349218434 (15 / 100)
train_acc: 0.36341161928306553, val_acc: 0.4088669950738916, train_loss: 1.4826535761577384, val_loss: 1.447212146420784 (16 / 100)
train_acc: 0.37453646477132263, val_acc: 0.39901477832512317, train_loss: 1.4685516777380436, val_loss: 1.4430648845992065 (17 / 100)
train_acc: 0.3794808405438813, val_acc: 0.4088669950738916, train_loss: 1.4309302397505168, val_loss: 1.3892129242713815 (18 / 100)
train_acc: 0.3757725587144623, val_acc: 0.3793103448275862, train_loss: 1.4522089122694415, val_loss: 1.468432990788239 (19 / 100)
train_acc: 0.3831891223733004, val_acc: 0.4088669950738916, train_loss: 1.405698616955572, val_loss: 1.3555683731445538 (20 / 100)
train_acc: 0.3868974042027194, val_acc: 0.4433497536945813, train_loss: 1.393253181419797, val_loss: 1.3424985429336285 (21 / 100)
train_acc: 0.37082818294190356, val_acc: 0.4482758620689655, train_loss: 1.4222292502229972, val_loss: 1.396259391249107 (22 / 100)
train_acc: 0.3930778739184178, val_acc: 0.43349753694581283, train_loss: 1.3621196419700556, val_loss: 1.3398237386947782 (23 / 100)
train_acc: 0.4227441285537701, val_acc: 0.4630541871921182, train_loss: 1.3473365386425344, val_loss: 1.2924883054395027 (24 / 100)
train_acc: 0.4264524103831891, val_acc: 0.4236453201970443, train_loss: 1.3418121645860235, val_loss: 1.3445749100793172 (25 / 100)
train_acc: 0.41285537700865266, val_acc: 0.4482758620689655, train_loss: 1.3261798466975963, val_loss: 1.3177132389228332 (26 / 100)
train_acc: 0.4252163164400494, val_acc: 0.43842364532019706, train_loss: 1.3534905490533382, val_loss: 1.3383370549807996 (27 / 100)
train_acc: 0.4363411619283066, val_acc: 0.4827586206896552, train_loss: 1.3386224455238125, val_loss: 1.2624281357074607 (28 / 100)
train_acc: 0.46600741656365885, val_acc: 0.4729064039408867, train_loss: 1.294183110277202, val_loss: 1.245690141405378 (29 / 100)
train_acc: 0.4635352286773795, val_acc: 0.46798029556650245, train_loss: 1.298308004849626, val_loss: 1.265074766328182 (30 / 100)
train_acc: 0.4227441285537701, val_acc: 0.45320197044334976, train_loss: 1.3568268796274776, val_loss: 1.3228921631874122 (31 / 100)
train_acc: 0.45859085290482077, val_acc: 0.47783251231527096, train_loss: 1.2858822208694534, val_loss: 1.2214170130602833 (32 / 100)
train_acc: 0.46971569839307786, val_acc: 0.4433497536945813, train_loss: 1.2945009565765984, val_loss: 1.302828726510109 (33 / 100)
train_acc: 0.47095179233621753, val_acc: 0.4729064039408867, train_loss: 1.2589409987917641, val_loss: 1.2175574196970522 (34 / 100)
train_acc: 0.48331273176761436, val_acc: 0.458128078817734, train_loss: 1.2409357529488128, val_loss: 1.2451946482869791 (35 / 100)
train_acc: 0.45859085290482077, val_acc: 0.49261083743842365, train_loss: 1.2832970959589125, val_loss: 1.243166139266761 (36 / 100)
train_acc: 0.4758961681087763, val_acc: 0.4827586206896552, train_loss: 1.2441281479574988, val_loss: 1.2354583931086687 (37 / 100)
train_acc: 0.5006180469715699, val_acc: 0.4630541871921182, train_loss: 1.2246661354201687, val_loss: 1.2395696869037423 (38 / 100)
train_acc: 0.47342398022249693, val_acc: 0.5369458128078818, train_loss: 1.2408200073595836, val_loss: 1.1697087605011287 (39 / 100)
train_acc: 0.5092707045735476, val_acc: 0.5123152709359606, train_loss: 1.1678360077300385, val_loss: 1.1749649094830592 (40 / 100)
train_acc: 0.5278121137206427, val_acc: 0.45320197044334976, train_loss: 1.1978039753304424, val_loss: 1.1595566046649013 (41 / 100)
train_acc: 0.5241038318912238, val_acc: 0.4975369458128079, train_loss: 1.1733871001395662, val_loss: 1.162972044474973 (42 / 100)
train_acc: 0.5278121137206427, val_acc: 0.4827586206896552, train_loss: 1.1480294477806987, val_loss: 1.2862925229988662 (43 / 100)
train_acc: 0.5389369592088998, val_acc: 0.4975369458128079, train_loss: 1.1220863163102837, val_loss: 1.2063995047743097 (44 / 100)
train_acc: 0.5377008652657602, val_acc: 0.4827586206896552, train_loss: 1.08854727397301, val_loss: 1.1191699792598855 (45 / 100)
train_acc: 0.5599505562422744, val_acc: 0.5123152709359606, train_loss: 1.0947988260219654, val_loss: 1.1147971364664915 (46 / 100)
train_acc: 0.5723114956736712, val_acc: 0.4975369458128079, train_loss: 1.0741975630169598, val_loss: 1.1215961049930216 (47 / 100)
train_acc: 0.5574783683559951, val_acc: 0.5073891625615764, train_loss: 1.1142076863936057, val_loss: 1.1416529766444503 (48 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5024630541871922, train_loss: 1.0482806735044652, val_loss: 1.1152030094503769 (49 / 100)
train_acc: 0.6032138442521632, val_acc: 0.5369458128078818, train_loss: 0.9786490711057731, val_loss: 1.1059701510250861 (50 / 100)
train_acc: 0.6044499381953028, val_acc: 0.4876847290640394, train_loss: 1.0085880305475299, val_loss: 1.209109278148031 (51 / 100)
train_acc: 0.5970333745364648, val_acc: 0.541871921182266, train_loss: 1.005657278563095, val_loss: 1.1103361627738464 (52 / 100)
train_acc: 0.5970333745364648, val_acc: 0.5517241379310345, train_loss: 0.9964775037117146, val_loss: 1.0737752247913717 (53 / 100)
train_acc: 0.6402966625463535, val_acc: 0.5763546798029556, train_loss: 0.8828198069842401, val_loss: 1.0881581608885027 (54 / 100)
train_acc: 0.6860321384425216, val_acc: 0.5270935960591133, train_loss: 0.8344741044439403, val_loss: 1.1888773927254042 (55 / 100)
train_acc: 0.6761433868974042, val_acc: 0.5073891625615764, train_loss: 0.8582632700798686, val_loss: 1.2554064743918152 (56 / 100)
train_acc: 0.6897404202719407, val_acc: 0.5566502463054187, train_loss: 0.8192380928285926, val_loss: 1.0417523354732345 (57 / 100)
train_acc: 0.7045735475896168, val_acc: 0.5320197044334976, train_loss: 0.7627374860648024, val_loss: 1.1984104355567782 (58 / 100)
train_acc: 0.6662546353522868, val_acc: 0.49261083743842365, train_loss: 0.8236153911895894, val_loss: 1.222348894391741 (59 / 100)
train_acc: 0.7045735475896168, val_acc: 0.5172413793103449, train_loss: 0.7291953379497834, val_loss: 1.116827696415004 (60 / 100)
train_acc: 0.7255871446229913, val_acc: 0.5714285714285714, train_loss: 0.7624099109832967, val_loss: 1.1974633615005192 (61 / 100)
train_acc: 0.7206427688504327, val_acc: 0.5960591133004927, train_loss: 0.7223132727909441, val_loss: 1.0463217526233841 (62 / 100)
train_acc: 0.7453646477132262, val_acc: 0.5714285714285714, train_loss: 0.6593929538031297, val_loss: 1.1650303244003521 (63 / 100)
train_acc: 0.7552533992583437, val_acc: 0.5615763546798029, train_loss: 0.629725207725473, val_loss: 1.1275798491950106 (64 / 100)
train_acc: 0.7836835599505563, val_acc: 0.5763546798029556, train_loss: 0.5830350079112059, val_loss: 1.1552963664966265 (65 / 100)
train_acc: 0.7972805933250927, val_acc: 0.5665024630541872, train_loss: 0.5592057280914745, val_loss: 1.3089748215792802 (66 / 100)
train_acc: 0.7898640296662547, val_acc: 0.5714285714285714, train_loss: 0.5338030156157957, val_loss: 1.2015944825017393 (67 / 100)
train_acc: 0.7725587144622992, val_acc: 0.4827586206896552, train_loss: 0.5869064440833329, val_loss: 1.5337247208421454 (68 / 100)
train_acc: 0.8071693448702101, val_acc: 0.5566502463054187, train_loss: 0.5312282656341313, val_loss: 1.377123534385794 (69 / 100)
train_acc: 0.8121137206427689, val_acc: 0.5812807881773399, train_loss: 0.4917296106352647, val_loss: 1.81664008841726 (70 / 100)
train_acc: 0.826946847960445, val_acc: 0.645320197044335, train_loss: 0.4741167350958835, val_loss: 1.1720059995580776 (71 / 100)
train_acc: 0.8566131025957973, val_acc: 0.6305418719211823, train_loss: 0.3641761021207378, val_loss: 1.3450822905073025 (72 / 100)
train_acc: 0.8380716934487021, val_acc: 0.6354679802955665, train_loss: 0.4321309339867534, val_loss: 1.1129103355807037 (73 / 100)
train_acc: 0.8640296662546354, val_acc: 0.5911330049261084, train_loss: 0.37358427042203723, val_loss: 1.5626118347562592 (74 / 100)
train_acc: 0.8504326328800988, val_acc: 0.6108374384236454, train_loss: 0.4098396145811187, val_loss: 1.4469122869040578 (75 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5714285714285714, train_loss: 0.3678710836967815, val_loss: 1.3627164011518356 (76 / 100)
train_acc: 0.8838071693448702, val_acc: 0.5862068965517241, train_loss: 0.2943534168457366, val_loss: 1.6561225453033823 (77 / 100)
train_acc: 0.896168108776267, val_acc: 0.6009852216748769, train_loss: 0.2580277410293244, val_loss: 1.4489835430248617 (78 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5911330049261084, train_loss: 0.35653414242936593, val_loss: 1.137580307246429 (79 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6059113300492611, train_loss: 0.30827674361772384, val_loss: 1.262716235198411 (80 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6108374384236454, train_loss: 0.22041449263779395, val_loss: 1.3891974787406733 (81 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6206896551724138, train_loss: 0.21857768615848203, val_loss: 1.6161539630936872 (82 / 100)
train_acc: 0.907292954264524, val_acc: 0.5862068965517241, train_loss: 0.2737284565738164, val_loss: 1.582026535067065 (83 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6059113300492611, train_loss: 0.2693876636908729, val_loss: 1.7023260904650384 (84 / 100)
train_acc: 0.9159456118665018, val_acc: 0.625615763546798, train_loss: 0.2080172499634869, val_loss: 1.7551908325679197 (85 / 100)
train_acc: 0.9357231149567367, val_acc: 0.5960591133004927, train_loss: 0.18359566828965845, val_loss: 1.6432629433171502 (86 / 100)
train_acc: 0.9381953028430161, val_acc: 0.6009852216748769, train_loss: 0.16618293976901635, val_loss: 1.856960888566642 (87 / 100)
train_acc: 0.9332509270704573, val_acc: 0.6108374384236454, train_loss: 0.17546162558017284, val_loss: 2.0165501398406005 (88 / 100)
train_acc: 0.9245982694684796, val_acc: 0.5862068965517241, train_loss: 0.22963472850832567, val_loss: 1.5621230737329117 (89 / 100)
train_acc: 0.9357231149567367, val_acc: 0.625615763546798, train_loss: 0.16997805794030982, val_loss: 2.156680556940915 (90 / 100)
train_acc: 0.9258343634116193, val_acc: 0.5615763546798029, train_loss: 0.21740599111072506, val_loss: 1.733694222760318 (91 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6403940886699507, train_loss: 0.1449277029822872, val_loss: 1.9365901359783604 (92 / 100)
train_acc: 0.965389369592089, val_acc: 0.6157635467980296, train_loss: 0.10598696442256188, val_loss: 2.3972773099767752 (93 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6059113300492611, train_loss: 0.1967825220232399, val_loss: 1.4849086629933324 (94 / 100)
train_acc: 0.9283065512978986, val_acc: 0.6059113300492611, train_loss: 0.19670052644054145, val_loss: 1.6083679134622584 (95 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6157635467980296, train_loss: 0.13108019038979585, val_loss: 1.881375177887273 (96 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6009852216748769, train_loss: 0.13736402472234774, val_loss: 1.8327364833484143 (97 / 100)
train_acc: 0.9641532756489494, val_acc: 0.5714285714285714, train_loss: 0.09902946837937139, val_loss: 2.147366923798481 (98 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6305418719211823, train_loss: 0.12442796088913996, val_loss: 2.1643088462904756 (99 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6108374384236454, train_loss: 0.10444212372418941, val_loss: 2.358805670526815 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 1}), val accuracy 0.645320197044335, val loss 1.1720059995580776
train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7801299428173578, val_loss: 1.75621894486432 (1 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7610624536448267, val_loss: 1.7375347555564542 (2 / 100)
train_acc: 0.22249690976514216, val_acc: 0.20689655172413793, train_loss: 1.7458026534399969, val_loss: 1.7663527098782543 (3 / 100)
train_acc: 0.27812113720642767, val_acc: 0.22660098522167488, train_loss: 1.7086842487415366, val_loss: 1.7228359207143924 (4 / 100)
train_acc: 0.2904820766378245, val_acc: 0.18719211822660098, train_loss: 1.686671172879977, val_loss: 1.765205033307005 (5 / 100)
train_acc: 0.3189122373300371, val_acc: 0.2955665024630542, train_loss: 1.6567461089828548, val_loss: 1.5769461921870416 (6 / 100)
train_acc: 0.3003708281829419, val_acc: 0.4187192118226601, train_loss: 1.6201343368393528, val_loss: 1.4821372131995967 (7 / 100)
train_acc: 0.3473423980222497, val_acc: 0.32019704433497537, train_loss: 1.6004507898252887, val_loss: 1.5034744228635515 (8 / 100)
train_acc: 0.3263288009888752, val_acc: 0.3793103448275862, train_loss: 1.5346224358114235, val_loss: 1.5150078546824715 (9 / 100)
train_acc: 0.32138442521631644, val_acc: 0.23645320197044334, train_loss: 1.5328126227752534, val_loss: 1.683806865086109 (10 / 100)
train_acc: 0.34857849196538937, val_acc: 0.3497536945812808, train_loss: 1.4932296849299125, val_loss: 1.4847915930113769 (11 / 100)
train_acc: 0.39555006180469715, val_acc: 0.42857142857142855, train_loss: 1.4467794619620362, val_loss: 1.3754199120798722 (12 / 100)
train_acc: 0.411619283065513, val_acc: 0.35467980295566504, train_loss: 1.39137726661154, val_loss: 1.3561959113980748 (13 / 100)
train_acc: 0.37330037082818296, val_acc: 0.39901477832512317, train_loss: 1.4201806611272108, val_loss: 1.4624827242837164 (14 / 100)
train_acc: 0.40667490729295425, val_acc: 0.4482758620689655, train_loss: 1.3522955257312035, val_loss: 1.4416815048368106 (15 / 100)
train_acc: 0.43016069221260816, val_acc: 0.4433497536945813, train_loss: 1.370755307901333, val_loss: 1.3292443021177658 (16 / 100)
train_acc: 0.449938195302843, val_acc: 0.42857142857142855, train_loss: 1.2895672094394603, val_loss: 1.2362930619070682 (17 / 100)
train_acc: 0.4573547589616811, val_acc: 0.4975369458128079, train_loss: 1.2713697584362054, val_loss: 1.2577658322057113 (18 / 100)
train_acc: 0.47095179233621753, val_acc: 0.49261083743842365, train_loss: 1.2336614647666073, val_loss: 1.2543413081192618 (19 / 100)
train_acc: 0.4610630407911001, val_acc: 0.4827586206896552, train_loss: 1.262315387042108, val_loss: 1.2045134907872805 (20 / 100)
train_acc: 0.4919653893695921, val_acc: 0.5073891625615764, train_loss: 1.1911110885358416, val_loss: 1.1953844219592993 (21 / 100)
train_acc: 0.5352286773794809, val_acc: 0.43349753694581283, train_loss: 1.13037333323428, val_loss: 1.4379483050313489 (22 / 100)
train_acc: 0.519159456118665, val_acc: 0.4975369458128079, train_loss: 1.145403498330134, val_loss: 1.1564564716639778 (23 / 100)
train_acc: 0.546353522867738, val_acc: 0.4876847290640394, train_loss: 1.1055386652905212, val_loss: 1.1664780716003456 (24 / 100)
train_acc: 0.5859085290482077, val_acc: 0.4876847290640394, train_loss: 1.0309921150891241, val_loss: 1.1870302798712782 (25 / 100)
train_acc: 0.6081582200247219, val_acc: 0.541871921182266, train_loss: 0.991880303407629, val_loss: 1.1106127597428308 (26 / 100)
train_acc: 0.6032138442521632, val_acc: 0.49261083743842365, train_loss: 0.9986830378050268, val_loss: 1.517352867596255 (27 / 100)
train_acc: 0.5871446229913473, val_acc: 0.5123152709359606, train_loss: 0.9731894550276333, val_loss: 1.1707208520673178 (28 / 100)
train_acc: 0.6452410383189122, val_acc: 0.5172413793103449, train_loss: 0.9017177868832469, val_loss: 1.1130062067156354 (29 / 100)
train_acc: 0.6749072929542645, val_acc: 0.5270935960591133, train_loss: 0.8161639566032495, val_loss: 1.118198100862832 (30 / 100)
train_acc: 0.69221260815822, val_acc: 0.5024630541871922, train_loss: 0.8156303394268116, val_loss: 1.4569432110034775 (31 / 100)
train_acc: 0.69221260815822, val_acc: 0.6059113300492611, train_loss: 0.8113018829831381, val_loss: 1.1386774150021557 (32 / 100)
train_acc: 0.7119901112484549, val_acc: 0.5270935960591133, train_loss: 0.7358386246913443, val_loss: 1.2866222212467286 (33 / 100)
train_acc: 0.7206427688504327, val_acc: 0.6009852216748769, train_loss: 0.710587831303864, val_loss: 1.354241362639836 (34 / 100)
train_acc: 0.7317676143386898, val_acc: 0.6009852216748769, train_loss: 0.6844790034889439, val_loss: 1.14945900733835 (35 / 100)
train_acc: 0.7663782447466008, val_acc: 0.6009852216748769, train_loss: 0.5918349802715079, val_loss: 1.2456076799942355 (36 / 100)
train_acc: 0.7849196538936959, val_acc: 0.5369458128078818, train_loss: 0.5842995142612528, val_loss: 1.3636068226081397 (37 / 100)
train_acc: 0.7775030902348579, val_acc: 0.5615763546798029, train_loss: 0.6198059905444736, val_loss: 1.482170416216545 (38 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5517241379310345, train_loss: 0.44953563083676973, val_loss: 1.2094289322792016 (39 / 100)
train_acc: 0.8355995055624228, val_acc: 0.5320197044334976, train_loss: 0.4180374174978589, val_loss: 1.615326251880509 (40 / 100)
train_acc: 0.8158220024721878, val_acc: 0.5615763546798029, train_loss: 0.5107358066349006, val_loss: 1.4488616703179082 (41 / 100)
train_acc: 0.8467243510506799, val_acc: 0.5517241379310345, train_loss: 0.44659215071882097, val_loss: 1.272241063599516 (42 / 100)
train_acc: 0.8590852904820766, val_acc: 0.5862068965517241, train_loss: 0.40101420614127026, val_loss: 1.7551665797903033 (43 / 100)
train_acc: 0.8454882571075402, val_acc: 0.5812807881773399, train_loss: 0.4176328484295915, val_loss: 1.270969825278362 (44 / 100)
train_acc: 0.8974042027194067, val_acc: 0.5911330049261084, train_loss: 0.29710577400712057, val_loss: 1.9435129964109419 (45 / 100)
train_acc: 0.8603213844252163, val_acc: 0.5763546798029556, train_loss: 0.38572532741631504, val_loss: 1.8376886058103274 (46 / 100)
train_acc: 0.8887515451174289, val_acc: 0.5665024630541872, train_loss: 0.3163485851217112, val_loss: 1.4181692388844607 (47 / 100)
train_acc: 0.8850432632880099, val_acc: 0.5911330049261084, train_loss: 0.3070987751811043, val_loss: 1.4728328491666633 (48 / 100)
train_acc: 0.9085290482076638, val_acc: 0.5665024630541872, train_loss: 0.2739228443398022, val_loss: 1.6893832342962396 (49 / 100)
train_acc: 0.9023485784919654, val_acc: 0.5960591133004927, train_loss: 0.25426466120188257, val_loss: 1.7526299002135328 (50 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6059113300492611, train_loss: 0.19287071018784832, val_loss: 2.219973161009145 (51 / 100)
train_acc: 0.9505562422744128, val_acc: 0.5960591133004927, train_loss: 0.15396842113678771, val_loss: 2.092652494096991 (52 / 100)
train_acc: 0.9283065512978986, val_acc: 0.6059113300492611, train_loss: 0.23163673403236568, val_loss: 1.2571908523296487 (53 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6403940886699507, train_loss: 0.2120558842740336, val_loss: 1.6587386918139502 (54 / 100)
train_acc: 0.9332509270704573, val_acc: 0.5812807881773399, train_loss: 0.1757762175702636, val_loss: 2.0524291250799678 (55 / 100)
train_acc: 0.9542645241038319, val_acc: 0.6354679802955665, train_loss: 0.14949850894612052, val_loss: 1.4388939395106484 (56 / 100)
train_acc: 0.9369592088998764, val_acc: 0.541871921182266, train_loss: 0.19573196801915305, val_loss: 1.837668590321036 (57 / 100)
train_acc: 0.957972805933251, val_acc: 0.6600985221674877, train_loss: 0.13265640022433436, val_loss: 2.001555358247804 (58 / 100)
train_acc: 0.9542645241038319, val_acc: 0.6551724137931034, train_loss: 0.1331260929296279, val_loss: 1.7044850429657645 (59 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6059113300492611, train_loss: 0.12372906113731846, val_loss: 3.083077639928592 (60 / 100)
train_acc: 0.9555006180469716, val_acc: 0.645320197044335, train_loss: 0.1184496823583162, val_loss: 2.057457968519239 (61 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6551724137931034, train_loss: 0.06510195758640398, val_loss: 1.965902459426907 (62 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6551724137931034, train_loss: 0.03811290178664388, val_loss: 1.9954086906125246 (63 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6502463054187192, train_loss: 0.051765425243542725, val_loss: 2.0926432656583014 (64 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.04170373785775731, val_loss: 2.155159375933114 (65 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.040179050307633406, val_loss: 2.1431554996321354 (66 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6600985221674877, train_loss: 0.03184413968853662, val_loss: 2.199521318445065 (67 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6748768472906403, train_loss: 0.030647165695727976, val_loss: 2.246254777668842 (68 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6798029556650246, train_loss: 0.017684865793574724, val_loss: 2.2935955089911486 (69 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.034411509635274576, val_loss: 2.3208185639874688 (70 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6798029556650246, train_loss: 0.024209182842994944, val_loss: 2.3841079033044137 (71 / 100)
train_acc: 0.9975278121137207, val_acc: 0.6748768472906403, train_loss: 0.026048913726995252, val_loss: 2.449539372486434 (72 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6798029556650246, train_loss: 0.013531222921072037, val_loss: 2.468502209103194 (73 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6699507389162561, train_loss: 0.02875927028019437, val_loss: 2.429243036090474 (74 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6699507389162561, train_loss: 0.019752820725788735, val_loss: 2.458738669974436 (75 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6748768472906403, train_loss: 0.01663016167795113, val_loss: 2.491652893902633 (76 / 100)
train_acc: 0.992583436341162, val_acc: 0.6699507389162561, train_loss: 0.02374359600623547, val_loss: 2.4957379002865 (77 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6748768472906403, train_loss: 0.029310492266830614, val_loss: 2.547094659853424 (78 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6748768472906403, train_loss: 0.017261828716075317, val_loss: 2.5933351140885654 (79 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6699507389162561, train_loss: 0.024263379747699602, val_loss: 2.5768144823647483 (80 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6798029556650246, train_loss: 0.027421344490664263, val_loss: 2.6085134398173815 (81 / 100)
train_acc: 0.992583436341162, val_acc: 0.6748768472906403, train_loss: 0.018678172704463248, val_loss: 2.6403998482985 (82 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6748768472906403, train_loss: 0.019387375439053264, val_loss: 2.6441690064413277 (83 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6650246305418719, train_loss: 0.015489519305518, val_loss: 2.6212065090685384 (84 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6699507389162561, train_loss: 0.01737028117232918, val_loss: 2.6581877111802807 (85 / 100)
train_acc: 0.992583436341162, val_acc: 0.6650246305418719, train_loss: 0.01838641968292123, val_loss: 2.705913611820479 (86 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6600985221674877, train_loss: 0.014656872625551353, val_loss: 2.72156977301132 (87 / 100)
train_acc: 0.9987639060568603, val_acc: 0.6600985221674877, train_loss: 0.011640795523804993, val_loss: 2.7392982802367563 (88 / 100)
train_acc: 0.992583436341162, val_acc: 0.6600985221674877, train_loss: 0.02517762761770279, val_loss: 2.785082060715248 (89 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6650246305418719, train_loss: 0.021555550608263616, val_loss: 2.8329349691644676 (90 / 100)
train_acc: 0.9975278121137207, val_acc: 0.6600985221674877, train_loss: 0.01288783506056287, val_loss: 2.89153351689737 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6748768472906403, train_loss: 0.02181178883952175, val_loss: 2.8858451420450444 (92 / 100)
train_acc: 0.9975278121137207, val_acc: 0.6650246305418719, train_loss: 0.013023079104712336, val_loss: 2.898839207118368 (93 / 100)
train_acc: 0.992583436341162, val_acc: 0.6650246305418719, train_loss: 0.015120219978030739, val_loss: 2.881822618944318 (94 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6847290640394089, train_loss: 0.01897998690163102, val_loss: 2.9692663794077743 (95 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6699507389162561, train_loss: 0.019247881119566587, val_loss: 2.9811784821775227 (96 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6748768472906403, train_loss: 0.024107844484751246, val_loss: 2.947866954239432 (97 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6798029556650246, train_loss: 0.014780072110839768, val_loss: 2.9152934163663446 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.6650246305418719, train_loss: 0.012861773169084887, val_loss: 2.8998901667853296 (99 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6650246305418719, train_loss: 0.01431022851517233, val_loss: 2.9252955291071547 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.05}), val accuracy 0.6847290640394089, val loss 2.9692663794077743
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7821152901325297, val_loss: 1.7594827031854339 (1 / 100)
train_acc: 0.1915945611866502, val_acc: 0.1921182266009852, train_loss: 1.7671305057586935, val_loss: 1.7573219684544454 (2 / 100)
train_acc: 0.2311495673671199, val_acc: 0.19704433497536947, train_loss: 1.7394192466335037, val_loss: 1.8513351261909372 (3 / 100)
train_acc: 0.24103831891223734, val_acc: 0.2857142857142857, train_loss: 1.742006964088223, val_loss: 1.7241279714800455 (4 / 100)
train_acc: 0.2249690976514215, val_acc: 0.28078817733990147, train_loss: 1.7474177165143423, val_loss: 1.7250609867678488 (5 / 100)
train_acc: 0.2904820766378245, val_acc: 0.33004926108374383, train_loss: 1.686941240567654, val_loss: 1.624984023019011 (6 / 100)
train_acc: 0.29171817058096416, val_acc: 0.30049261083743845, train_loss: 1.633921330879881, val_loss: 1.6028641538666974 (7 / 100)
train_acc: 0.3189122373300371, val_acc: 0.3251231527093596, train_loss: 1.609685198927692, val_loss: 1.5738701285987065 (8 / 100)
train_acc: 0.32756489493201485, val_acc: 0.3399014778325123, train_loss: 1.6100317670034685, val_loss: 1.5839980699745893 (9 / 100)
train_acc: 0.30407911001236093, val_acc: 0.33497536945812806, train_loss: 1.622377882487105, val_loss: 1.6848962471402924 (10 / 100)
train_acc: 0.3510506798516687, val_acc: 0.3399014778325123, train_loss: 1.5752150826754765, val_loss: 1.562039028247589 (11 / 100)
train_acc: 0.34487021013597036, val_acc: 0.3497536945812808, train_loss: 1.5564817663176245, val_loss: 1.551580178326574 (12 / 100)
train_acc: 0.2867737948084054, val_acc: 0.35960591133004927, train_loss: 1.6736834669584693, val_loss: 1.52177791642438 (13 / 100)
train_acc: 0.33498145859085293, val_acc: 0.35960591133004927, train_loss: 1.5857051008269283, val_loss: 1.5328767710718616 (14 / 100)
train_acc: 0.3584672435105068, val_acc: 0.3842364532019704, train_loss: 1.532660120791941, val_loss: 1.4984139016109148 (15 / 100)
train_acc: 0.36341161928306553, val_acc: 0.37438423645320196, train_loss: 1.529268030772545, val_loss: 1.6397039960757853 (16 / 100)
train_acc: 0.37824474660074164, val_acc: 0.3448275862068966, train_loss: 1.5031039042879537, val_loss: 1.5330819067696633 (17 / 100)
train_acc: 0.3510506798516687, val_acc: 0.3645320197044335, train_loss: 1.5234484572345748, val_loss: 1.650516298604129 (18 / 100)
train_acc: 0.380716934487021, val_acc: 0.33497536945812806, train_loss: 1.4974217799449585, val_loss: 1.496564151618281 (19 / 100)
train_acc: 0.3980222496909765, val_acc: 0.3694581280788177, train_loss: 1.4454938902695778, val_loss: 1.6280041298842782 (20 / 100)
train_acc: 0.40667490729295425, val_acc: 0.4433497536945813, train_loss: 1.4616226610648175, val_loss: 1.382579759423956 (21 / 100)
train_acc: 0.4079110012360939, val_acc: 0.43349753694581283, train_loss: 1.4175471107214137, val_loss: 1.4236949206573035 (22 / 100)
train_acc: 0.41285537700865266, val_acc: 0.4187192118226601, train_loss: 1.421282968356082, val_loss: 1.428522976161224 (23 / 100)
train_acc: 0.3930778739184178, val_acc: 0.3448275862068966, train_loss: 1.411761883015391, val_loss: 1.4144349673698688 (24 / 100)
train_acc: 0.3943139678615575, val_acc: 0.42857142857142855, train_loss: 1.384196824432156, val_loss: 1.309829602687817 (25 / 100)
train_acc: 0.3992583436341162, val_acc: 0.3054187192118227, train_loss: 1.3725975638414343, val_loss: 1.6117907721420814 (26 / 100)
train_acc: 0.4388133498145859, val_acc: 0.3891625615763547, train_loss: 1.3427324141795909, val_loss: 1.3133515060828824 (27 / 100)
train_acc: 0.47095179233621753, val_acc: 0.4433497536945813, train_loss: 1.2778434635534863, val_loss: 1.235237474511997 (28 / 100)
train_acc: 0.4647713226205192, val_acc: 0.4729064039408867, train_loss: 1.26338575796969, val_loss: 1.2939296790531702 (29 / 100)
train_acc: 0.4721878862793572, val_acc: 0.5024630541871922, train_loss: 1.2797797407001736, val_loss: 1.2575695508806577 (30 / 100)
train_acc: 0.4932014833127318, val_acc: 0.47783251231527096, train_loss: 1.1519739106205398, val_loss: 1.308768698147365 (31 / 100)
train_acc: 0.47095179233621753, val_acc: 0.41379310344827586, train_loss: 1.21080712865398, val_loss: 1.3161864427510153 (32 / 100)
train_acc: 0.5055624227441285, val_acc: 0.45320197044334976, train_loss: 1.1604962521342028, val_loss: 1.3350416598061623 (33 / 100)
train_acc: 0.5327564894932015, val_acc: 0.4975369458128079, train_loss: 1.1304590389666658, val_loss: 1.1544796707007685 (34 / 100)
train_acc: 0.553770086526576, val_acc: 0.5024630541871922, train_loss: 1.106512431308572, val_loss: 1.2623741661973775 (35 / 100)
train_acc: 0.5710754017305315, val_acc: 0.5123152709359606, train_loss: 1.0710731068411923, val_loss: 1.232802879046924 (36 / 100)
train_acc: 0.5896168108776267, val_acc: 0.4876847290640394, train_loss: 1.020749735596448, val_loss: 1.240163281046111 (37 / 100)
train_acc: 0.6007416563658838, val_acc: 0.5073891625615764, train_loss: 0.9657393444895892, val_loss: 1.3518308383490651 (38 / 100)
train_acc: 0.5982694684796045, val_acc: 0.5566502463054187, train_loss: 0.9700467470107769, val_loss: 1.33592419847479 (39 / 100)
train_acc: 0.6242274412855378, val_acc: 0.5270935960591133, train_loss: 0.9471914912625797, val_loss: 1.1990352223072145 (40 / 100)
train_acc: 0.6378244746600742, val_acc: 0.5566502463054187, train_loss: 0.8826767153144619, val_loss: 1.3038816507813966 (41 / 100)
train_acc: 0.657601977750309, val_acc: 0.5073891625615764, train_loss: 0.831832357331171, val_loss: 1.3489637894583453 (42 / 100)
train_acc: 0.6637824474660075, val_acc: 0.5615763546798029, train_loss: 0.8129968537093683, val_loss: 1.4519679293843912 (43 / 100)
train_acc: 0.7058096415327565, val_acc: 0.5665024630541872, train_loss: 0.7309711082609387, val_loss: 1.169446929335007 (44 / 100)
train_acc: 0.69221260815822, val_acc: 0.5862068965517241, train_loss: 0.7830378313736509, val_loss: 1.1023266126075988 (45 / 100)
train_acc: 0.7404202719406675, val_acc: 0.6059113300492611, train_loss: 0.6781689469392869, val_loss: 1.3260107375130865 (46 / 100)
train_acc: 0.7441285537700866, val_acc: 0.6157635467980296, train_loss: 0.6581532809289335, val_loss: 1.1484003572041177 (47 / 100)
train_acc: 0.7428924598269468, val_acc: 0.6059113300492611, train_loss: 0.6866910484134783, val_loss: 1.473062618319037 (48 / 100)
train_acc: 0.757725587144623, val_acc: 0.5911330049261084, train_loss: 0.616160219178359, val_loss: 1.3465751286210685 (49 / 100)
train_acc: 0.7676143386897404, val_acc: 0.6305418719211823, train_loss: 0.5788611108794053, val_loss: 1.3274813602710593 (50 / 100)
train_acc: 0.8034610630407911, val_acc: 0.541871921182266, train_loss: 0.5078442282376094, val_loss: 1.7212680164229106 (51 / 100)
train_acc: 0.8046971569839307, val_acc: 0.5911330049261084, train_loss: 0.5019183531679831, val_loss: 1.2400980395049297 (52 / 100)
train_acc: 0.826946847960445, val_acc: 0.7142857142857143, train_loss: 0.4619505538044518, val_loss: 0.9971990238856799 (53 / 100)
train_acc: 0.8182941903584673, val_acc: 0.6551724137931034, train_loss: 0.48233110456737804, val_loss: 1.0910158321775238 (54 / 100)
train_acc: 0.8739184177997528, val_acc: 0.6157635467980296, train_loss: 0.36207396182495233, val_loss: 1.1466719411276831 (55 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6995073891625616, train_loss: 0.3802418054550039, val_loss: 1.1132102106592339 (56 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6699507389162561, train_loss: 0.281503807186933, val_loss: 1.69142233194976 (57 / 100)
train_acc: 0.896168108776267, val_acc: 0.6945812807881774, train_loss: 0.311491743301137, val_loss: 0.9927911511782942 (58 / 100)
train_acc: 0.8689740420271941, val_acc: 0.7192118226600985, train_loss: 0.32602085849115964, val_loss: 0.9056997111278214 (59 / 100)
train_acc: 0.8986402966625463, val_acc: 0.7142857142857143, train_loss: 0.30880688884202273, val_loss: 1.1593092357363608 (60 / 100)
train_acc: 0.9369592088998764, val_acc: 0.7093596059113301, train_loss: 0.20629112269586627, val_loss: 1.0339933251916187 (61 / 100)
train_acc: 0.9530284301606922, val_acc: 0.7389162561576355, train_loss: 0.13164528102898332, val_loss: 1.061068008685934 (62 / 100)
train_acc: 0.965389369592089, val_acc: 0.7586206896551724, train_loss: 0.10973036245008924, val_loss: 1.061010070622261 (63 / 100)
train_acc: 0.969097651421508, val_acc: 0.7487684729064039, train_loss: 0.08449691055142246, val_loss: 1.1737851168721767 (64 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7586206896551724, train_loss: 0.08103081617131369, val_loss: 1.1508687682119496 (65 / 100)
train_acc: 0.965389369592089, val_acc: 0.7586206896551724, train_loss: 0.08746421042419925, val_loss: 1.2036607606437406 (66 / 100)
train_acc: 0.9666254635352287, val_acc: 0.7536945812807881, train_loss: 0.09970493708611713, val_loss: 1.2123933308230246 (67 / 100)
train_acc: 0.9666254635352287, val_acc: 0.7586206896551724, train_loss: 0.08954633637912783, val_loss: 1.2197242194025093 (68 / 100)
train_acc: 0.9703337453646477, val_acc: 0.7536945812807881, train_loss: 0.07634572281383613, val_loss: 1.3323366700538568 (69 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7586206896551724, train_loss: 0.06897382034801582, val_loss: 1.3384215491158622 (70 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7536945812807881, train_loss: 0.07799841623813172, val_loss: 1.3734880210143592 (71 / 100)
train_acc: 0.9777503090234858, val_acc: 0.7389162561576355, train_loss: 0.055012062983990306, val_loss: 1.4188317830119226 (72 / 100)
train_acc: 0.9777503090234858, val_acc: 0.729064039408867, train_loss: 0.07387195499924706, val_loss: 1.4828287439301537 (73 / 100)
train_acc: 0.9715698393077874, val_acc: 0.729064039408867, train_loss: 0.0768316767566431, val_loss: 1.3548898802785745 (74 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7389162561576355, train_loss: 0.06570417948794748, val_loss: 1.3479121294735101 (75 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7536945812807881, train_loss: 0.06652006996871515, val_loss: 1.3372841773949233 (76 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7339901477832512, train_loss: 0.054204296122670026, val_loss: 1.4116764926062575 (77 / 100)
train_acc: 0.9802224969097652, val_acc: 0.7438423645320197, train_loss: 0.07035603629349188, val_loss: 1.470624834445897 (78 / 100)
train_acc: 0.9839307787391842, val_acc: 0.7339901477832512, train_loss: 0.042754335515431334, val_loss: 1.5181171224668182 (79 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7438423645320197, train_loss: 0.06969352352015021, val_loss: 1.3946709116104201 (80 / 100)
train_acc: 0.9802224969097652, val_acc: 0.7536945812807881, train_loss: 0.049626680180817215, val_loss: 1.376686280574925 (81 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7389162561576355, train_loss: 0.06432976887753632, val_loss: 1.396266855047144 (82 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7438423645320197, train_loss: 0.051988066053213676, val_loss: 1.4277080984630168 (83 / 100)
train_acc: 0.9789864029666254, val_acc: 0.7389162561576355, train_loss: 0.05622910097591367, val_loss: 1.5570343762149879 (84 / 100)
train_acc: 0.9901112484548825, val_acc: 0.7192118226600985, train_loss: 0.03648989530664734, val_loss: 1.6273806858532534 (85 / 100)
train_acc: 0.9901112484548825, val_acc: 0.7241379310344828, train_loss: 0.04091888393548275, val_loss: 1.7239358765646595 (86 / 100)
train_acc: 0.9740420271940667, val_acc: 0.7339901477832512, train_loss: 0.08033428542840908, val_loss: 1.5312412642493036 (87 / 100)
train_acc: 0.9864029666254636, val_acc: 0.729064039408867, train_loss: 0.04681510300512514, val_loss: 1.508522879313953 (88 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7241379310344828, train_loss: 0.0663829934317043, val_loss: 1.728814771041054 (89 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7241379310344828, train_loss: 0.04594315984487828, val_loss: 1.6881702991496093 (90 / 100)
train_acc: 0.9851668726823238, val_acc: 0.7241379310344828, train_loss: 0.04918003730632466, val_loss: 1.6558389710675319 (91 / 100)
train_acc: 0.9802224969097652, val_acc: 0.729064039408867, train_loss: 0.0489448961722394, val_loss: 1.6629854376138797 (92 / 100)
train_acc: 0.9826946847960445, val_acc: 0.7339901477832512, train_loss: 0.03606729970137475, val_loss: 1.7737686152436904 (93 / 100)
train_acc: 0.9864029666254636, val_acc: 0.7389162561576355, train_loss: 0.039559564572771634, val_loss: 1.838160174233573 (94 / 100)
train_acc: 0.9888751545117429, val_acc: 0.7241379310344828, train_loss: 0.03872694485856517, val_loss: 1.8719484348107 (95 / 100)
train_acc: 0.9888751545117429, val_acc: 0.729064039408867, train_loss: 0.036339419291841674, val_loss: 1.9420247195297715 (96 / 100)
train_acc: 0.9789864029666254, val_acc: 0.7536945812807881, train_loss: 0.054286055276066766, val_loss: 1.6921043020117972 (97 / 100)
train_acc: 0.9876390605686032, val_acc: 0.7389162561576355, train_loss: 0.04185774358742317, val_loss: 1.7462429777131843 (98 / 100)
train_acc: 0.9876390605686032, val_acc: 0.7142857142857143, train_loss: 0.04084027285039499, val_loss: 1.8423414864575058 (99 / 100)
train_acc: 0.9814585908529048, val_acc: 0.729064039408867, train_loss: 0.035305346929835446, val_loss: 1.7949705159181517 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7586206896551724, val loss 1.061010070622261
train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7850514754966105, val_loss: 1.7643612118190146 (1 / 100)
train_acc: 0.1965389369592089, val_acc: 0.2413793103448276, train_loss: 1.7617203249182778, val_loss: 1.746691770154267 (2 / 100)
train_acc: 0.20148331273176762, val_acc: 0.2315270935960591, train_loss: 1.7642595107829468, val_loss: 1.7291616741659606 (3 / 100)
train_acc: 0.22620519159456118, val_acc: 0.2857142857142857, train_loss: 1.7214223224536156, val_loss: 1.6876601732423153 (4 / 100)
train_acc: 0.27070457354758964, val_acc: 0.30049261083743845, train_loss: 1.7186096946447535, val_loss: 1.7410201450874065 (5 / 100)
train_acc: 0.2941903584672435, val_acc: 0.26108374384236455, train_loss: 1.6760806891473174, val_loss: 1.671479163498714 (6 / 100)
train_acc: 0.27070457354758964, val_acc: 0.21674876847290642, train_loss: 1.6666799114720046, val_loss: 1.7279091726970204 (7 / 100)
train_acc: 0.2249690976514215, val_acc: 0.3497536945812808, train_loss: 1.772542627249719, val_loss: 1.716082615805377 (8 / 100)
train_acc: 0.3127317676143387, val_acc: 0.29064039408866993, train_loss: 1.6616262411157634, val_loss: 1.5733868641219115 (9 / 100)
train_acc: 0.3473423980222497, val_acc: 0.35467980295566504, train_loss: 1.5829468492524439, val_loss: 1.509418526893766 (10 / 100)
train_acc: 0.3584672435105068, val_acc: 0.26108374384236455, train_loss: 1.507098404232445, val_loss: 1.5849379048558878 (11 / 100)
train_acc: 0.36711990111248455, val_acc: 0.31527093596059114, train_loss: 1.497202061752159, val_loss: 1.4725076177437317 (12 / 100)
train_acc: 0.37824474660074164, val_acc: 0.2955665024630542, train_loss: 1.4552105016849834, val_loss: 1.6194866237969234 (13 / 100)
train_acc: 0.3374536464771323, val_acc: 0.39408866995073893, train_loss: 1.60675262903843, val_loss: 1.5028334086751702 (14 / 100)
train_acc: 0.37453646477132263, val_acc: 0.43349753694581283, train_loss: 1.4688215342676094, val_loss: 1.3207505970752884 (15 / 100)
train_acc: 0.3695920889987639, val_acc: 0.4236453201970443, train_loss: 1.4473655114804564, val_loss: 1.398210284157927 (16 / 100)
train_acc: 0.4079110012360939, val_acc: 0.41379310344827586, train_loss: 1.405992947049135, val_loss: 1.3625922531917178 (17 / 100)
train_acc: 0.3794808405438813, val_acc: 0.4482758620689655, train_loss: 1.3641354675198663, val_loss: 1.2872130903117176 (18 / 100)
train_acc: 0.43139678615574784, val_acc: 0.42857142857142855, train_loss: 1.3182708805954206, val_loss: 1.3290590673244644 (19 / 100)
train_acc: 0.42398022249690975, val_acc: 0.42857142857142855, train_loss: 1.3163220950198558, val_loss: 1.349807332008343 (20 / 100)
train_acc: 0.4004944375772559, val_acc: 0.43349753694581283, train_loss: 1.3379993488821023, val_loss: 1.2583015655061882 (21 / 100)
train_acc: 0.484548825710754, val_acc: 0.4039408866995074, train_loss: 1.21772835133839, val_loss: 1.3360045840000283 (22 / 100)
train_acc: 0.4969097651421508, val_acc: 0.4729064039408867, train_loss: 1.2409974432404167, val_loss: 1.2221666818181869 (23 / 100)
train_acc: 0.49814585908529047, val_acc: 0.49261083743842365, train_loss: 1.2183587383133518, val_loss: 1.2196600736655625 (24 / 100)
train_acc: 0.49443757725587145, val_acc: 0.47783251231527096, train_loss: 1.1916135686584397, val_loss: 1.2992462976812729 (25 / 100)
train_acc: 0.5265760197775031, val_acc: 0.4729064039408867, train_loss: 1.1449025195962272, val_loss: 1.227830605553876 (26 / 100)
train_acc: 0.5648949320148331, val_acc: 0.49261083743842365, train_loss: 1.0924992234214717, val_loss: 1.1701609319066766 (27 / 100)
train_acc: 0.5550061804697157, val_acc: 0.5123152709359606, train_loss: 1.1012822234881086, val_loss: 1.1560255993763213 (28 / 100)
train_acc: 0.5500618046971569, val_acc: 0.5270935960591133, train_loss: 1.0595671470439332, val_loss: 1.2163428041735307 (29 / 100)
train_acc: 0.6019777503090235, val_acc: 0.5517241379310345, train_loss: 1.0081765766638908, val_loss: 1.1173615620054047 (30 / 100)
train_acc: 0.6279357231149567, val_acc: 0.5024630541871922, train_loss: 0.9187438779767275, val_loss: 1.1816895477877463 (31 / 100)
train_acc: 0.6081582200247219, val_acc: 0.5024630541871922, train_loss: 0.9801547511104306, val_loss: 1.131095894451799 (32 / 100)
train_acc: 0.6477132262051916, val_acc: 0.4433497536945813, train_loss: 0.8917072024127314, val_loss: 1.4029935742246693 (33 / 100)
train_acc: 0.6736711990111248, val_acc: 0.5467980295566502, train_loss: 0.8304922521777441, val_loss: 1.4895890129023586 (34 / 100)
train_acc: 0.6761433868974042, val_acc: 0.5714285714285714, train_loss: 0.7956257314410876, val_loss: 1.0455240850965377 (35 / 100)
train_acc: 0.6983930778739185, val_acc: 0.5172413793103449, train_loss: 0.8105931037436015, val_loss: 1.1694587614442327 (36 / 100)
train_acc: 0.7021013597033374, val_acc: 0.5615763546798029, train_loss: 0.7563165258270849, val_loss: 1.2271421525278703 (37 / 100)
train_acc: 0.7416563658838071, val_acc: 0.4975369458128079, train_loss: 0.6664048595393102, val_loss: 1.5992158287264444 (38 / 100)
train_acc: 0.7268232385661311, val_acc: 0.5615763546798029, train_loss: 0.7013827664006331, val_loss: 1.2415375700725124 (39 / 100)
train_acc: 0.754017305315204, val_acc: 0.5714285714285714, train_loss: 0.667301026793434, val_loss: 1.2438442075781047 (40 / 100)
train_acc: 0.7799752781211372, val_acc: 0.5221674876847291, train_loss: 0.5650671390432068, val_loss: 1.3847617962090253 (41 / 100)
train_acc: 0.7713226205191595, val_acc: 0.5763546798029556, train_loss: 0.6120612898332669, val_loss: 1.3678910532608408 (42 / 100)
train_acc: 0.799752781211372, val_acc: 0.5615763546798029, train_loss: 0.509209264783541, val_loss: 1.501306936071424 (43 / 100)
train_acc: 0.8207663782447466, val_acc: 0.5615763546798029, train_loss: 0.4560020042143587, val_loss: 1.3641886592204935 (44 / 100)
train_acc: 0.796044499381953, val_acc: 0.5123152709359606, train_loss: 0.54312958558204, val_loss: 1.6219597573350804 (45 / 100)
train_acc: 0.8294190358467244, val_acc: 0.5123152709359606, train_loss: 0.5008162759585197, val_loss: 1.2419997063176385 (46 / 100)
train_acc: 0.8504326328800988, val_acc: 0.5714285714285714, train_loss: 0.41986468121206805, val_loss: 1.3634773968842817 (47 / 100)
train_acc: 0.8763906056860321, val_acc: 0.6699507389162561, train_loss: 0.3533264806745079, val_loss: 1.326404650223079 (48 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5467980295566502, train_loss: 0.3126185497335804, val_loss: 2.0773811023223576 (49 / 100)
train_acc: 0.8516687268232386, val_acc: 0.5123152709359606, train_loss: 0.40620559490802705, val_loss: 1.4094147833403696 (50 / 100)
train_acc: 0.8726823238566132, val_acc: 0.5763546798029556, train_loss: 0.3427009054992638, val_loss: 1.7580686514013506 (51 / 100)
train_acc: 0.892459826946848, val_acc: 0.6009852216748769, train_loss: 0.3054963724574878, val_loss: 1.5344140905464811 (52 / 100)
train_acc: 0.8813349814585909, val_acc: 0.5123152709359606, train_loss: 0.3218749768949115, val_loss: 1.4975215907167332 (53 / 100)
train_acc: 0.9085290482076638, val_acc: 0.6059113300492611, train_loss: 0.2659947153074927, val_loss: 1.4902349340321102 (54 / 100)
train_acc: 0.930778739184178, val_acc: 0.5665024630541872, train_loss: 0.19444347091009945, val_loss: 1.6465077376718005 (55 / 100)
train_acc: 0.9134734239802225, val_acc: 0.625615763546798, train_loss: 0.23185277987174846, val_loss: 1.8628859003189162 (56 / 100)
train_acc: 0.9184177997527813, val_acc: 0.5960591133004927, train_loss: 0.22550738373557186, val_loss: 1.8131455141739012 (57 / 100)
train_acc: 0.9332509270704573, val_acc: 0.5369458128078818, train_loss: 0.17739965550242306, val_loss: 2.0009506277354627 (58 / 100)
train_acc: 0.9011124845488258, val_acc: 0.5862068965517241, train_loss: 0.2681038350198413, val_loss: 2.141262909755331 (59 / 100)
train_acc: 0.9258343634116193, val_acc: 0.6108374384236454, train_loss: 0.20607140420835893, val_loss: 1.7753605842957356 (60 / 100)
train_acc: 0.930778739184178, val_acc: 0.5911330049261084, train_loss: 0.2120404996447569, val_loss: 1.7483693813455516 (61 / 100)
train_acc: 0.9505562422744128, val_acc: 0.5763546798029556, train_loss: 0.1340886164359905, val_loss: 2.9204953692009297 (62 / 100)
train_acc: 0.9357231149567367, val_acc: 0.6108374384236454, train_loss: 0.15833653478304152, val_loss: 2.110135823635045 (63 / 100)
train_acc: 0.934487021013597, val_acc: 0.6157635467980296, train_loss: 0.18887086115013094, val_loss: 2.1261793473377604 (64 / 100)
train_acc: 0.92336217552534, val_acc: 0.6305418719211823, train_loss: 0.23381936992202024, val_loss: 1.576541620522297 (65 / 100)
train_acc: 0.9171817058096415, val_acc: 0.5615763546798029, train_loss: 0.24914970562985564, val_loss: 1.4211048997681717 (66 / 100)
train_acc: 0.9419035846724351, val_acc: 0.6699507389162561, train_loss: 0.1507025019936862, val_loss: 1.6262577413925396 (67 / 100)
train_acc: 0.8838071693448702, val_acc: 0.6748768472906403, train_loss: 0.35412539274642435, val_loss: 1.6292415945033722 (68 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6009852216748769, train_loss: 0.15133507231109958, val_loss: 2.354901968845593 (69 / 100)
train_acc: 0.9406674907292955, val_acc: 0.6502463054187192, train_loss: 0.17167146936777347, val_loss: 1.8433252883515334 (70 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6403940886699507, train_loss: 0.1669732388224089, val_loss: 2.273737893903197 (71 / 100)
train_acc: 0.957972805933251, val_acc: 0.6305418719211823, train_loss: 0.15210541555996437, val_loss: 1.8044018476761032 (72 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6403940886699507, train_loss: 0.1363994201417317, val_loss: 1.3756083608260883 (73 / 100)
train_acc: 0.9678615574783683, val_acc: 0.5566502463054187, train_loss: 0.08130392760075214, val_loss: 2.7963659163619496 (74 / 100)
train_acc: 0.9468479604449939, val_acc: 0.625615763546798, train_loss: 0.14721886587084002, val_loss: 1.7862194770295632 (75 / 100)
train_acc: 0.9208899876390606, val_acc: 0.5960591133004927, train_loss: 0.2600085129696595, val_loss: 1.8897950837154658 (76 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6354679802955665, train_loss: 0.1134376443360733, val_loss: 2.1993662747256275 (77 / 100)
train_acc: 0.9678615574783683, val_acc: 0.645320197044335, train_loss: 0.10498084037648733, val_loss: 1.937663340234551 (78 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6157635467980296, train_loss: 0.05976578081199354, val_loss: 1.9161134412503007 (79 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6059113300492611, train_loss: 0.08958964648441273, val_loss: 2.504351133489844 (80 / 100)
train_acc: 0.9814585908529048, val_acc: 0.625615763546798, train_loss: 0.057972908609435055, val_loss: 2.548767318866523 (81 / 100)
train_acc: 0.969097651421508, val_acc: 0.5812807881773399, train_loss: 0.10451727995029633, val_loss: 1.7107918485723839 (82 / 100)
train_acc: 0.9456118665018541, val_acc: 0.6206896551724138, train_loss: 0.15040501012790336, val_loss: 1.401002281368366 (83 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6403940886699507, train_loss: 0.14986862034084475, val_loss: 2.3175580090306367 (84 / 100)
train_acc: 0.965389369592089, val_acc: 0.6403940886699507, train_loss: 0.09843175122410759, val_loss: 2.503111118313127 (85 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6206896551724138, train_loss: 0.09846480933049111, val_loss: 2.134307799083204 (86 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.05354636030821924, val_loss: 2.7012614804535664 (87 / 100)
train_acc: 0.965389369592089, val_acc: 0.6748768472906403, train_loss: 0.09050360509874794, val_loss: 2.7742220368878594 (88 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6551724137931034, train_loss: 0.03807187065647913, val_loss: 2.795059047309049 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5862068965517241, train_loss: 0.05296594294983023, val_loss: 2.647626069965061 (90 / 100)
train_acc: 0.969097651421508, val_acc: 0.6305418719211823, train_loss: 0.0749568152339261, val_loss: 2.3989342609282787 (91 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6108374384236454, train_loss: 0.12129118371805538, val_loss: 1.7646105888441865 (92 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6748768472906403, train_loss: 0.05425119930498385, val_loss: 2.2502383926672302 (93 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6551724137931034, train_loss: 0.0255556557470258, val_loss: 2.7686495193706944 (94 / 100)
train_acc: 0.9715698393077874, val_acc: 0.645320197044335, train_loss: 0.07103962627123254, val_loss: 2.0691026960100447 (95 / 100)
train_acc: 0.9666254635352287, val_acc: 0.5960591133004927, train_loss: 0.11307831791923721, val_loss: 2.2800179984181974 (96 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6009852216748769, train_loss: 0.09354310748898349, val_loss: 1.951916807391933 (97 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.04053563446874819, val_loss: 2.578723914517558 (98 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6403940886699507, train_loss: 0.06789637407649433, val_loss: 2.521652108966717 (99 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6748768472906403, train_loss: 0.08186156228092605, val_loss: 2.4356210725060823 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.6748768472906403, val loss 1.6292415945033722
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.776967489233123, val_loss: 1.7582466878327243 (1 / 100)
train_acc: 0.19777503090234858, val_acc: 0.22167487684729065, train_loss: 1.7646027604493282, val_loss: 1.7541500412184616 (2 / 100)
train_acc: 0.2360939431396786, val_acc: 0.24630541871921183, train_loss: 1.7461854777907853, val_loss: 1.727215109787551 (3 / 100)
train_acc: 0.29171817058096416, val_acc: 0.2512315270935961, train_loss: 1.702305775490326, val_loss: 1.7059865861103451 (4 / 100)
train_acc: 0.2978986402966625, val_acc: 0.2660098522167488, train_loss: 1.6820696542230613, val_loss: 1.6175166016141769 (5 / 100)
train_acc: 0.2954264524103832, val_acc: 0.2857142857142857, train_loss: 1.631164346843479, val_loss: 1.5843056193713485 (6 / 100)
train_acc: 0.32014833127317677, val_acc: 0.2955665024630542, train_loss: 1.5914972441452837, val_loss: 1.5864127991821966 (7 / 100)
train_acc: 0.3510506798516687, val_acc: 0.3251231527093596, train_loss: 1.5643548935983325, val_loss: 1.515073879598984 (8 / 100)
train_acc: 0.3621755253399258, val_acc: 0.2857142857142857, train_loss: 1.5239337256871284, val_loss: 1.5145620060671727 (9 / 100)
train_acc: 0.34857849196538937, val_acc: 0.2512315270935961, train_loss: 1.5207043805140057, val_loss: 1.62702505224444 (10 / 100)
train_acc: 0.3658838071693449, val_acc: 0.35960591133004927, train_loss: 1.4754853764334774, val_loss: 1.5410675879182487 (11 / 100)
train_acc: 0.3819530284301607, val_acc: 0.270935960591133, train_loss: 1.4617641700065622, val_loss: 1.5229013183434021 (12 / 100)
train_acc: 0.34981458590852904, val_acc: 0.4433497536945813, train_loss: 1.431708400122757, val_loss: 1.3501778465186434 (13 / 100)
train_acc: 0.4227441285537701, val_acc: 0.42857142857142855, train_loss: 1.3787765726907586, val_loss: 1.3779009075587607 (14 / 100)
train_acc: 0.4042027194066749, val_acc: 0.4630541871921182, train_loss: 1.3870532362363837, val_loss: 1.2946326732635498 (15 / 100)
train_acc: 0.43510506798516685, val_acc: 0.46798029556650245, train_loss: 1.387797451431878, val_loss: 1.3191164209337658 (16 / 100)
train_acc: 0.45982694684796044, val_acc: 0.43349753694581283, train_loss: 1.3281183724645043, val_loss: 1.3501675581109935 (17 / 100)
train_acc: 0.4363411619283066, val_acc: 0.49261083743842365, train_loss: 1.3172761297638542, val_loss: 1.3038576577097325 (18 / 100)
train_acc: 0.45241038318912236, val_acc: 0.45320197044334976, train_loss: 1.3097079074279634, val_loss: 1.2687263935070319 (19 / 100)
train_acc: 0.4635352286773795, val_acc: 0.4876847290640394, train_loss: 1.2775012462483937, val_loss: 1.195078841864769 (20 / 100)
train_acc: 0.4783683559950556, val_acc: 0.4729064039408867, train_loss: 1.2396086505965338, val_loss: 1.2866504086649477 (21 / 100)
train_acc: 0.49443757725587145, val_acc: 0.4975369458128079, train_loss: 1.2271937834759725, val_loss: 1.2079303150106533 (22 / 100)
train_acc: 0.49814585908529047, val_acc: 0.4729064039408867, train_loss: 1.2074986003680046, val_loss: 1.2501246817593503 (23 / 100)
train_acc: 0.5315203955500618, val_acc: 0.5123152709359606, train_loss: 1.1705578802837282, val_loss: 1.157660375674957 (24 / 100)
train_acc: 0.5426452410383189, val_acc: 0.4876847290640394, train_loss: 1.1435449540394051, val_loss: 1.2068568010048326 (25 / 100)
train_acc: 0.5253399258343634, val_acc: 0.5320197044334976, train_loss: 1.1304440866736754, val_loss: 1.1262998507527882 (26 / 100)
train_acc: 0.5488257107540173, val_acc: 0.5517241379310345, train_loss: 1.1036394865462749, val_loss: 1.183346620627812 (27 / 100)
train_acc: 0.553770086526576, val_acc: 0.4975369458128079, train_loss: 1.0533751592647898, val_loss: 1.2943288102525796 (28 / 100)
train_acc: 0.5995055624227441, val_acc: 0.5517241379310345, train_loss: 0.998048343381422, val_loss: 1.061076927067611 (29 / 100)
train_acc: 0.6168108776266996, val_acc: 0.5221674876847291, train_loss: 0.9660368360606643, val_loss: 1.1925345389126556 (30 / 100)
train_acc: 0.6316440049443758, val_acc: 0.541871921182266, train_loss: 0.9518406473661972, val_loss: 1.2107326297337198 (31 / 100)
train_acc: 0.6106304079110012, val_acc: 0.5320197044334976, train_loss: 0.9781582278875249, val_loss: 1.1677855772925128 (32 / 100)
train_acc: 0.6736711990111248, val_acc: 0.5270935960591133, train_loss: 0.8343654132743996, val_loss: 1.1056935749030465 (33 / 100)
train_acc: 0.6613102595797281, val_acc: 0.541871921182266, train_loss: 0.8998262686252004, val_loss: 1.2525416735945076 (34 / 100)
train_acc: 0.7255871446229913, val_acc: 0.5615763546798029, train_loss: 0.745603241496092, val_loss: 1.202577945340443 (35 / 100)
train_acc: 0.69221260815822, val_acc: 0.5172413793103449, train_loss: 0.7954142624132418, val_loss: 1.4568152544386868 (36 / 100)
train_acc: 0.7404202719406675, val_acc: 0.6009852216748769, train_loss: 0.732968217657582, val_loss: 1.1075355984600894 (37 / 100)
train_acc: 0.754017305315204, val_acc: 0.5517241379310345, train_loss: 0.6110570629683354, val_loss: 1.2451169625878922 (38 / 100)
train_acc: 0.6872682323856613, val_acc: 0.4729064039408867, train_loss: 0.8065015836463428, val_loss: 1.240245496110963 (39 / 100)
train_acc: 0.8071693448702101, val_acc: 0.6059113300492611, train_loss: 0.5225413395241547, val_loss: 1.0026213855578983 (40 / 100)
train_acc: 0.8071693448702101, val_acc: 0.5320197044334976, train_loss: 0.5631317085919185, val_loss: 1.3699337060521977 (41 / 100)
train_acc: 0.823238566131026, val_acc: 0.6157635467980296, train_loss: 0.5147044414053447, val_loss: 1.502155628036983 (42 / 100)
train_acc: 0.8566131025957973, val_acc: 0.6059113300492611, train_loss: 0.4208522458895765, val_loss: 1.1951246202872892 (43 / 100)
train_acc: 0.857849196538937, val_acc: 0.6305418719211823, train_loss: 0.4071518632183853, val_loss: 1.4931234150317503 (44 / 100)
train_acc: 0.8467243510506799, val_acc: 0.6206896551724138, train_loss: 0.41562513839476484, val_loss: 1.6338776285425196 (45 / 100)
train_acc: 0.8689740420271941, val_acc: 0.645320197044335, train_loss: 0.36228857582667556, val_loss: 1.1647132394349047 (46 / 100)
train_acc: 0.8590852904820766, val_acc: 0.5862068965517241, train_loss: 0.41777380921489965, val_loss: 1.6648910312817014 (47 / 100)
train_acc: 0.8739184177997528, val_acc: 0.6059113300492611, train_loss: 0.3338925753005208, val_loss: 1.5011281341754745 (48 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6403940886699507, train_loss: 0.30020733124246113, val_loss: 1.9838610200459146 (49 / 100)
train_acc: 0.907292954264524, val_acc: 0.625615763546798, train_loss: 0.24522738595238722, val_loss: 2.3173250575077358 (50 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6108374384236454, train_loss: 0.20506012439727783, val_loss: 1.6015076531565249 (51 / 100)
train_acc: 0.9171817058096415, val_acc: 0.5517241379310345, train_loss: 0.2461917846842366, val_loss: 2.3629905866284675 (52 / 100)
train_acc: 0.92336217552534, val_acc: 0.6354679802955665, train_loss: 0.23272258625337014, val_loss: 1.6149489750232309 (53 / 100)
train_acc: 0.9221260815822002, val_acc: 0.5911330049261084, train_loss: 0.22829983408283097, val_loss: 1.911260807455467 (54 / 100)
train_acc: 0.9443757725587144, val_acc: 0.6157635467980296, train_loss: 0.14938687055161032, val_loss: 1.770568989180579 (55 / 100)
train_acc: 0.9493201483312732, val_acc: 0.5812807881773399, train_loss: 0.16543528927566095, val_loss: 2.329001203546383 (56 / 100)
train_acc: 0.9381953028430161, val_acc: 0.6748768472906403, train_loss: 0.19319546458452977, val_loss: 1.4908012969446887 (57 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6108374384236454, train_loss: 0.1505119402712149, val_loss: 1.8232540344369823 (58 / 100)
train_acc: 0.9530284301606922, val_acc: 0.625615763546798, train_loss: 0.1239118029366907, val_loss: 2.2572853993899717 (59 / 100)
train_acc: 0.965389369592089, val_acc: 0.6157635467980296, train_loss: 0.10633138216322816, val_loss: 3.136493459710934 (60 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6305418719211823, train_loss: 0.11338842239309153, val_loss: 2.4714466527177783 (61 / 100)
train_acc: 0.9826946847960445, val_acc: 0.645320197044335, train_loss: 0.050870944012522845, val_loss: 2.4485762694786333 (62 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6305418719211823, train_loss: 0.0511635967768609, val_loss: 2.398014363396931 (63 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6354679802955665, train_loss: 0.051976841371345284, val_loss: 2.4136859125691683 (64 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6502463054187192, train_loss: 0.03150470501412862, val_loss: 2.4435764122479067 (65 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6206896551724138, train_loss: 0.06031909979170715, val_loss: 2.4064860338060727 (66 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6403940886699507, train_loss: 0.04326694945911837, val_loss: 2.4525374144756147 (67 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6354679802955665, train_loss: 0.02933194905482647, val_loss: 2.485879677269846 (68 / 100)
train_acc: 0.9864029666254636, val_acc: 0.645320197044335, train_loss: 0.04075374488335457, val_loss: 2.51048703851371 (69 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.043195913247625964, val_loss: 2.544625918853459 (70 / 100)
train_acc: 0.9864029666254636, val_acc: 0.645320197044335, train_loss: 0.04222844395560888, val_loss: 2.5580111536486396 (71 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6403940886699507, train_loss: 0.031426099086426684, val_loss: 2.51517959768549 (72 / 100)
train_acc: 0.9913473423980222, val_acc: 0.645320197044335, train_loss: 0.025029493498124358, val_loss: 2.6036869152426134 (73 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6108374384236454, train_loss: 0.04653461150392171, val_loss: 2.4452294434232664 (74 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6157635467980296, train_loss: 0.03145824241991833, val_loss: 2.4962178333639513 (75 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6305418719211823, train_loss: 0.03245427139904649, val_loss: 2.57796011182475 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6354679802955665, train_loss: 0.04966033418629461, val_loss: 2.551083899483892 (77 / 100)
train_acc: 0.992583436341162, val_acc: 0.6206896551724138, train_loss: 0.027130817600764214, val_loss: 2.582234380280443 (78 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6206896551724138, train_loss: 0.03804712124601725, val_loss: 2.6383312876001366 (79 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6354679802955665, train_loss: 0.037295828790982956, val_loss: 2.7016149060479524 (80 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6305418719211823, train_loss: 0.030239355136791178, val_loss: 2.666260570140895 (81 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6305418719211823, train_loss: 0.02110002892568468, val_loss: 2.718139527466497 (82 / 100)
train_acc: 0.992583436341162, val_acc: 0.625615763546798, train_loss: 0.021629833320457356, val_loss: 2.7267199384755103 (83 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6206896551724138, train_loss: 0.03505111035369383, val_loss: 2.708912881137115 (84 / 100)
train_acc: 0.992583436341162, val_acc: 0.5960591133004927, train_loss: 0.02660675028198582, val_loss: 2.6498375044667664 (85 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6108374384236454, train_loss: 0.02570355527922603, val_loss: 2.761917969276165 (86 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6108374384236454, train_loss: 0.0284813144445714, val_loss: 2.761187468843507 (87 / 100)
train_acc: 0.9950556242274413, val_acc: 0.625615763546798, train_loss: 0.01883360732471103, val_loss: 2.8229768064808964 (88 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6403940886699507, train_loss: 0.023190780534732475, val_loss: 2.876741086320924 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6305418719211823, train_loss: 0.04798626914454626, val_loss: 2.783201045003431 (90 / 100)
train_acc: 0.992583436341162, val_acc: 0.6206896551724138, train_loss: 0.0287792744536335, val_loss: 2.813861195089782 (91 / 100)
train_acc: 0.9962917181705809, val_acc: 0.625615763546798, train_loss: 0.017452731120719014, val_loss: 2.847651155124157 (92 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6206896551724138, train_loss: 0.022603544375510386, val_loss: 2.8452435432396497 (93 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6305418719211823, train_loss: 0.03301516245263174, val_loss: 2.811224928043159 (94 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6305418719211823, train_loss: 0.018789279593525474, val_loss: 2.88629745262597 (95 / 100)
train_acc: 0.992583436341162, val_acc: 0.6305418719211823, train_loss: 0.024988493606982333, val_loss: 2.844180810040441 (96 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6403940886699507, train_loss: 0.023624640165359628, val_loss: 2.894106763337046 (97 / 100)
train_acc: 0.9938195302843016, val_acc: 0.645320197044335, train_loss: 0.019202928165864885, val_loss: 2.947528563109525 (98 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6600985221674877, train_loss: 0.016574103841086107, val_loss: 2.9635587126163427 (99 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6551724137931034, train_loss: 0.013740466168548621, val_loss: 2.9728621849285557 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.05}), val accuracy 0.6748768472906403, val loss 1.4908012969446887
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7792128162419398, val_loss: 1.7594294154585288 (1 / 100)
train_acc: 0.17799752781211373, val_acc: 0.2019704433497537, train_loss: 1.7672833801052625, val_loss: 1.7626652529674212 (2 / 100)
train_acc: 0.2200247218788628, val_acc: 0.21674876847290642, train_loss: 1.7664811768844189, val_loss: 1.7536705086383912 (3 / 100)
train_acc: 0.2595797280593325, val_acc: 0.2857142857142857, train_loss: 1.7226095544393043, val_loss: 1.7389429590384948 (4 / 100)
train_acc: 0.22620519159456118, val_acc: 0.18226600985221675, train_loss: 1.7472887982249408, val_loss: 1.7712535288533553 (5 / 100)
train_acc: 0.2595797280593325, val_acc: 0.29064039408866993, train_loss: 1.6918006382412905, val_loss: 1.6017330802720169 (6 / 100)
train_acc: 0.21631644004944375, val_acc: 0.33004926108374383, train_loss: 1.7609345859885952, val_loss: 1.6470220993305076 (7 / 100)
train_acc: 0.315203955500618, val_acc: 0.29064039408866993, train_loss: 1.6676338343744077, val_loss: 1.5958415128914594 (8 / 100)
train_acc: 0.3572311495673671, val_acc: 0.3645320197044335, train_loss: 1.5894066723079705, val_loss: 1.59106400447526 (9 / 100)
train_acc: 0.3362175525339926, val_acc: 0.3891625615763547, train_loss: 1.6348704728856223, val_loss: 1.5665363484415515 (10 / 100)
train_acc: 0.3226205191594561, val_acc: 0.3399014778325123, train_loss: 1.5902025964852464, val_loss: 1.5499609931936404 (11 / 100)
train_acc: 0.33868974042027195, val_acc: 0.3645320197044335, train_loss: 1.5520111727626127, val_loss: 1.5379284725987852 (12 / 100)
train_acc: 0.33498145859085293, val_acc: 0.3054187192118227, train_loss: 1.5661828653479388, val_loss: 1.8896742577623264 (13 / 100)
train_acc: 0.35599505562422745, val_acc: 0.37438423645320196, train_loss: 1.5447108182683127, val_loss: 1.5849916200919691 (14 / 100)
train_acc: 0.34981458590852904, val_acc: 0.37438423645320196, train_loss: 1.527376758153418, val_loss: 1.5468116088453772 (15 / 100)
train_acc: 0.35599505562422745, val_acc: 0.29064039408866993, train_loss: 1.5270675413393415, val_loss: 1.5359860870051267 (16 / 100)
train_acc: 0.37330037082818296, val_acc: 0.3891625615763547, train_loss: 1.507519272260819, val_loss: 1.4221759388599489 (17 / 100)
train_acc: 0.36711990111248455, val_acc: 0.3891625615763547, train_loss: 1.4424161931640285, val_loss: 1.382003333180996 (18 / 100)
train_acc: 0.37330037082818296, val_acc: 0.4039408866995074, train_loss: 1.467861630713247, val_loss: 1.361834037480096 (19 / 100)
train_acc: 0.3868974042027194, val_acc: 0.3645320197044335, train_loss: 1.4356539066701355, val_loss: 1.4868904358060488 (20 / 100)
train_acc: 0.3930778739184178, val_acc: 0.3251231527093596, train_loss: 1.4180453402739668, val_loss: 1.3714747986770028 (21 / 100)
train_acc: 0.4338689740420272, val_acc: 0.45320197044334976, train_loss: 1.3773649976633682, val_loss: 1.2813921708778795 (22 / 100)
train_acc: 0.41903584672435107, val_acc: 0.41379310344827586, train_loss: 1.399729352356919, val_loss: 1.2894391185544394 (23 / 100)
train_acc: 0.43510506798516685, val_acc: 0.39901477832512317, train_loss: 1.3332647387265275, val_loss: 1.378940029684546 (24 / 100)
train_acc: 0.4227441285537701, val_acc: 0.41379310344827586, train_loss: 1.3286606376928511, val_loss: 1.2918593472447888 (25 / 100)
train_acc: 0.415327564894932, val_acc: 0.45320197044334976, train_loss: 1.3128010887740127, val_loss: 1.308827251636336 (26 / 100)
train_acc: 0.46600741656365885, val_acc: 0.46798029556650245, train_loss: 1.2743071820149463, val_loss: 1.2676364532832443 (27 / 100)
train_acc: 0.42398022249690975, val_acc: 0.4975369458128079, train_loss: 1.287095228143322, val_loss: 1.267157914603285 (28 / 100)
train_acc: 0.48702101359703337, val_acc: 0.41379310344827586, train_loss: 1.232604162360004, val_loss: 1.3630229269929708 (29 / 100)
train_acc: 0.44252163164400493, val_acc: 0.5024630541871922, train_loss: 1.2663481132356433, val_loss: 1.209525987432508 (30 / 100)
train_acc: 0.453646477132262, val_acc: 0.4876847290640394, train_loss: 1.2339519629225006, val_loss: 1.2682617703094858 (31 / 100)
train_acc: 0.48331273176761436, val_acc: 0.4729064039408867, train_loss: 1.1668732039565946, val_loss: 1.2257745445068247 (32 / 100)
train_acc: 0.5043263288009888, val_acc: 0.4975369458128079, train_loss: 1.1763937847575976, val_loss: 1.2570398593771046 (33 / 100)
train_acc: 0.5166872682323856, val_acc: 0.41379310344827586, train_loss: 1.1703745720560383, val_loss: 1.4273914086994866 (34 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5221674876847291, train_loss: 1.0985596568976403, val_loss: 1.2133032080575163 (35 / 100)
train_acc: 0.5401730531520396, val_acc: 0.45320197044334976, train_loss: 1.1392616954515833, val_loss: 1.3133658117848663 (36 / 100)
train_acc: 0.546353522867738, val_acc: 0.4975369458128079, train_loss: 1.0829290046974813, val_loss: 1.2332098774722058 (37 / 100)
train_acc: 0.5525339925834364, val_acc: 0.5221674876847291, train_loss: 1.0716700515582034, val_loss: 1.119634421000927 (38 / 100)
train_acc: 0.5488257107540173, val_acc: 0.4827586206896552, train_loss: 1.0276542667700128, val_loss: 1.4046374465444404 (39 / 100)
train_acc: 0.5475896168108776, val_acc: 0.4827586206896552, train_loss: 1.0342281031225462, val_loss: 1.1590134742224745 (40 / 100)
train_acc: 0.5945611866501854, val_acc: 0.5221674876847291, train_loss: 0.986570529059515, val_loss: 1.2638003221286342 (41 / 100)
train_acc: 0.5982694684796045, val_acc: 0.5665024630541872, train_loss: 0.94714765318834, val_loss: 1.2384678653895562 (42 / 100)
train_acc: 0.630407911001236, val_acc: 0.5320197044334976, train_loss: 0.8666709922300133, val_loss: 1.155206502952012 (43 / 100)
train_acc: 0.4684796044499382, val_acc: 0.4827586206896552, train_loss: 1.2733950031407832, val_loss: 1.3316080012344962 (44 / 100)
train_acc: 0.6390605686032138, val_acc: 0.5221674876847291, train_loss: 0.8904327391399294, val_loss: 1.2659752439395549 (45 / 100)
train_acc: 0.6514215080346106, val_acc: 0.5073891625615764, train_loss: 0.8964998906268767, val_loss: 1.1898392333185732 (46 / 100)
train_acc: 0.7292954264524104, val_acc: 0.47783251231527096, train_loss: 0.7385583799171211, val_loss: 2.2757057738421587 (47 / 100)
train_acc: 0.681087762669963, val_acc: 0.5467980295566502, train_loss: 0.8141957953185469, val_loss: 1.4305213413802274 (48 / 100)
train_acc: 0.6823238566131026, val_acc: 0.5615763546798029, train_loss: 0.7589698973928011, val_loss: 1.367035019573907 (49 / 100)
train_acc: 0.7330037082818294, val_acc: 0.5123152709359606, train_loss: 0.7101292430396723, val_loss: 1.5829804759894686 (50 / 100)
train_acc: 0.7552533992583437, val_acc: 0.5467980295566502, train_loss: 0.610310037292273, val_loss: 1.4153402926299372 (51 / 100)
train_acc: 0.7985166872682324, val_acc: 0.5024630541871922, train_loss: 0.5909645090291762, val_loss: 1.4829192044112482 (52 / 100)
train_acc: 0.788627935723115, val_acc: 0.47783251231527096, train_loss: 0.597557821586194, val_loss: 2.1105283856979145 (53 / 100)
train_acc: 0.7737948084054388, val_acc: 0.5566502463054187, train_loss: 0.6058889777757623, val_loss: 1.5804747395914764 (54 / 100)
train_acc: 0.8454882571075402, val_acc: 0.6206896551724138, train_loss: 0.4368648271183443, val_loss: 1.2068309783935547 (55 / 100)
train_acc: 0.8405438813349815, val_acc: 0.5812807881773399, train_loss: 0.41427639240976905, val_loss: 1.6990426866879016 (56 / 100)
train_acc: 0.7478368355995055, val_acc: 0.5073891625615764, train_loss: 0.7325953380728534, val_loss: 1.6969882646217722 (57 / 100)
train_acc: 0.8220024721878862, val_acc: 0.5763546798029556, train_loss: 0.4738693862085142, val_loss: 1.4242706357551913 (58 / 100)
train_acc: 0.8467243510506799, val_acc: 0.6059113300492611, train_loss: 0.44842881855770156, val_loss: 1.6629880472944287 (59 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5911330049261084, train_loss: 0.35576300376425274, val_loss: 1.7406395755965134 (60 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6354679802955665, train_loss: 0.19859770938698823, val_loss: 1.7520137972432404 (61 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6502463054187192, train_loss: 0.14308289809633687, val_loss: 1.9141728402358558 (62 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6502463054187192, train_loss: 0.09143203415888349, val_loss: 2.25123950472019 (63 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6502463054187192, train_loss: 0.10485682248774505, val_loss: 2.2829641661620492 (64 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6354679802955665, train_loss: 0.08266576465187025, val_loss: 2.665406399759753 (65 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6600985221674877, train_loss: 0.09532944454692939, val_loss: 2.483670356825655 (66 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.07234412556967718, val_loss: 2.619687600676062 (67 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6502463054187192, train_loss: 0.0709956303809865, val_loss: 2.9598608592460893 (68 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6699507389162561, train_loss: 0.09411665005206472, val_loss: 2.822125168269491 (69 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6600985221674877, train_loss: 0.08678192113916423, val_loss: 2.6362278250050664 (70 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6502463054187192, train_loss: 0.08317216939772899, val_loss: 2.784586591673602 (71 / 100)
train_acc: 0.9777503090234858, val_acc: 0.645320197044335, train_loss: 0.06953566301296314, val_loss: 2.8336669177257368 (72 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6403940886699507, train_loss: 0.07095051636949311, val_loss: 2.7703284383407367 (73 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.06857966595733417, val_loss: 2.7715032218125066 (74 / 100)
train_acc: 0.9839307787391842, val_acc: 0.645320197044335, train_loss: 0.05928212220058748, val_loss: 2.9468473765650405 (75 / 100)
train_acc: 0.9740420271940667, val_acc: 0.645320197044335, train_loss: 0.07191613283381326, val_loss: 2.8188873182963854 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.04463093316157168, val_loss: 2.9575891553474762 (77 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6354679802955665, train_loss: 0.07269533411386724, val_loss: 3.0054158518467045 (78 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6403940886699507, train_loss: 0.05495186022981283, val_loss: 3.051488102363248 (79 / 100)
train_acc: 0.9826946847960445, val_acc: 0.645320197044335, train_loss: 0.05083463321657499, val_loss: 3.112891425052887 (80 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6502463054187192, train_loss: 0.06819295912649487, val_loss: 3.3171589679905935 (81 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6551724137931034, train_loss: 0.0636256199389954, val_loss: 3.2058753051194064 (82 / 100)
train_acc: 0.992583436341162, val_acc: 0.645320197044335, train_loss: 0.02782278936195138, val_loss: 3.3280664007064744 (83 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.06347055517698837, val_loss: 3.210581269757501 (84 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6551724137931034, train_loss: 0.0687330293714337, val_loss: 3.6235221841652403 (85 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6600985221674877, train_loss: 0.05191557442744082, val_loss: 3.447178026725506 (86 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6502463054187192, train_loss: 0.06920570334044317, val_loss: 3.3083609630321633 (87 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6551724137931034, train_loss: 0.062363433896832174, val_loss: 3.2895487458835095 (88 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6403940886699507, train_loss: 0.053723001509573313, val_loss: 3.310869369600794 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6305418719211823, train_loss: 0.042898023526365, val_loss: 3.2104508289562657 (90 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6354679802955665, train_loss: 0.055908413546341754, val_loss: 3.212021275694147 (91 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.043632578496143166, val_loss: 3.2868709752125107 (92 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6157635467980296, train_loss: 0.04135372288000156, val_loss: 3.2732374738589884 (93 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6354679802955665, train_loss: 0.03943592228907148, val_loss: 3.3099201336282813 (94 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6551724137931034, train_loss: 0.047418555606280915, val_loss: 3.430973885681829 (95 / 100)
train_acc: 0.992583436341162, val_acc: 0.6354679802955665, train_loss: 0.034439201260673985, val_loss: 3.4955529332748188 (96 / 100)
train_acc: 0.9938195302843016, val_acc: 0.645320197044335, train_loss: 0.028394947093261038, val_loss: 3.7471489906311035 (97 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6551724137931034, train_loss: 0.02034599082578982, val_loss: 3.7930239691522907 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.645320197044335, train_loss: 0.02883841581780772, val_loss: 3.77325124576174 (99 / 100)
train_acc: 0.9901112484548825, val_acc: 0.645320197044335, train_loss: 0.03262179006899538, val_loss: 3.836640273408937 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6699507389162561, val loss 2.822125168269491
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.77804977386932, val_loss: 1.7618477450215757 (1 / 100)
train_acc: 0.20148331273176762, val_acc: 0.1921182266009852, train_loss: 1.7639254224020413, val_loss: 1.7392238607547554 (2 / 100)
train_acc: 0.2249690976514215, val_acc: 0.2561576354679803, train_loss: 1.7415032204060974, val_loss: 1.7080704308495733 (3 / 100)
train_acc: 0.28182941903584674, val_acc: 0.2955665024630542, train_loss: 1.7041854637367617, val_loss: 1.6513840124524872 (4 / 100)
train_acc: 0.30902348578491967, val_acc: 0.2512315270935961, train_loss: 1.6515891216004588, val_loss: 1.626999766368584 (5 / 100)
train_acc: 0.3003708281829419, val_acc: 0.32019704433497537, train_loss: 1.62024944482834, val_loss: 1.5387862885526835 (6 / 100)
train_acc: 0.34981458590852904, val_acc: 0.3497536945812808, train_loss: 1.5394876412909169, val_loss: 1.5229972142891344 (7 / 100)
train_acc: 0.3263288009888752, val_acc: 0.35467980295566504, train_loss: 1.5638771095440915, val_loss: 1.46356524916118 (8 / 100)
train_acc: 0.37824474660074164, val_acc: 0.39408866995073893, train_loss: 1.4837942238349113, val_loss: 1.4976810122945625 (9 / 100)
train_acc: 0.36093943139678614, val_acc: 0.39901477832512317, train_loss: 1.522403815473408, val_loss: 1.3726887127448772 (10 / 100)
train_acc: 0.38813349814585907, val_acc: 0.3645320197044335, train_loss: 1.4020399664182157, val_loss: 1.4749874064487776 (11 / 100)
train_acc: 0.4004944375772559, val_acc: 0.41379310344827586, train_loss: 1.4207824511345297, val_loss: 1.3287221903871433 (12 / 100)
train_acc: 0.38813349814585907, val_acc: 0.43842364532019706, train_loss: 1.3955523369486165, val_loss: 1.3428655451741711 (13 / 100)
train_acc: 0.3831891223733004, val_acc: 0.3842364532019704, train_loss: 1.3961024172373844, val_loss: 1.3049487756390876 (14 / 100)
train_acc: 0.4054388133498146, val_acc: 0.43842364532019706, train_loss: 1.3622280278223553, val_loss: 1.339087710004722 (15 / 100)
train_acc: 0.4363411619283066, val_acc: 0.47783251231527096, train_loss: 1.332843205837443, val_loss: 1.256544911802696 (16 / 100)
train_acc: 0.4264524103831891, val_acc: 0.4482758620689655, train_loss: 1.320094535023674, val_loss: 1.2723100285224727 (17 / 100)
train_acc: 0.449938195302843, val_acc: 0.458128078817734, train_loss: 1.2896849625779614, val_loss: 1.2811032703944616 (18 / 100)
train_acc: 0.48084054388133496, val_acc: 0.49261083743842365, train_loss: 1.2722040578372988, val_loss: 1.1926450752859632 (19 / 100)
train_acc: 0.4857849196538937, val_acc: 0.43842364532019706, train_loss: 1.227212227466522, val_loss: 1.3764750575784392 (20 / 100)
train_acc: 0.41903584672435107, val_acc: 0.5172413793103449, train_loss: 1.4006471396671385, val_loss: 1.2333402340048052 (21 / 100)
train_acc: 0.4672435105067985, val_acc: 0.4482758620689655, train_loss: 1.266899090172776, val_loss: 1.3256924407822746 (22 / 100)
train_acc: 0.522867737948084, val_acc: 0.46798029556650245, train_loss: 1.1966364513368926, val_loss: 1.2898454666137695 (23 / 100)
train_acc: 0.511742892459827, val_acc: 0.4482758620689655, train_loss: 1.1628582779645036, val_loss: 1.250744528958363 (24 / 100)
train_acc: 0.5512978986402967, val_acc: 0.4827586206896552, train_loss: 1.1354887099436983, val_loss: 1.3123422350202287 (25 / 100)
train_acc: 0.5364647713226205, val_acc: 0.5566502463054187, train_loss: 1.1168004191850114, val_loss: 1.1304340638550632 (26 / 100)
train_acc: 0.5686032138442522, val_acc: 0.5172413793103449, train_loss: 1.059208520410677, val_loss: 1.419701367176225 (27 / 100)
train_acc: 0.5574783683559951, val_acc: 0.5024630541871922, train_loss: 1.0903477661394514, val_loss: 1.1261288156650338 (28 / 100)
train_acc: 0.588380716934487, val_acc: 0.41379310344827586, train_loss: 1.0176351157342842, val_loss: 1.4183141815251317 (29 / 100)
train_acc: 0.584672435105068, val_acc: 0.5320197044334976, train_loss: 1.019228807043823, val_loss: 1.1761029905873566 (30 / 100)
train_acc: 0.61557478368356, val_acc: 0.541871921182266, train_loss: 0.9338258512235248, val_loss: 1.1392969380458589 (31 / 100)
train_acc: 0.6378244746600742, val_acc: 0.4827586206896552, train_loss: 0.9258810961054931, val_loss: 1.1496508024596228 (32 / 100)
train_acc: 0.6365883807169345, val_acc: 0.5073891625615764, train_loss: 0.9271428243191486, val_loss: 1.137827483157219 (33 / 100)
train_acc: 0.6477132262051916, val_acc: 0.5566502463054187, train_loss: 0.8989181497925144, val_loss: 1.1041656248087954 (34 / 100)
train_acc: 0.6934487021013597, val_acc: 0.5566502463054187, train_loss: 0.7619920469479744, val_loss: 1.2843953755688784 (35 / 100)
train_acc: 0.7008652657601978, val_acc: 0.5615763546798029, train_loss: 0.7719712454839455, val_loss: 1.1869208213730986 (36 / 100)
train_acc: 0.7379480840543882, val_acc: 0.541871921182266, train_loss: 0.6911260007485766, val_loss: 1.2909783477266434 (37 / 100)
train_acc: 0.7441285537700866, val_acc: 0.4975369458128079, train_loss: 0.6614001924528916, val_loss: 1.4075461764053758 (38 / 100)
train_acc: 0.7750309023485785, val_acc: 0.5270935960591133, train_loss: 0.5821129805667439, val_loss: 1.6772285566247742 (39 / 100)
train_acc: 0.7861557478368356, val_acc: 0.5911330049261084, train_loss: 0.5891993146007524, val_loss: 1.2549903523452177 (40 / 100)
train_acc: 0.7750309023485785, val_acc: 0.5763546798029556, train_loss: 0.6723805459674416, val_loss: 1.4035831234725238 (41 / 100)
train_acc: 0.7972805933250927, val_acc: 0.5615763546798029, train_loss: 0.564315874438056, val_loss: 1.1878893117012062 (42 / 100)
train_acc: 0.8158220024721878, val_acc: 0.5911330049261084, train_loss: 0.4933040296780901, val_loss: 1.4125514817355302 (43 / 100)
train_acc: 0.7058096415327565, val_acc: 0.6403940886699507, train_loss: 0.7992681398969351, val_loss: 1.1694931699137383 (44 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5665024630541872, train_loss: 0.41625379617193575, val_loss: 1.3784700153496465 (45 / 100)
train_acc: 0.865265760197775, val_acc: 0.5911330049261084, train_loss: 0.39843974316812714, val_loss: 1.697019914394529 (46 / 100)
train_acc: 0.8566131025957973, val_acc: 0.5615763546798029, train_loss: 0.41751995428530925, val_loss: 1.741427651767073 (47 / 100)
train_acc: 0.8887515451174289, val_acc: 0.5123152709359606, train_loss: 0.33825383080245536, val_loss: 1.3672056960795314 (48 / 100)
train_acc: 0.9023485784919654, val_acc: 0.5960591133004927, train_loss: 0.2688092629900674, val_loss: 1.9574161856045276 (49 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6206896551724138, train_loss: 0.30347763858413224, val_loss: 1.7006816394590392 (50 / 100)
train_acc: 0.9097651421508035, val_acc: 0.5960591133004927, train_loss: 0.2457400986231744, val_loss: 2.118671815970848 (51 / 100)
train_acc: 0.927070457354759, val_acc: 0.645320197044335, train_loss: 0.21669387478468888, val_loss: 2.0680182614349967 (52 / 100)
train_acc: 0.9147095179233622, val_acc: 0.5862068965517241, train_loss: 0.23260205888335578, val_loss: 1.4914485128055066 (53 / 100)
train_acc: 0.927070457354759, val_acc: 0.5615763546798029, train_loss: 0.18459542793750172, val_loss: 2.2374948938491896 (54 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6403940886699507, train_loss: 0.1551531181936653, val_loss: 1.9941891208658078 (55 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6108374384236454, train_loss: 0.17904279420638114, val_loss: 1.4965926074042109 (56 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6403940886699507, train_loss: 0.15472270914886438, val_loss: 2.06274745558283 (57 / 100)
train_acc: 0.9431396786155748, val_acc: 0.6206896551724138, train_loss: 0.1545672207444501, val_loss: 2.0518062123524143 (58 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6157635467980296, train_loss: 0.34118266291317745, val_loss: 1.9111736842564173 (59 / 100)
train_acc: 0.9443757725587144, val_acc: 0.5714285714285714, train_loss: 0.17821881370285092, val_loss: 2.068398258368957 (60 / 100)
train_acc: 0.9456118665018541, val_acc: 0.5763546798029556, train_loss: 0.17045973419995775, val_loss: 1.620166979399808 (61 / 100)
train_acc: 0.9369592088998764, val_acc: 0.6650246305418719, train_loss: 0.18662187991242474, val_loss: 1.5418505836002931 (62 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6403940886699507, train_loss: 0.11197589929083222, val_loss: 2.28329727684923 (63 / 100)
train_acc: 0.9678615574783683, val_acc: 0.5960591133004927, train_loss: 0.13167505240705607, val_loss: 1.461387433441989 (64 / 100)
train_acc: 0.969097651421508, val_acc: 0.625615763546798, train_loss: 0.09583250259144786, val_loss: 2.5568429437176934 (65 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6059113300492611, train_loss: 0.12413590343390465, val_loss: 2.222487207116752 (66 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6206896551724138, train_loss: 0.10991766544148712, val_loss: 1.788064182098276 (67 / 100)
train_acc: 0.9443757725587144, val_acc: 0.6157635467980296, train_loss: 0.15934702404055223, val_loss: 1.5313949074063982 (68 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6059113300492611, train_loss: 0.10907476897292732, val_loss: 2.3109543476198695 (69 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6059113300492611, train_loss: 0.06967109964863478, val_loss: 2.6989769818160334 (70 / 100)
train_acc: 0.9381953028430161, val_acc: 0.645320197044335, train_loss: 0.176497654802867, val_loss: 2.4814806521819732 (71 / 100)
train_acc: 0.9604449938195303, val_acc: 0.5714285714285714, train_loss: 0.1125757355330459, val_loss: 2.443184265362218 (72 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6059113300492611, train_loss: 0.10325334113372124, val_loss: 2.037777680481596 (73 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6206896551724138, train_loss: 0.07079384589224723, val_loss: 2.644030084604113 (74 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6009852216748769, train_loss: 0.06923009571245191, val_loss: 2.9284539557442875 (75 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6403940886699507, train_loss: 0.06014748276827214, val_loss: 2.4151909201603217 (76 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6059113300492611, train_loss: 0.07942635756635254, val_loss: 2.0066625559564883 (77 / 100)
train_acc: 0.9839307787391842, val_acc: 0.5960591133004927, train_loss: 0.06421653007252696, val_loss: 1.8841145449671253 (78 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6108374384236454, train_loss: 0.09259978301445544, val_loss: 2.2347118091021705 (79 / 100)
train_acc: 0.9703337453646477, val_acc: 0.5665024630541872, train_loss: 0.08580001101947686, val_loss: 1.7364176155017514 (80 / 100)
train_acc: 0.9765142150803461, val_acc: 0.625615763546798, train_loss: 0.05943090909785777, val_loss: 2.5252455637372773 (81 / 100)
train_acc: 0.9728059332509271, val_acc: 0.5960591133004927, train_loss: 0.08493853838393656, val_loss: 1.67679559010003 (82 / 100)
train_acc: 0.9728059332509271, val_acc: 0.5812807881773399, train_loss: 0.07159786053434733, val_loss: 2.1857359818930697 (83 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6108374384236454, train_loss: 0.09718704650959067, val_loss: 2.3336204331496666 (84 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.06101411721025615, val_loss: 3.7098984131084873 (85 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6009852216748769, train_loss: 0.14376774736034267, val_loss: 1.671632078187219 (86 / 100)
train_acc: 0.9789864029666254, val_acc: 0.625615763546798, train_loss: 0.06195144217152825, val_loss: 2.083181971986893 (87 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6305418719211823, train_loss: 0.025033050473452497, val_loss: 2.0128615891992165 (88 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6403940886699507, train_loss: 0.03544311057799237, val_loss: 2.090220211174688 (89 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6206896551724138, train_loss: 0.03624938444979259, val_loss: 2.3755704898552352 (90 / 100)
train_acc: 0.9851668726823238, val_acc: 0.5911330049261084, train_loss: 0.06315374860657455, val_loss: 2.1777015525131977 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5566502463054187, train_loss: 0.029383081440872552, val_loss: 3.7326514321600723 (92 / 100)
train_acc: 0.9740420271940667, val_acc: 0.5960591133004927, train_loss: 0.09258776453723129, val_loss: 2.707173793773933 (93 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6206896551724138, train_loss: 0.08779433911162048, val_loss: 2.096806556720452 (94 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5714285714285714, train_loss: 0.02159507976032158, val_loss: 2.862195538182564 (95 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6157635467980296, train_loss: 0.03364227537171655, val_loss: 2.385645579675148 (96 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6206896551724138, train_loss: 0.05583015669998339, val_loss: 2.74873277060504 (97 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6403940886699507, train_loss: 0.1339933683609933, val_loss: 2.2561277168724923 (98 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6206896551724138, train_loss: 0.10812765381981622, val_loss: 2.365854796444254 (99 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.04112163123447904, val_loss: 2.4431703337307633 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 1}), val accuracy 0.6650246305418719, val loss 1.5418505836002931
train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7838938557468031, val_loss: 1.765847340005959 (1 / 100)
train_acc: 0.18046971569839307, val_acc: 0.18719211822660098, train_loss: 1.7617608095128987, val_loss: 1.749580385062495 (2 / 100)
train_acc: 0.1915945611866502, val_acc: 0.1921182266009852, train_loss: 1.749507782043721, val_loss: 1.7397921425955636 (3 / 100)
train_acc: 0.26823238566131025, val_acc: 0.22167487684729065, train_loss: 1.7223061564826259, val_loss: 1.6791220486457712 (4 / 100)
train_acc: 0.30902348578491967, val_acc: 0.24630541871921183, train_loss: 1.6938990367799813, val_loss: 1.6939042307473169 (5 / 100)
train_acc: 0.3003708281829419, val_acc: 0.3103448275862069, train_loss: 1.6392053670729931, val_loss: 1.5724190438322245 (6 / 100)
train_acc: 0.33498145859085293, val_acc: 0.2660098522167488, train_loss: 1.5886904848520775, val_loss: 1.6919039734478654 (7 / 100)
train_acc: 0.3003708281829419, val_acc: 0.35960591133004927, train_loss: 1.6089904734171807, val_loss: 1.495892658022237 (8 / 100)
train_acc: 0.3411619283065513, val_acc: 0.3103448275862069, train_loss: 1.571541928979758, val_loss: 1.516724865424809 (9 / 100)
train_acc: 0.32756489493201485, val_acc: 0.33497536945812806, train_loss: 1.5107769064319738, val_loss: 1.496528538577075 (10 / 100)
train_acc: 0.3646477132262052, val_acc: 0.41379310344827586, train_loss: 1.4428116115562994, val_loss: 1.4146858524219157 (11 / 100)
train_acc: 0.37453646477132263, val_acc: 0.35960591133004927, train_loss: 1.436965786040345, val_loss: 1.392394776414768 (12 / 100)
train_acc: 0.3695920889987639, val_acc: 0.37438423645320196, train_loss: 1.4415484573991395, val_loss: 1.407646991936444 (13 / 100)
train_acc: 0.37824474660074164, val_acc: 0.47783251231527096, train_loss: 1.3895156144801117, val_loss: 1.3533643842330707 (14 / 100)
train_acc: 0.37824474660074164, val_acc: 0.3891625615763547, train_loss: 1.4317298975804238, val_loss: 1.3813859341767034 (15 / 100)
train_acc: 0.4042027194066749, val_acc: 0.4039408866995074, train_loss: 1.3584447686545487, val_loss: 1.2949965070621134 (16 / 100)
train_acc: 0.446229913473424, val_acc: 0.43349753694581283, train_loss: 1.3374415730369105, val_loss: 1.4318916709552258 (17 / 100)
train_acc: 0.4388133498145859, val_acc: 0.4827586206896552, train_loss: 1.3811381597012025, val_loss: 1.3551355177545783 (18 / 100)
train_acc: 0.446229913473424, val_acc: 0.4433497536945813, train_loss: 1.331643389682982, val_loss: 1.290211967646782 (19 / 100)
train_acc: 0.40667490729295425, val_acc: 0.4630541871921182, train_loss: 1.3438916850296323, val_loss: 1.3358724410897993 (20 / 100)
train_acc: 0.4437577255871446, val_acc: 0.4482758620689655, train_loss: 1.29695636704472, val_loss: 1.2348686820767782 (21 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4630541871921182, train_loss: 1.2762844787981955, val_loss: 1.1886208386256778 (22 / 100)
train_acc: 0.48084054388133496, val_acc: 0.43349753694581283, train_loss: 1.238919207280587, val_loss: 1.2496981333042014 (23 / 100)
train_acc: 0.46600741656365885, val_acc: 0.4729064039408867, train_loss: 1.2284429182375611, val_loss: 1.1802557677470993 (24 / 100)
train_acc: 0.5253399258343634, val_acc: 0.49261083743842365, train_loss: 1.1948089016088008, val_loss: 1.1985290244295093 (25 / 100)
train_acc: 0.5055624227441285, val_acc: 0.43842364532019706, train_loss: 1.2229939186381469, val_loss: 1.2111688003751444 (26 / 100)
train_acc: 0.515451174289246, val_acc: 0.5073891625615764, train_loss: 1.1924923440287227, val_loss: 1.1168240716891924 (27 / 100)
train_acc: 0.5475896168108776, val_acc: 0.46798029556650245, train_loss: 1.1243702799487025, val_loss: 1.1984869896484713 (28 / 100)
train_acc: 0.515451174289246, val_acc: 0.5270935960591133, train_loss: 1.1323302542176028, val_loss: 1.0918036725720748 (29 / 100)
train_acc: 0.5475896168108776, val_acc: 0.47783251231527096, train_loss: 1.0798100135824442, val_loss: 1.2250922072697155 (30 / 100)
train_acc: 0.5834363411619283, val_acc: 0.3842364532019704, train_loss: 1.03806065923646, val_loss: 1.4509677951559057 (31 / 100)
train_acc: 0.5512978986402967, val_acc: 0.5369458128078818, train_loss: 1.106973749598113, val_loss: 1.0870859114994555 (32 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5024630541871922, train_loss: 0.9825749047312365, val_loss: 1.2150841786943634 (33 / 100)
train_acc: 0.6118665018541409, val_acc: 0.5369458128078818, train_loss: 0.9577958424689595, val_loss: 1.0746243989526345 (34 / 100)
train_acc: 0.6205191594561187, val_acc: 0.5221674876847291, train_loss: 0.9200084872534602, val_loss: 1.110918222096166 (35 / 100)
train_acc: 0.6353522867737948, val_acc: 0.5517241379310345, train_loss: 0.8974791698903767, val_loss: 1.0966784995177696 (36 / 100)
train_acc: 0.6662546353522868, val_acc: 0.541871921182266, train_loss: 0.8380924526634264, val_loss: 1.0897267484312574 (37 / 100)
train_acc: 0.6897404202719407, val_acc: 0.6157635467980296, train_loss: 0.8156033903912944, val_loss: 1.0179602348158512 (38 / 100)
train_acc: 0.7045735475896168, val_acc: 0.5615763546798029, train_loss: 0.7894621750038251, val_loss: 1.2104886702716058 (39 / 100)
train_acc: 0.681087762669963, val_acc: 0.5517241379310345, train_loss: 0.7928524548544724, val_loss: 1.0608102404718915 (40 / 100)
train_acc: 0.7132262051915945, val_acc: 0.5665024630541872, train_loss: 0.724027065396751, val_loss: 1.1605572198412102 (41 / 100)
train_acc: 0.7601977750309024, val_acc: 0.5615763546798029, train_loss: 0.6497133281381228, val_loss: 1.1736137535184474 (42 / 100)
train_acc: 0.7441285537700866, val_acc: 0.5615763546798029, train_loss: 0.689131863037647, val_loss: 1.2583947995026123 (43 / 100)
train_acc: 0.8022249690976514, val_acc: 0.6059113300492611, train_loss: 0.522308319917568, val_loss: 1.1627062770533445 (44 / 100)
train_acc: 0.8158220024721878, val_acc: 0.5615763546798029, train_loss: 0.44794466395313276, val_loss: 1.373279513396653 (45 / 100)
train_acc: 0.8071693448702101, val_acc: 0.5615763546798029, train_loss: 0.546325695971476, val_loss: 1.3741016100192893 (46 / 100)
train_acc: 0.8145859085290482, val_acc: 0.5911330049261084, train_loss: 0.5116894150841221, val_loss: 1.14308408622084 (47 / 100)
train_acc: 0.8529048207663782, val_acc: 0.5517241379310345, train_loss: 0.43163537772830546, val_loss: 1.4873694817127265 (48 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6059113300492611, train_loss: 0.3514191552683508, val_loss: 1.3640346838335686 (49 / 100)
train_acc: 0.8640296662546354, val_acc: 0.6354679802955665, train_loss: 0.3633746954212967, val_loss: 1.4541480952295764 (50 / 100)
train_acc: 0.8887515451174289, val_acc: 0.625615763546798, train_loss: 0.3176119678247402, val_loss: 1.4450152061255694 (51 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5270935960591133, train_loss: 0.3792034797600674, val_loss: 1.575617951125347 (52 / 100)
train_acc: 0.8702101359703337, val_acc: 0.5714285714285714, train_loss: 0.3522406249538488, val_loss: 1.67408366449948 (53 / 100)
train_acc: 0.892459826946848, val_acc: 0.625615763546798, train_loss: 0.29701825005678073, val_loss: 1.7216611378298605 (54 / 100)
train_acc: 0.9283065512978986, val_acc: 0.5714285714285714, train_loss: 0.19404568711965722, val_loss: 2.9263515266878852 (55 / 100)
train_acc: 0.8974042027194067, val_acc: 0.5665024630541872, train_loss: 0.29125753220064826, val_loss: 1.9965980152778438 (56 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6059113300492611, train_loss: 0.292388521770317, val_loss: 1.4501524476582193 (57 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6157635467980296, train_loss: 0.20892994981650517, val_loss: 1.4278803937540854 (58 / 100)
train_acc: 0.9419035846724351, val_acc: 0.6108374384236454, train_loss: 0.18421632072650015, val_loss: 2.7272139229797965 (59 / 100)
train_acc: 0.9184177997527813, val_acc: 0.625615763546798, train_loss: 0.2528563695412926, val_loss: 1.5810541014365962 (60 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6305418719211823, train_loss: 0.1324718453736034, val_loss: 1.5403927505897184 (61 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6502463054187192, train_loss: 0.08839094254783411, val_loss: 1.6135307902773026 (62 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6502463054187192, train_loss: 0.08776873991363054, val_loss: 1.6987968219324874 (63 / 100)
train_acc: 0.9728059332509271, val_acc: 0.645320197044335, train_loss: 0.09010941417351347, val_loss: 1.648765938622611 (64 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6354679802955665, train_loss: 0.08031359224664267, val_loss: 1.7017649641177925 (65 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6600985221674877, train_loss: 0.07105734575958865, val_loss: 1.7742889679124203 (66 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6305418719211823, train_loss: 0.07182806944163753, val_loss: 1.7963312453237072 (67 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6403940886699507, train_loss: 0.06396823618630101, val_loss: 1.8595264098914386 (68 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6502463054187192, train_loss: 0.08078221433389614, val_loss: 1.9419999862539357 (69 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.06695423123273625, val_loss: 1.9212404342707743 (70 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6403940886699507, train_loss: 0.06633085049303164, val_loss: 1.934075590424937 (71 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6403940886699507, train_loss: 0.06221477769784933, val_loss: 1.9396228825517476 (72 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6354679802955665, train_loss: 0.051597851316751944, val_loss: 1.950863954468901 (73 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6354679802955665, train_loss: 0.05352115586911741, val_loss: 1.9680369651963558 (74 / 100)
train_acc: 0.9728059332509271, val_acc: 0.645320197044335, train_loss: 0.07489084829006469, val_loss: 1.9703772349897863 (75 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6305418719211823, train_loss: 0.07893511767145729, val_loss: 1.9282283735979955 (76 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.05666625190282192, val_loss: 1.8990241711950067 (77 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6502463054187192, train_loss: 0.04838834026982669, val_loss: 1.9155658982657446 (78 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6305418719211823, train_loss: 0.06206147897670938, val_loss: 1.9424112853158284 (79 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.059950539445658806, val_loss: 2.0025118242930895 (80 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6502463054187192, train_loss: 0.05707511325149218, val_loss: 2.032833632577229 (81 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.04940753224759022, val_loss: 2.0714183452681367 (82 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.054649051541159774, val_loss: 2.1159267155407684 (83 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6502463054187192, train_loss: 0.06859373840087811, val_loss: 2.1345781046768715 (84 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6403940886699507, train_loss: 0.04623306033299943, val_loss: 2.165965258781546 (85 / 100)
train_acc: 0.9765142150803461, val_acc: 0.645320197044335, train_loss: 0.06199928727668649, val_loss: 2.1389041945264844 (86 / 100)
train_acc: 0.9777503090234858, val_acc: 0.645320197044335, train_loss: 0.06442979136591245, val_loss: 2.0829989616506794 (87 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6403940886699507, train_loss: 0.03539354942608924, val_loss: 2.1433751054585275 (88 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.04307145712887396, val_loss: 2.1514421108321016 (89 / 100)
train_acc: 0.9752781211372065, val_acc: 0.645320197044335, train_loss: 0.0766454673981195, val_loss: 2.1054370097926096 (90 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6403940886699507, train_loss: 0.052201567837054416, val_loss: 2.1012730363554555 (91 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6305418719211823, train_loss: 0.06617244440781318, val_loss: 2.09587212853831 (92 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6403940886699507, train_loss: 0.0447210091156413, val_loss: 2.10186591993999 (93 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.05660964193557043, val_loss: 2.103848060363619 (94 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6502463054187192, train_loss: 0.04129656755114469, val_loss: 2.115198475973947 (95 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.05382333447056165, val_loss: 2.165255827269531 (96 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6403940886699507, train_loss: 0.04188714039178706, val_loss: 2.1671598638807024 (97 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6699507389162561, train_loss: 0.047880000620267364, val_loss: 2.153886217201872 (98 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6650246305418719, train_loss: 0.04870475399477637, val_loss: 2.169307813268577 (99 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6650246305418719, train_loss: 0.04834204299976343, val_loss: 2.1397088936397006 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.05}), val accuracy 0.6699507389162561, val loss 2.153886217201872
train_acc: 0.1668726823238566, val_acc: 0.19704433497536947, train_loss: 1.7880478782029028, val_loss: 1.771635675665193 (1 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7661769146972297, val_loss: 1.7481744958849377 (2 / 100)
train_acc: 0.20395550061804696, val_acc: 0.20689655172413793, train_loss: 1.752708246887688, val_loss: 1.735363308432067 (3 / 100)
train_acc: 0.2484548825710754, val_acc: 0.29064039408866993, train_loss: 1.7311468662231313, val_loss: 1.668926852677256 (4 / 100)
train_acc: 0.27441285537700866, val_acc: 0.30049261083743845, train_loss: 1.6845871221886577, val_loss: 1.6232491467386632 (5 / 100)
train_acc: 0.3053152039555006, val_acc: 0.2660098522167488, train_loss: 1.6287131897451261, val_loss: 1.6301200607140076 (6 / 100)
train_acc: 0.34981458590852904, val_acc: 0.2955665024630542, train_loss: 1.6016996664228782, val_loss: 1.6196540858357997 (7 / 100)
train_acc: 0.311495673671199, val_acc: 0.24630541871921183, train_loss: 1.5764337228461456, val_loss: 1.6245038380176562 (8 / 100)
train_acc: 0.3683559950556242, val_acc: 0.35960591133004927, train_loss: 1.524804488690144, val_loss: 1.559689949298727 (9 / 100)
train_acc: 0.37330037082818296, val_acc: 0.3842364532019704, train_loss: 1.4849381983206504, val_loss: 1.452556707001672 (10 / 100)
train_acc: 0.380716934487021, val_acc: 0.27586206896551724, train_loss: 1.5111322274756225, val_loss: 1.5898078362929997 (11 / 100)
train_acc: 0.35599505562422745, val_acc: 0.39901477832512317, train_loss: 1.4907683042719573, val_loss: 1.4190430353427756 (12 / 100)
train_acc: 0.38813349814585907, val_acc: 0.3842364532019704, train_loss: 1.410662464217291, val_loss: 1.3975090193631026 (13 / 100)
train_acc: 0.4042027194066749, val_acc: 0.4039408866995074, train_loss: 1.4014720202081725, val_loss: 1.3382299786130782 (14 / 100)
train_acc: 0.3930778739184178, val_acc: 0.4433497536945813, train_loss: 1.3974093838292088, val_loss: 1.3846986399495542 (15 / 100)
train_acc: 0.41656365883807167, val_acc: 0.39408866995073893, train_loss: 1.3570983098964904, val_loss: 1.4132870476821373 (16 / 100)
train_acc: 0.4177997527812114, val_acc: 0.4187192118226601, train_loss: 1.3902707664279914, val_loss: 1.3055176488284408 (17 / 100)
train_acc: 0.415327564894932, val_acc: 0.43842364532019706, train_loss: 1.3573394988759044, val_loss: 1.2612347021478738 (18 / 100)
train_acc: 0.4635352286773795, val_acc: 0.43349753694581283, train_loss: 1.3230321737390809, val_loss: 1.267510088206512 (19 / 100)
train_acc: 0.4400494437577256, val_acc: 0.4630541871921182, train_loss: 1.3179187068833114, val_loss: 1.2468585832952865 (20 / 100)
train_acc: 0.44870210135970334, val_acc: 0.4482758620689655, train_loss: 1.2809499456502305, val_loss: 1.2475939519299661 (21 / 100)
train_acc: 0.48331273176761436, val_acc: 0.5073891625615764, train_loss: 1.2819857147921738, val_loss: 1.2084888413621875 (22 / 100)
train_acc: 0.45859085290482077, val_acc: 0.47783251231527096, train_loss: 1.2902587403178363, val_loss: 1.2431726708200765 (23 / 100)
train_acc: 0.46971569839307786, val_acc: 0.4630541871921182, train_loss: 1.262232698969847, val_loss: 1.2008487156459264 (24 / 100)
train_acc: 0.48084054388133496, val_acc: 0.458128078817734, train_loss: 1.244032890599207, val_loss: 1.2159267458422431 (25 / 100)
train_acc: 0.48702101359703337, val_acc: 0.4729064039408867, train_loss: 1.1879285181998027, val_loss: 1.1723729278066475 (26 / 100)
train_acc: 0.515451174289246, val_acc: 0.43349753694581283, train_loss: 1.23529129093156, val_loss: 1.2930546869785327 (27 / 100)
train_acc: 0.5055624227441285, val_acc: 0.4876847290640394, train_loss: 1.2270823220534732, val_loss: 1.1682680246277983 (28 / 100)
train_acc: 0.522867737948084, val_acc: 0.5320197044334976, train_loss: 1.1622093074548672, val_loss: 1.1277148247939612 (29 / 100)
train_acc: 0.5475896168108776, val_acc: 0.5024630541871922, train_loss: 1.0912985170285399, val_loss: 1.1624610826299695 (30 / 100)
train_acc: 0.5698393077873919, val_acc: 0.47783251231527096, train_loss: 1.0978565839371368, val_loss: 1.1839481827073497 (31 / 100)
train_acc: 0.5574783683559951, val_acc: 0.5073891625615764, train_loss: 1.1017893221233919, val_loss: 1.1131592536794728 (32 / 100)
train_acc: 0.580964153275649, val_acc: 0.5320197044334976, train_loss: 1.0576056316402846, val_loss: 1.0860763130516842 (33 / 100)
train_acc: 0.588380716934487, val_acc: 0.5024630541871922, train_loss: 1.025364173799569, val_loss: 1.1808026967377498 (34 / 100)
train_acc: 0.6007416563658838, val_acc: 0.5270935960591133, train_loss: 1.0178241547017517, val_loss: 1.1451470517172602 (35 / 100)
train_acc: 0.6205191594561187, val_acc: 0.5763546798029556, train_loss: 0.9569731221358178, val_loss: 1.106772785116299 (36 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5270935960591133, train_loss: 0.9080513568390137, val_loss: 1.2783104474908613 (37 / 100)
train_acc: 0.6761433868974042, val_acc: 0.5024630541871922, train_loss: 0.8323352027440395, val_loss: 1.1506964479173933 (38 / 100)
train_acc: 0.6378244746600742, val_acc: 0.541871921182266, train_loss: 0.9407634763841428, val_loss: 1.1546347252841067 (39 / 100)
train_acc: 0.6711990111248455, val_acc: 0.5467980295566502, train_loss: 0.8190267516302384, val_loss: 1.1038962306060227 (40 / 100)
train_acc: 0.6798516687268232, val_acc: 0.5615763546798029, train_loss: 0.8542600803086431, val_loss: 1.1102144437764079 (41 / 100)
train_acc: 0.6934487021013597, val_acc: 0.5123152709359606, train_loss: 0.7680252731509497, val_loss: 1.2069354430208066 (42 / 100)
train_acc: 0.7255871446229913, val_acc: 0.5665024630541872, train_loss: 0.7308538977531037, val_loss: 1.1035962915185638 (43 / 100)
train_acc: 0.7725587144622992, val_acc: 0.5862068965517241, train_loss: 0.6335572388543481, val_loss: 1.1119464644657566 (44 / 100)
train_acc: 0.7441285537700866, val_acc: 0.5517241379310345, train_loss: 0.6816448399840828, val_loss: 1.1409306273671793 (45 / 100)
train_acc: 0.7713226205191595, val_acc: 0.6009852216748769, train_loss: 0.6178909954609181, val_loss: 1.110842057343187 (46 / 100)
train_acc: 0.7812113720642769, val_acc: 0.5714285714285714, train_loss: 0.5968357102095859, val_loss: 1.2687101992480274 (47 / 100)
train_acc: 0.788627935723115, val_acc: 0.5763546798029556, train_loss: 0.553515090341179, val_loss: 1.3714096854472984 (48 / 100)
train_acc: 0.8244746600741656, val_acc: 0.5665024630541872, train_loss: 0.44905213726171017, val_loss: 1.2231299607037323 (49 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5467980295566502, train_loss: 0.4103638207072528, val_loss: 1.4057548640690414 (50 / 100)
train_acc: 0.8491965389369592, val_acc: 0.5960591133004927, train_loss: 0.4104771308131212, val_loss: 1.2391926801850643 (51 / 100)
train_acc: 0.8553770086526576, val_acc: 0.5221674876847291, train_loss: 0.3785712368261387, val_loss: 1.8500063213808784 (52 / 100)
train_acc: 0.8355995055624228, val_acc: 0.5763546798029556, train_loss: 0.41702034240600055, val_loss: 1.4038032951026127 (53 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6009852216748769, train_loss: 0.29586711710109403, val_loss: 1.3353306941798169 (54 / 100)
train_acc: 0.8689740420271941, val_acc: 0.5862068965517241, train_loss: 0.3576018462517058, val_loss: 1.2894936394808916 (55 / 100)
train_acc: 0.8825710754017305, val_acc: 0.5911330049261084, train_loss: 0.34024438698521653, val_loss: 1.3806678667444314 (56 / 100)
train_acc: 0.8825710754017305, val_acc: 0.6354679802955665, train_loss: 0.2933894995541274, val_loss: 1.3964967971364852 (57 / 100)
train_acc: 0.907292954264524, val_acc: 0.5960591133004927, train_loss: 0.2652786898303533, val_loss: 1.217098462170568 (58 / 100)
train_acc: 0.9159456118665018, val_acc: 0.6108374384236454, train_loss: 0.2214813683232654, val_loss: 1.947913832265168 (59 / 100)
train_acc: 0.927070457354759, val_acc: 0.5862068965517241, train_loss: 0.20507634131811164, val_loss: 1.5691179759396707 (60 / 100)
train_acc: 0.9369592088998764, val_acc: 0.6403940886699507, train_loss: 0.1855882807020029, val_loss: 1.66397128375293 (61 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6502463054187192, train_loss: 0.11183592769212569, val_loss: 1.6913380922355088 (62 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6354679802955665, train_loss: 0.11018436786353736, val_loss: 1.7451980067004125 (63 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6748768472906403, train_loss: 0.07051991370054163, val_loss: 1.7572072497729598 (64 / 100)
train_acc: 0.969097651421508, val_acc: 0.6551724137931034, train_loss: 0.09200200398092254, val_loss: 1.8218748499019979 (65 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6551724137931034, train_loss: 0.0634167455165556, val_loss: 1.8052434563049542 (66 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6699507389162561, train_loss: 0.06013587672535067, val_loss: 1.8691973739069672 (67 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6551724137931034, train_loss: 0.07197657518540089, val_loss: 1.9173906624610788 (68 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6551724137931034, train_loss: 0.07643074556098438, val_loss: 1.924882753729233 (69 / 100)
train_acc: 0.9814585908529048, val_acc: 0.645320197044335, train_loss: 0.07082763590535658, val_loss: 1.9447319572195043 (70 / 100)
train_acc: 0.9777503090234858, val_acc: 0.645320197044335, train_loss: 0.060838421431976764, val_loss: 1.9792676206880015 (71 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6403940886699507, train_loss: 0.05882404672674955, val_loss: 2.0165781722280194 (72 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.06676024480346401, val_loss: 2.035114877916909 (73 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6650246305418719, train_loss: 0.06793275722334155, val_loss: 2.085897349371699 (74 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6600985221674877, train_loss: 0.04640430425799121, val_loss: 2.243600382006227 (75 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.06734345206815352, val_loss: 2.225400476620115 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6650246305418719, train_loss: 0.05637451007959925, val_loss: 2.2594980923413055 (77 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6551724137931034, train_loss: 0.04960083489925618, val_loss: 2.347603689860828 (78 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6699507389162561, train_loss: 0.05174191655390821, val_loss: 2.3157142852914743 (79 / 100)
train_acc: 0.9752781211372065, val_acc: 0.645320197044335, train_loss: 0.06442080171058145, val_loss: 2.223590924822051 (80 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.05548117526119623, val_loss: 2.1875132198991447 (81 / 100)
train_acc: 0.9777503090234858, val_acc: 0.645320197044335, train_loss: 0.060558982773675905, val_loss: 2.2211393393906467 (82 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6206896551724138, train_loss: 0.06523384262516413, val_loss: 2.220374843169903 (83 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6551724137931034, train_loss: 0.054548164088237566, val_loss: 2.331062231745039 (84 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.07349779431987899, val_loss: 2.116930813624941 (85 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6699507389162561, train_loss: 0.05022490245575886, val_loss: 2.1176392855902613 (86 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6650246305418719, train_loss: 0.05636491586439247, val_loss: 2.1162909169502444 (87 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6699507389162561, train_loss: 0.0734957285658963, val_loss: 2.0088611306815314 (88 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6699507389162561, train_loss: 0.04650318666791678, val_loss: 2.18450924680738 (89 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6748768472906403, train_loss: 0.041209796156356636, val_loss: 2.2772552350471758 (90 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6798029556650246, train_loss: 0.06393165332213394, val_loss: 2.3052514662296315 (91 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.04867709728996229, val_loss: 2.3624336795853864 (92 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6650246305418719, train_loss: 0.03807091904741946, val_loss: 2.2697552583487752 (93 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6551724137931034, train_loss: 0.04299880429637263, val_loss: 2.321569365233623 (94 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6650246305418719, train_loss: 0.036347793781271086, val_loss: 2.4478877324776107 (95 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6551724137931034, train_loss: 0.03296755536082887, val_loss: 2.3917030248735927 (96 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6600985221674877, train_loss: 0.04768039829964543, val_loss: 2.443899607423491 (97 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6600985221674877, train_loss: 0.05145175881195717, val_loss: 2.576919698950105 (98 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6551724137931034, train_loss: 0.037556962412881846, val_loss: 2.5598468199152076 (99 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6650246305418719, train_loss: 0.03585534882633883, val_loss: 2.5670915407500243 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6798029556650246, val loss 2.3052514662296315
train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7904793417497973, val_loss: 1.7843709608604168 (1 / 100)
train_acc: 0.20395550061804696, val_acc: 0.18226600985221675, train_loss: 1.7814592448683693, val_loss: 1.7706126438573075 (2 / 100)
train_acc: 0.1915945611866502, val_acc: 0.17733990147783252, train_loss: 1.7662195208930263, val_loss: 1.7502281225373593 (3 / 100)
train_acc: 0.22249690976514216, val_acc: 0.18226600985221675, train_loss: 1.7548419245978073, val_loss: 1.7364052534103394 (4 / 100)
train_acc: 0.24474660074165636, val_acc: 0.23645320197044334, train_loss: 1.7370607376982756, val_loss: 1.6941195626564214 (5 / 100)
train_acc: 0.2954264524103832, val_acc: 0.3645320197044335, train_loss: 1.6736032031522545, val_loss: 1.5586054659829351 (6 / 100)
train_acc: 0.24474660074165636, val_acc: 0.23645320197044334, train_loss: 1.729934103409351, val_loss: 1.7092005460720343 (7 / 100)
train_acc: 0.3053152039555006, val_acc: 0.32019704433497537, train_loss: 1.6554482204215635, val_loss: 1.6090902512883904 (8 / 100)
train_acc: 0.3399258343634116, val_acc: 0.29064039408866993, train_loss: 1.6025536984242084, val_loss: 1.6199712994063429 (9 / 100)
train_acc: 0.34363411619283063, val_acc: 0.30049261083743845, train_loss: 1.5557120597848786, val_loss: 1.4947425667288268 (10 / 100)
train_acc: 0.35599505562422745, val_acc: 0.39408866995073893, train_loss: 1.511788757239343, val_loss: 1.5070624562907102 (11 / 100)
train_acc: 0.3522867737948084, val_acc: 0.3793103448275862, train_loss: 1.5192616510450176, val_loss: 1.485660019179283 (12 / 100)
train_acc: 0.37330037082818296, val_acc: 0.39408866995073893, train_loss: 1.4827348213407991, val_loss: 1.3963497800780047 (13 / 100)
train_acc: 0.3584672435105068, val_acc: 0.3399014778325123, train_loss: 1.5089825568594066, val_loss: 1.4576596832040496 (14 / 100)
train_acc: 0.3720642768850433, val_acc: 0.270935960591133, train_loss: 1.4573385400147314, val_loss: 1.6100806373680754 (15 / 100)
train_acc: 0.38813349814585907, val_acc: 0.4729064039408867, train_loss: 1.4403110548061848, val_loss: 1.3307926179152991 (16 / 100)
train_acc: 0.38813349814585907, val_acc: 0.4088669950738916, train_loss: 1.3909937690008702, val_loss: 1.3730962435012968 (17 / 100)
train_acc: 0.3992583436341162, val_acc: 0.4039408866995074, train_loss: 1.406364455358649, val_loss: 1.3464957405193685 (18 / 100)
train_acc: 0.40667490729295425, val_acc: 0.35960591133004927, train_loss: 1.3753074462098451, val_loss: 1.4121258769716536 (19 / 100)
train_acc: 0.3943139678615575, val_acc: 0.4433497536945813, train_loss: 1.4520375987950007, val_loss: 1.3488987513950892 (20 / 100)
train_acc: 0.446229913473424, val_acc: 0.458128078817734, train_loss: 1.3437577729172112, val_loss: 1.279044494840312 (21 / 100)
train_acc: 0.42398022249690975, val_acc: 0.41379310344827586, train_loss: 1.3412654019698813, val_loss: 1.3196624285481833 (22 / 100)
train_acc: 0.45859085290482077, val_acc: 0.4729064039408867, train_loss: 1.3126879712412471, val_loss: 1.2435817965145768 (23 / 100)
train_acc: 0.46600741656365885, val_acc: 0.3842364532019704, train_loss: 1.2795375691650825, val_loss: 1.3522773341005072 (24 / 100)
train_acc: 0.4363411619283066, val_acc: 0.4729064039408867, train_loss: 1.293846699746489, val_loss: 1.2169747276259173 (25 / 100)
train_acc: 0.4857849196538937, val_acc: 0.4729064039408867, train_loss: 1.2466376449622683, val_loss: 1.2525491015664463 (26 / 100)
train_acc: 0.484548825710754, val_acc: 0.4876847290640394, train_loss: 1.2440315871067777, val_loss: 1.2218856004071352 (27 / 100)
train_acc: 0.4672435105067985, val_acc: 0.5024630541871922, train_loss: 1.247803874157268, val_loss: 1.2007156704446953 (28 / 100)
train_acc: 0.47713226205191595, val_acc: 0.4236453201970443, train_loss: 1.2229273532907512, val_loss: 1.3541932423126521 (29 / 100)
train_acc: 0.5414091470951793, val_acc: 0.5073891625615764, train_loss: 1.1852033682010967, val_loss: 1.203516291573717 (30 / 100)
train_acc: 0.5377008652657602, val_acc: 0.5123152709359606, train_loss: 1.1330630609809396, val_loss: 1.2397131270962982 (31 / 100)
train_acc: 0.5278121137206427, val_acc: 0.5073891625615764, train_loss: 1.1263635439984732, val_loss: 1.183551751480901 (32 / 100)
train_acc: 0.5562422744128553, val_acc: 0.5024630541871922, train_loss: 1.0929839120365044, val_loss: 1.1120627634043765 (33 / 100)
train_acc: 0.5377008652657602, val_acc: 0.4876847290640394, train_loss: 1.1014921816966148, val_loss: 1.2003893068271319 (34 / 100)
train_acc: 0.5710754017305315, val_acc: 0.5517241379310345, train_loss: 1.0318918403500532, val_loss: 1.0909060938604946 (35 / 100)
train_acc: 0.5859085290482077, val_acc: 0.5517241379310345, train_loss: 0.9905658878561003, val_loss: 1.2482289740898338 (36 / 100)
train_acc: 0.5896168108776267, val_acc: 0.5665024630541872, train_loss: 0.9992034436745756, val_loss: 1.061522452114838 (37 / 100)
train_acc: 0.6341161928306551, val_acc: 0.5320197044334976, train_loss: 0.9439244875212388, val_loss: 1.1184148741473119 (38 / 100)
train_acc: 0.6415327564894932, val_acc: 0.5369458128078818, train_loss: 0.926078077889196, val_loss: 1.1080572613941624 (39 / 100)
train_acc: 0.619283065512979, val_acc: 0.49261083743842365, train_loss: 0.9356253659916749, val_loss: 1.1936847504430217 (40 / 100)
train_acc: 0.622991347342398, val_acc: 0.5960591133004927, train_loss: 0.8964705117258654, val_loss: 1.0486160002905747 (41 / 100)
train_acc: 0.6724351050679852, val_acc: 0.4088669950738916, train_loss: 0.8230580447336062, val_loss: 1.6744257379047975 (42 / 100)
train_acc: 0.6613102595797281, val_acc: 0.5665024630541872, train_loss: 0.8719504215513967, val_loss: 1.0855996826012146 (43 / 100)
train_acc: 0.73053152039555, val_acc: 0.47783251231527096, train_loss: 0.6870750619100846, val_loss: 1.5013269382744587 (44 / 100)
train_acc: 0.7391841779975278, val_acc: 0.6059113300492611, train_loss: 0.7266878459892697, val_loss: 1.211386555521359 (45 / 100)
train_acc: 0.7033374536464772, val_acc: 0.5911330049261084, train_loss: 0.7573728649813696, val_loss: 1.0605975706589046 (46 / 100)
train_acc: 0.7428924598269468, val_acc: 0.5369458128078818, train_loss: 0.6623325816485731, val_loss: 1.2392026994175511 (47 / 100)
train_acc: 0.7725587144622992, val_acc: 0.6009852216748769, train_loss: 0.5997065020948464, val_loss: 1.123169097407111 (48 / 100)
train_acc: 0.8195302843016069, val_acc: 0.6502463054187192, train_loss: 0.4680808803943827, val_loss: 1.1450149173219804 (49 / 100)
train_acc: 0.8145859085290482, val_acc: 0.5566502463054187, train_loss: 0.4853157258888405, val_loss: 1.2469873545792303 (50 / 100)
train_acc: 0.8158220024721878, val_acc: 0.6305418719211823, train_loss: 0.4780130751053394, val_loss: 0.9996111836339453 (51 / 100)
train_acc: 0.8331273176761433, val_acc: 0.6157635467980296, train_loss: 0.46305758516190226, val_loss: 1.1364871784677646 (52 / 100)
train_acc: 0.8355995055624228, val_acc: 0.6157635467980296, train_loss: 0.47889321519358935, val_loss: 1.1037426725984207 (53 / 100)
train_acc: 0.861557478368356, val_acc: 0.6305418719211823, train_loss: 0.352134523786632, val_loss: 1.2992352457175702 (54 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6305418719211823, train_loss: 0.34219116922951454, val_loss: 1.32413685556703 (55 / 100)
train_acc: 0.8590852904820766, val_acc: 0.6206896551724138, train_loss: 0.37640584962919116, val_loss: 1.1860676945136686 (56 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6009852216748769, train_loss: 0.38508221274990084, val_loss: 1.520855719232794 (57 / 100)
train_acc: 0.8862793572311496, val_acc: 0.5960591133004927, train_loss: 0.3520626429611142, val_loss: 1.2004442532074275 (58 / 100)
train_acc: 0.8776266996291718, val_acc: 0.6157635467980296, train_loss: 0.3079967096503202, val_loss: 1.1604834154174832 (59 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6305418719211823, train_loss: 0.22779232963726237, val_loss: 1.5278842946872335 (60 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6551724137931034, train_loss: 0.25789805883898576, val_loss: 2.039845239939948 (61 / 100)
train_acc: 0.9443757725587144, val_acc: 0.6403940886699507, train_loss: 0.19245576438561948, val_loss: 2.01206052362038 (62 / 100)
train_acc: 0.9060568603213844, val_acc: 0.625615763546798, train_loss: 0.249135887556524, val_loss: 1.235016841166125 (63 / 100)
train_acc: 0.9221260815822002, val_acc: 0.6600985221674877, train_loss: 0.21312052066747572, val_loss: 1.4901677715073665 (64 / 100)
train_acc: 0.9258343634116193, val_acc: 0.645320197044335, train_loss: 0.20544676948223628, val_loss: 1.397584592767537 (65 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6551724137931034, train_loss: 0.17644064299697781, val_loss: 1.544099669132767 (66 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6551724137931034, train_loss: 0.22751289860279805, val_loss: 2.0471056529453824 (67 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6305418719211823, train_loss: 0.1652420261144933, val_loss: 1.4005834052128157 (68 / 100)
train_acc: 0.9629171817058096, val_acc: 0.625615763546798, train_loss: 0.11221300874121846, val_loss: 2.0984603636370505 (69 / 100)
train_acc: 0.9332509270704573, val_acc: 0.6305418719211823, train_loss: 0.18363851951653937, val_loss: 2.40691123689924 (70 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6206896551724138, train_loss: 0.13372523189327773, val_loss: 2.1978933329652683 (71 / 100)
train_acc: 0.9381953028430161, val_acc: 0.6600985221674877, train_loss: 0.1772492267697939, val_loss: 1.8512411704791591 (72 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6502463054187192, train_loss: 0.12776391556381728, val_loss: 2.1075012466590395 (73 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6995073891625616, train_loss: 0.12426795687973131, val_loss: 1.908599778312474 (74 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6896551724137931, train_loss: 0.1490539027923633, val_loss: 1.6260082862647296 (75 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6798029556650246, train_loss: 0.11003479334365747, val_loss: 1.443130744795494 (76 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6847290640394089, train_loss: 0.11904331703747453, val_loss: 1.6364445383912825 (77 / 100)
train_acc: 0.9641532756489494, val_acc: 0.645320197044335, train_loss: 0.09217709531293541, val_loss: 1.4711368847454858 (78 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6650246305418719, train_loss: 0.08695517876386938, val_loss: 1.9042635228246303 (79 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6059113300492611, train_loss: 0.07493037171431613, val_loss: 2.2972772908328203 (80 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6798029556650246, train_loss: 0.12532747955935258, val_loss: 1.404740906260871 (81 / 100)
train_acc: 0.965389369592089, val_acc: 0.6551724137931034, train_loss: 0.09970543897285947, val_loss: 2.45037198184159 (82 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6502463054187192, train_loss: 0.1062737068222382, val_loss: 1.9191932231921869 (83 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6995073891625616, train_loss: 0.04291215270043354, val_loss: 2.3637281418433918 (84 / 100)
train_acc: 0.9555006180469716, val_acc: 0.7044334975369458, train_loss: 0.13066186305545316, val_loss: 1.489564021819918 (85 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6945812807881774, train_loss: 0.07268836491997958, val_loss: 1.6420571627691756 (86 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6354679802955665, train_loss: 0.04496564853318598, val_loss: 2.62084332005731 (87 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6699507389162561, train_loss: 0.08047553738383449, val_loss: 1.5122364659798262 (88 / 100)
train_acc: 0.9789864029666254, val_acc: 0.7192118226600985, train_loss: 0.05063989710486384, val_loss: 2.1263578563488177 (89 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.07183896979070711, val_loss: 1.5805251416314412 (90 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6798029556650246, train_loss: 0.11897929769805983, val_loss: 2.1451396674945435 (91 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6650246305418719, train_loss: 0.08056779087915998, val_loss: 1.8289056082664452 (92 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6995073891625616, train_loss: 0.060128838377020453, val_loss: 2.096624263988927 (93 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6945812807881774, train_loss: 0.05124475045431272, val_loss: 1.9994796549745382 (94 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.08652861432917186, val_loss: 1.7499542418371867 (95 / 100)
train_acc: 0.969097651421508, val_acc: 0.6896551724137931, train_loss: 0.07278111308228284, val_loss: 1.5556093636404704 (96 / 100)
train_acc: 0.9864029666254636, val_acc: 0.7241379310344828, train_loss: 0.04936564219275165, val_loss: 1.7575208784030576 (97 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6945812807881774, train_loss: 0.06535713138848506, val_loss: 1.907188067882519 (98 / 100)
train_acc: 0.957972805933251, val_acc: 0.6995073891625616, train_loss: 0.133341349541913, val_loss: 1.7205418266099075 (99 / 100)
train_acc: 0.9752781211372065, val_acc: 0.7142857142857143, train_loss: 0.07594117820630844, val_loss: 2.105782536450278 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.7241379310344828, val loss 1.7575208784030576
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7880159004951732, val_loss: 1.7824495044247857 (1 / 100)
train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.777164466154148, val_loss: 1.760853433843904 (2 / 100)
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.760569806594047, val_loss: 1.7423614915368593 (3 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7453734610961895, val_loss: 1.7230457913112172 (4 / 100)
train_acc: 0.2200247218788628, val_acc: 0.19704433497536947, train_loss: 1.7309123735934753, val_loss: 1.7263187457775246 (5 / 100)
train_acc: 0.2595797280593325, val_acc: 0.3251231527093596, train_loss: 1.696924720912693, val_loss: 1.6351606534619636 (6 / 100)
train_acc: 0.3189122373300371, val_acc: 0.2561576354679803, train_loss: 1.6321686590263074, val_loss: 1.601752890154646 (7 / 100)
train_acc: 0.3189122373300371, val_acc: 0.31527093596059114, train_loss: 1.6221064743211744, val_loss: 1.563684583884742 (8 / 100)
train_acc: 0.30778739184178, val_acc: 0.28078817733990147, train_loss: 1.6168636512402699, val_loss: 1.5901200266307212 (9 / 100)
train_acc: 0.3411619283065513, val_acc: 0.3448275862068966, train_loss: 1.5453350205061904, val_loss: 1.5572999827380252 (10 / 100)
train_acc: 0.33498145859085293, val_acc: 0.27586206896551724, train_loss: 1.579211882371985, val_loss: 1.6766999965818057 (11 / 100)
train_acc: 0.3374536464771323, val_acc: 0.3793103448275862, train_loss: 1.5981269722668585, val_loss: 1.5254485753956686 (12 / 100)
train_acc: 0.3683559950556242, val_acc: 0.4039408866995074, train_loss: 1.5043812248998578, val_loss: 1.4479555050140531 (13 / 100)
train_acc: 0.40667490729295425, val_acc: 0.24630541871921183, train_loss: 1.4534438435904617, val_loss: 1.9376633672291421 (14 / 100)
train_acc: 0.3374536464771323, val_acc: 0.35960591133004927, train_loss: 1.5534231004078396, val_loss: 1.4381754357239296 (15 / 100)
train_acc: 0.36711990111248455, val_acc: 0.3891625615763547, train_loss: 1.4632875586322271, val_loss: 1.422004643332195 (16 / 100)
train_acc: 0.380716934487021, val_acc: 0.4088669950738916, train_loss: 1.446042804547087, val_loss: 1.367917742635229 (17 / 100)
train_acc: 0.3930778739184178, val_acc: 0.35467980295566504, train_loss: 1.4141105064208193, val_loss: 1.355444668549035 (18 / 100)
train_acc: 0.44746600741656367, val_acc: 0.31527093596059114, train_loss: 1.359354884427027, val_loss: 1.6177617158795812 (19 / 100)
train_acc: 0.3930778739184178, val_acc: 0.3448275862068966, train_loss: 1.406591386229205, val_loss: 1.503072777405161 (20 / 100)
train_acc: 0.41409147095179233, val_acc: 0.41379310344827586, train_loss: 1.3783150444219374, val_loss: 1.3936433175514484 (21 / 100)
train_acc: 0.4400494437577256, val_acc: 0.4729064039408867, train_loss: 1.3171183921498038, val_loss: 1.2951163667176158 (22 / 100)
train_acc: 0.4363411619283066, val_acc: 0.42857142857142855, train_loss: 1.3629175314060396, val_loss: 1.263086999578429 (23 / 100)
train_acc: 0.4338689740420272, val_acc: 0.4236453201970443, train_loss: 1.300406983078484, val_loss: 1.2924605472921737 (24 / 100)
train_acc: 0.4264524103831891, val_acc: 0.4630541871921182, train_loss: 1.304742546694535, val_loss: 1.2821009931305947 (25 / 100)
train_acc: 0.4758961681087763, val_acc: 0.4482758620689655, train_loss: 1.2528026833375099, val_loss: 1.289053966846372 (26 / 100)
train_acc: 0.4796044499381953, val_acc: 0.47783251231527096, train_loss: 1.2606517360885299, val_loss: 1.2450336772820045 (27 / 100)
train_acc: 0.453646477132262, val_acc: 0.5221674876847291, train_loss: 1.2629716932699913, val_loss: 1.2042688589377943 (28 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4433497536945813, train_loss: 1.2215998771016765, val_loss: 1.2727948697329743 (29 / 100)
train_acc: 0.48331273176761436, val_acc: 0.4876847290640394, train_loss: 1.2398294035082842, val_loss: 1.3527624049210196 (30 / 100)
train_acc: 0.5043263288009888, val_acc: 0.4975369458128079, train_loss: 1.1752547612148987, val_loss: 1.2187109918429935 (31 / 100)
train_acc: 0.5241038318912238, val_acc: 0.5221674876847291, train_loss: 1.1448284091407201, val_loss: 1.1006332682858546 (32 / 100)
train_acc: 0.5278121137206427, val_acc: 0.5320197044334976, train_loss: 1.123651562131969, val_loss: 1.1631600689418211 (33 / 100)
train_acc: 0.5377008652657602, val_acc: 0.49261083743842365, train_loss: 1.08502751213069, val_loss: 1.1930428402764457 (34 / 100)
train_acc: 0.5611866501854141, val_acc: 0.541871921182266, train_loss: 1.0689757194448313, val_loss: 1.0616425545932038 (35 / 100)
train_acc: 0.5797280593325093, val_acc: 0.4827586206896552, train_loss: 1.1006652597149165, val_loss: 1.2861492011347428 (36 / 100)
train_acc: 0.5995055624227441, val_acc: 0.4630541871921182, train_loss: 1.020230540091676, val_loss: 1.17698215733608 (37 / 100)
train_acc: 0.6044499381953028, val_acc: 0.5566502463054187, train_loss: 0.991264117957635, val_loss: 1.1500204813304207 (38 / 100)
train_acc: 0.6118665018541409, val_acc: 0.541871921182266, train_loss: 0.960758347225425, val_loss: 1.2148138337534637 (39 / 100)
train_acc: 0.6650185414091471, val_acc: 0.5270935960591133, train_loss: 0.867880396554143, val_loss: 1.4908980859324263 (40 / 100)
train_acc: 0.657601977750309, val_acc: 0.5172413793103449, train_loss: 0.8490737144672974, val_loss: 1.154005219783689 (41 / 100)
train_acc: 0.6773794808405439, val_acc: 0.5763546798029556, train_loss: 0.8417420595773808, val_loss: 1.1419849777456574 (42 / 100)
train_acc: 0.681087762669963, val_acc: 0.5714285714285714, train_loss: 0.806243058556532, val_loss: 1.0009468820294722 (43 / 100)
train_acc: 0.7119901112484549, val_acc: 0.6009852216748769, train_loss: 0.7432624335931465, val_loss: 1.0239429401940312 (44 / 100)
train_acc: 0.7416563658838071, val_acc: 0.5960591133004927, train_loss: 0.6911476085743002, val_loss: 1.1200424397520243 (45 / 100)
train_acc: 0.757725587144623, val_acc: 0.5467980295566502, train_loss: 0.6290116812596362, val_loss: 1.4158794498208709 (46 / 100)
train_acc: 0.761433868974042, val_acc: 0.5320197044334976, train_loss: 0.6376925316375619, val_loss: 1.5564832722612203 (47 / 100)
train_acc: 0.754017305315204, val_acc: 0.6206896551724138, train_loss: 0.6452529097369634, val_loss: 1.042596434431123 (48 / 100)
train_acc: 0.7985166872682324, val_acc: 0.5566502463054187, train_loss: 0.5411739708908704, val_loss: 1.4595898469093398 (49 / 100)
train_acc: 0.8195302843016069, val_acc: 0.541871921182266, train_loss: 0.5004458745713581, val_loss: 1.1885549370291197 (50 / 100)
train_acc: 0.823238566131026, val_acc: 0.6502463054187192, train_loss: 0.4778594032795674, val_loss: 1.1822441528583396 (51 / 100)
train_acc: 0.8059332509270705, val_acc: 0.6354679802955665, train_loss: 0.5277163578641724, val_loss: 1.2358797583086738 (52 / 100)
train_acc: 0.8454882571075402, val_acc: 0.5763546798029556, train_loss: 0.41684386992484, val_loss: 1.7032248210437193 (53 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5763546798029556, train_loss: 0.453185807089281, val_loss: 1.561939698721975 (54 / 100)
train_acc: 0.8331273176761433, val_acc: 0.6206896551724138, train_loss: 0.4310831012772983, val_loss: 1.5984916898417356 (55 / 100)
train_acc: 0.8788627935723115, val_acc: 0.5763546798029556, train_loss: 0.343173704645395, val_loss: 1.6768942630936947 (56 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5517241379310345, train_loss: 0.2878010951360165, val_loss: 1.6648629492726819 (57 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6059113300492611, train_loss: 0.30396599568454236, val_loss: 1.3532858355879196 (58 / 100)
train_acc: 0.9134734239802225, val_acc: 0.5369458128078818, train_loss: 0.2333774674955493, val_loss: 2.374909197755635 (59 / 100)
train_acc: 0.8949320148331273, val_acc: 0.5960591133004927, train_loss: 0.3004138899785184, val_loss: 1.6978836869958587 (60 / 100)
train_acc: 0.9419035846724351, val_acc: 0.6502463054187192, train_loss: 0.18903484373216428, val_loss: 1.4482524330392847 (61 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6403940886699507, train_loss: 0.10709737759309144, val_loss: 1.57003462784396 (62 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6502463054187192, train_loss: 0.08473042046883787, val_loss: 1.6181754120464982 (63 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6600985221674877, train_loss: 0.09731966958868195, val_loss: 1.6007599431305684 (64 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6551724137931034, train_loss: 0.07410880262020639, val_loss: 1.663751667943494 (65 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.0665579540712577, val_loss: 1.7140177118367161 (66 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6600985221674877, train_loss: 0.0604385137373791, val_loss: 1.7743736053335255 (67 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6798029556650246, train_loss: 0.05748146529365861, val_loss: 1.7410855586892866 (68 / 100)
train_acc: 0.965389369592089, val_acc: 0.6551724137931034, train_loss: 0.08453019639322873, val_loss: 1.8450547262952832 (69 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6748768472906403, train_loss: 0.04941787870257761, val_loss: 1.8662306722161806 (70 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6551724137931034, train_loss: 0.06250280454957441, val_loss: 1.92489042305594 (71 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.04648745133586421, val_loss: 2.0080663018625944 (72 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.05852396909535456, val_loss: 1.9738277731270626 (73 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6650246305418719, train_loss: 0.053384608608683194, val_loss: 2.0546152239362594 (74 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.06383722247175955, val_loss: 1.9030120337537944 (75 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6650246305418719, train_loss: 0.04446263955065656, val_loss: 2.009999297522559 (76 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6650246305418719, train_loss: 0.04688426178096643, val_loss: 2.0157195723115517 (77 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.06015424244336056, val_loss: 2.102050872859109 (78 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6600985221674877, train_loss: 0.03742035387120726, val_loss: 2.1462622452252016 (79 / 100)
train_acc: 0.9901112484548825, val_acc: 0.645320197044335, train_loss: 0.03895533158603885, val_loss: 2.2243018021137257 (80 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6502463054187192, train_loss: 0.033596480134022694, val_loss: 2.3180999603177526 (81 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6699507389162561, train_loss: 0.04911132576807468, val_loss: 2.1354922766755955 (82 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.040074133762009946, val_loss: 2.2635301192993014 (83 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6600985221674877, train_loss: 0.03878850592086964, val_loss: 2.1794336135751506 (84 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6600985221674877, train_loss: 0.03874888850378312, val_loss: 2.215066750061336 (85 / 100)
train_acc: 0.992583436341162, val_acc: 0.6551724137931034, train_loss: 0.0282938766249482, val_loss: 2.283387669201555 (86 / 100)
train_acc: 0.9888751545117429, val_acc: 0.645320197044335, train_loss: 0.03259150722502686, val_loss: 2.342612507308058 (87 / 100)
train_acc: 0.9950556242274413, val_acc: 0.645320197044335, train_loss: 0.025937813026724068, val_loss: 2.3954469464682595 (88 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.04246537764979773, val_loss: 2.349965410279523 (89 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.055259476485964354, val_loss: 2.327997138347532 (90 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.04824292074027845, val_loss: 2.2634986069402085 (91 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6650246305418719, train_loss: 0.019910331708419382, val_loss: 2.2926446264013283 (92 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6699507389162561, train_loss: 0.04943698666827484, val_loss: 2.2937865832756303 (93 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.046379790315577214, val_loss: 2.208962540321162 (94 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6600985221674877, train_loss: 0.029107393077557404, val_loss: 2.29310107818378 (95 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6650246305418719, train_loss: 0.02724700598869293, val_loss: 2.2725593327301477 (96 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6600985221674877, train_loss: 0.04495807469227295, val_loss: 2.222693655878452 (97 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6600985221674877, train_loss: 0.04306600149833329, val_loss: 2.2834054519390237 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.6600985221674877, train_loss: 0.029158752982600216, val_loss: 2.328433359785033 (99 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.04833201336484732, val_loss: 2.3257952464625165 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.05}), val accuracy 0.6798029556650246, val loss 1.7410855586892866
train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7878302253220963, val_loss: 1.7761001052527592 (1 / 100)
train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7699840295742115, val_loss: 1.7493972561042297 (2 / 100)
train_acc: 0.18788627935723115, val_acc: 0.2512315270935961, train_loss: 1.75424521770996, val_loss: 1.729469665752843 (3 / 100)
train_acc: 0.2360939431396786, val_acc: 0.35467980295566504, train_loss: 1.7332063829353626, val_loss: 1.6714895493878519 (4 / 100)
train_acc: 0.2892459826946848, val_acc: 0.27586206896551724, train_loss: 1.6810060496383308, val_loss: 1.6590223723444446 (5 / 100)
train_acc: 0.29666254635352285, val_acc: 0.3103448275862069, train_loss: 1.6520614624023438, val_loss: 1.6156904679801076 (6 / 100)
train_acc: 0.32756489493201485, val_acc: 0.35467980295566504, train_loss: 1.5848332375324847, val_loss: 1.5560161268769814 (7 / 100)
train_acc: 0.3238566131025958, val_acc: 0.3645320197044335, train_loss: 1.5720448885918843, val_loss: 1.4991765022277832 (8 / 100)
train_acc: 0.3288009888751545, val_acc: 0.4236453201970443, train_loss: 1.5363411415640003, val_loss: 1.4167013309272052 (9 / 100)
train_acc: 0.377008652657602, val_acc: 0.4433497536945813, train_loss: 1.5077083138806564, val_loss: 1.4374697572492026 (10 / 100)
train_acc: 0.3856613102595797, val_acc: 0.3645320197044335, train_loss: 1.4671339730839206, val_loss: 1.4314956588698138 (11 / 100)
train_acc: 0.40296662546353523, val_acc: 0.30049261083743845, train_loss: 1.4183432548980335, val_loss: 1.538724885491902 (12 / 100)
train_acc: 0.3720642768850433, val_acc: 0.41379310344827586, train_loss: 1.4551369771085063, val_loss: 1.408976708139692 (13 / 100)
train_acc: 0.40296662546353523, val_acc: 0.4039408866995074, train_loss: 1.3976222593498466, val_loss: 1.3559067677981749 (14 / 100)
train_acc: 0.3992583436341162, val_acc: 0.4088669950738916, train_loss: 1.4020347568691145, val_loss: 1.422868857242791 (15 / 100)
train_acc: 0.39555006180469715, val_acc: 0.4433497536945813, train_loss: 1.3889500526032135, val_loss: 1.3056400849901397 (16 / 100)
train_acc: 0.39555006180469715, val_acc: 0.35960591133004927, train_loss: 1.4128445694856206, val_loss: 1.4706629400182827 (17 / 100)
train_acc: 0.39555006180469715, val_acc: 0.4482758620689655, train_loss: 1.3712013656335649, val_loss: 1.293911259162602 (18 / 100)
train_acc: 0.4647713226205192, val_acc: 0.4433497536945813, train_loss: 1.321658414138115, val_loss: 1.2881853536432013 (19 / 100)
train_acc: 0.43139678615574784, val_acc: 0.458128078817734, train_loss: 1.3216993139759718, val_loss: 1.2808965482735282 (20 / 100)
train_acc: 0.41903584672435107, val_acc: 0.4187192118226601, train_loss: 1.3327404766059188, val_loss: 1.3388549547477309 (21 / 100)
train_acc: 0.45488257107540175, val_acc: 0.42857142857142855, train_loss: 1.2783838006563033, val_loss: 1.3114813366547007 (22 / 100)
train_acc: 0.4400494437577256, val_acc: 0.43842364532019706, train_loss: 1.3213929198728356, val_loss: 1.2987754550473443 (23 / 100)
train_acc: 0.4511742892459827, val_acc: 0.5123152709359606, train_loss: 1.263007661762874, val_loss: 1.164142648281135 (24 / 100)
train_acc: 0.46600741656365885, val_acc: 0.5123152709359606, train_loss: 1.2677014629979364, val_loss: 1.1423773668669714 (25 / 100)
train_acc: 0.4857849196538937, val_acc: 0.49261083743842365, train_loss: 1.220136555369911, val_loss: 1.1592199514652122 (26 / 100)
train_acc: 0.4969097651421508, val_acc: 0.5024630541871922, train_loss: 1.2250750548170581, val_loss: 1.1853734795095885 (27 / 100)
train_acc: 0.511742892459827, val_acc: 0.5073891625615764, train_loss: 1.182335178990594, val_loss: 1.1191146156470764 (28 / 100)
train_acc: 0.546353522867738, val_acc: 0.5270935960591133, train_loss: 1.1166635084947933, val_loss: 1.1451743697297985 (29 / 100)
train_acc: 0.5364647713226205, val_acc: 0.5024630541871922, train_loss: 1.1494913649352725, val_loss: 1.0936740287419022 (30 / 100)
train_acc: 0.5500618046971569, val_acc: 0.5517241379310345, train_loss: 1.1045837480441307, val_loss: 1.1905180979244814 (31 / 100)
train_acc: 0.5562422744128553, val_acc: 0.5467980295566502, train_loss: 1.0685315317807003, val_loss: 1.18424448517743 (32 / 100)
train_acc: 0.5562422744128553, val_acc: 0.5960591133004927, train_loss: 1.0987179668341638, val_loss: 1.0632883313254182 (33 / 100)
train_acc: 0.5982694684796045, val_acc: 0.5467980295566502, train_loss: 1.0004665829489936, val_loss: 1.2062546569725563 (34 / 100)
train_acc: 0.5723114956736712, val_acc: 0.5221674876847291, train_loss: 1.0186921253487264, val_loss: 1.1765870049669238 (35 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5172413793103449, train_loss: 0.9958530430151299, val_loss: 1.1842164282728298 (36 / 100)
train_acc: 0.630407911001236, val_acc: 0.5665024630541872, train_loss: 0.9285033748235337, val_loss: 1.1009514748756521 (37 / 100)
train_acc: 0.6674907292954264, val_acc: 0.5369458128078818, train_loss: 0.8688952164685328, val_loss: 1.2111664975217997 (38 / 100)
train_acc: 0.6118665018541409, val_acc: 0.5172413793103449, train_loss: 0.9428467837488106, val_loss: 1.218490709812183 (39 / 100)
train_acc: 0.7082818294190358, val_acc: 0.5566502463054187, train_loss: 0.7865834437283067, val_loss: 1.058438958205613 (40 / 100)
train_acc: 0.6823238566131026, val_acc: 0.5763546798029556, train_loss: 0.7954045052286721, val_loss: 1.0973447067984219 (41 / 100)

