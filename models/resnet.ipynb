{"cells":[{"metadata":{"colab_type":"text","id":"MbtUcKfE_I4g"},"cell_type":"markdown","source":"**Installs**"},{"metadata":{"colab_type":"code","id":"tzg4cO9xLvUG","trusted":false,"colab":{}},"cell_type":"code","source":"!pip3 install 'torch==1.3.1'\n!pip3 install 'torchvision==0.5.0'\n!pip3 install 'Pillow-SIMD'\n!pip3 install 'tqdm'","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"fxs_3zcG_NZd"},"cell_type":"markdown","source":"**Imports**"},{"metadata":{"colab_type":"code","id":"C7N0hU-VLx8W","trusted":true,"colab":{}},"cell_type":"code","source":"import os\nimport logging\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Subset, DataLoader\nfrom torch.backends import cudnn\n\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.models import resnet152\n\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\n\n#NUM_CLASSES = 102\nNUM_CLASSES = 6\nDEVICE = 'cuda'\nMOMENTUM = 0.9","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"uvABcepY_Vfe"},"cell_type":"markdown","source":"**Model definition**"},{"metadata":{"colab_type":"code","id":"vztVCv3fQXjR","trusted":true,"colab":{}},"cell_type":"code","source":"def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n                                                         transforms.CenterCrop(224),\n                                                         transforms.ToTensor()\n                                                         ]):\n    train_transform = transforms.Compose(compose)\n    eval_transform = transforms.Compose([\n          transforms.Resize(224),\n          transforms.CenterCrop(224),\n          transforms.ToTensor()\n          ])\n\n    '''\n    if not os.path.isdir('./Homework2-Caltech101'):\n        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n\n    '''\n    if not os.path.isdir('./AIML_project'):\n        !git clone https://github.com/anphetamina/AIML_project.git\n    \n    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n\n    return train_dataset, test_dataset\n\ndef test_network(net, test_dataset, batch_size):\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    net.train(False)\n\n    criterion = nn.CrossEntropyLoss()\n\n    sum_test_losses = 0.0\n    running_corrects = 0\n    for images, labels in test_dataloader:\n      images = images.to(DEVICE)\n      labels = labels.to(DEVICE)\n\n      # Forward Pass\n      outputs = net(images)\n\n      # Get predictions\n      _, preds = torch.max(outputs.data, 1)\n      test_loss = criterion(outputs, labels)\n      sum_test_losses += test_loss.item()*images.size(0)\n\n      # Update Corrects\n      running_corrects += torch.sum(preds == labels.data).data.item()\n\n    # Calculate Accuracy\n    accuracy = running_corrects / float(len(test_dataset))\n\n    # Calculate loss\n    test_loss = sum_test_losses / float(len(test_dataset))\n\n    return accuracy, test_loss\n\ndef train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n  \n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n    net = net.to(DEVICE)\n    best_net = resnet152(num_classes=NUM_CLASSES)\n    best_net = best_net.to(DEVICE)\n\n    cudnn.benchmark\n\n    train_accuracies = []\n    train_losses = []\n    val_accuracies = []\n    val_losses = []\n\n    current_step = 0\n    best_val_accuracy = 0.0\n    best_val_loss = 0.0\n    for epoch in range(num_epochs):\n\n        train_running_corrects = 0\n        sum_train_losses = 0.0\n\n        for images, labels in train_dataloader:\n            images = images.to(DEVICE)\n            labels = labels.to(DEVICE)\n            net.train()\n            optimizer.zero_grad()\n\n            outputs = net(images)\n            _, preds = torch.max(outputs.data, 1)\n            train_running_corrects += torch.sum(preds == labels.data).data.item()\n            loss = criterion(outputs, labels)\n            sum_train_losses += loss.item()*images.size(0)\n            loss.backward()\n\n            optimizer.step()\n            current_step += 1\n        \n        if val_dataset is not None:\n            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n            if val_accuracy > best_val_accuracy:\n                best_val_accuracy = val_accuracy\n                best_val_loss = val_loss\n                best_net.load_state_dict(net.state_dict())\n            val_accuracies.append(val_accuracy)\n            val_losses.append(val_loss)\n\n        # Calculate accuracy on train set\n        train_accuracy = train_running_corrects / float(len(train_dataset))\n        train_accuracies.append(train_accuracy)\n\n        # Calculate loss on training set\n        train_loss = sum_train_losses/float(len(train_dataset))\n        train_losses.append(loss)\n\n        if verbosity:\n            if val_dataset is not None:\n                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n            else:\n                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n\n        scheduler.step()\n\n    if plot:\n\n        fig, ax = plt.subplots()\n        line1, = ax.plot(train_losses, label='Loss on training set')\n        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n        ax.legend()\n        plt.xlabel(\"Epochs\")\n        plt.show()\n\n        if val_dataset is not None:\n            fig, ax = plt.subplots()\n            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n            ax.legend()\n            plt.xlabel(\"Epochs\")\n            plt.show()\n        \n            fig, ax = plt.subplots()\n            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n            ax.legend()\n            plt.xlabel(\"Epochs\")\n            plt.show()\n\n    \n    return best_net, best_val_accuracy, best_val_loss\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"I6fTm2sD_BOt"},"cell_type":"markdown","source":"**Train + validation**"},{"metadata":{"colab_type":"code","id":"XtBXC1cO_A6A","outputId":"3573a9e9-315f-4c41-a306-04318bc56fd7","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"cell_type":"code","source":"BATCH_SIZE = 32\nLR = 0.001\nMOMENTUM = 0.9\nWEIGHT_DECAY = 5e-05\nNUM_EPOCHS = 100\nSTEP_SIZE = 60\nGAMMA = 0.1\n\nTRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\ncompose=[transforms.Resize(224),\n         transforms.CenterCrop(224),\n         transforms.RandomGrayscale(),\n         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n         transforms.ToTensor()\n         ]\ntrain_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\ntrain_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\nval_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\nval_dataset = Subset(val_dataset, val_indexes)\ntrain_dataset = Subset(train_dataset, train_indexes)\nprint('training set {}'.format(len(train_dataset)))\nprint('validation set {}'.format(len(val_dataset)))\n\nnet = resnet152(num_classes=NUM_CLASSES)\nbest_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n\nprint('val accuracy {}'.format(val_accuracy))\nprint('val loss {}'.format(val_loss))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"1kgj76dvQxIJ"},"cell_type":"markdown","source":"**Testing**"},{"metadata":{"colab_type":"code","id":"_dKdDvgnQw7d","trusted":false,"colab":{}},"cell_type":"code","source":"# todo","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"qxj7-SlSKb_3"},"cell_type":"markdown","source":"**Grid search**"},{"metadata":{"colab_type":"code","id":"aPmSObkPKbu3","outputId":"6d85d512-36ce-41fc-efb2-26ed50ef97db","trusted":false,"colab":{"base_uri":"https://localhost:8080/","height":978}},"cell_type":"code","source":"NUM_CLASSES = 6\nDEVICE = 'cuda'\n#BATCH_SIZE = 16\n#LR = 0.001\nMOMENTUM = 0.9\n#WEIGHT_DECAY = 5e-5\nNUM_EPOCHS = 100\nSTEP_SIZE = 60\n#GAMMA = 0.1\n\nlr_range = [0.0005, 0.001, 0.005]\nbatch_size_range = [8, 16]\nweight_decay_range = [5e-5, 5e-3]\ngamma_range = [0.05, 0.1, 1]\nhyperparameters_sets = []\n\nfor lr in lr_range:\n  for batch_size in batch_size_range:\n    for weight_decay in weight_decay_range:\n      for gamma in gamma_range:\n        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n\nfor set in hyperparameters_sets:\n  print(set)\n\n\nTRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\ncompose=[transforms.Resize(224),\n         transforms.CenterCrop(224),\n         transforms.RandomGrayscale(),\n         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n         transforms.ToTensor()\n         ]\ntrain_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n\ntrain_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\nval_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\nval_dataset = Subset(val_dataset, val_indexes)\ntrain_dataset = Subset(train_dataset, train_indexes)\nprint('training set {}'.format(len(train_dataset)))\nprint('validation set {}'.format(len(val_dataset)))\n\nbest_net = resnet152(num_classes=NUM_CLASSES)\nbest_net = best_net.to(DEVICE)\nbest_set = {}\nbest_accuracy = 0.0\nbest_loss = 0.0\nval_accuracies = []\nval_losses = []\n\nfor set in hyperparameters_sets:\n\n  net = resnet152(num_classes=NUM_CLASSES)\n  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset, verbosity=True)\n  val_accuracies.append(val_accuracy)\n  val_losses.append(val_loss)\n\n  if val_accuracy > best_accuracy:\n    best_accuracy = val_accuracy\n    best_loss = val_loss\n    best_net = copy.deepcopy(current_net)\n    best_set = copy.deepcopy(set)\n  \n  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n\nprint(\"\\n({}), best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\nprint(\"\\nval_accuracies\")\nprint(val_accuracies)","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"S1laZWm8Q0tm"},"cell_type":"markdown","source":"**Testing**"},{"metadata":{"colab_type":"code","id":"TKl555WRQ1AF","trusted":false,"colab":{}},"cell_type":"code","source":"# todo","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"jJGI06ylKePa"},"cell_type":"markdown","source":"**Mean / std computation**"},{"metadata":{"colab_type":"code","id":"YDJptx12L1OL","trusted":false,"colab":{}},"cell_type":"code","source":"TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\npixel_mean = np.zeros(3)\npixel_std = np.zeros(3)\nk = 1\ndataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\nfor image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n    image = np.array(image)\n    pixels = image.reshape((-1, image.shape[2]))\n\n    for pixel in pixels:\n        diff = pixel - pixel_mean\n        pixel_mean += diff / k\n        pixel_std += diff * (pixel - pixel_mean)\n        k += 1\n\npixel_std = np.sqrt(pixel_std / (k - 2))\nprint(pixel_mean)\nprint(pixel_std)","execution_count":0,"outputs":[]}],"metadata":{"colab":{"name":"vgg.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}