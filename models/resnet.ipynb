{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet152\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "    best_net = best_net.to(DEVICE)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "ce579cb5-c66f-4e68-e61d-d5381eb0d2e3",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.2976923220850565\n",
        "BATCH_SIZE = 16\n",
        "LR = 0.009\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 1\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         #transforms.RandomGrayscale(),\n",
        "         #transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.21755253399258342, val_acc: 0.32019704433497537, train_loss: 3.4461549595643035, val_loss: 16.028000899723597 (1 / 100)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.31527093596059114, train_loss: 2.153428207369169, val_loss: 2.162119218281337 (2 / 100)\n",
            "train_acc: 0.30902348578491967, val_acc: 0.32019704433497537, train_loss: 1.831501019457804, val_loss: 1.5306335059292797 (3 / 100)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.2857142857142857, train_loss: 1.4970990782615134, val_loss: 1.7468935151405522 (4 / 100)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.37438423645320196, train_loss: 1.4749756053882122, val_loss: 1.553557989045317 (5 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3842364532019704, train_loss: 1.4699755439946913, val_loss: 1.4540853374110068 (6 / 100)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3251231527093596, train_loss: 1.4141852443091507, val_loss: 1.64676449862607 (7 / 100)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.4236453201970443, train_loss: 1.3676184028276555, val_loss: 1.3328783758755387 (8 / 100)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.3842364532019704, train_loss: 1.375013154722999, val_loss: 1.3649442824236866 (9 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.3793103448275862, train_loss: 1.3383940558498368, val_loss: 1.4383331319968689 (10 / 100)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.3793103448275862, train_loss: 1.3007881980301865, val_loss: 1.3914292739529914 (11 / 100)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.3842364532019704, train_loss: 1.2706943059291769, val_loss: 1.32158593003973 (12 / 100)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.43842364532019706, train_loss: 1.1483149529976957, val_loss: 1.412172925883326 (13 / 100)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4729064039408867, train_loss: 1.1779250364810485, val_loss: 1.3804388610013012 (14 / 100)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.4088669950738916, train_loss: 1.1300873259826114, val_loss: 1.4108923312478465 (15 / 100)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.4482758620689655, train_loss: 1.1227158982909948, val_loss: 1.4062661801652956 (16 / 100)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.458128078817734, train_loss: 1.07628416116217, val_loss: 1.5444370772451015 (17 / 100)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.47783251231527096, train_loss: 1.0090956519943821, val_loss: 1.4017469612835662 (18 / 100)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.4729064039408867, train_loss: 1.0085052070570522, val_loss: 1.332839144274519 (19 / 100)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.37438423645320196, train_loss: 0.9639489115831731, val_loss: 2.2662294157620133 (20 / 100)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.43349753694581283, train_loss: 0.8414749173799757, val_loss: 1.6456612172385154 (21 / 100)\n",
            "train_acc: 0.688504326328801, val_acc: 0.4729064039408867, train_loss: 0.8022200018720073, val_loss: 1.5537568307275256 (22 / 100)\n",
            "train_acc: 0.6637824474660075, val_acc: 0.4630541871921182, train_loss: 0.8589219123088238, val_loss: 1.5553613948117335 (23 / 100)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.43349753694581283, train_loss: 0.7005498894065508, val_loss: 1.8421841178621565 (24 / 100)\n",
            "train_acc: 0.715698393077874, val_acc: 0.4729064039408867, train_loss: 0.7235850067751664, val_loss: 1.7849708683972287 (25 / 100)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.4729064039408867, train_loss: 0.7397889957218736, val_loss: 1.7146972723195117 (26 / 100)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.5763546798029556, train_loss: 0.5687772648222514, val_loss: 1.4494723745167548 (27 / 100)\n",
            "train_acc: 0.7552533992583437, val_acc: 0.46798029556650245, train_loss: 0.6773883312093313, val_loss: 1.6853315877209742 (28 / 100)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.4630541871921182, train_loss: 0.4916573509445002, val_loss: 1.7657738521768542 (29 / 100)\n",
            "train_acc: 0.8504326328800988, val_acc: 0.46798029556650245, train_loss: 0.408376672580304, val_loss: 2.1644472412287894 (30 / 100)\n",
            "train_acc: 0.8182941903584673, val_acc: 0.5123152709359606, train_loss: 0.516708534049752, val_loss: 2.08975839379973 (31 / 100)\n",
            "train_acc: 0.826946847960445, val_acc: 0.46798029556650245, train_loss: 0.4752144498200293, val_loss: 2.7703123585931184 (32 / 100)\n",
            "train_acc: 0.830655129789864, val_acc: 0.43349753694581283, train_loss: 0.4816036911034319, val_loss: 2.6326649177250605 (33 / 100)\n",
            "train_acc: 0.8541409147095179, val_acc: 0.46798029556650245, train_loss: 0.40847171994089637, val_loss: 1.9727525945954723 (34 / 100)\n",
            "train_acc: 0.9048207663782447, val_acc: 0.5763546798029556, train_loss: 0.29986732807678107, val_loss: 1.8474140672260904 (35 / 100)\n",
            "train_acc: 0.8788627935723115, val_acc: 0.4876847290640394, train_loss: 0.35949949465222353, val_loss: 2.412581684260533 (36 / 100)\n",
            "train_acc: 0.8813349814585909, val_acc: 0.4876847290640394, train_loss: 0.34645273953639383, val_loss: 2.034184707796632 (37 / 100)\n",
            "train_acc: 0.9023485784919654, val_acc: 0.4876847290640394, train_loss: 0.2740954904090636, val_loss: 2.7222487139584395 (38 / 100)\n",
            "train_acc: 0.8887515451174289, val_acc: 0.47783251231527096, train_loss: 0.31195917508216076, val_loss: 2.2337310537328863 (39 / 100)\n",
            "train_acc: 0.9258343634116193, val_acc: 0.5073891625615764, train_loss: 0.21204630817817374, val_loss: 2.5548188745094635 (40 / 100)\n",
            "train_acc: 0.8862793572311496, val_acc: 0.49261083743842365, train_loss: 0.3049886191657506, val_loss: 2.435584696642871 (41 / 100)\n",
            "train_acc: 0.8430160692212608, val_acc: 0.5221674876847291, train_loss: 0.4295777125267959, val_loss: 1.9756633372142398 (42 / 100)\n",
            "train_acc: 0.9221260815822002, val_acc: 0.5467980295566502, train_loss: 0.20311584430706442, val_loss: 2.196838579741605 (43 / 100)\n",
            "train_acc: 0.9419035846724351, val_acc: 0.5123152709359606, train_loss: 0.18875324274833477, val_loss: 2.1692107722089795 (44 / 100)\n",
            "train_acc: 0.9394313967861557, val_acc: 0.5172413793103449, train_loss: 0.17574512825908117, val_loss: 2.212035358245737 (45 / 100)\n",
            "train_acc: 0.9629171817058096, val_acc: 0.46798029556650245, train_loss: 0.13085394841705175, val_loss: 3.015515866537987 (46 / 100)\n",
            "train_acc: 0.9221260815822002, val_acc: 0.4876847290640394, train_loss: 0.24903535695081147, val_loss: 2.889114556054176 (47 / 100)\n",
            "train_acc: 0.9493201483312732, val_acc: 0.5566502463054187, train_loss: 0.12524041048123308, val_loss: 2.1316414055565893 (48 / 100)\n",
            "train_acc: 0.9555006180469716, val_acc: 0.5123152709359606, train_loss: 0.12564421409213794, val_loss: 2.7402564011183865 (49 / 100)\n",
            "train_acc: 0.9369592088998764, val_acc: 0.5467980295566502, train_loss: 0.1543794341928732, val_loss: 2.0971804099717164 (50 / 100)\n",
            "train_acc: 0.9629171817058096, val_acc: 0.5763546798029556, train_loss: 0.13096117162881293, val_loss: 2.275235206035558 (51 / 100)\n",
            "train_acc: 0.9431396786155748, val_acc: 0.5369458128078818, train_loss: 0.19519649242247802, val_loss: 2.652729063785722 (52 / 100)\n",
            "train_acc: 0.9567367119901112, val_acc: 0.5369458128078818, train_loss: 0.1334320419135288, val_loss: 2.5543075852793424 (53 / 100)\n",
            "train_acc: 0.9666254635352287, val_acc: 0.5812807881773399, train_loss: 0.11313973988402906, val_loss: 2.1651505355177254 (54 / 100)\n",
            "train_acc: 0.9962917181705809, val_acc: 0.5911330049261084, train_loss: 0.017712795539391864, val_loss: 2.108232236260851 (55 / 100)\n",
            "train_acc: 0.9950556242274413, val_acc: 0.5665024630541872, train_loss: 0.02024858576626654, val_loss: 2.3460074175754793 (56 / 100)\n",
            "train_acc: 0.9962917181705809, val_acc: 0.5665024630541872, train_loss: 0.012445145985111594, val_loss: 2.3981752195969004 (57 / 100)\n",
            "train_acc: 0.9975278121137207, val_acc: 0.5960591133004927, train_loss: 0.015364576172548702, val_loss: 2.506966360684099 (58 / 100)\n",
            "train_acc: 0.9913473423980222, val_acc: 0.5369458128078818, train_loss: 0.03818281561053359, val_loss: 2.759026527404785 (59 / 100)\n",
            "train_acc: 0.9752781211372065, val_acc: 0.5665024630541872, train_loss: 0.06963059840295337, val_loss: 2.487949260937169 (60 / 100)\n",
            "train_acc: 0.9901112484548825, val_acc: 0.6059113300492611, train_loss: 0.0350996866840662, val_loss: 2.2666016088917926 (61 / 100)\n",
            "train_acc: 0.9765142150803461, val_acc: 0.4827586206896552, train_loss: 0.06231986991922994, val_loss: 3.128554232602049 (62 / 100)\n",
            "train_acc: 0.9666254635352287, val_acc: 0.5123152709359606, train_loss: 0.08487633897776731, val_loss: 2.5524781901260902 (63 / 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9698867433a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mbest_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val accuracy {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b20803267196>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset, verbosity, plot)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N9hKn1aB5Ow",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSE19H6PB5h3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "692b1ddc-73e2-4271-bd12-b11706f66124"
      },
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        #transforms.RandomGrayscale(),\n",
        "        #transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 20\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = random.uniform(0.001, 0.006)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-5, -4)\n",
        "  NUM_EPOCHS = 30\n",
        "  STEP_SIZE = 18\n",
        "  GAMMA = 10**random.uniform(-1, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"---------------------------------------------\")\n",
        "  \n",
        "  net = resnet152(num_classes=NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "---------------------------------------------\n",
            "train_acc: 0.25092707045735474, val_acc: 0.21182266009852216, train_loss: 2.8360635070187787, val_loss: 1.754578704023596 (1 / 30)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.2413793103448276, train_loss: 2.033004798759489, val_loss: 2.1232859439450533 (2 / 30)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3251231527093596, train_loss: 1.7142444093088873, val_loss: 1.8651411962039366 (3 / 30)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3694581280788177, train_loss: 1.6663536601072484, val_loss: 1.597207959649598 (4 / 30)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.35960591133004927, train_loss: 1.5455494893643411, val_loss: 1.7473113372408111 (5 / 30)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3645320197044335, train_loss: 1.6272054904765634, val_loss: 2.1481774284921844 (6 / 30)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.41379310344827586, train_loss: 1.4329661263523643, val_loss: 1.3475333234946716 (7 / 30)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.4088669950738916, train_loss: 1.4656733685577166, val_loss: 3.8709751291228045 (8 / 30)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.37438423645320196, train_loss: 1.4163368841626294, val_loss: 1.3421443806493223 (9 / 30)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.4088669950738916, train_loss: 1.4631188496376293, val_loss: 1.6240168833380262 (10 / 30)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.3645320197044335, train_loss: 1.4020321887856804, val_loss: 1.7378997042261322 (11 / 30)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4039408866995074, train_loss: 1.3766784190542176, val_loss: 1.3718663225033012 (12 / 30)\n",
            "train_acc: 0.411619283065513, val_acc: 0.47783251231527096, train_loss: 1.3256885967089602, val_loss: 1.238147769949119 (13 / 30)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.30049261083743845, train_loss: 1.3034514582201342, val_loss: 2.0590338178456125 (14 / 30)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.39408866995073893, train_loss: 1.338950586407382, val_loss: 1.4595678941956882 (15 / 30)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.41379310344827586, train_loss: 1.2450997608406436, val_loss: 1.5035659532828871 (16 / 30)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.3842364532019704, train_loss: 1.1085148591488343, val_loss: 1.9614692803086906 (17 / 30)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.4630541871921182, train_loss: 1.118932532733686, val_loss: 1.2938097562695958 (18 / 30)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.4482758620689655, train_loss: 1.0567019980386987, val_loss: 1.3825959325423969 (19 / 30)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.4236453201970443, train_loss: 1.1227751444237783, val_loss: 1.6115801029017407 (20 / 30)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.43349753694581283, train_loss: 1.0848221660986523, val_loss: 1.4823967124440987 (21 / 30)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.4187192118226601, train_loss: 1.0254931535355387, val_loss: 2.0521925317830054 (22 / 30)\n",
            "train_acc: 0.61557478368356, val_acc: 0.4876847290640394, train_loss: 0.996654800785192, val_loss: 1.3172906378807105 (23 / 30)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.3694581280788177, train_loss: 0.9993457652729728, val_loss: 2.0388935023340684 (24 / 30)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.4975369458128079, train_loss: 0.9231668897848047, val_loss: 1.467078797922933 (25 / 30)\n",
            "train_acc: 0.6687268232385661, val_acc: 0.4975369458128079, train_loss: 0.8510560579736094, val_loss: 1.5601803722052738 (26 / 30)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.4827586206896552, train_loss: 0.8920477108548687, val_loss: 1.4787192456240725 (27 / 30)\n",
            "train_acc: 0.7132262051915945, val_acc: 0.4827586206896552, train_loss: 0.7386050115262327, val_loss: 1.807316624472294 (28 / 30)\n",
            "train_acc: 0.7194066749072929, val_acc: 0.5073891625615764, train_loss: 0.7506845701757556, val_loss: 1.6825030854182879 (29 / 30)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.42857142857142855, train_loss: 0.7037792488729998, val_loss: 1.9807272321484946 (30 / 30)\n",
            "lr 0.003149050913917944, batch 8, decay 6.256843284483036e-05, gamma 0.8254205519719666, val accuracy 0.5073891625615764, val loss 1.6825030854182879 [1 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.24474660074165636, val_acc: 0.2561576354679803, train_loss: 2.8685443716673973, val_loss: 1.9297507408217256 (1 / 30)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.3694581280788177, train_loss: 2.013303842179118, val_loss: 1.495247532581461 (2 / 30)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.35467980295566504, train_loss: 1.7221828111169954, val_loss: 1.8678043117664132 (3 / 30)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3842364532019704, train_loss: 1.5758639659516154, val_loss: 1.6371720395064706 (4 / 30)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3497536945812808, train_loss: 1.5381405297551667, val_loss: 1.8802092104709793 (5 / 30)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.3842364532019704, train_loss: 1.698171909718932, val_loss: 2.572512246705041 (6 / 30)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3694581280788177, train_loss: 1.5067775258322433, val_loss: 2.0522822347180596 (7 / 30)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3793103448275862, train_loss: 1.4523010648814652, val_loss: 1.6066090191526365 (8 / 30)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.4187192118226601, train_loss: 1.5193330444423172, val_loss: 1.8264997028952161 (9 / 30)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.3842364532019704, train_loss: 1.4015581522353353, val_loss: 1.4126031351794164 (10 / 30)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.3694581280788177, train_loss: 1.325780755362493, val_loss: 1.6211837923585488 (11 / 30)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.33497536945812806, train_loss: 1.3760827952173937, val_loss: 2.0302872246709365 (12 / 30)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.3399014778325123, train_loss: 1.3165253287340124, val_loss: 2.0071932235962064 (13 / 30)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.39408866995073893, train_loss: 1.3543832010332821, val_loss: 2.335305664926914 (14 / 30)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.39408866995073893, train_loss: 1.3316046605151428, val_loss: 1.6745726436817001 (15 / 30)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.39408866995073893, train_loss: 1.285591822766845, val_loss: 1.731057950428554 (16 / 30)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.3842364532019704, train_loss: 1.3110818076045316, val_loss: 13.669993465757136 (17 / 30)\n",
            "train_acc: 0.446229913473424, val_acc: 0.5024630541871922, train_loss: 1.2986018038798026, val_loss: 1.3981136606244617 (18 / 30)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.458128078817734, train_loss: 1.0439601843377715, val_loss: 1.61112817872334 (19 / 30)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.39901477832512317, train_loss: 0.9112972809446167, val_loss: 2.109013621443011 (20 / 30)\n",
            "train_acc: 0.595797280593325, val_acc: 0.49261083743842365, train_loss: 0.9217348738270725, val_loss: 3.8246926403985233 (21 / 30)\n",
            "train_acc: 0.6440049443757726, val_acc: 0.43349753694581283, train_loss: 0.8669087176564597, val_loss: 2.4061799031760307 (22 / 30)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.5024630541871922, train_loss: 0.8802706165278356, val_loss: 1.686250461439781 (23 / 30)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.47783251231527096, train_loss: 0.7937303203882187, val_loss: 2.117304970478189 (24 / 30)\n",
            "train_acc: 0.695920889987639, val_acc: 0.5221674876847291, train_loss: 0.7690501599140898, val_loss: 1.7654033238664637 (25 / 30)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.43349753694581283, train_loss: 0.786761885373053, val_loss: 1.5122680452656863 (26 / 30)\n",
            "train_acc: 0.7070457354758962, val_acc: 0.47783251231527096, train_loss: 0.7449938496494175, val_loss: 1.8900578559325834 (27 / 30)\n",
            "train_acc: 0.6909765142150803, val_acc: 0.5024630541871922, train_loss: 0.7584310434067942, val_loss: 1.5827578617434197 (28 / 30)\n",
            "train_acc: 0.6823238566131026, val_acc: 0.5862068965517241, train_loss: 0.7622708207449895, val_loss: 1.4801913344214115 (29 / 30)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.5320197044334976, train_loss: 0.6845831907871185, val_loss: 1.2990717864388903 (30 / 30)\n",
            "lr 0.004370054390760577, batch 8, decay 2.4983989017395743e-05, gamma 0.2790351363752022, val accuracy 0.5862068965517241, val loss 1.4801913344214115 [2 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.26452410383189123, val_acc: 0.27586206896551724, train_loss: 2.379960071318524, val_loss: 3.4735443395346843 (1 / 30)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.27586206896551724, train_loss: 1.9287659747638868, val_loss: 2.0293556023113832 (2 / 30)\n",
            "train_acc: 0.30778739184178, val_acc: 0.30049261083743845, train_loss: 1.7349921787625042, val_loss: 1.752160960523953 (3 / 30)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.39408866995073893, train_loss: 1.8306671697807548, val_loss: 1.4968807010227823 (4 / 30)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.30049261083743845, train_loss: 1.7009433096801985, val_loss: 1.8680763773142999 (5 / 30)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.4088669950738916, train_loss: 1.5316855264977265, val_loss: 1.6823801269084948 (6 / 30)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.41379310344827586, train_loss: 1.5724365322197913, val_loss: 1.3666302003883963 (7 / 30)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.42857142857142855, train_loss: 1.4045648191709013, val_loss: 1.4607994160041433 (8 / 30)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.4088669950738916, train_loss: 1.5076674881618015, val_loss: 1.4511264935502866 (9 / 30)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.39408866995073893, train_loss: 1.394355600048202, val_loss: 1.5135358137450194 (10 / 30)\n",
            "train_acc: 0.4758961681087763, val_acc: 0.3793103448275862, train_loss: 1.3230627487852193, val_loss: 1.6124192476272583 (11 / 30)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.31527093596059114, train_loss: 1.3092745443799145, val_loss: 1.8547120945794242 (12 / 30)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4236453201970443, train_loss: 1.3268449169448928, val_loss: 1.4362547186207888 (13 / 30)\n",
            "train_acc: 0.519159456118665, val_acc: 0.45320197044334976, train_loss: 1.1995004752952472, val_loss: 1.5822372653801453 (14 / 30)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.39408866995073893, train_loss: 1.2940581571333782, val_loss: 1.607819471453211 (15 / 30)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.47783251231527096, train_loss: 1.1957342110399263, val_loss: 1.309878223048055 (16 / 30)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.45320197044334976, train_loss: 1.1239817864520587, val_loss: 1.3681411655078382 (17 / 30)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4482758620689655, train_loss: 1.2202039973255436, val_loss: 1.593776431576959 (18 / 30)\n",
            "train_acc: 0.65389369592089, val_acc: 0.5467980295566502, train_loss: 0.8655260144117, val_loss: 1.2584704642225368 (19 / 30)\n",
            "train_acc: 0.7082818294190358, val_acc: 0.5369458128078818, train_loss: 0.7328225418427966, val_loss: 1.1866967413813023 (20 / 30)\n",
            "train_acc: 0.761433868974042, val_acc: 0.5467980295566502, train_loss: 0.6131746546447056, val_loss: 1.2354558400919873 (21 / 30)\n",
            "train_acc: 0.7601977750309024, val_acc: 0.5172413793103449, train_loss: 0.6165230350824458, val_loss: 1.2592922132003483 (22 / 30)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.5320197044334976, train_loss: 0.5760405156462095, val_loss: 1.328961276655714 (23 / 30)\n",
            "train_acc: 0.7775030902348579, val_acc: 0.5221674876847291, train_loss: 0.5646831401346346, val_loss: 1.3678467579075855 (24 / 30)\n",
            "train_acc: 0.8158220024721878, val_acc: 0.5172413793103449, train_loss: 0.4829329023844527, val_loss: 1.4185307131612241 (25 / 30)\n",
            "train_acc: 0.8603213844252163, val_acc: 0.5566502463054187, train_loss: 0.41356047976886384, val_loss: 1.4002945951640313 (26 / 30)\n",
            "train_acc: 0.8405438813349815, val_acc: 0.5566502463054187, train_loss: 0.4503410672964655, val_loss: 1.362995246361042 (27 / 30)\n",
            "train_acc: 0.8640296662546354, val_acc: 0.5073891625615764, train_loss: 0.3623174915207626, val_loss: 1.516213278465083 (28 / 30)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.5615763546798029, train_loss: 0.4247641539102137, val_loss: 1.4249550990870434 (29 / 30)\n",
            "train_acc: 0.8862793572311496, val_acc: 0.541871921182266, train_loss: 0.3381342014069905, val_loss: 1.4302119586268083 (30 / 30)\n",
            "lr 0.0013956457803157216, batch 8, decay 1.761025272281164e-05, gamma 0.13405878555049575, val accuracy 0.5615763546798029, val loss 1.4249550990870434 [3 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.23856613102595797, val_acc: 0.3645320197044335, train_loss: 2.202292610894617, val_loss: 2.503738297030256 (1 / 30)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3103448275862069, train_loss: 2.1736790500258927, val_loss: 1.5890989468015473 (2 / 30)\n",
            "train_acc: 0.26081582200247216, val_acc: 0.29064039408866993, train_loss: 1.8896538990242373, val_loss: 1.7266455921046253 (3 / 30)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3251231527093596, train_loss: 1.5852659535496432, val_loss: 2.3532201732907976 (4 / 30)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.35467980295566504, train_loss: 1.7069188481650335, val_loss: 1.504488161338374 (5 / 30)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.3448275862068966, train_loss: 1.6561241810047729, val_loss: 1.8380166961641735 (6 / 30)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.39408866995073893, train_loss: 1.5516244436813373, val_loss: 1.4277430514396705 (7 / 30)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.4039408866995074, train_loss: 1.4633394428177728, val_loss: 1.381696382766874 (8 / 30)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3694581280788177, train_loss: 1.4281557366638749, val_loss: 1.5463191728873793 (9 / 30)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.458128078817734, train_loss: 1.4169380252234574, val_loss: 1.3182456370057731 (10 / 30)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.39408866995073893, train_loss: 1.3977239500312193, val_loss: 1.6695986622072794 (11 / 30)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.28078817733990147, train_loss: 1.2769437851510914, val_loss: 1.698418150394421 (12 / 30)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.4039408866995074, train_loss: 1.401681269644512, val_loss: 1.848349982294543 (13 / 30)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.43349753694581283, train_loss: 1.349188883608145, val_loss: 1.8362520944896004 (14 / 30)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.35960591133004927, train_loss: 1.2879323157745475, val_loss: 1.594687531734335 (15 / 30)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.47783251231527096, train_loss: 1.1936218149140385, val_loss: 1.515521199245171 (16 / 30)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.39408866995073893, train_loss: 1.2091782561633437, val_loss: 1.4867986558106145 (17 / 30)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4482758620689655, train_loss: 1.2674015098802829, val_loss: 1.4762640833267437 (18 / 30)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.4729064039408867, train_loss: 1.0097844191033702, val_loss: 1.4552835924872036 (19 / 30)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.4088669950738916, train_loss: 0.9161286984739551, val_loss: 1.6380927586203138 (20 / 30)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.4482758620689655, train_loss: 0.9703742588406293, val_loss: 1.5883428439718161 (21 / 30)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.458128078817734, train_loss: 0.9381296979482153, val_loss: 1.5590111786508796 (22 / 30)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.4975369458128079, train_loss: 0.8794338602954879, val_loss: 1.3783097132086166 (23 / 30)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.458128078817734, train_loss: 0.8950573015861369, val_loss: 1.6609094048955757 (24 / 30)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.4827586206896552, train_loss: 0.8718130448545307, val_loss: 1.3310130159255906 (25 / 30)\n",
            "train_acc: 0.6996291718170581, val_acc: 0.458128078817734, train_loss: 0.7622620579044074, val_loss: 1.8043875001334204 (26 / 30)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.458128078817734, train_loss: 0.8085437621115459, val_loss: 1.484706421791039 (27 / 30)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5320197044334976, train_loss: 0.7316534186175786, val_loss: 1.405789856840237 (28 / 30)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5073891625615764, train_loss: 0.7949476405628237, val_loss: 1.443992102087425 (29 / 30)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5172413793103449, train_loss: 0.7311069526247984, val_loss: 1.5246700988027262 (30 / 30)\n",
            "lr 0.0017283386367491806, batch 8, decay 5.075974197515026e-06, gamma 0.6430214592694454, val accuracy 0.5320197044334976, val loss 1.405789856840237 [4 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2311495673671199, val_acc: 0.3103448275862069, train_loss: 3.623693150259803, val_loss: 1.766727109260747 (1 / 30)\n",
            "train_acc: 0.2620519159456119, val_acc: 0.3497536945812808, train_loss: 1.8953618732164759, val_loss: 2.890737066715222 (2 / 30)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.32019704433497537, train_loss: 1.6521292858571734, val_loss: 1.6774609523453736 (3 / 30)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.35467980295566504, train_loss: 1.6528849501544967, val_loss: 4.008367947169712 (4 / 30)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3891625615763547, train_loss: 1.590443319973751, val_loss: 1.5383561092057252 (5 / 30)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3793103448275862, train_loss: 1.4788653353972843, val_loss: 1.6074710168274753 (6 / 30)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3694581280788177, train_loss: 1.4592372917274314, val_loss: 1.9503452067304714 (7 / 30)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.37438423645320196, train_loss: 1.4238485653409263, val_loss: 1.971620636033307 (8 / 30)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.3448275862068966, train_loss: 1.3388653538283075, val_loss: 2.101247714070851 (9 / 30)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.3891625615763547, train_loss: 1.3879089508716786, val_loss: 4.552794780637243 (10 / 30)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.31527093596059114, train_loss: 1.3637582501315952, val_loss: 2.2601670989849296 (11 / 30)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.3645320197044335, train_loss: 1.348661007780964, val_loss: 2.421360769882578 (12 / 30)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.3448275862068966, train_loss: 1.2495622471324888, val_loss: 3.6582962224636173 (13 / 30)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.4433497536945813, train_loss: 1.2895489726284672, val_loss: 2.4337001181588382 (14 / 30)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.35960591133004927, train_loss: 1.279659264314602, val_loss: 1.9032828875363166 (15 / 30)\n",
            "train_acc: 0.484548825710754, val_acc: 0.3793103448275862, train_loss: 1.2337195678753377, val_loss: 2.1649352488259375 (16 / 30)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.39901477832512317, train_loss: 1.2441203694408403, val_loss: 1.5131806942629697 (17 / 30)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4039408866995074, train_loss: 1.1081589809601622, val_loss: 3.074167041355753 (18 / 30)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4630541871921182, train_loss: 1.0468264896289086, val_loss: 1.7107549224581038 (19 / 30)\n",
            "train_acc: 0.695920889987639, val_acc: 0.5024630541871922, train_loss: 0.7558876153712514, val_loss: 1.9380622538439747 (20 / 30)\n",
            "train_acc: 0.7280593325092707, val_acc: 0.4729064039408867, train_loss: 0.7149382400866344, val_loss: 2.138863542984272 (21 / 30)\n",
            "train_acc: 0.7404202719406675, val_acc: 0.41379310344827586, train_loss: 0.6462438952348141, val_loss: 4.2074077881028495 (22 / 30)\n",
            "train_acc: 0.7490729295426453, val_acc: 0.5123152709359606, train_loss: 0.6629470896219883, val_loss: 1.4900284571013427 (23 / 30)\n",
            "train_acc: 0.7564894932014833, val_acc: 0.458128078817734, train_loss: 0.6088269334493668, val_loss: 1.8894476044941417 (24 / 30)\n",
            "train_acc: 0.7836835599505563, val_acc: 0.541871921182266, train_loss: 0.5585414078385927, val_loss: 1.645122166337638 (25 / 30)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.4433497536945813, train_loss: 0.5158992621158934, val_loss: 3.8133967416039827 (26 / 30)\n",
            "train_acc: 0.7515451174289246, val_acc: 0.4876847290640394, train_loss: 0.6500891562003288, val_loss: 2.2453354661687843 (27 / 30)\n",
            "train_acc: 0.7787391841779975, val_acc: 0.4876847290640394, train_loss: 0.5945704908689257, val_loss: 2.373055372332117 (28 / 30)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.45320197044334976, train_loss: 0.5278291112854985, val_loss: 2.286399771427286 (29 / 30)\n",
            "train_acc: 0.8133498145859085, val_acc: 0.5270935960591133, train_loss: 0.48618767612207364, val_loss: 2.253510808709807 (30 / 30)\n",
            "lr 0.005039312748392438, batch 8, decay 2.190527344808628e-05, gamma 0.21616510432563296, val accuracy 0.541871921182266, val loss 1.645122166337638 [5 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2880098887515451, val_acc: 0.30049261083743845, train_loss: 2.101609855411374, val_loss: 2.0904341533853503 (1 / 30)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.31527093596059114, train_loss: 2.090916737637797, val_loss: 1.742014374932632 (2 / 30)\n",
            "train_acc: 0.311495673671199, val_acc: 0.37438423645320196, train_loss: 1.8707995178967678, val_loss: 2.0989065516758436 (3 / 30)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.35467980295566504, train_loss: 1.810747036975158, val_loss: 2.0008586592274935 (4 / 30)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.3645320197044335, train_loss: 1.6201173254232324, val_loss: 1.6845503282077208 (5 / 30)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.33497536945812806, train_loss: 1.522403873530837, val_loss: 1.6752061773403524 (6 / 30)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.33004926108374383, train_loss: 1.5136939739562083, val_loss: 1.7422964514182706 (7 / 30)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3694581280788177, train_loss: 1.506275430450628, val_loss: 1.7787154883586715 (8 / 30)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.35960591133004927, train_loss: 1.3975348808562063, val_loss: 1.9203100092892575 (9 / 30)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.37438423645320196, train_loss: 1.4166324306624782, val_loss: 1.5346483497196817 (10 / 30)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.3842364532019704, train_loss: 1.3618618006759284, val_loss: 1.3893971742667588 (11 / 30)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.41379310344827586, train_loss: 1.4769654586377043, val_loss: 1.4421426128284098 (12 / 30)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.35960591133004927, train_loss: 1.4224645835065428, val_loss: 1.7033604994196023 (13 / 30)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.3842364532019704, train_loss: 1.1790333620844724, val_loss: 1.5319721176119274 (14 / 30)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.3399014778325123, train_loss: 1.2229747912202984, val_loss: 1.8398736850381485 (15 / 30)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.41379310344827586, train_loss: 1.2464697464140149, val_loss: 1.5272146551479846 (16 / 30)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.43349753694581283, train_loss: 1.158093377303134, val_loss: 1.550428618351227 (17 / 30)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.39408866995073893, train_loss: 1.168432737015676, val_loss: 1.6421483649408877 (18 / 30)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.47783251231527096, train_loss: 0.9210748828680465, val_loss: 1.4616909996042111 (19 / 30)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5369458128078818, train_loss: 0.7711914911847769, val_loss: 1.392506042137522 (20 / 30)\n",
            "train_acc: 0.7391841779975278, val_acc: 0.5615763546798029, train_loss: 0.6681382801977754, val_loss: 1.387393525668553 (21 / 30)\n",
            "train_acc: 0.7503090234857849, val_acc: 0.5172413793103449, train_loss: 0.6316563394956742, val_loss: 1.5370148173693954 (22 / 30)\n",
            "train_acc: 0.7725587144622992, val_acc: 0.5073891625615764, train_loss: 0.5844680417158695, val_loss: 1.4761953982226368 (23 / 30)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.4729064039408867, train_loss: 0.5938472240905385, val_loss: 1.8089679755600803 (24 / 30)\n",
            "train_acc: 0.796044499381953, val_acc: 0.5123152709359606, train_loss: 0.5254001947504333, val_loss: 1.6112019372691075 (25 / 30)\n",
            "train_acc: 0.7453646477132262, val_acc: 0.5862068965517241, train_loss: 0.6534416553263905, val_loss: 1.3540217230472658 (26 / 30)\n",
            "train_acc: 0.7515451174289246, val_acc: 0.541871921182266, train_loss: 0.6389233861187628, val_loss: 1.4622476840841359 (27 / 30)\n",
            "train_acc: 0.8145859085290482, val_acc: 0.5123152709359606, train_loss: 0.5424767617684212, val_loss: 1.6249350961205995 (28 / 30)\n",
            "train_acc: 0.7861557478368356, val_acc: 0.4827586206896552, train_loss: 0.5497741545970714, val_loss: 1.729927503416691 (29 / 30)\n",
            "train_acc: 0.8009888751545118, val_acc: 0.5320197044334976, train_loss: 0.5117958508551637, val_loss: 1.5962805677517293 (30 / 30)\n",
            "lr 0.002079668637156788, batch 8, decay 9.35265161244351e-05, gamma 0.27285577635295216, val accuracy 0.5862068965517241, val loss 1.3540217230472658 [6 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.242274412855377, val_acc: 0.3054187192118227, train_loss: 2.630358144880373, val_loss: 2.097042988086569 (1 / 30)\n",
            "train_acc: 0.27441285537700866, val_acc: 0.2660098522167488, train_loss: 2.1675953773691865, val_loss: 4.152619633181342 (2 / 30)\n",
            "train_acc: 0.311495673671199, val_acc: 0.31527093596059114, train_loss: 1.7977134229520932, val_loss: 1.674081032792923 (3 / 30)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3497536945812808, train_loss: 1.6106464774411158, val_loss: 1.7684840333872829 (4 / 30)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3497536945812808, train_loss: 1.5727529183895832, val_loss: 1.4578596488595597 (5 / 30)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.31527093596059114, train_loss: 1.7177225196612043, val_loss: 1.5476314187637104 (6 / 30)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3645320197044335, train_loss: 1.4370268095556384, val_loss: 1.502152350735782 (7 / 30)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.4039408866995074, train_loss: 1.4661091305269447, val_loss: 1.4729475566906294 (8 / 30)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.39408866995073893, train_loss: 1.421413505033156, val_loss: 1.5378884552734826 (9 / 30)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3694581280788177, train_loss: 1.624547552266728, val_loss: 1.6094682416305166 (10 / 30)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3497536945812808, train_loss: 1.429640866622642, val_loss: 1.4072235238375923 (11 / 30)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.3497536945812808, train_loss: 1.3590433270439082, val_loss: 1.6245218027988677 (12 / 30)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.37438423645320196, train_loss: 1.306594993629031, val_loss: 1.6387838747701033 (13 / 30)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.41379310344827586, train_loss: 1.3323362074027987, val_loss: 1.3787524612079114 (14 / 30)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.45320197044334976, train_loss: 1.2654090384470371, val_loss: 1.43546462059021 (15 / 30)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.45320197044334976, train_loss: 1.3766369442415178, val_loss: 1.386273781067045 (16 / 30)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.3891625615763547, train_loss: 1.1777972509009287, val_loss: 1.4579296763894594 (17 / 30)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.43842364532019706, train_loss: 1.1654305447754076, val_loss: 1.5443142165104156 (18 / 30)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5517241379310345, train_loss: 0.9041813644402107, val_loss: 1.2079971506090588 (19 / 30)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5763546798029556, train_loss: 0.8341651708440226, val_loss: 1.1761996575764246 (20 / 30)\n",
            "train_acc: 0.7132262051915945, val_acc: 0.541871921182266, train_loss: 0.7362804784173577, val_loss: 1.202874554789125 (21 / 30)\n",
            "train_acc: 0.7181705809641533, val_acc: 0.5270935960591133, train_loss: 0.7392651421767378, val_loss: 1.2512758688386438 (22 / 30)\n",
            "train_acc: 0.7342398022249691, val_acc: 0.5024630541871922, train_loss: 0.6762938464085753, val_loss: 1.479696458783643 (23 / 30)\n",
            "train_acc: 0.7935723114956736, val_acc: 0.5911330049261084, train_loss: 0.5266482077069277, val_loss: 1.2441625970925017 (24 / 30)\n",
            "train_acc: 0.830655129789864, val_acc: 0.5615763546798029, train_loss: 0.48401681248130846, val_loss: 1.355937771609264 (25 / 30)\n",
            "train_acc: 0.8207663782447466, val_acc: 0.5270935960591133, train_loss: 0.47293275602079, val_loss: 1.5287877943715438 (26 / 30)\n",
            "train_acc: 0.857849196538937, val_acc: 0.5320197044334976, train_loss: 0.44219333928064597, val_loss: 1.4982121736545282 (27 / 30)\n",
            "train_acc: 0.8603213844252163, val_acc: 0.5763546798029556, train_loss: 0.41220784408347716, val_loss: 1.3429665518511693 (28 / 30)\n",
            "train_acc: 0.861557478368356, val_acc: 0.5073891625615764, train_loss: 0.38012398364959454, val_loss: 1.5705638331145488 (29 / 30)\n",
            "train_acc: 0.8479604449938195, val_acc: 0.5615763546798029, train_loss: 0.43865249257152544, val_loss: 1.4605240839455516 (30 / 30)\n",
            "lr 0.0024294902368032162, batch 8, decay 2.4613300639705193e-06, gamma 0.1162206247261106, val accuracy 0.5911330049261084, val loss 1.2441625970925017 [7 / 20]\n",
            "---------------------------------------------\n",
            "train_acc: 0.28553770086526575, val_acc: 0.28078817733990147, train_loss: 2.091251953865306, val_loss: 3.168967931141407 (1 / 30)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3103448275862069, train_loss: 2.258145470849074, val_loss: 2.4493237093751654 (2 / 30)\n",
            "train_acc: 0.311495673671199, val_acc: 0.33497536945812806, train_loss: 2.04367767364634, val_loss: 1.6666993865825859 (3 / 30)\n",
            "train_acc: 0.30902348578491967, val_acc: 0.3054187192118227, train_loss: 1.800914296997787, val_loss: 1.5155420547048446 (4 / 30)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.4187192118226601, train_loss: 1.6198753980535217, val_loss: 1.4934572621519342 (5 / 30)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3891625615763547, train_loss: 1.5831995981438052, val_loss: 1.4838425555252677 (6 / 30)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.3842364532019704, train_loss: 1.4640838691713784, val_loss: 1.6320801427211669 (7 / 30)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.3891625615763547, train_loss: 1.4423847398887606, val_loss: 1.380030456141298 (8 / 30)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4088669950738916, train_loss: 1.457191835669858, val_loss: 1.4859273145938743 (9 / 30)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.41379310344827586, train_loss: 1.4273199366108595, val_loss: 1.4532915066028465 (10 / 30)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.35960591133004927, train_loss: 1.3830653769418837, val_loss: 1.6858699028127886 (11 / 30)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.43349753694581283, train_loss: 1.254291044030113, val_loss: 1.411989762278026 (12 / 30)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.39901477832512317, train_loss: 1.2581368353222444, val_loss: 1.52221079001873 (13 / 30)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.43842364532019706, train_loss: 1.119211435612701, val_loss: 1.9175543456242001 (14 / 30)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.4975369458128079, train_loss: 1.1836958793538757, val_loss: 1.3190421570698028 (15 / 30)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.4088669950738916, train_loss: 1.1447644174762062, val_loss: 1.717902729076705 (16 / 30)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.42857142857142855, train_loss: 1.1494562543366837, val_loss: 1.5655327947268933 (17 / 30)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.5172413793103449, train_loss: 1.051364780651182, val_loss: 1.2989413714761218 (18 / 30)\n",
            "train_acc: 0.6687268232385661, val_acc: 0.4975369458128079, train_loss: 0.8361167901820689, val_loss: 1.5263413349395902 (19 / 30)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.4827586206896552, train_loss: 0.7273710093775255, val_loss: 1.5489496022022415 (20 / 30)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.4630541871921182, train_loss: 0.7794522655614374, val_loss: 1.5382557890098083 (21 / 30)\n",
            "train_acc: 0.7194066749072929, val_acc: 0.49261083743842365, train_loss: 0.741596229438876, val_loss: 1.4397308767722745 (22 / 30)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.4876847290640394, train_loss: 0.6698513237301292, val_loss: 1.6677440968640331 (23 / 30)\n",
            "train_acc: 0.7428924598269468, val_acc: 0.5221674876847291, train_loss: 0.6295456258563972, val_loss: 1.6100457301868007 (24 / 30)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5270935960591133, train_loss: 0.751825457008277, val_loss: 1.4133488579923883 (25 / 30)\n",
            "train_acc: 0.7428924598269468, val_acc: 0.5024630541871922, train_loss: 0.6947767778733752, val_loss: 1.580092074248591 (26 / 30)\n",
            "train_acc: 0.7676143386897404, val_acc: 0.4729064039408867, train_loss: 0.5968139202544657, val_loss: 1.5058563060948413 (27 / 30)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.4876847290640394, train_loss: 0.5922372927624452, val_loss: 1.6899546983794038 (28 / 30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7c6ee9e79dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mcurrent_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b20803267196>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset, verbosity, plot)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "6f9b6113-ebc5-42e9-c6ea-e4fb357d30bf",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = resnet152(num_classes=NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 24392 (delta 10), reused 13 (delta 5), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24392/24392), 2.15 GiB | 40.79 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (24636/24636), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5911330049261084, val loss 1.464456105467134\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5714285714285714, val loss 1.1493462312397698\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.2976923220850565\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5714285714285714, val loss 1.5292216216402101\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5517241379310345, val loss 2.2198262414321523\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.541871921182266, val loss 1.4739784601286714\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6354679802955665, val loss 1.4432697883380459\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5467980295566502, val loss 1.4287934297411313\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6157635467980296, val loss 1.2100772047277741\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5812807881773399, val loss 1.2167480200382288\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6206896551724138, val loss 1.2259140389012586\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6206896551724138, val loss 1.2343330753260646\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5911330049261084, val loss 1.668155833418146\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5566502463054187, val loss 1.222032011436124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "1bd7620b-b85a-4ec4-adb1-a0b86857073d"
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6021e5c8a16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpixel_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Computing mean/std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b20803267196>\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(train_data_dir, test_data_dir, compose)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/anphetamina/AIML_project.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     91\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     92\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Faster and available in Python 3.5 and above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AIML_project/ravdess-emotional-song-mel-672'"
          ]
        }
      ]
    }
  ]
}