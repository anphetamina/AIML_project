{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg11\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()#,\n",
        "          #transforms.Normalize((45.6068733, 0.81077038, 57.85301916), (66.92374056, 9.88349788, 49.96761776))\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg11()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            acc_diff = train_accuracy-val_accuracy\n",
        "            if acc_diff > 0.25:\n",
        "              print(\"overfit -> train_accuracy {}, val_accuracy {}\".format(train_accuracy, val_accuracy))\n",
        "              return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "        \n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "        \n",
        "\n",
        "        if train_accuracy < 0.25 and epoch > num_epochs*0.1 or train_accuracy < 0.35 and epoch > num_epochs*0.5:\n",
        "          print(\"underfit -> train_accuracy = {}\".format(train_accuracy))\n",
        "          return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "8664ff1e-a00a-4183-d992-6989e9b5ccd2",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "source": [
        "# lr 0.0006444500508054211, batch 14, decay 2.1280582227123365e-05, gamma 0.19924404264743992, val accuracy 0.6305418719211823, val loss 1.0403618915327664 [5 / 50]\n",
        "# lr 0.00038041059192815333, batch 9, decay 3.8372561126798785e-05, gamma 0.057680309789029396, val accuracy 0.6108374384236454, val loss 0.9877617955207825 [38 / 50]\n",
        "# lr 0.00043660847130590896, batch 10, decay 0.00025031720443271155, gamma 0.011678955740792939, val accuracy 0.5615763546798029, val loss 1.0453474251507537 [43 / 50]\n",
        "# lr 0.00027531434783290124, batch 9, decay 4.3783604017624755e-06, gamma 0.11844128056704877, val accuracy 0.5517241379310345, val loss 1.117455956383879 [44 / 50]\n",
        "# lr 0.0007220498435995008, batch 14, decay 2.228552014354877e-05, gamma 0.08113961287843949, val accuracy 0.625615763546798, val loss 0.9968108699239534 [49 / 50]\n",
        "# lr 0.0008377019231346562, batch 8, decay 2.4427015675775187e-06, gamma 0.00903130010323455, val accuracy 0.5849802371541502, val loss 1.0701400147596367 [1 / 50]\n",
        "# lr 0.0010316163585472981, batch 8, decay 1.8309942558988887e-05, gamma 0.002673690056313373, val accuracy 0.5592885375494071, val loss 1.0480610431418589 [5 / 50]\n",
        "# lr 0.0016661746592012004, batch 8, decay 3.3763075569909223e-06, gamma 0.006052773438030023, val accuracy 0.6067193675889329, val loss 1.0441360360548901 [6 / 50]\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "LR = 0.0016661746592012004\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 3.3763075569909223e-06\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.006052773438030023\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg11()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7769966431984354, val_loss: 1.7528151361813098 (1 / 100)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.1921182266009852, train_loss: 1.7568124678579926, val_loss: 1.7314458903420735 (2 / 100)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.3251231527093596, train_loss: 1.7148307454306058, val_loss: 1.6364169150150467 (3 / 100)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.2315270935960591, train_loss: 1.648387673758753, val_loss: 1.561875629894839 (4 / 100)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.39408866995073893, train_loss: 1.56933183634679, val_loss: 1.436902018603433 (5 / 100)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.4039408866995074, train_loss: 1.5394843022519784, val_loss: 1.4288246478940465 (6 / 100)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3645320197044335, train_loss: 1.4916156366817441, val_loss: 1.3596990043893824 (7 / 100)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.41379310344827586, train_loss: 1.4428927871883284, val_loss: 1.3270727284436155 (8 / 100)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3842364532019704, train_loss: 1.411518293346551, val_loss: 1.3296967738954892 (9 / 100)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3891625615763547, train_loss: 1.3613156567987317, val_loss: 1.2983370396891252 (10 / 100)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4482758620689655, train_loss: 1.3432683703041783, val_loss: 1.259992968859931 (11 / 100)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.43842364532019706, train_loss: 1.3129778674565376, val_loss: 1.2544936106122773 (12 / 100)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4236453201970443, train_loss: 1.3063071949962337, val_loss: 1.4105484456264328 (13 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4482758620689655, train_loss: 1.3039696788316308, val_loss: 1.267802991890555 (14 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4187192118226601, train_loss: 1.263734789065584, val_loss: 1.314446323610879 (15 / 100)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.458128078817734, train_loss: 1.2437363972033204, val_loss: 1.1985695454581031 (16 / 100)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.47783251231527096, train_loss: 1.2486410804083674, val_loss: 1.1965558828391465 (17 / 100)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.5221674876847291, train_loss: 1.169055448326988, val_loss: 1.1332845270927316 (18 / 100)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.5615763546798029, train_loss: 1.1472546671170682, val_loss: 1.1594826276666426 (19 / 100)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.5615763546798029, train_loss: 1.1164602343319963, val_loss: 1.0693567850319623 (20 / 100)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5320197044334976, train_loss: 1.081999367924939, val_loss: 1.1094918538784158 (21 / 100)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.4729064039408867, train_loss: 1.0941730590332277, val_loss: 1.3222907382279194 (22 / 100)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5172413793103449, train_loss: 1.0122847919558418, val_loss: 1.1025436300362272 (23 / 100)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5714285714285714, train_loss: 0.9248830971523327, val_loss: 1.083101467252365 (24 / 100)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.5911330049261084, train_loss: 0.8862506285291373, val_loss: 1.1043619638299706 (25 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5812807881773399, train_loss: 0.9004518521583567, val_loss: 1.010627460597184 (26 / 100)\n",
            "train_acc: 0.6934487021013597, val_acc: 0.5320197044334976, train_loss: 0.7789959004252449, val_loss: 1.1348916779597993 (27 / 100)\n",
            "train_acc: 0.715698393077874, val_acc: 0.5024630541871922, train_loss: 0.721549032055698, val_loss: 1.3024715822318504 (28 / 100)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.541871921182266, train_loss: 0.6912205371043296, val_loss: 1.2295159942704468 (29 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5862068965517241, train_loss: 0.7459482757653235, val_loss: 1.0907015298387688 (30 / 100)\n",
            "train_acc: 0.788627935723115, val_acc: 0.5960591133004927, train_loss: 0.5587861644028144, val_loss: 1.2297278278566934 (31 / 100)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.5960591133004927, train_loss: 0.528735946665883, val_loss: 1.3495030156497299 (32 / 100)\n",
            "train_acc: 0.8430160692212608, val_acc: 0.5960591133004927, train_loss: 0.4486924691312245, val_loss: 1.1350680566186389 (33 / 100)\n",
            "overfit -> train_accuracy 0.8442521631644005, val_accuracy 0.5566502463054187\n",
            "val accuracy 0.5960591133004927\n",
            "val loss 1.2297278278566934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUIpGmogDgOC",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eOsPQVDgG6",
        "colab_type": "code",
        "outputId": "5cecbf4c-86e9-4a86-99c1-5d3c6ef6ede5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# best scores\n",
        "# \n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = vgg11()\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = 10**random.uniform(-5, -3)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-6, -3)\n",
        "  NUM_EPOCHS = 80\n",
        "  STEP_SIZE = 48\n",
        "  GAMMA = 10**random.uniform(-2, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"-------------------------------------\")\n",
        "  print(set)\n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "\n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "-------------------------------------\n",
            "{'lr': 6.87058653262615e-05, 'batch_size': 11, 'weight_decay': 0.0002907904402306258, 'gamma': 0.3452849738179014}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7887585941144946, val_loss: 1.7877258355981611 (1 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.785982954782078, val_loss: 1.7848116212290497 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.19704433497536947, train_loss: 1.7837268041886565, val_loss: 1.782029298138736 (3 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7821260082117558, val_loss: 1.77940324550779 (4 / 80)\n",
            "train_acc: 0.16563658838071693, val_acc: 0.18226600985221675, train_loss: 1.7808360979789857, val_loss: 1.7767154712395128 (5 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7786879697158398, val_loss: 1.774125811501677 (6 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.775055715268563, val_loss: 1.7714474465459438 (7 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.7734820630553332, val_loss: 1.7689472166775482 (8 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7741290254262823, val_loss: 1.7667156545986682 (9 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7707272959580675, val_loss: 1.764472509252614 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18046971569839307\n",
            "lr 6.87058653262615e-05, batch 11, decay 0.0002907904402306258, gamma 0.3452849738179014, val accuracy 0.19704433497536947, val loss 1.782029298138736 [1 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00032381259201563257, 'batch_size': 11, 'weight_decay': 0.00012890436972817662, 'gamma': 0.023213138693782234}\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.788759824519399, val_loss: 1.7848785581259892 (1 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7831569691965694, val_loss: 1.7776533294781087 (2 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7766288991911596, val_loss: 1.7695574143837238 (3 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7676411016909832, val_loss: 1.7605839163211767 (4 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7617450343958379, val_loss: 1.75310845328082 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.755790419867366, val_loss: 1.7474357118747506 (6 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7485467786399926, val_loss: 1.7410717292372229 (7 / 80)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.18719211822660098, train_loss: 1.7451698794795203, val_loss: 1.7334059641279023 (8 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.24630541871921183, train_loss: 1.7307687411349548, val_loss: 1.721913890885602 (9 / 80)\n",
            "train_acc: 0.26328800988875156, val_acc: 0.19704433497536947, train_loss: 1.718468537584076, val_loss: 1.710659638414242 (10 / 80)\n",
            "train_acc: 0.27564894932014833, val_acc: 0.3399014778325123, train_loss: 1.7186331362895235, val_loss: 1.6872685771857576 (11 / 80)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.27586206896551724, train_loss: 1.679874492664125, val_loss: 1.6422144855771745 (12 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3103448275862069, train_loss: 1.631629150641716, val_loss: 1.566756609038179 (13 / 80)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.28078817733990147, train_loss: 1.5745559590413927, val_loss: 1.6197323147299254 (14 / 80)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3399014778325123, train_loss: 1.5650144181823258, val_loss: 1.4796721465481912 (15 / 80)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3399014778325123, train_loss: 1.5225654125803039, val_loss: 1.4708270503969616 (16 / 80)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.3251231527093596, train_loss: 1.5149067360332191, val_loss: 1.4905134827045385 (17 / 80)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.31527093596059114, train_loss: 1.4955695768074582, val_loss: 1.524568610003429 (18 / 80)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.4236453201970443, train_loss: 1.4822473607045612, val_loss: 1.388589264724055 (19 / 80)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3793103448275862, train_loss: 1.4546107345517398, val_loss: 1.3973773823583067 (20 / 80)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.4088669950738916, train_loss: 1.4282049627327653, val_loss: 1.3735795041610455 (21 / 80)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.42857142857142855, train_loss: 1.4413129044109576, val_loss: 1.335635196692838 (22 / 80)\n",
            "train_acc: 0.415327564894932, val_acc: 0.3793103448275862, train_loss: 1.406516781327751, val_loss: 1.3972975608750517 (23 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.39901477832512317, train_loss: 1.4154124852311332, val_loss: 1.3766387407415606 (24 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.37438423645320196, train_loss: 1.401945825191894, val_loss: 1.3321593588796155 (25 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.4236453201970443, train_loss: 1.403983973012719, val_loss: 1.3111175733246827 (26 / 80)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.3793103448275862, train_loss: 1.4225272602587018, val_loss: 1.3415115267185156 (27 / 80)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.43842364532019706, train_loss: 1.3754592304324043, val_loss: 1.3453965771374443 (28 / 80)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.43349753694581283, train_loss: 1.3496772540072428, val_loss: 1.2862371535136783 (29 / 80)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.43349753694581283, train_loss: 1.351313419115116, val_loss: 1.2706739059809982 (30 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.43349753694581283, train_loss: 1.3788974368380675, val_loss: 1.2705026888495008 (31 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4729064039408867, train_loss: 1.3063695709991219, val_loss: 1.2802587107484564 (32 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4876847290640394, train_loss: 1.3295137229454974, val_loss: 1.2538200669687958 (33 / 80)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.43842364532019706, train_loss: 1.3125536239928162, val_loss: 1.2372381311332064 (34 / 80)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.458128078817734, train_loss: 1.2870506680350664, val_loss: 1.2268556494430956 (35 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.4187192118226601, train_loss: 1.3123210273655441, val_loss: 1.3045700330452379 (36 / 80)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.458128078817734, train_loss: 1.2760416012169846, val_loss: 1.2551845376714696 (37 / 80)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.4630541871921182, train_loss: 1.2685753706064449, val_loss: 1.2768965102181646 (38 / 80)\n",
            "train_acc: 0.4758961681087763, val_acc: 0.4876847290640394, train_loss: 1.2668816015511124, val_loss: 1.2119491760953893 (39 / 80)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4433497536945813, train_loss: 1.2789893837735444, val_loss: 1.2570175886741413 (40 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.46798029556650245, train_loss: 1.2482793894038064, val_loss: 1.3703952628403462 (41 / 80)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.4433497536945813, train_loss: 1.2394344774990058, val_loss: 1.234342000460977 (42 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4876847290640394, train_loss: 1.2341456689557568, val_loss: 1.216400808888703 (43 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.46798029556650245, train_loss: 1.2069260823564565, val_loss: 1.1647917205476996 (44 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.4827586206896552, train_loss: 1.183660689478899, val_loss: 1.2856034698157475 (45 / 80)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.45320197044334976, train_loss: 1.1838550482898471, val_loss: 1.2614115300436912 (46 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.43349753694581283, train_loss: 1.2010821017847662, val_loss: 1.2713473069256749 (47 / 80)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.47783251231527096, train_loss: 1.1804011419176024, val_loss: 1.1692165444637168 (48 / 80)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.49261083743842365, train_loss: 1.1193662292435673, val_loss: 1.153833177289352 (49 / 80)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.5024630541871922, train_loss: 1.1065636403186359, val_loss: 1.1519735041510295 (50 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.5123152709359606, train_loss: 1.1309391584325632, val_loss: 1.142503213706275 (51 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.5123152709359606, train_loss: 1.1112211085809913, val_loss: 1.141020753407126 (52 / 80)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.5172413793103449, train_loss: 1.1289707660232988, val_loss: 1.1399509746746477 (53 / 80)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.5172413793103449, train_loss: 1.107131454425925, val_loss: 1.1414725166823476 (54 / 80)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5123152709359606, train_loss: 1.1118016970909128, val_loss: 1.143481697061379 (55 / 80)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.5024630541871922, train_loss: 1.0833184053046152, val_loss: 1.1368913844301196 (56 / 80)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5073891625615764, train_loss: 1.0944939627046195, val_loss: 1.1364362040176768 (57 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5073891625615764, train_loss: 1.0837459521476358, val_loss: 1.1365543891643655 (58 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5073891625615764, train_loss: 1.090269200144651, val_loss: 1.1376025635620644 (59 / 80)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5024630541871922, train_loss: 1.0875379037945467, val_loss: 1.141565755083056 (60 / 80)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.5024630541871922, train_loss: 1.1008529789073505, val_loss: 1.1387394549224177 (61 / 80)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.4975369458128079, train_loss: 1.1042318589460423, val_loss: 1.134943497885624 (62 / 80)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.5024630541871922, train_loss: 1.0962200186161235, val_loss: 1.134869571683442 (63 / 80)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5024630541871922, train_loss: 1.1014055059336318, val_loss: 1.1341883493174474 (64 / 80)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.5024630541871922, train_loss: 1.0810771017935132, val_loss: 1.1320034576754265 (65 / 80)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.4975369458128079, train_loss: 1.0715263902919991, val_loss: 1.1338478638033562 (66 / 80)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.5024630541871922, train_loss: 1.0806852718366238, val_loss: 1.134693424983565 (67 / 80)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.5073891625615764, train_loss: 1.0857884522126837, val_loss: 1.1354252355439323 (68 / 80)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.5073891625615764, train_loss: 1.072859094228379, val_loss: 1.1330221862041305 (69 / 80)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.5024630541871922, train_loss: 1.1106265478287403, val_loss: 1.1326201120620878 (70 / 80)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5024630541871922, train_loss: 1.0774587395017314, val_loss: 1.1302289216976447 (71 / 80)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.5024630541871922, train_loss: 1.0620560784569777, val_loss: 1.1288661918616647 (72 / 80)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5024630541871922, train_loss: 1.0738675069013248, val_loss: 1.134495311769946 (73 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.5024630541871922, train_loss: 1.071173154821502, val_loss: 1.131242306068026 (74 / 80)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5073891625615764, train_loss: 1.0578408160227337, val_loss: 1.1345570119730946 (75 / 80)\n",
            "train_acc: 0.5686032138442522, val_acc: 0.5024630541871922, train_loss: 1.0318389354441753, val_loss: 1.1384975590142123 (76 / 80)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5024630541871922, train_loss: 1.0628936851422484, val_loss: 1.1381935503682479 (77 / 80)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.4975369458128079, train_loss: 1.0490736528881106, val_loss: 1.1383064703401087 (78 / 80)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.4975369458128079, train_loss: 1.050982714657141, val_loss: 1.138759946588225 (79 / 80)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.4975369458128079, train_loss: 1.0690692387640992, val_loss: 1.1355863454306654 (80 / 80)\n",
            "lr 0.00032381259201563257, batch 11, decay 0.00012890436972817662, gamma 0.023213138693782234, val accuracy 0.5172413793103449, val loss 1.1399509746746477 [2 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00010105746440697143, 'batch_size': 9, 'weight_decay': 7.168475186733455e-06, 'gamma': 0.6629497649106064}\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.789067440186207, val_loss: 1.7871722576066191 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.1724137931034483, train_loss: 1.7864273537516742, val_loss: 1.7847367654293043 (2 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.17733990147783252, train_loss: 1.7838816944836686, val_loss: 1.7818673954808653 (3 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.20689655172413793, train_loss: 1.7812168431665163, val_loss: 1.7793491139200521 (4 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.20689655172413793, train_loss: 1.7786879157843194, val_loss: 1.7763204374924082 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7768030318400474, val_loss: 1.7734263448292398 (6 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.774463122206359, val_loss: 1.7701088501314812 (7 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.771986294146374, val_loss: 1.7668335249858538 (8 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7676844714745898, val_loss: 1.7637061696921663 (9 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7645378316141325, val_loss: 1.7599302436330635 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1841779975278121\n",
            "lr 0.00010105746440697143, batch 9, decay 7.168475186733455e-06, gamma 0.6629497649106064, val accuracy 0.20689655172413793, val loss 1.7793491139200521 [3 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.000953839039916152, 'batch_size': 9, 'weight_decay': 0.00015319613136737035, 'gamma': 0.9262521929212527}\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.7843165374067422, val_loss: 1.7708172668964404 (1 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7655035493105686, val_loss: 1.7479674604725954 (2 / 80)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.3054187192118227, train_loss: 1.7520700083085428, val_loss: 1.7269958827295915 (3 / 80)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.2512315270935961, train_loss: 1.7259858877608745, val_loss: 1.6628634677144694 (4 / 80)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3103448275862069, train_loss: 1.6564312617769936, val_loss: 1.5577736816969998 (5 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.35467980295566504, train_loss: 1.6255239062609868, val_loss: 1.67831336571078 (6 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.39901477832512317, train_loss: 1.5800065270755141, val_loss: 1.4451959597066117 (7 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3891625615763547, train_loss: 1.5232941260738633, val_loss: 1.416880770857111 (8 / 80)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.42857142857142855, train_loss: 1.4862068400836845, val_loss: 1.437072193094075 (9 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.39901477832512317, train_loss: 1.4811254803123521, val_loss: 1.3871605854316298 (10 / 80)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.32019704433497537, train_loss: 1.4483213461521087, val_loss: 1.4217302056368937 (11 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.33497536945812806, train_loss: 1.392251394956162, val_loss: 1.3533584220068795 (12 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3793103448275862, train_loss: 1.3917552447878976, val_loss: 1.4445895179739139 (13 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.43349753694581283, train_loss: 1.3980080531760406, val_loss: 1.264357538646078 (14 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.47783251231527096, train_loss: 1.3380119545645413, val_loss: 1.2456724725920578 (15 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.458128078817734, train_loss: 1.3532899060414365, val_loss: 1.2524754625235872 (16 / 80)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.42857142857142855, train_loss: 1.2822939464718803, val_loss: 1.2742195728377168 (17 / 80)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.43842364532019706, train_loss: 1.3062145637788054, val_loss: 1.2979426210736993 (18 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4433497536945813, train_loss: 1.3008204361122235, val_loss: 1.2254492332195412 (19 / 80)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.45320197044334976, train_loss: 1.2765251797415564, val_loss: 1.1887216465226536 (20 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.46798029556650245, train_loss: 1.220579541878883, val_loss: 1.2009116872190841 (21 / 80)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.45320197044334976, train_loss: 1.2088771994388001, val_loss: 1.1675156146434729 (22 / 80)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.5172413793103449, train_loss: 1.2321708146367585, val_loss: 1.1726773102295223 (23 / 80)\n",
            "train_acc: 0.5043263288009888, val_acc: 0.5172413793103449, train_loss: 1.1690235319184727, val_loss: 1.1385198490960258 (24 / 80)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.5221674876847291, train_loss: 1.1694997893128318, val_loss: 1.1286629517677382 (25 / 80)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.45320197044334976, train_loss: 1.1517868654247563, val_loss: 1.175784477165767 (26 / 80)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.47783251231527096, train_loss: 1.1121123941483986, val_loss: 1.1247045186352846 (27 / 80)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5517241379310345, train_loss: 1.0523336397850027, val_loss: 1.219099949439758 (28 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5665024630541872, train_loss: 1.0975021914439678, val_loss: 1.059812302366266 (29 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4975369458128079, train_loss: 1.0614410124175775, val_loss: 1.0644254017933248 (30 / 80)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.5517241379310345, train_loss: 0.9824870001105649, val_loss: 1.1160743897184362 (31 / 80)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.3842364532019704, train_loss: 0.9544631979153094, val_loss: 1.3165174578798229 (32 / 80)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5665024630541872, train_loss: 0.9836446231758345, val_loss: 1.061188992021119 (33 / 80)\n",
            "train_acc: 0.65389369592089, val_acc: 0.541871921182266, train_loss: 0.8814733447633656, val_loss: 1.0081454135220627 (34 / 80)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5714285714285714, train_loss: 0.8408737665569532, val_loss: 1.0947997106119918 (35 / 80)\n",
            "train_acc: 0.6440049443757726, val_acc: 0.6108374384236454, train_loss: 0.8527851865450737, val_loss: 0.965564813373124 (36 / 80)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.5320197044334976, train_loss: 0.7801615160755233, val_loss: 1.1373400344637228 (37 / 80)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5517241379310345, train_loss: 0.746745854837196, val_loss: 1.3588215792414002 (38 / 80)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5763546798029556, train_loss: 0.6684505015022233, val_loss: 1.109989947139336 (39 / 80)\n",
            "train_acc: 0.7317676143386898, val_acc: 0.5812807881773399, train_loss: 0.6519573966434918, val_loss: 1.3616854762796111 (40 / 80)\n",
            "train_acc: 0.757725587144623, val_acc: 0.6059113300492611, train_loss: 0.6356143814929484, val_loss: 1.3224064221816698 (41 / 80)\n",
            "train_acc: 0.7799752781211372, val_acc: 0.6305418719211823, train_loss: 0.568807085784905, val_loss: 1.160102125679331 (42 / 80)\n",
            "train_acc: 0.8318912237330037, val_acc: 0.6403940886699507, train_loss: 0.4525507856045282, val_loss: 1.032604592994516 (43 / 80)\n",
            "train_acc: 0.8294190358467244, val_acc: 0.6354679802955665, train_loss: 0.46788043972238325, val_loss: 1.0510986533951876 (44 / 80)\n",
            "train_acc: 0.8665018541409147, val_acc: 0.6305418719211823, train_loss: 0.36674270030613, val_loss: 1.1558004913879145 (45 / 80)\n",
            "train_acc: 0.8529048207663782, val_acc: 0.6650246305418719, train_loss: 0.399278126610961, val_loss: 1.0745352168975792 (46 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.2754236514093298\n",
            "lr 0.000953839039916152, batch 9, decay 0.00015319613136737035, gamma 0.9262521929212527, val accuracy 0.6650246305418719, val loss 1.0745352168975792 [4 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}\n",
            "train_acc: 0.18541409147095178, val_acc: 0.2019704433497537, train_loss: 1.787222889798828, val_loss: 1.7792626043845867 (1 / 80)\n",
            "train_acc: 0.16563658838071693, val_acc: 0.1921182266009852, train_loss: 1.7763476816773858, val_loss: 1.7650453386635616 (2 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7601544238138846, val_loss: 1.7504996349071633 (3 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18719211822660098, train_loss: 1.7537464436848171, val_loss: 1.7423658001011815 (4 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18719211822660098, train_loss: 1.7451746896996043, val_loss: 1.7310849633710137 (5 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.22167487684729065, train_loss: 1.7384023071072157, val_loss: 1.7164962990530606 (6 / 80)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.1921182266009852, train_loss: 1.7213749421394358, val_loss: 1.7045474175749153 (7 / 80)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.3251231527093596, train_loss: 1.7036924455015563, val_loss: 1.6588450012535885 (8 / 80)\n",
            "train_acc: 0.3164400494437577, val_acc: 0.37438423645320196, train_loss: 1.649252489117079, val_loss: 1.5668467324355553 (9 / 80)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3399014778325123, train_loss: 1.5850570257868255, val_loss: 1.5274077160605068 (10 / 80)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.37438423645320196, train_loss: 1.5427747144097892, val_loss: 1.5124577612712466 (11 / 80)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.32019704433497537, train_loss: 1.5512995970411265, val_loss: 1.5868867800153534 (12 / 80)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.3497536945812808, train_loss: 1.555502282526938, val_loss: 1.4769557755568932 (13 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.2561576354679803, train_loss: 1.4770200704909373, val_loss: 1.8925036561900173 (14 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3842364532019704, train_loss: 1.537875084411376, val_loss: 1.4012378002035206 (15 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3399014778325123, train_loss: 1.4604699120975395, val_loss: 1.506527908917131 (16 / 80)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.35467980295566504, train_loss: 1.4340916007057256, val_loss: 1.5185675127752896 (17 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3842364532019704, train_loss: 1.4395211963040573, val_loss: 1.3730327671971814 (18 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.3891625615763547, train_loss: 1.3738763677175025, val_loss: 1.3312684831948116 (19 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4482758620689655, train_loss: 1.3767264574508289, val_loss: 1.3022156953811646 (20 / 80)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.42857142857142855, train_loss: 1.3915724064717334, val_loss: 1.299436984391048 (21 / 80)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.45320197044334976, train_loss: 1.3846096771461855, val_loss: 1.2727831560989906 (22 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.4433497536945813, train_loss: 1.3467396804222513, val_loss: 1.265419943579312 (23 / 80)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.3793103448275862, train_loss: 1.3601737239010108, val_loss: 1.3642062524269367 (24 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.42857142857142855, train_loss: 1.335786685808038, val_loss: 1.2785878345884125 (25 / 80)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.43842364532019706, train_loss: 1.3403208815712568, val_loss: 1.264502593155565 (26 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4236453201970443, train_loss: 1.2789577535999426, val_loss: 1.2763923077747739 (27 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.3793103448275862, train_loss: 1.3201243102329476, val_loss: 1.3224709033966064 (28 / 80)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4827586206896552, train_loss: 1.2736264495236618, val_loss: 1.228312714346524 (29 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4827586206896552, train_loss: 1.2923648538636632, val_loss: 1.1967953320207267 (30 / 80)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.49261083743842365, train_loss: 1.2294056629220989, val_loss: 1.1863625090697716 (31 / 80)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.4729064039408867, train_loss: 1.2671826901777714, val_loss: 1.2205022881770957 (32 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.45320197044334976, train_loss: 1.2245221230833434, val_loss: 1.2310690448201935 (33 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.49261083743842365, train_loss: 1.2072741372328901, val_loss: 1.2238941357053559 (34 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.47783251231527096, train_loss: 1.1560617201260495, val_loss: 1.1895125035581917 (35 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.45320197044334976, train_loss: 1.1739372881440209, val_loss: 1.1984874750005787 (36 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.4729064039408867, train_loss: 1.1849658424391587, val_loss: 1.182812657849542 (37 / 80)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.4827586206896552, train_loss: 1.0996569210872957, val_loss: 1.1680588804442307 (38 / 80)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.46798029556650245, train_loss: 1.179755399710463, val_loss: 1.156045173776561 (39 / 80)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4729064039408867, train_loss: 1.1203457184863475, val_loss: 1.132735803209502 (40 / 80)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.4433497536945813, train_loss: 1.1172435747825613, val_loss: 1.2293911226864518 (41 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4827586206896552, train_loss: 1.1043445775181755, val_loss: 1.1996202551085373 (42 / 80)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.5320197044334976, train_loss: 1.0737247892156963, val_loss: 1.0612037469600808 (43 / 80)\n",
            "train_acc: 0.5784919653893696, val_acc: 0.541871921182266, train_loss: 1.0420518560226828, val_loss: 1.0665424198939883 (44 / 80)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5073891625615764, train_loss: 1.0440986126992846, val_loss: 1.242678243538429 (45 / 80)\n",
            "train_acc: 0.595797280593325, val_acc: 0.5221674876847291, train_loss: 1.0113001997008164, val_loss: 1.0953919846436073 (46 / 80)\n",
            "train_acc: 0.588380716934487, val_acc: 0.5812807881773399, train_loss: 1.0109490018397826, val_loss: 1.0277004118623405 (47 / 80)\n",
            "train_acc: 0.595797280593325, val_acc: 0.5615763546798029, train_loss: 0.9877357492488158, val_loss: 1.0390881649379073 (48 / 80)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.5566502463054187, train_loss: 0.9056266692866501, val_loss: 1.041390743748895 (49 / 80)\n",
            "train_acc: 0.6847960444993819, val_acc: 0.541871921182266, train_loss: 0.8282799451106558, val_loss: 1.0570352241910737 (50 / 80)\n",
            "train_acc: 0.6786155747836835, val_acc: 0.5665024630541872, train_loss: 0.8207695367751812, val_loss: 1.028143989628759 (51 / 80)\n",
            "train_acc: 0.6909765142150803, val_acc: 0.5615763546798029, train_loss: 0.8005277433781453, val_loss: 0.9992058790963272 (52 / 80)\n",
            "train_acc: 0.7082818294190358, val_acc: 0.5763546798029556, train_loss: 0.776104182041767, val_loss: 1.0135603814289487 (53 / 80)\n",
            "train_acc: 0.7107540173053152, val_acc: 0.5960591133004927, train_loss: 0.7555687693494507, val_loss: 1.0247759736817459 (54 / 80)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.5615763546798029, train_loss: 0.757194256605707, val_loss: 1.0548285698068554 (55 / 80)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5665024630541872, train_loss: 0.7419022188714173, val_loss: 1.0752273551348983 (56 / 80)\n",
            "train_acc: 0.7070457354758962, val_acc: 0.6206896551724138, train_loss: 0.7512619475499072, val_loss: 1.0138117352436329 (57 / 80)\n",
            "train_acc: 0.723114956736712, val_acc: 0.5615763546798029, train_loss: 0.7123733114253163, val_loss: 1.1282346413053315 (58 / 80)\n",
            "train_acc: 0.7132262051915945, val_acc: 0.5911330049261084, train_loss: 0.7324233345033506, val_loss: 1.0951590229725015 (59 / 80)\n",
            "train_acc: 0.7317676143386898, val_acc: 0.5862068965517241, train_loss: 0.7002866710219602, val_loss: 1.0648832958320091 (60 / 80)\n",
            "train_acc: 0.7428924598269468, val_acc: 0.6059113300492611, train_loss: 0.678812905722407, val_loss: 1.0712166531332608 (61 / 80)\n",
            "train_acc: 0.7490729295426453, val_acc: 0.6059113300492611, train_loss: 0.6569333027113501, val_loss: 1.0585244647387801 (62 / 80)\n",
            "train_acc: 0.7552533992583437, val_acc: 0.5812807881773399, train_loss: 0.6231728311816901, val_loss: 1.0974382059327488 (63 / 80)\n",
            "train_acc: 0.7663782447466008, val_acc: 0.5960591133004927, train_loss: 0.6345368919178052, val_loss: 1.0251343044741401 (64 / 80)\n",
            "train_acc: 0.761433868974042, val_acc: 0.6305418719211823, train_loss: 0.6138986942205205, val_loss: 1.0403618915327664 (65 / 80)\n",
            "train_acc: 0.7775030902348579, val_acc: 0.5812807881773399, train_loss: 0.6046364948024561, val_loss: 1.0489437292362083 (66 / 80)\n",
            "train_acc: 0.7688504326328801, val_acc: 0.6157635467980296, train_loss: 0.6019679345144477, val_loss: 0.9912499353803438 (67 / 80)\n",
            "train_acc: 0.7935723114956736, val_acc: 0.6108374384236454, train_loss: 0.5833981561719708, val_loss: 1.0248023600413882 (68 / 80)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.6206896551724138, train_loss: 0.5418609713373431, val_loss: 0.9862481807840282 (69 / 80)\n",
            "train_acc: 0.7911001236093943, val_acc: 0.5812807881773399, train_loss: 0.5428760911537189, val_loss: 1.1533048132370258 (70 / 80)\n",
            "train_acc: 0.8084054388133498, val_acc: 0.6305418719211823, train_loss: 0.5400103992599492, val_loss: 1.0390700451258956 (71 / 80)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.5960591133004927, train_loss: 0.528687273689784, val_loss: 1.1654685119102741 (72 / 80)\n",
            "train_acc: 0.788627935723115, val_acc: 0.6157635467980296, train_loss: 0.5387095710992519, val_loss: 1.1068128532376782 (73 / 80)\n",
            "train_acc: 0.8084054388133498, val_acc: 0.5911330049261084, train_loss: 0.52215400697348, val_loss: 1.0810633075648342 (74 / 80)\n",
            "train_acc: 0.8182941903584673, val_acc: 0.6157635467980296, train_loss: 0.5075325077890024, val_loss: 1.0864405503560757 (75 / 80)\n",
            "train_acc: 0.823238566131026, val_acc: 0.6108374384236454, train_loss: 0.46471283370249056, val_loss: 1.1147774457931519 (76 / 80)\n",
            "train_acc: 0.8281829419035847, val_acc: 0.625615763546798, train_loss: 0.47437365454413244, val_loss: 1.0410206153475006 (77 / 80)\n",
            "train_acc: 0.8343634116192831, val_acc: 0.5960591133004927, train_loss: 0.44080895984865387, val_loss: 1.2352065731739175 (78 / 80)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6206896551724138, train_loss: 0.4301221124984425, val_loss: 1.0899376540348447 (79 / 80)\n",
            "train_acc: 0.8491965389369592, val_acc: 0.6108374384236454, train_loss: 0.4410361370948985, val_loss: 1.0437787154625202 (80 / 80)\n",
            "lr 0.0006444500508054211, batch 14, decay 2.1280582227123365e-05, gamma 0.19924404264743992, val accuracy 0.6305418719211823, val loss 1.0403618915327664 [5 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0001305446116361885, 'batch_size': 14, 'weight_decay': 0.00010370951313656249, 'gamma': 0.011122564036501074}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.24630541871921183, train_loss: 1.7911253729915737, val_loss: 1.7889860991773934 (1 / 80)\n",
            "train_acc: 0.16563658838071693, val_acc: 0.18226600985221675, train_loss: 1.7896173013597543, val_loss: 1.786014540442105 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7852197245997463, val_loss: 1.7829572784489598 (3 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7827301821101582, val_loss: 1.7797618282252345 (4 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.779560592472185, val_loss: 1.7766350055563038 (5 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7776200956997676, val_loss: 1.773538770346806 (6 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7759767928435863, val_loss: 1.7698548785571395 (7 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7714564200532157, val_loss: 1.76623168484918 (8 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7690501071614004, val_loss: 1.7626149901028336 (9 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.763103476266189, val_loss: 1.7586268638742382 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19283065512978986\n",
            "lr 0.0001305446116361885, batch 14, decay 0.00010370951313656249, gamma 0.011122564036501074, val accuracy 0.24630541871921183, val loss 1.7889860991773934 [6 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.3278612890785774e-05, 'batch_size': 14, 'weight_decay': 7.589757136798515e-06, 'gamma': 0.09659098336434087}\n",
            "train_acc: 0.19901112484548825, val_acc: 0.16748768472906403, train_loss: 1.791314975587635, val_loss: 1.791052135927924 (1 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.1625615763546798, train_loss: 1.7908138889906875, val_loss: 1.7907539441667755 (2 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.1724137931034483, train_loss: 1.7903956602176718, val_loss: 1.7904509388167282 (3 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.19704433497536947, train_loss: 1.7909288083667072, val_loss: 1.7901354493765995 (4 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.1921182266009852, train_loss: 1.7902444212044715, val_loss: 1.7898006233675727 (5 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.20689655172413793, train_loss: 1.7899467200961778, val_loss: 1.7895073068553005 (6 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.2019704433497537, train_loss: 1.789289941451753, val_loss: 1.7891784495320813 (7 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.19704433497536947, train_loss: 1.7894069895019342, val_loss: 1.7888674530489692 (8 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.2019704433497537, train_loss: 1.789302989637896, val_loss: 1.7885767262557457 (9 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.19704433497536947, train_loss: 1.7886143996482726, val_loss: 1.7882703131642834 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1668726823238566\n",
            "lr 2.3278612890785774e-05, batch 14, decay 7.589757136798515e-06, gamma 0.09659098336434087, val accuracy 0.20689655172413793, val loss 1.7895073068553005 [7 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0009634199776520317, 'batch_size': 15, 'weight_decay': 1.9424564221617045e-05, 'gamma': 0.07349147747689912}\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.786665228152894, val_loss: 1.774316380763876 (1 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7669209924115534, val_loss: 1.7544501285834853 (2 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7585920702541715, val_loss: 1.7445145217068676 (3 / 80)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.3645320197044335, train_loss: 1.7492692757890604, val_loss: 1.7311473339062018 (4 / 80)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.23645320197044334, train_loss: 1.7323195565910952, val_loss: 1.7026332822339287 (5 / 80)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.29064039408866993, train_loss: 1.704760705584796, val_loss: 1.6675647356240033 (6 / 80)\n",
            "train_acc: 0.315203955500618, val_acc: 0.3251231527093596, train_loss: 1.639566122527765, val_loss: 1.607150181173691 (7 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.37438423645320196, train_loss: 1.5878085108711044, val_loss: 1.5244458032946282 (8 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.2955665024630542, train_loss: 1.5556854061202154, val_loss: 1.579487159921618 (9 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.29064039408866993, train_loss: 1.5216060648447798, val_loss: 1.6251128066349498 (10 / 80)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.39901477832512317, train_loss: 1.4753642908869626, val_loss: 1.4044798706552666 (11 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.37438423645320196, train_loss: 1.4392656518885467, val_loss: 1.3746400390352522 (12 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.3399014778325123, train_loss: 1.4287441637371614, val_loss: 1.3460592659823414 (13 / 80)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.31527093596059114, train_loss: 1.4014112048302356, val_loss: 1.4415982885313738 (14 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.4236453201970443, train_loss: 1.4576514377287497, val_loss: 1.3479073059382698 (15 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3842364532019704, train_loss: 1.41751869389389, val_loss: 1.316191076645123 (16 / 80)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.3645320197044335, train_loss: 1.3771791864826595, val_loss: 1.3648258735393655 (17 / 80)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.41379310344827586, train_loss: 1.349396808701481, val_loss: 1.2892836802111471 (18 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.32019704433497537, train_loss: 1.375269352063555, val_loss: 1.4318600288165615 (19 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4236453201970443, train_loss: 1.3248776650546654, val_loss: 1.288839027799409 (20 / 80)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.41379310344827586, train_loss: 1.3024861326323747, val_loss: 1.2919705607033716 (21 / 80)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.458128078817734, train_loss: 1.3233630705822825, val_loss: 1.2453127794077832 (22 / 80)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4433497536945813, train_loss: 1.2745911145976507, val_loss: 1.225804489821636 (23 / 80)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4630541871921182, train_loss: 1.262476594766374, val_loss: 1.2328006296322263 (24 / 80)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.43349753694581283, train_loss: 1.2560162710760374, val_loss: 1.2900656664312766 (25 / 80)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4827586206896552, train_loss: 1.2552694027002427, val_loss: 1.2109088621703274 (26 / 80)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.43842364532019706, train_loss: 1.2827296893587807, val_loss: 1.2183743867968104 (27 / 80)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.5024630541871922, train_loss: 1.2298771252738236, val_loss: 1.1668280383636211 (28 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4630541871921182, train_loss: 1.2149536407774841, val_loss: 1.2436247600123214 (29 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.4876847290640394, train_loss: 1.179842229826636, val_loss: 1.1917519939356838 (30 / 80)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.47783251231527096, train_loss: 1.177790672655306, val_loss: 1.1682661478155352 (31 / 80)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.49261083743842365, train_loss: 1.1074474403088999, val_loss: 1.1727781800800943 (32 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.4876847290640394, train_loss: 1.1572481330451918, val_loss: 1.218942379716582 (33 / 80)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.4975369458128079, train_loss: 1.0709693049470927, val_loss: 1.1478605863496 (34 / 80)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.49261083743842365, train_loss: 1.093535809714361, val_loss: 1.1059578862683526 (35 / 80)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.49261083743842365, train_loss: 1.0416084498498583, val_loss: 1.0926710082392388 (36 / 80)\n",
            "train_acc: 0.588380716934487, val_acc: 0.4876847290640394, train_loss: 1.0093203555373533, val_loss: 1.16413760655032 (37 / 80)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.5024630541871922, train_loss: 1.0421229617852068, val_loss: 1.0747496277240698 (38 / 80)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5369458128078818, train_loss: 0.9593849137185972, val_loss: 1.1949351051170838 (39 / 80)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.49261083743842365, train_loss: 1.0171635249636524, val_loss: 1.1452754841649473 (40 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5073891625615764, train_loss: 0.9526032627144614, val_loss: 1.109876732814488 (41 / 80)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5172413793103449, train_loss: 0.9361037322410989, val_loss: 1.0476969348386003 (42 / 80)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5073891625615764, train_loss: 0.8547297485531924, val_loss: 1.2476113623586194 (43 / 80)\n",
            "train_acc: 0.6761433868974042, val_acc: 0.5172413793103449, train_loss: 0.8458620588328547, val_loss: 1.153444245237435 (44 / 80)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5911330049261084, train_loss: 0.835431748805441, val_loss: 1.0313909115462467 (45 / 80)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.5270935960591133, train_loss: 0.8040402977737714, val_loss: 1.0488723375527143 (46 / 80)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.6108374384236454, train_loss: 0.7424383254074786, val_loss: 1.106118556901152 (47 / 80)\n",
            "train_acc: 0.7391841779975278, val_acc: 0.5763546798029556, train_loss: 0.6779079132233327, val_loss: 1.123381285831846 (48 / 80)\n",
            "train_acc: 0.788627935723115, val_acc: 0.6403940886699507, train_loss: 0.5921969447648717, val_loss: 0.9407640683827142 (49 / 80)\n",
            "train_acc: 0.8170580964153276, val_acc: 0.625615763546798, train_loss: 0.508535963422141, val_loss: 0.9636944830417633 (50 / 80)\n",
            "train_acc: 0.8331273176761433, val_acc: 0.6009852216748769, train_loss: 0.5013664025348256, val_loss: 1.0107342264628763 (51 / 80)\n",
            "train_acc: 0.8294190358467244, val_acc: 0.5960591133004927, train_loss: 0.46167221361465005, val_loss: 1.008301425156335 (52 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.2518830642951524\n",
            "lr 0.0009634199776520317, batch 15, decay 1.9424564221617045e-05, gamma 0.07349147747689912, val accuracy 0.6403940886699507, val loss 0.9407640683827142 [8 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00010189554549947586, 'batch_size': 13, 'weight_decay': 3.7938384472088194e-05, 'gamma': 0.09548688661589924}\n",
            "train_acc: 0.1841779975278121, val_acc: 0.15763546798029557, train_loss: 1.7910205140544104, val_loss: 1.7904848882130213 (1 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.1724137931034483, train_loss: 1.7898006425947135, val_loss: 1.7883698035930764 (2 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.1724137931034483, train_loss: 1.7881470473646675, val_loss: 1.7866255150639951 (3 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.15763546798029557, train_loss: 1.7856369581446512, val_loss: 1.7845543229521201 (4 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.16748768472906403, train_loss: 1.7839533962926404, val_loss: 1.7826210407200704 (5 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.19704433497536947, train_loss: 1.783540470933148, val_loss: 1.7806962082538698 (6 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.19704433497536947, train_loss: 1.7807572909132365, val_loss: 1.7786100926657615 (7 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.7794604294084944, val_loss: 1.7765302499526827 (8 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.19704433497536947, train_loss: 1.7768926784046206, val_loss: 1.7742538716405483 (9 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18719211822660098, train_loss: 1.7750525310985532, val_loss: 1.7719405954107275 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18788627935723115\n",
            "lr 0.00010189554549947586, batch 13, decay 3.7938384472088194e-05, gamma 0.09548688661589924, val accuracy 0.19704433497536947, val loss 1.7806962082538698 [9 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00017744405536419445, 'batch_size': 9, 'weight_decay': 0.00012317359545354354, 'gamma': 0.845852187456105}\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7916947212737924, val_loss: 1.7892627322615073 (1 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.21674876847290642, train_loss: 1.7872253833211986, val_loss: 1.784052419545028 (2 / 80)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.18226600985221675, train_loss: 1.7816941341746724, val_loss: 1.7787476090962075 (3 / 80)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.19704433497536947, train_loss: 1.7790260401880196, val_loss: 1.7734342320212002 (4 / 80)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.19704433497536947, train_loss: 1.7736998784674702, val_loss: 1.7675559491359543 (5 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.19704433497536947, train_loss: 1.7673112196739584, val_loss: 1.7611320112726372 (6 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7639878858594575, val_loss: 1.7561942661924315 (7 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7599243861341063, val_loss: 1.7515102730596006 (8 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18719211822660098, train_loss: 1.7611129714178362, val_loss: 1.7480444502947954 (9 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.19704433497536947, train_loss: 1.7528144352515638, val_loss: 1.7441711848592523 (10 / 80)\n",
            "underfit -> train_accuracy = 0.2027194066749073\n",
            "lr 0.00017744405536419445, batch 9, decay 0.00012317359545354354, gamma 0.845852187456105, val accuracy 0.21674876847290642, val loss 1.784052419545028 [10 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0002363879745266706, 'batch_size': 15, 'weight_decay': 1.2859972654017638e-06, 'gamma': 0.0727587904402118}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7891807382274765, val_loss: 1.7869080610463184 (1 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.1921182266009852, train_loss: 1.785039386878939, val_loss: 1.7816807748061683 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7809068900250975, val_loss: 1.7759456141241665 (3 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.775704463715901, val_loss: 1.7704732394570788 (4 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7718106013145964, val_loss: 1.7648393602794028 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7657020041910179, val_loss: 1.758992694281592 (6 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7593911507515736, val_loss: 1.7534237236812198 (7 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7582281615737048, val_loss: 1.7492405293610296 (8 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7539863371289115, val_loss: 1.7456974325508907 (9 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.751209494209997, val_loss: 1.741910687221095 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1915945611866502\n",
            "lr 0.0002363879745266706, batch 15, decay 1.2859972654017638e-06, gamma 0.0727587904402118, val accuracy 0.1921182266009852, val loss 1.7816807748061683 [11 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005465334588837794, 'batch_size': 8, 'weight_decay': 1.711446646796338e-06, 'gamma': 0.584732316549937}\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18719211822660098, train_loss: 1.7836723259853933, val_loss: 1.7714930473290054 (1 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18719211822660098, train_loss: 1.7695924120279414, val_loss: 1.7545736851950584 (2 / 80)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.2512315270935961, train_loss: 1.7630677853880177, val_loss: 1.742377163741389 (3 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.2019704433497537, train_loss: 1.7446508775977476, val_loss: 1.7219984584253998 (4 / 80)\n",
            "train_acc: 0.2558714462299135, val_acc: 0.3054187192118227, train_loss: 1.7237332441898152, val_loss: 1.6890023347779448 (5 / 80)\n",
            "train_acc: 0.2954264524103832, val_acc: 0.2955665024630542, train_loss: 1.6778607658756384, val_loss: 1.6109397311515996 (6 / 80)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.3103448275862069, train_loss: 1.608709555768554, val_loss: 1.5618932135586667 (7 / 80)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.2413793103448276, train_loss: 1.5818598880461325, val_loss: 1.8779087865293906 (8 / 80)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.33497536945812806, train_loss: 1.5870682897025488, val_loss: 1.5722151237168336 (9 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.35960591133004927, train_loss: 1.5160533712879836, val_loss: 1.4858352809116757 (10 / 80)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.35960591133004927, train_loss: 1.5284189279058809, val_loss: 1.4786360205100675 (11 / 80)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.3694581280788177, train_loss: 1.4754494512626355, val_loss: 1.4851975323531428 (12 / 80)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.35467980295566504, train_loss: 1.4907377729899214, val_loss: 1.5056374008432398 (13 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.35960591133004927, train_loss: 1.4421964519840236, val_loss: 1.4627277792380948 (14 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.35467980295566504, train_loss: 1.4651580714472145, val_loss: 1.4609584156515563 (15 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.4236453201970443, train_loss: 1.4553415719304597, val_loss: 1.358055942164266 (16 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.3842364532019704, train_loss: 1.3844294357948161, val_loss: 1.3460659886815864 (17 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.41379310344827586, train_loss: 1.3872943897035124, val_loss: 1.3264535242700812 (18 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.37438423645320196, train_loss: 1.367954702400896, val_loss: 1.3701828744611129 (19 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.3448275862068966, train_loss: 1.376709552866272, val_loss: 1.479715694347626 (20 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4482758620689655, train_loss: 1.3540345452477227, val_loss: 1.2934694994846587 (21 / 80)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.458128078817734, train_loss: 1.3375207390567134, val_loss: 1.3508591757619322 (22 / 80)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4187192118226601, train_loss: 1.3246232720623794, val_loss: 1.328382266566084 (23 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.4187192118226601, train_loss: 1.2731987735986414, val_loss: 1.3638565340652842 (24 / 80)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.4187192118226601, train_loss: 1.2845582263578739, val_loss: 1.3952607421452188 (25 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4729064039408867, train_loss: 1.2337107755639791, val_loss: 1.3143641003246964 (26 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.458128078817734, train_loss: 1.2466795317764188, val_loss: 1.268025020954057 (27 / 80)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.4088669950738916, train_loss: 1.2094642563420261, val_loss: 1.3368873508105725 (28 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.4827586206896552, train_loss: 1.2045944730195186, val_loss: 1.2167328666583659 (29 / 80)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.4975369458128079, train_loss: 1.1824299499337252, val_loss: 1.1383853128978185 (30 / 80)\n",
            "train_acc: 0.511742892459827, val_acc: 0.4975369458128079, train_loss: 1.1705051429192126, val_loss: 1.1762634580358495 (31 / 80)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.458128078817734, train_loss: 1.1404973420283409, val_loss: 1.39688052890336 (32 / 80)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.49261083743842365, train_loss: 1.1272150258935427, val_loss: 1.1048166875181527 (33 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5369458128078818, train_loss: 1.0772371799011609, val_loss: 1.0812879278154797 (34 / 80)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5024630541871922, train_loss: 1.0555276461083751, val_loss: 1.0840413176954673 (35 / 80)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5221674876847291, train_loss: 1.0096365928060487, val_loss: 1.0834341119662882 (36 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5320197044334976, train_loss: 0.9831471213304216, val_loss: 1.0630706266816614 (37 / 80)\n",
            "train_acc: 0.6365883807169345, val_acc: 0.4975369458128079, train_loss: 0.9130582859548562, val_loss: 1.1709376520711212 (38 / 80)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.5566502463054187, train_loss: 1.005147853504742, val_loss: 1.1434824936495627 (39 / 80)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.5024630541871922, train_loss: 0.9283118987702321, val_loss: 1.1501974877465535 (40 / 80)\n",
            "train_acc: 0.6724351050679852, val_acc: 0.5566502463054187, train_loss: 0.8353607654571533, val_loss: 1.067342251098802 (41 / 80)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.5024630541871922, train_loss: 0.8628874850656253, val_loss: 1.1586129862099446 (42 / 80)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5911330049261084, train_loss: 0.7434219278128097, val_loss: 0.9477890726967986 (43 / 80)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5763546798029556, train_loss: 0.706371915355159, val_loss: 1.0445652237079415 (44 / 80)\n",
            "train_acc: 0.7503090234857849, val_acc: 0.6305418719211823, train_loss: 0.641275816411701, val_loss: 0.9919763516469542 (45 / 80)\n",
            "train_acc: 0.765142150803461, val_acc: 0.6354679802955665, train_loss: 0.6334164693712157, val_loss: 1.0427736769168836 (46 / 80)\n",
            "train_acc: 0.8133498145859085, val_acc: 0.6157635467980296, train_loss: 0.547641984759214, val_loss: 1.0603813656738825 (47 / 80)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.5862068965517241, train_loss: 0.552942528860236, val_loss: 1.0078091777016964 (48 / 80)\n",
            "train_acc: 0.8405438813349815, val_acc: 0.6059113300492611, train_loss: 0.4203287769749079, val_loss: 1.1467087944152907 (49 / 80)\n",
            "train_acc: 0.8800988875154512, val_acc: 0.645320197044335, train_loss: 0.35731089188819765, val_loss: 1.0584736058277449 (50 / 80)\n",
            "train_acc: 0.8677379480840544, val_acc: 0.6305418719211823, train_loss: 0.3403515865835183, val_loss: 1.2486861762154866 (51 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.2507565747410596\n",
            "lr 0.0005465334588837794, batch 8, decay 1.711446646796338e-06, gamma 0.584732316549937, val accuracy 0.645320197044335, val loss 1.0584736058277449 [12 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0008670113918889819, 'batch_size': 11, 'weight_decay': 0.0003892040977696076, 'gamma': 0.02508334820776559}\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7783415731599805, val_loss: 1.7632855987313933 (1 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.21182266009852216, train_loss: 1.7647181528313052, val_loss: 1.7519341519313494 (2 / 80)\n",
            "train_acc: 0.22249690976514216, val_acc: 0.18226600985221675, train_loss: 1.7495299511403766, val_loss: 1.7333315634375135 (3 / 80)\n",
            "train_acc: 0.2373300370828183, val_acc: 0.26108374384236455, train_loss: 1.732881354165755, val_loss: 1.7121631635233687 (4 / 80)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.2019704433497537, train_loss: 1.6923270184265815, val_loss: 1.8312842017911337 (5 / 80)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3399014778325123, train_loss: 1.6624587747753035, val_loss: 1.5463856811006669 (6 / 80)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3399014778325123, train_loss: 1.594323554056684, val_loss: 1.5236128885757747 (7 / 80)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.35960591133004927, train_loss: 1.5680036423969623, val_loss: 1.481627111951706 (8 / 80)\n",
            "train_acc: 0.380716934487021, val_acc: 0.28078817733990147, train_loss: 1.5002506162386446, val_loss: 1.566476924078805 (9 / 80)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3251231527093596, train_loss: 1.50512472351343, val_loss: 1.469620294171601 (10 / 80)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3793103448275862, train_loss: 1.4730796800702994, val_loss: 1.40218427322181 (11 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3793103448275862, train_loss: 1.4468655945786144, val_loss: 1.3995197236244314 (12 / 80)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.37438423645320196, train_loss: 1.489084980691172, val_loss: 1.3805601849344564 (13 / 80)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.3251231527093596, train_loss: 1.4098156391469157, val_loss: 1.3892290210488982 (14 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.4187192118226601, train_loss: 1.4067143565792088, val_loss: 1.383583631127926 (15 / 80)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.4039408866995074, train_loss: 1.385444401589548, val_loss: 1.3232481045088744 (16 / 80)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.4433497536945813, train_loss: 1.3761696170817495, val_loss: 1.2858427548643403 (17 / 80)\n",
            "train_acc: 0.415327564894932, val_acc: 0.4630541871921182, train_loss: 1.3421032635773658, val_loss: 1.2543461701552856 (18 / 80)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.4482758620689655, train_loss: 1.3305145552927542, val_loss: 1.2893194418235365 (19 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.45320197044334976, train_loss: 1.297895181532696, val_loss: 1.2630238163060155 (20 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.42857142857142855, train_loss: 1.306460084225545, val_loss: 1.29711537701743 (21 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.5024630541871922, train_loss: 1.2721348597181152, val_loss: 1.219912954151924 (22 / 80)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.43842364532019706, train_loss: 1.2346195761293945, val_loss: 1.2631108056148286 (23 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.42857142857142855, train_loss: 1.2729093651983736, val_loss: 1.2328880728759202 (24 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.5073891625615764, train_loss: 1.2104548503942927, val_loss: 1.149159736821217 (25 / 80)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.4236453201970443, train_loss: 1.2123926821980988, val_loss: 1.2748114173048235 (26 / 80)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4975369458128079, train_loss: 1.1801144205890273, val_loss: 1.2099745065120642 (27 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.5073891625615764, train_loss: 1.1720385376101519, val_loss: 1.1498881613679708 (28 / 80)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.5073891625615764, train_loss: 1.1594995442589076, val_loss: 1.135923074090422 (29 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.5270935960591133, train_loss: 1.1271902963021776, val_loss: 1.1496396443526733 (30 / 80)\n",
            "train_acc: 0.511742892459827, val_acc: 0.5566502463054187, train_loss: 1.117115535164351, val_loss: 1.1036048117529582 (31 / 80)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.5221674876847291, train_loss: 1.0751097761509003, val_loss: 1.0736036250743959 (32 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4975369458128079, train_loss: 1.0722036153188594, val_loss: 1.201435373040843 (33 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5320197044334976, train_loss: 1.0635257375844478, val_loss: 1.1671878669062272 (34 / 80)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.4729064039408867, train_loss: 1.0029864924210405, val_loss: 1.3422290433216564 (35 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5172413793103449, train_loss: 0.9471875280694407, val_loss: 1.066661687613708 (36 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.541871921182266, train_loss: 0.9486126831568068, val_loss: 1.0393799334911291 (37 / 80)\n",
            "train_acc: 0.6440049443757726, val_acc: 0.5320197044334976, train_loss: 0.8966210511028398, val_loss: 1.0827014364045242 (38 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.541871921182266, train_loss: 0.8638875182759482, val_loss: 1.1010513340898336 (39 / 80)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.4876847290640394, train_loss: 0.8737510092399913, val_loss: 1.173086239492952 (40 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.5911330049261084, train_loss: 0.8306006381405593, val_loss: 1.0060809524775727 (41 / 80)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.5566502463054187, train_loss: 0.7897210343843337, val_loss: 1.0611242624045594 (42 / 80)\n",
            "train_acc: 0.7144622991347342, val_acc: 0.5960591133004927, train_loss: 0.7394109100140217, val_loss: 1.0160163582252164 (43 / 80)\n",
            "train_acc: 0.7404202719406675, val_acc: 0.6157635467980296, train_loss: 0.6973929629742878, val_loss: 1.0746936818649029 (44 / 80)\n",
            "train_acc: 0.7466007416563659, val_acc: 0.6009852216748769, train_loss: 0.6457612467342608, val_loss: 1.0078718637304354 (45 / 80)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.5911330049261084, train_loss: 0.5776814613007791, val_loss: 1.056036905114874 (46 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.25419084559786154\n",
            "lr 0.0008670113918889819, batch 11, decay 0.0003892040977696076, gamma 0.02508334820776559, val accuracy 0.6157635467980296, val loss 1.0746936818649029 [13 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.3042208394929954e-05, 'batch_size': 9, 'weight_decay': 2.2544953140818472e-05, 'gamma': 0.1726830675807015}\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7915298629308072, val_loss: 1.7906943829776032 (1 / 80)\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.79069139046781, val_loss: 1.7897180571344686 (2 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7900462038584781, val_loss: 1.7887903827751799 (3 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7891896599155421, val_loss: 1.7878265739074481 (4 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7886277745179693, val_loss: 1.7868581587457892 (5 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7884019938918068, val_loss: 1.7859662242710883 (6 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.786817290726934, val_loss: 1.7849784420041614 (7 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7862159759358807, val_loss: 1.7840587669992682 (8 / 80)\n",
            "train_acc: 0.22744128553770088, val_acc: 0.18226600985221675, train_loss: 1.784831752146425, val_loss: 1.7829637644913396 (9 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18719211822660098, train_loss: 1.783462997125312, val_loss: 1.7819292927023225 (10 / 80)\n",
            "underfit -> train_accuracy = 0.20519159456118666\n",
            "lr 3.3042208394929954e-05, batch 9, decay 2.2544953140818472e-05, gamma 0.1726830675807015, val accuracy 0.18719211822660098, val loss 1.7819292927023225 [14 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.197395076331845e-05, 'batch_size': 9, 'weight_decay': 3.558941299187794e-05, 'gamma': 0.019386212704505884}\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7924532119659027, val_loss: 1.7920219998054316 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7919292393956696, val_loss: 1.790701379916938 (2 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7905474725848223, val_loss: 1.7895015372431338 (3 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7894555118086901, val_loss: 1.7883586642777392 (4 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7882258606192798, val_loss: 1.7872381239689041 (5 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.1921182266009852, train_loss: 1.7877407831373557, val_loss: 1.7861061947686332 (6 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.2019704433497537, train_loss: 1.7866976237562295, val_loss: 1.7849850437324035 (7 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.1921182266009852, train_loss: 1.7855170708798949, val_loss: 1.7838412652461988 (8 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2413793103448276, train_loss: 1.784582667651371, val_loss: 1.7827796489734369 (9 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2315270935960591, train_loss: 1.7830326754613623, val_loss: 1.7816130486615185 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1841779975278121\n",
            "lr 3.197395076331845e-05, batch 9, decay 3.558941299187794e-05, gamma 0.019386212704505884, val accuracy 0.2413793103448276, val loss 1.7827796489734369 [15 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0008953725585146094, 'batch_size': 14, 'weight_decay': 0.000203492637897574, 'gamma': 0.04966470353985619}\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.787415564133888, val_loss: 1.7756503162712887 (1 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.770330794220065, val_loss: 1.7558711027276928 (2 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2561576354679803, train_loss: 1.757707850894763, val_loss: 1.7435344210986434 (3 / 80)\n",
            "train_acc: 0.2311495673671199, val_acc: 0.18719211822660098, train_loss: 1.746915886811774, val_loss: 1.7283571300835445 (4 / 80)\n",
            "train_acc: 0.23980222496909764, val_acc: 0.19704433497536947, train_loss: 1.739060390864963, val_loss: 1.7119896288575798 (5 / 80)\n",
            "train_acc: 0.24721878862793573, val_acc: 0.2660098522167488, train_loss: 1.6966830701262163, val_loss: 1.653645922397745 (6 / 80)\n",
            "train_acc: 0.30778739184178, val_acc: 0.2512315270935961, train_loss: 1.6333165970367318, val_loss: 1.6327147072759167 (7 / 80)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.2857142857142857, train_loss: 1.5876114814920979, val_loss: 1.6017859023192833 (8 / 80)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.39408866995073893, train_loss: 1.5605416918272437, val_loss: 1.4567518110932975 (9 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.35467980295566504, train_loss: 1.4850983266040627, val_loss: 1.4743560552597046 (10 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3793103448275862, train_loss: 1.5068980922510362, val_loss: 1.4520978475439137 (11 / 80)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.4088669950738916, train_loss: 1.4274535445848708, val_loss: 1.3615094587720673 (12 / 80)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.41379310344827586, train_loss: 1.4223714851773124, val_loss: 1.3596570615110726 (13 / 80)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.43349753694581283, train_loss: 1.4326310436274714, val_loss: 1.3216071375485123 (14 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.41379310344827586, train_loss: 1.444635716887428, val_loss: 1.3487221208111992 (15 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.41379310344827586, train_loss: 1.4019482053254533, val_loss: 1.3270318878108058 (16 / 80)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.3694581280788177, train_loss: 1.3823514941006863, val_loss: 1.3214745480438759 (17 / 80)\n",
            "train_acc: 0.415327564894932, val_acc: 0.37438423645320196, train_loss: 1.3656235413144633, val_loss: 1.308371848073499 (18 / 80)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.4433497536945813, train_loss: 1.3287267583262345, val_loss: 1.3242356242804691 (19 / 80)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.43842364532019706, train_loss: 1.341282256306765, val_loss: 1.2390337319209659 (20 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.43349753694581283, train_loss: 1.3022530345598464, val_loss: 1.3566006915322666 (21 / 80)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.43349753694581283, train_loss: 1.292161051952942, val_loss: 1.3499034766493172 (22 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4236453201970443, train_loss: 1.3299484490169435, val_loss: 1.2663237925233513 (23 / 80)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.458128078817734, train_loss: 1.2724302780200878, val_loss: 1.1923482582486908 (24 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.46798029556650245, train_loss: 1.252830580226865, val_loss: 1.1688316073910943 (25 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.458128078817734, train_loss: 1.2270899947700453, val_loss: 1.1708993829529861 (26 / 80)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.4827586206896552, train_loss: 1.2687320856582396, val_loss: 1.2291586481291672 (27 / 80)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4876847290640394, train_loss: 1.206395809376343, val_loss: 1.1784535584778622 (28 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.4975369458128079, train_loss: 1.2019392051567106, val_loss: 1.1564478771439914 (29 / 80)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.43842364532019706, train_loss: 1.1723808355178174, val_loss: 1.1881667992164349 (30 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4630541871921182, train_loss: 1.1415808744572002, val_loss: 1.2314749462851162 (31 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.458128078817734, train_loss: 1.182304038252907, val_loss: 1.3218758805044766 (32 / 80)\n",
            "train_acc: 0.511742892459827, val_acc: 0.5024630541871922, train_loss: 1.1465580912101991, val_loss: 1.1459572993475815 (33 / 80)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4630541871921182, train_loss: 1.1473055473806242, val_loss: 1.2037130799786797 (34 / 80)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.47783251231527096, train_loss: 1.116285782367249, val_loss: 1.2355582385227597 (35 / 80)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.4975369458128079, train_loss: 1.1022970828196617, val_loss: 1.2752575977095242 (36 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5320197044334976, train_loss: 1.0694759581675488, val_loss: 1.1210231205512737 (37 / 80)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5073891625615764, train_loss: 1.0366843348675223, val_loss: 1.1419818298570041 (38 / 80)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.5270935960591133, train_loss: 0.999210163158893, val_loss: 1.1661884702485183 (39 / 80)\n",
            "train_acc: 0.588380716934487, val_acc: 0.47783251231527096, train_loss: 1.0100532989714144, val_loss: 1.1681699074547867 (40 / 80)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5812807881773399, train_loss: 1.0168186483630732, val_loss: 1.0441231028787021 (41 / 80)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5812807881773399, train_loss: 0.9386046972351404, val_loss: 1.0400537314086125 (42 / 80)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.5714285714285714, train_loss: 0.8804272951463834, val_loss: 1.1277720928192139 (43 / 80)\n",
            "train_acc: 0.6217552533992583, val_acc: 0.541871921182266, train_loss: 0.9207747448212726, val_loss: 1.1285162136472504 (44 / 80)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.5911330049261084, train_loss: 0.8544420566782815, val_loss: 1.0964395342202022 (45 / 80)\n",
            "train_acc: 0.6761433868974042, val_acc: 0.5320197044334976, train_loss: 0.853040805447971, val_loss: 1.0764849021516998 (46 / 80)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5812807881773399, train_loss: 0.8051347997780931, val_loss: 1.0548291781852985 (47 / 80)\n",
            "train_acc: 0.6909765142150803, val_acc: 0.6206896551724138, train_loss: 0.7858065099297702, val_loss: 0.9601221865621107 (48 / 80)\n",
            "train_acc: 0.7379480840543882, val_acc: 0.645320197044335, train_loss: 0.6991468897119293, val_loss: 0.8902628134036886 (49 / 80)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.6551724137931034, train_loss: 0.5949805986380253, val_loss: 0.9024412734755154 (50 / 80)\n",
            "train_acc: 0.7861557478368356, val_acc: 0.6502463054187192, train_loss: 0.5721001311197269, val_loss: 0.9060757858999844 (51 / 80)\n",
            "train_acc: 0.7812113720642769, val_acc: 0.6354679802955665, train_loss: 0.586283428873061, val_loss: 0.8987611655531258 (52 / 80)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6403940886699507, train_loss: 0.5152946879306741, val_loss: 0.9180378975539372 (53 / 80)\n",
            "train_acc: 0.8022249690976514, val_acc: 0.6206896551724138, train_loss: 0.5634213156988948, val_loss: 0.9302061590655096 (54 / 80)\n",
            "train_acc: 0.7985166872682324, val_acc: 0.6403940886699507, train_loss: 0.5359824541841066, val_loss: 0.9233844752969413 (55 / 80)\n",
            "train_acc: 0.8158220024721878, val_acc: 0.645320197044335, train_loss: 0.5135496058334379, val_loss: 0.9221451755227714 (56 / 80)\n",
            "train_acc: 0.8084054388133498, val_acc: 0.6551724137931034, train_loss: 0.4997240919412582, val_loss: 0.9296531923886003 (57 / 80)\n",
            "train_acc: 0.8294190358467244, val_acc: 0.645320197044335, train_loss: 0.4761414296547474, val_loss: 0.9388067537340624 (58 / 80)\n",
            "train_acc: 0.8281829419035847, val_acc: 0.625615763546798, train_loss: 0.48682703742727507, val_loss: 0.9763080354394584 (59 / 80)\n",
            "train_acc: 0.8158220024721878, val_acc: 0.6354679802955665, train_loss: 0.48625512073007593, val_loss: 0.9724553083551342 (60 / 80)\n",
            "train_acc: 0.8207663782447466, val_acc: 0.6305418719211823, train_loss: 0.47333962846966404, val_loss: 0.9849876288709969 (61 / 80)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6403940886699507, train_loss: 0.4930337985012823, val_loss: 0.9632591214673273 (62 / 80)\n",
            "train_acc: 0.8294190358467244, val_acc: 0.625615763546798, train_loss: 0.46177852035894973, val_loss: 0.9884029513803022 (63 / 80)\n",
            "train_acc: 0.823238566131026, val_acc: 0.6403940886699507, train_loss: 0.4685932102766261, val_loss: 1.0060558771264965 (64 / 80)\n",
            "train_acc: 0.8281829419035847, val_acc: 0.6354679802955665, train_loss: 0.438939513544217, val_loss: 0.9815003419744557 (65 / 80)\n",
            "train_acc: 0.8590852904820766, val_acc: 0.6354679802955665, train_loss: 0.42789524387480743, val_loss: 1.0090743262192299 (66 / 80)\n",
            "train_acc: 0.861557478368356, val_acc: 0.6305418719211823, train_loss: 0.4090430800088109, val_loss: 0.9809014488910807 (67 / 80)\n",
            "train_acc: 0.8504326328800988, val_acc: 0.6305418719211823, train_loss: 0.40116065729533784, val_loss: 0.9977589578464113 (68 / 80)\n",
            "train_acc: 0.8566131025957973, val_acc: 0.625615763546798, train_loss: 0.430286761433144, val_loss: 1.0251140717802376 (69 / 80)\n",
            "train_acc: 0.8393077873918418, val_acc: 0.6403940886699507, train_loss: 0.42102183543412736, val_loss: 1.0241043505997494 (70 / 80)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6403940886699507, train_loss: 0.4173261045083422, val_loss: 0.9891311567405174 (71 / 80)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6305418719211823, train_loss: 0.44632277730737246, val_loss: 1.0030901719783913 (72 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.25077484213923407\n",
            "lr 0.0008953725585146094, batch 14, decay 0.000203492637897574, gamma 0.04966470353985619, val accuracy 0.6551724137931034, val loss 0.9024412734755154 [16 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.6848678710363327e-05, 'batch_size': 13, 'weight_decay': 2.434939383279698e-05, 'gamma': 0.8043372181468511}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7895991986407926, val_loss: 1.7894282710963283 (1 / 80)\n",
            "train_acc: 0.1631644004944376, val_acc: 0.18226600985221675, train_loss: 1.7894321033185434, val_loss: 1.7887662936901223 (2 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7891038642972892, val_loss: 1.7881003588878464 (3 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7889707117941236, val_loss: 1.7875428005979566 (4 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18719211822660098, train_loss: 1.7875054267192505, val_loss: 1.786891032909525 (5 / 80)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.20689655172413793, train_loss: 1.7882221506906233, val_loss: 1.786285328160366 (6 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.22167487684729065, train_loss: 1.7876705911162463, val_loss: 1.7856773619581325 (7 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2512315270935961, train_loss: 1.7863168135856373, val_loss: 1.7851064140573512 (8 / 80)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.2857142857142857, train_loss: 1.7852237161216689, val_loss: 1.784512523359853 (9 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.2561576354679803, train_loss: 1.7848315443774532, val_loss: 1.7838956857549733 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18046971569839307\n",
            "lr 1.6848678710363327e-05, batch 13, decay 2.434939383279698e-05, gamma 0.8043372181468511, val accuracy 0.2857142857142857, val loss 1.784512523359853 [17 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 4.783176617531722e-05, 'batch_size': 10, 'weight_decay': 0.0009642418472764449, 'gamma': 0.03561973625955027}\n",
            "train_acc: 0.1668726823238566, val_acc: 0.2019704433497537, train_loss: 1.7896279705174922, val_loss: 1.7886661238271027 (1 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.19704433497536947, train_loss: 1.7885034353977671, val_loss: 1.7877183935325134 (2 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.21674876847290642, train_loss: 1.7882599864518833, val_loss: 1.7868574845967033 (3 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18719211822660098, train_loss: 1.7860787015026078, val_loss: 1.7858835646671614 (4 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7862809827212793, val_loss: 1.7849680778428252 (5 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7849221876436758, val_loss: 1.78396161260276 (6 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7843121241580129, val_loss: 1.7830340339632458 (7 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.784400378081059, val_loss: 1.7821194802599 (8 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7832948828509771, val_loss: 1.781144921415545 (9 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7828001223034853, val_loss: 1.7802673073237754 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18170580964153277\n",
            "lr 4.783176617531722e-05, batch 10, decay 0.0009642418472764449, gamma 0.03561973625955027, val accuracy 0.21674876847290642, val loss 1.7868574845967033 [18 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0002531721137862798, 'batch_size': 8, 'weight_decay': 0.0009655920272047319, 'gamma': 0.15488009464632205}\n",
            "train_acc: 0.18294190358467244, val_acc: 0.3054187192118227, train_loss: 1.789054440184783, val_loss: 1.7843526437364776 (1 / 80)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.18226600985221675, train_loss: 1.7816456823030715, val_loss: 1.7761704557634928 (2 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7754314595600877, val_loss: 1.767180021760499 (3 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.765440572177524, val_loss: 1.7567397649652265 (4 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7581094434146387, val_loss: 1.7490777851912775 (5 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.7578396468581021, val_loss: 1.7432840663224018 (6 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.19704433497536947, train_loss: 1.7535008460246442, val_loss: 1.737018322709746 (7 / 80)\n",
            "train_acc: 0.2311495673671199, val_acc: 0.29064039408866993, train_loss: 1.7387481115951822, val_loss: 1.7277642194860674 (8 / 80)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.33004926108374383, train_loss: 1.7345173322078766, val_loss: 1.7141256074012794 (9 / 80)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.2413793103448276, train_loss: 1.7129745944616084, val_loss: 1.6908158856659687 (10 / 80)\n",
            "train_acc: 0.29913473423980225, val_acc: 0.2857142857142857, train_loss: 1.690199688869, val_loss: 1.636707287703829 (11 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3251231527093596, train_loss: 1.632972244131845, val_loss: 1.5848777006412376 (12 / 80)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.3399014778325123, train_loss: 1.6032216148117122, val_loss: 1.5376284539405936 (13 / 80)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3103448275862069, train_loss: 1.5741397995589248, val_loss: 1.6105776449729656 (14 / 80)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.35960591133004927, train_loss: 1.59932220998889, val_loss: 1.5170055375310587 (15 / 80)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.3399014778325123, train_loss: 1.5544735265455965, val_loss: 1.4908969290738034 (16 / 80)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3448275862068966, train_loss: 1.522565576879881, val_loss: 1.5345609675487275 (17 / 80)\n",
            "train_acc: 0.34610630407911, val_acc: 0.33497536945812806, train_loss: 1.5117590338986353, val_loss: 1.4851932525634766 (18 / 80)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.35467980295566504, train_loss: 1.4987435332040115, val_loss: 1.454722967053869 (19 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.3842364532019704, train_loss: 1.4626893840997268, val_loss: 1.4561962488249605 (20 / 80)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.35467980295566504, train_loss: 1.521939418224528, val_loss: 1.4407730219986639 (21 / 80)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.35467980295566504, train_loss: 1.4535022618891429, val_loss: 1.4627476754446922 (22 / 80)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.41379310344827586, train_loss: 1.4439881558176613, val_loss: 1.4280078032333863 (23 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.39901477832512317, train_loss: 1.428920632681829, val_loss: 1.4459364575705504 (24 / 80)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.3842364532019704, train_loss: 1.44481319373264, val_loss: 1.3868786968621127 (25 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.37438423645320196, train_loss: 1.4469472317229979, val_loss: 1.3776721032382233 (26 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.3793103448275862, train_loss: 1.3940344419703348, val_loss: 1.397299778285285 (27 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.39901477832512317, train_loss: 1.3589537610819078, val_loss: 1.342888882007505 (28 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4187192118226601, train_loss: 1.4159452602801423, val_loss: 1.3340356426285993 (29 / 80)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.4482758620689655, train_loss: 1.376444389410455, val_loss: 1.3205630973054858 (30 / 80)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.3842364532019704, train_loss: 1.3633285380706504, val_loss: 1.3920504136625769 (31 / 80)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.4729064039408867, train_loss: 1.359041180392573, val_loss: 1.295046733517952 (32 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.3793103448275862, train_loss: 1.3684176532240822, val_loss: 1.344804361535998 (33 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.42857142857142855, train_loss: 1.387951353129704, val_loss: 1.2940462780703466 (34 / 80)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.39901477832512317, train_loss: 1.346973545324375, val_loss: 1.3040526982011467 (35 / 80)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.3399014778325123, train_loss: 1.339445559144462, val_loss: 1.370599028512175 (36 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4729064039408867, train_loss: 1.3215143211987168, val_loss: 1.2611518734194376 (37 / 80)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.4187192118226601, train_loss: 1.3015599645701859, val_loss: 1.2635611589319014 (38 / 80)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.46798029556650245, train_loss: 1.2820683000114261, val_loss: 1.2456508246548657 (39 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.37438423645320196, train_loss: 1.2885912913179811, val_loss: 1.3625852268904888 (40 / 80)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.46798029556650245, train_loss: 1.2707391330426645, val_loss: 1.205890939153474 (41 / 80)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.3891625615763547, train_loss: 1.2454068959864462, val_loss: 1.3970345182371844 (42 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.46798029556650245, train_loss: 1.2318289724946465, val_loss: 1.2982136063975067 (43 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.43349753694581283, train_loss: 1.246812275814627, val_loss: 1.218558172287025 (44 / 80)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.4827586206896552, train_loss: 1.20597825961001, val_loss: 1.2008642383984156 (45 / 80)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.4975369458128079, train_loss: 1.2114606610924117, val_loss: 1.1791857381172368 (46 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4975369458128079, train_loss: 1.1912728156088603, val_loss: 1.314421798208077 (47 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.5172413793103449, train_loss: 1.177028500842223, val_loss: 1.168079918241266 (48 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5221674876847291, train_loss: 1.1236788315885, val_loss: 1.1751735735996602 (49 / 80)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5320197044334976, train_loss: 1.104209935561983, val_loss: 1.1580818873908132 (50 / 80)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5221674876847291, train_loss: 1.0912479657325227, val_loss: 1.1983618284093922 (51 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.5123152709359606, train_loss: 1.0847943963756963, val_loss: 1.1532148607258725 (52 / 80)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5221674876847291, train_loss: 1.0667636527119224, val_loss: 1.1452814913148364 (53 / 80)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.4975369458128079, train_loss: 1.0839065208717977, val_loss: 1.137929481532186 (54 / 80)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5024630541871922, train_loss: 1.0429119223864618, val_loss: 1.1620496696439282 (55 / 80)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.5073891625615764, train_loss: 1.041378605351018, val_loss: 1.1465212227088477 (56 / 80)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5369458128078818, train_loss: 1.045298169068854, val_loss: 1.1617277737321525 (57 / 80)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.49261083743842365, train_loss: 1.0310620427573713, val_loss: 1.161767637641559 (58 / 80)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5073891625615764, train_loss: 1.0508521808534677, val_loss: 1.170350309956837 (59 / 80)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.5123152709359606, train_loss: 1.048866125208191, val_loss: 1.1291136083931759 (60 / 80)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.5270935960591133, train_loss: 1.0157268091538927, val_loss: 1.1373830728342968 (61 / 80)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.5123152709359606, train_loss: 1.0023694249107162, val_loss: 1.128943940101586 (62 / 80)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5172413793103449, train_loss: 1.0168085429812834, val_loss: 1.1268905142845191 (63 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5221674876847291, train_loss: 0.9833448779008297, val_loss: 1.1459653988260354 (64 / 80)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.5270935960591133, train_loss: 0.9850073246784941, val_loss: 1.1229854079302897 (65 / 80)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5123152709359606, train_loss: 0.9923739978497933, val_loss: 1.2482002072146374 (66 / 80)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.5270935960591133, train_loss: 0.9946838810358413, val_loss: 1.135863816356424 (67 / 80)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5221674876847291, train_loss: 1.0003854409136494, val_loss: 1.1240946483142271 (68 / 80)\n",
            "train_acc: 0.61557478368356, val_acc: 0.5123152709359606, train_loss: 0.9791652142485818, val_loss: 1.1817280153922847 (69 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5467980295566502, train_loss: 0.9886539778102313, val_loss: 1.117496659603025 (70 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5123152709359606, train_loss: 0.955635701475391, val_loss: 1.170106169331837 (71 / 80)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5467980295566502, train_loss: 0.9765714050370772, val_loss: 1.1125595358204958 (72 / 80)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5123152709359606, train_loss: 0.9644300059423458, val_loss: 1.152000006783772 (73 / 80)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.5517241379310345, train_loss: 0.9233744778061385, val_loss: 1.1015644120465358 (74 / 80)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5073891625615764, train_loss: 0.9521179968406007, val_loss: 1.1700292035863904 (75 / 80)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.541871921182266, train_loss: 0.9454403006102158, val_loss: 1.1266387524863182 (76 / 80)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5369458128078818, train_loss: 0.9383655793881976, val_loss: 1.1959145703339225 (77 / 80)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.5467980295566502, train_loss: 0.9270373345600218, val_loss: 1.139235940179214 (78 / 80)\n",
            "train_acc: 0.6118665018541409, val_acc: 0.5172413793103449, train_loss: 0.9692476349796442, val_loss: 1.1845936270182944 (79 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5566502463054187, train_loss: 0.9163771433058127, val_loss: 1.1655204400346784 (80 / 80)\n",
            "lr 0.0002531721137862798, batch 8, decay 0.0009655920272047319, gamma 0.15488009464632205, val accuracy 0.5566502463054187, val loss 1.1655204400346784 [19 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.905352466839929e-05, 'batch_size': 14, 'weight_decay': 8.696974751849823e-05, 'gamma': 0.04630137073797267}\n",
            "train_acc: 0.1557478368355995, val_acc: 0.18226600985221675, train_loss: 1.790477024315314, val_loss: 1.7890354066059506 (1 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.7889568214805518, val_loss: 1.7886278588196327 (2 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7898984197043666, val_loss: 1.7882286680155788 (3 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7893896434451506, val_loss: 1.7878210256839622 (4 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7890916440926024, val_loss: 1.787447789619709 (5 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18719211822660098, train_loss: 1.7885848157043363, val_loss: 1.78703733970379 (6 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18719211822660098, train_loss: 1.7870276687466464, val_loss: 1.7866613453832165 (7 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.1921182266009852, train_loss: 1.788017912759769, val_loss: 1.7862822639531102 (8 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.1921182266009852, train_loss: 1.7868480725105673, val_loss: 1.7859024919312576 (9 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2019704433497537, train_loss: 1.7879698787837741, val_loss: 1.7855143999231273 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1841779975278121\n",
            "lr 1.905352466839929e-05, batch 14, decay 8.696974751849823e-05, gamma 0.04630137073797267, val accuracy 0.2019704433497537, val loss 1.7855143999231273 [20 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00037657242094956675, 'batch_size': 14, 'weight_decay': 0.0006370553781871713, 'gamma': 0.0812292656012972}\n",
            "train_acc: 0.17058096415327564, val_acc: 0.19704433497536947, train_loss: 1.792964639121434, val_loss: 1.7871162357001469 (1 / 80)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.18226600985221675, train_loss: 1.786119551682207, val_loss: 1.7808319905708576 (2 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.20689655172413793, train_loss: 1.7800710531336121, val_loss: 1.7730719262155994 (3 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7724212011683858, val_loss: 1.7644403556297565 (4 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7650907133948817, val_loss: 1.755947441890322 (5 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.759258204396487, val_loss: 1.7498310763260414 (6 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7608038402163644, val_loss: 1.7453570283692459 (7 / 80)\n",
            "train_acc: 0.21755253399258342, val_acc: 0.2019704433497537, train_loss: 1.753454827997092, val_loss: 1.7398754769358142 (8 / 80)\n",
            "train_acc: 0.21755253399258342, val_acc: 0.22167487684729065, train_loss: 1.7480005425192664, val_loss: 1.7332626827831925 (9 / 80)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.22167487684729065, train_loss: 1.7385284420291631, val_loss: 1.7215363362739826 (10 / 80)\n",
            "underfit -> train_accuracy = 0.22991347342398022\n",
            "lr 0.00037657242094956675, batch 14, decay 0.0006370553781871713, gamma 0.0812292656012972, val accuracy 0.22167487684729065, val loss 1.7332626827831925 [21 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0002055106070295775, 'batch_size': 10, 'weight_decay': 2.792640215163258e-05, 'gamma': 0.6679608767136781}\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7912129636748022, val_loss: 1.7894050892937947 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.787606562465908, val_loss: 1.7858272338735646 (2 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.23645320197044334, train_loss: 1.7843774088528306, val_loss: 1.7826859375526165 (3 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.781033476291982, val_loss: 1.7788196637712677 (4 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7786532612459915, val_loss: 1.7750854110482879 (5 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.772522323653194, val_loss: 1.7704382506497387 (6 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7707996842887699, val_loss: 1.765560981088084 (7 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.76552544182399, val_loss: 1.76116462587723 (8 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7601813976785308, val_loss: 1.7567053892342328 (9 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7592298577830876, val_loss: 1.7529475929701857 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18046971569839307\n",
            "lr 0.0002055106070295775, batch 10, decay 2.792640215163258e-05, gamma 0.6679608767136781, val accuracy 0.23645320197044334, val loss 1.7826859375526165 [22 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00012041850834594425, 'batch_size': 11, 'weight_decay': 2.0271215230368365e-05, 'gamma': 0.042630499910263776}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.1625615763546798, train_loss: 1.792549537787184, val_loss: 1.7912093306997139 (1 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.1477832512315271, train_loss: 1.7907904981830065, val_loss: 1.788928284433675 (2 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.270935960591133, train_loss: 1.7881625402990466, val_loss: 1.786708316779489 (3 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.2413793103448276, train_loss: 1.786511115002249, val_loss: 1.7845563042927257 (4 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.24630541871921183, train_loss: 1.7851231970510022, val_loss: 1.7823121124887702 (5 / 80)\n",
            "train_acc: 0.22249690976514216, val_acc: 0.2019704433497537, train_loss: 1.783069941994581, val_loss: 1.7801735336557398 (6 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.18226600985221675, train_loss: 1.7792985160801702, val_loss: 1.7776191586931351 (7 / 80)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18226600985221675, train_loss: 1.778994392405629, val_loss: 1.774961579609387 (8 / 80)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.18226600985221675, train_loss: 1.7738786147463013, val_loss: 1.7720296705884886 (9 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.7730262889555564, val_loss: 1.7689976709816844 (10 / 80)\n",
            "underfit -> train_accuracy = 0.20148331273176762\n",
            "lr 0.00012041850834594425, batch 11, decay 2.0271215230368365e-05, gamma 0.042630499910263776, val accuracy 0.270935960591133, val loss 1.786708316779489 [23 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.2379438732413894e-05, 'batch_size': 11, 'weight_decay': 7.883912666714595e-06, 'gamma': 0.29274769663507344}\n",
            "train_acc: 0.14585908529048208, val_acc: 0.10344827586206896, train_loss: 1.7930757482208044, val_loss: 1.7922773149800417 (1 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18719211822660098, train_loss: 1.792243747540251, val_loss: 1.7917129006879082 (2 / 80)\n",
            "train_acc: 0.15451174289245984, val_acc: 0.2019704433497537, train_loss: 1.791853348610575, val_loss: 1.791147052360873 (3 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.22660098522167488, train_loss: 1.7913818042564156, val_loss: 1.7906180473384012 (4 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.21674876847290642, train_loss: 1.7911705879404753, val_loss: 1.7900925023215157 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.2413793103448276, train_loss: 1.7898380803531415, val_loss: 1.7895808959829396 (6 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.23645320197044334, train_loss: 1.789481217840546, val_loss: 1.7890240435529812 (7 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.2413793103448276, train_loss: 1.7902858560842696, val_loss: 1.78850945874388 (8 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.24630541871921183, train_loss: 1.7881288836411993, val_loss: 1.7879804173126597 (9 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.23645320197044334, train_loss: 1.78863177090257, val_loss: 1.7874526595834441 (10 / 80)\n",
            "underfit -> train_accuracy = 0.17676143386897405\n",
            "lr 2.2379438732413894e-05, batch 11, decay 7.883912666714595e-06, gamma 0.29274769663507344, val accuracy 0.24630541871921183, val loss 1.7879804173126597 [24 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.996216955726189e-05, 'batch_size': 10, 'weight_decay': 5.670661568395657e-06, 'gamma': 0.6007000313731713}\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18719211822660098, train_loss: 1.7903237045179634, val_loss: 1.7890934409766361 (1 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.20689655172413793, train_loss: 1.7892668035033312, val_loss: 1.788133008139474 (2 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.21674876847290642, train_loss: 1.788569912774896, val_loss: 1.7871808894162107 (3 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.2315270935960591, train_loss: 1.7876057032454293, val_loss: 1.786216427539957 (4 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.24630541871921183, train_loss: 1.7872999088725878, val_loss: 1.7853131300122866 (5 / 80)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.2413793103448276, train_loss: 1.7855439258299592, val_loss: 1.7843019639329958 (6 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.24630541871921183, train_loss: 1.7847676324313886, val_loss: 1.7833733517548134 (7 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.2413793103448276, train_loss: 1.7832985089352753, val_loss: 1.7823802291466098 (8 / 80)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.22660098522167488, train_loss: 1.7821050117572836, val_loss: 1.7814334519390989 (9 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.21182266009852216, train_loss: 1.7827060381767923, val_loss: 1.780527304545999 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18665018541409148\n",
            "lr 2.996216955726189e-05, batch 10, decay 5.670661568395657e-06, gamma 0.6007000313731713, val accuracy 0.24630541871921183, val loss 1.7853131300122866 [25 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 5.995488393472277e-05, 'batch_size': 13, 'weight_decay': 0.00012064524987386579, 'gamma': 0.6958797886028412}\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7923434980130755, val_loss: 1.7911480559504092 (1 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7905060741014327, val_loss: 1.7901057316164666 (2 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.7900737914520377, val_loss: 1.7890593905754277 (3 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18719211822660098, train_loss: 1.788598641624262, val_loss: 1.7880795031345535 (4 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18719211822660098, train_loss: 1.7884649695513128, val_loss: 1.7870584150840496 (5 / 80)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.19704433497536947, train_loss: 1.787133121962011, val_loss: 1.786107160774945 (6 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.22167487684729065, train_loss: 1.78682032857454, val_loss: 1.785096594265529 (7 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.22167487684729065, train_loss: 1.7859037007920084, val_loss: 1.7841444773039794 (8 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.2413793103448276, train_loss: 1.7847974739499086, val_loss: 1.7831120872732453 (9 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.2512315270935961, train_loss: 1.7835114637323009, val_loss: 1.7821070014549594 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1965389369592089\n",
            "lr 5.995488393472277e-05, batch 13, decay 0.00012064524987386579, gamma 0.6958797886028412, val accuracy 0.2512315270935961, val loss 1.7821070014549594 [26 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0002675993513121015, 'batch_size': 15, 'weight_decay': 2.2029421346186062e-06, 'gamma': 0.12487823074737385}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.789440775389135, val_loss: 1.7872180650974143 (1 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.2019704433497537, train_loss: 1.7866482121688032, val_loss: 1.7839031495484226 (2 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.2413793103448276, train_loss: 1.783963984405744, val_loss: 1.7808871592206907 (3 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18719211822660098, train_loss: 1.780119381080599, val_loss: 1.7772946334237536 (4 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7778425844402337, val_loss: 1.7735321609844714 (5 / 80)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18226600985221675, train_loss: 1.7741894876706439, val_loss: 1.7693386224690328 (6 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7702956933468323, val_loss: 1.7643736459938764 (7 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7662352305849638, val_loss: 1.7604945486989514 (8 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7634515078607094, val_loss: 1.7558644346415704 (9 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7554671189693645, val_loss: 1.7518606197657844 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18170580964153277\n",
            "lr 0.0002675993513121015, batch 15, decay 2.2029421346186062e-06, gamma 0.12487823074737385, val accuracy 0.2413793103448276, val loss 1.7808871592206907 [27 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00013201408595811797, 'batch_size': 15, 'weight_decay': 0.0008423099611946554, 'gamma': 0.07363128886597509}\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7885736938754766, val_loss: 1.7875813492413224 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.17733990147783252, train_loss: 1.7867762494293515, val_loss: 1.7850503128737651 (2 / 80)\n",
            "train_acc: 0.1631644004944376, val_acc: 0.18226600985221675, train_loss: 1.7856618255855716, val_loss: 1.7828014942225565 (3 / 80)\n",
            "train_acc: 0.1631644004944376, val_acc: 0.17733990147783252, train_loss: 1.7835409938920708, val_loss: 1.7805004965495594 (4 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.16748768472906403, train_loss: 1.7802320860224985, val_loss: 1.778071934366461 (5 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.13793103448275862, train_loss: 1.778160168891784, val_loss: 1.7755755315273267 (6 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.16748768472906403, train_loss: 1.7765854337748845, val_loss: 1.7729688319079395 (7 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7737261447387809, val_loss: 1.7701868259260807 (8 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7719885822574346, val_loss: 1.767380592271025 (9 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7692077426592117, val_loss: 1.7645380068295107 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1915945611866502\n",
            "lr 0.00013201408595811797, batch 15, decay 0.0008423099611946554, gamma 0.07363128886597509, val accuracy 0.18226600985221675, val loss 1.7875813492413224 [28 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.3143892945388419e-05, 'batch_size': 10, 'weight_decay': 1.9203760627025567e-06, 'gamma': 0.03335634522775482}\n",
            "train_acc: 0.15822002472187885, val_acc: 0.1625615763546798, train_loss: 1.7923226054430892, val_loss: 1.792053003616521 (1 / 80)\n",
            "train_acc: 0.15327564894932014, val_acc: 0.1625615763546798, train_loss: 1.792616332564572, val_loss: 1.791713618879835 (2 / 80)\n",
            "train_acc: 0.14091470951792337, val_acc: 0.09359605911330049, train_loss: 1.79258643667247, val_loss: 1.7913775567350716 (3 / 80)\n",
            "train_acc: 0.15451174289245984, val_acc: 0.09359605911330049, train_loss: 1.7927947019322399, val_loss: 1.7910394169426904 (4 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.11822660098522167, train_loss: 1.790465960249176, val_loss: 1.7907165717608824 (5 / 80)\n",
            "train_acc: 0.15945611866501855, val_acc: 0.12807881773399016, train_loss: 1.7915009675715556, val_loss: 1.7903897315997797 (6 / 80)\n",
            "train_acc: 0.16069221260815822, val_acc: 0.12807881773399016, train_loss: 1.7906161045703959, val_loss: 1.7900824969625238 (7 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.1477832512315271, train_loss: 1.789972129209964, val_loss: 1.7897561465578127 (8 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.1724137931034483, train_loss: 1.7906595636504543, val_loss: 1.7894364712860784 (9 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.17733990147783252, train_loss: 1.7897932164011838, val_loss: 1.789126704479086 (10 / 80)\n",
            "underfit -> train_accuracy = 0.16440049443757726\n",
            "lr 1.3143892945388419e-05, batch 10, decay 1.9203760627025567e-06, gamma 0.03335634522775482, val accuracy 0.17733990147783252, val loss 1.789126704479086 [29 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.1085429508322516e-05, 'batch_size': 15, 'weight_decay': 9.705207707771695e-05, 'gamma': 0.011606333970593474}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7915245732211948, val_loss: 1.7914933612193968 (1 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7914812242144855, val_loss: 1.7912060139801702 (2 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7905706149538603, val_loss: 1.790916427015671 (3 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7906499894794043, val_loss: 1.7906431693748888 (4 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7909508790309703, val_loss: 1.7903463171033436 (5 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.18226600985221675, train_loss: 1.7897395726629477, val_loss: 1.7900766069665919 (6 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7892998803236575, val_loss: 1.7897902715382317 (7 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.789698251098284, val_loss: 1.789504631399521 (8 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7897162738040882, val_loss: 1.789235137953547 (9 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18719211822660098, train_loss: 1.7896169676032143, val_loss: 1.7889673110886748 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1915945611866502\n",
            "lr 2.1085429508322516e-05, batch 15, decay 9.705207707771695e-05, gamma 0.011606333970593474, val accuracy 0.18719211822660098, val loss 1.7889673110886748 [30 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.883937077429172e-05, 'batch_size': 11, 'weight_decay': 0.00018999372579880553, 'gamma': 0.43087269959236435}\n",
            "train_acc: 0.12484548825710753, val_acc: 0.08866995073891626, train_loss: 1.794301411719493, val_loss: 1.7936250382456287 (1 / 80)\n",
            "train_acc: 0.15203955500618047, val_acc: 0.20689655172413793, train_loss: 1.7933033194913264, val_loss: 1.7925488778523035 (2 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.791791564307195, val_loss: 1.7914894044105643 (3 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.791463270912359, val_loss: 1.7904578876025572 (4 / 80)\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.790903668615815, val_loss: 1.7894233653110823 (5 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7885386861298966, val_loss: 1.788465787037253 (6 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.788704072147129, val_loss: 1.7874867140953177 (7 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7872472086412503, val_loss: 1.7865410138820779 (8 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7855913818840339, val_loss: 1.7855855414432844 (9 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7861148453466087, val_loss: 1.7845964754743529 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1792336217552534\n",
            "lr 3.883937077429172e-05, batch 11, decay 0.00018999372579880553, gamma 0.43087269959236435, val accuracy 0.20689655172413793, val loss 1.7925488778523035 [31 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.599327095348746e-05, 'batch_size': 9, 'weight_decay': 4.620437981705745e-06, 'gamma': 0.5441579856142484}\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7903038801162587, val_loss: 1.789510677600729 (1 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7903637741640561, val_loss: 1.7883795488056877 (2 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.789259526137221, val_loss: 1.7874711458318926 (3 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7871661915619972, val_loss: 1.7864242269487804 (4 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7869992991460415, val_loss: 1.785475764955793 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7852324287145778, val_loss: 1.784562998217315 (6 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7853642168681614, val_loss: 1.7835972467666776 (7 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7839785507789205, val_loss: 1.7825771828590355 (8 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.784311771982238, val_loss: 1.7816898141588484 (9 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7826340994227803, val_loss: 1.780665792855136 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1965389369592089\n",
            "lr 3.599327095348746e-05, batch 9, decay 4.620437981705745e-06, gamma 0.5441579856142484, val accuracy 0.18226600985221675, val loss 1.789510677600729 [32 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.198340929319736e-05, 'batch_size': 8, 'weight_decay': 3.1784350343264584e-05, 'gamma': 0.6970499109344321}\n",
            "train_acc: 0.15451174289245984, val_acc: 0.18226600985221675, train_loss: 1.7928273123775336, val_loss: 1.7924881515831783 (1 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7922214862000663, val_loss: 1.7912744412868482 (2 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7924582082939384, val_loss: 1.7901339108133552 (3 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7902392411261465, val_loss: 1.7890180507904203 (4 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7884125431034856, val_loss: 1.7877352055657674 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7879710526047885, val_loss: 1.786680124663367 (6 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7865245489608519, val_loss: 1.7855473686321615 (7 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7856711953767888, val_loss: 1.7843824648504774 (8 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.785597116602366, val_loss: 1.783299290487919 (9 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.784121125531285, val_loss: 1.7821250032321574 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18541409147095178\n",
            "lr 3.198340929319736e-05, batch 8, decay 3.1784350343264584e-05, gamma 0.6970499109344321, val accuracy 0.18226600985221675, val loss 1.7924881515831783 [33 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0004399454097313953, 'batch_size': 11, 'weight_decay': 3.263890362796817e-05, 'gamma': 0.028474867178585227}\n",
            "train_acc: 0.18294190358467244, val_acc: 0.22167487684729065, train_loss: 1.786174948194855, val_loss: 1.7808288787973339 (1 / 80)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.270935960591133, train_loss: 1.7776872016885519, val_loss: 1.7687880534843858 (2 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18719211822660098, train_loss: 1.7658059137271274, val_loss: 1.7556556422134926 (3 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.27586206896551724, train_loss: 1.7610154384735635, val_loss: 1.7482037033353532 (4 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.2413793103448276, train_loss: 1.7498694127805448, val_loss: 1.739262146315551 (5 / 80)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.27586206896551724, train_loss: 1.7482927093105056, val_loss: 1.726956122027242 (6 / 80)\n",
            "train_acc: 0.24598269468479605, val_acc: 0.2413793103448276, train_loss: 1.7343539387098201, val_loss: 1.7036950323969273 (7 / 80)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.24630541871921183, train_loss: 1.7095959328013681, val_loss: 1.686984711679919 (8 / 80)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.3054187192118227, train_loss: 1.6659774316108713, val_loss: 1.5769165214059389 (9 / 80)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3251231527093596, train_loss: 1.605791806585267, val_loss: 1.5711847625929733 (10 / 80)\n",
            "train_acc: 0.30778739184178, val_acc: 0.32019704433497537, train_loss: 1.5653303758470325, val_loss: 1.5019696986146749 (11 / 80)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.3645320197044335, train_loss: 1.54336654756803, val_loss: 1.6111215065265525 (12 / 80)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.3251231527093596, train_loss: 1.5341585961496285, val_loss: 1.4745340106522509 (13 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3645320197044335, train_loss: 1.5260404295326016, val_loss: 1.4710213750454004 (14 / 80)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.2955665024630542, train_loss: 1.5162324850874571, val_loss: 1.531145482814958 (15 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3645320197044335, train_loss: 1.4857536969874492, val_loss: 1.4574556526879372 (16 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.39408866995073893, train_loss: 1.5002803102559301, val_loss: 1.4244163617711936 (17 / 80)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.41379310344827586, train_loss: 1.4500172297356302, val_loss: 1.4028443168536784 (18 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3891625615763547, train_loss: 1.4843863841187674, val_loss: 1.416801592986572 (19 / 80)\n",
            "train_acc: 0.377008652657602, val_acc: 0.3645320197044335, train_loss: 1.4639962198413052, val_loss: 1.4153139514876116 (20 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4088669950738916, train_loss: 1.4358703169893423, val_loss: 1.4060507043829105 (21 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.43349753694581283, train_loss: 1.4140312637769985, val_loss: 1.3938969461788684 (22 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.37438423645320196, train_loss: 1.423202447455068, val_loss: 1.374310329042632 (23 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.4039408866995074, train_loss: 1.4092237488153692, val_loss: 1.3654413707737851 (24 / 80)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.43842364532019706, train_loss: 1.4175471169102767, val_loss: 1.342031460090224 (25 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.4187192118226601, train_loss: 1.3809293593994914, val_loss: 1.322366358611384 (26 / 80)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.3842364532019704, train_loss: 1.382617865195233, val_loss: 1.3168861824890663 (27 / 80)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.42857142857142855, train_loss: 1.3480592064273962, val_loss: 1.324254757665061 (28 / 80)\n",
            "train_acc: 0.415327564894932, val_acc: 0.41379310344827586, train_loss: 1.3335929773793969, val_loss: 1.3677612375743284 (29 / 80)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4630541871921182, train_loss: 1.346611248842718, val_loss: 1.2886023060441605 (30 / 80)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.4187192118226601, train_loss: 1.3319973962563372, val_loss: 1.3461772256296844 (31 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.43842364532019706, train_loss: 1.3539280892155225, val_loss: 1.276640339437964 (32 / 80)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.4876847290640394, train_loss: 1.3005333492723472, val_loss: 1.2663202467810344 (33 / 80)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.47783251231527096, train_loss: 1.302263988184251, val_loss: 1.2794148772220892 (34 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.4187192118226601, train_loss: 1.3023242492168885, val_loss: 1.2681040942962534 (35 / 80)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.47783251231527096, train_loss: 1.2969016912399027, val_loss: 1.2572762191002005 (36 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.5073891625615764, train_loss: 1.270869871668232, val_loss: 1.2298295856109394 (37 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.47783251231527096, train_loss: 1.2780724841231026, val_loss: 1.210747679759716 (38 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4827586206896552, train_loss: 1.267361853193441, val_loss: 1.2433313471930367 (39 / 80)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.4827586206896552, train_loss: 1.2292726305860229, val_loss: 1.2155800417726264 (40 / 80)\n",
            "train_acc: 0.511742892459827, val_acc: 0.4433497536945813, train_loss: 1.208809780470373, val_loss: 1.2495703773545515 (41 / 80)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.42857142857142855, train_loss: 1.2132038846151496, val_loss: 1.1847744308081753 (42 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.4827586206896552, train_loss: 1.1973712358103399, val_loss: 1.1748961489188847 (43 / 80)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.45320197044334976, train_loss: 1.194709660759373, val_loss: 1.2745383111714141 (44 / 80)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4433497536945813, train_loss: 1.1802830388136347, val_loss: 1.2082030641034318 (45 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.46798029556650245, train_loss: 1.143044337943399, val_loss: 1.1855918512555765 (46 / 80)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5024630541871922, train_loss: 1.127315458614835, val_loss: 1.1577239071794332 (47 / 80)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.4827586206896552, train_loss: 1.123570757463335, val_loss: 1.14254816823405 (48 / 80)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.5073891625615764, train_loss: 1.0736619057997197, val_loss: 1.1287611370603439 (49 / 80)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.5073891625615764, train_loss: 1.035278143414166, val_loss: 1.1250845000074414 (50 / 80)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5073891625615764, train_loss: 1.050646655491757, val_loss: 1.131116128613796 (51 / 80)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.5123152709359606, train_loss: 1.028489035935278, val_loss: 1.1269027106280398 (52 / 80)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5221674876847291, train_loss: 1.0269387605311107, val_loss: 1.1265894488748072 (53 / 80)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5270935960591133, train_loss: 1.02478223383353, val_loss: 1.1229615669532362 (54 / 80)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.5172413793103449, train_loss: 1.0224977455416187, val_loss: 1.1230847571283726 (55 / 80)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5221674876847291, train_loss: 1.0059685161882925, val_loss: 1.123695067290602 (56 / 80)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.5123152709359606, train_loss: 1.010048722454585, val_loss: 1.1328006295735025 (57 / 80)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5172413793103449, train_loss: 1.0095272776664999, val_loss: 1.12807629202387 (58 / 80)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5320197044334976, train_loss: 1.0105207125910722, val_loss: 1.1262729640664726 (59 / 80)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5172413793103449, train_loss: 1.009282129435663, val_loss: 1.1226033286508081 (60 / 80)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.5172413793103449, train_loss: 0.9894624489494248, val_loss: 1.1316954343776984 (61 / 80)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.5073891625615764, train_loss: 1.0077499527719023, val_loss: 1.122639370669285 (62 / 80)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.5172413793103449, train_loss: 0.9903117130949117, val_loss: 1.1170176434986696 (63 / 80)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5320197044334976, train_loss: 0.9711798623259489, val_loss: 1.1205902915870027 (64 / 80)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5369458128078818, train_loss: 0.9860505831919435, val_loss: 1.124489773670441 (65 / 80)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5369458128078818, train_loss: 0.9847337041045591, val_loss: 1.125073643740762 (66 / 80)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5369458128078818, train_loss: 0.9943706465445283, val_loss: 1.1233507253853559 (67 / 80)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5270935960591133, train_loss: 0.9948651758201043, val_loss: 1.1209997032663506 (68 / 80)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.5172413793103449, train_loss: 0.9478679495335215, val_loss: 1.1194363339193936 (69 / 80)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.5270935960591133, train_loss: 0.9509896490865644, val_loss: 1.1238298853629916 (70 / 80)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5369458128078818, train_loss: 0.9662105225956779, val_loss: 1.118209304774336 (71 / 80)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.541871921182266, train_loss: 0.9593249957257944, val_loss: 1.1236164769515615 (72 / 80)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.5172413793103449, train_loss: 0.9908442782383178, val_loss: 1.12382774781711 (73 / 80)\n",
            "train_acc: 0.61557478368356, val_acc: 0.5270935960591133, train_loss: 0.9493398034602072, val_loss: 1.1342344372143298 (74 / 80)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.5369458128078818, train_loss: 0.9813566204938664, val_loss: 1.1290425505544164 (75 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5369458128078818, train_loss: 0.9760363628749352, val_loss: 1.120019984069129 (76 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5320197044334976, train_loss: 0.9467313009669961, val_loss: 1.124017425652208 (77 / 80)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5270935960591133, train_loss: 0.9475437888993026, val_loss: 1.1271809404119482 (78 / 80)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.5270935960591133, train_loss: 0.9654337595066123, val_loss: 1.1222557821884531 (79 / 80)\n",
            "train_acc: 0.6353522867737948, val_acc: 0.5270935960591133, train_loss: 0.9480480616555373, val_loss: 1.1230442444679185 (80 / 80)\n",
            "lr 0.0004399454097313953, batch 11, decay 3.263890362796817e-05, gamma 0.028474867178585227, val accuracy 0.541871921182266, val loss 1.1236164769515615 [34 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00036180239778692643, 'batch_size': 12, 'weight_decay': 2.5691244557863772e-05, 'gamma': 0.7369094218288808}\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.790940792657831, val_loss: 1.7864045568287665 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7855782557476878, val_loss: 1.7799846333235942 (2 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.780024998120236, val_loss: 1.7741656015659202 (3 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7723952103014782, val_loss: 1.7665244393748016 (4 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7656263006927055, val_loss: 1.7580997151107036 (5 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7629583163373403, val_loss: 1.7523001726037764 (6 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7553530035561182, val_loss: 1.7466757550028158 (7 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7568423158600834, val_loss: 1.741093640844223 (8 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7459801563668458, val_loss: 1.734224874985042 (9 / 80)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.3103448275862069, train_loss: 1.7435742529714653, val_loss: 1.7242449345847068 (10 / 80)\n",
            "underfit -> train_accuracy = 0.2249690976514215\n",
            "lr 0.00036180239778692643, batch 12, decay 2.5691244557863772e-05, gamma 0.7369094218288808, val accuracy 0.3103448275862069, val loss 1.7242449345847068 [35 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 5.628622738889949e-05, 'batch_size': 11, 'weight_decay': 2.3498178071729428e-05, 'gamma': 0.02075261186968871}\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7898308451302414, val_loss: 1.7888959986822945 (1 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.1921182266009852, train_loss: 1.788151834892254, val_loss: 1.787287297507225 (2 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.27586206896551724, train_loss: 1.7873030638665293, val_loss: 1.7857967808916064 (3 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.2315270935960591, train_loss: 1.786762634520183, val_loss: 1.7842531744482482 (4 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.21674876847290642, train_loss: 1.7845484427969593, val_loss: 1.7826549161243908 (5 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.20689655172413793, train_loss: 1.7841918419848561, val_loss: 1.7809355300048302 (6 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.1921182266009852, train_loss: 1.782309803149314, val_loss: 1.7793796215151332 (7 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.1921182266009852, train_loss: 1.7809634364874314, val_loss: 1.7777826046121532 (8 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.18226600985221675, train_loss: 1.7784683349253367, val_loss: 1.7759712458831336 (9 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7766911793403484, val_loss: 1.7741898192560732 (10 / 80)\n",
            "underfit -> train_accuracy = 0.207663782447466\n",
            "lr 5.628622738889949e-05, batch 11, decay 2.3498178071729428e-05, gamma 0.02075261186968871, val accuracy 0.27586206896551724, val loss 1.7857967808916064 [36 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0008652828929293144, 'batch_size': 12, 'weight_decay': 0.00015810245434232114, 'gamma': 0.056134226755877197}\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18719211822660098, train_loss: 1.7843857736905808, val_loss: 1.77100556237357 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.21182266009852216, train_loss: 1.7645570083955309, val_loss: 1.7492770537954245 (2 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.1921182266009852, train_loss: 1.7560460518847585, val_loss: 1.7381467284827397 (3 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.733821499627659, val_loss: 1.7206286062747973 (4 / 80)\n",
            "train_acc: 0.26081582200247216, val_acc: 0.270935960591133, train_loss: 1.7120504806598715, val_loss: 1.6625629880745423 (5 / 80)\n",
            "train_acc: 0.31025957972805934, val_acc: 0.31527093596059114, train_loss: 1.6491083347311126, val_loss: 1.5536053362738322 (6 / 80)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.2857142857142857, train_loss: 1.6200772487041535, val_loss: 1.6014699636421768 (7 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.35467980295566504, train_loss: 1.590594791806083, val_loss: 1.5212817843911683 (8 / 80)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.2857142857142857, train_loss: 1.5438696664697014, val_loss: 1.4846553732021688 (9 / 80)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.3251231527093596, train_loss: 1.5151075764256443, val_loss: 1.4589152212800651 (10 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.35467980295566504, train_loss: 1.4694900385970975, val_loss: 1.4407652634117991 (11 / 80)\n",
            "train_acc: 0.377008652657602, val_acc: 0.39408866995073893, train_loss: 1.4461339069680024, val_loss: 1.4375635667387487 (12 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.43842364532019706, train_loss: 1.434220207636377, val_loss: 1.3582016399928503 (13 / 80)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3842364532019704, train_loss: 1.4857000432291492, val_loss: 1.3707127870597275 (14 / 80)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.42857142857142855, train_loss: 1.433487373170511, val_loss: 1.4189287118723828 (15 / 80)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.46798029556650245, train_loss: 1.388946308046395, val_loss: 1.325936642186395 (16 / 80)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.4039408866995074, train_loss: 1.3906634011581005, val_loss: 1.356097498550791 (17 / 80)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.43842364532019706, train_loss: 1.327712007299784, val_loss: 1.2920915099787595 (18 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.39901477832512317, train_loss: 1.3432538917539145, val_loss: 1.4147894499924383 (19 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.458128078817734, train_loss: 1.328394416383524, val_loss: 1.2798945222582137 (20 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4729064039408867, train_loss: 1.3225058473379563, val_loss: 1.2417410641468216 (21 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4236453201970443, train_loss: 1.2970434490623521, val_loss: 1.2878327093688138 (22 / 80)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.46798029556650245, train_loss: 1.3066334314782482, val_loss: 1.220058940314307 (23 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.5024630541871922, train_loss: 1.2890165768683473, val_loss: 1.255091988981651 (24 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.47783251231527096, train_loss: 1.2523242557888714, val_loss: 1.2437462642275054 (25 / 80)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.4729064039408867, train_loss: 1.2660097268367432, val_loss: 1.2665851122052798 (26 / 80)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.5024630541871922, train_loss: 1.2450143207873048, val_loss: 1.213479634576243 (27 / 80)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.49261083743842365, train_loss: 1.1850928474857723, val_loss: 1.166396155733193 (28 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.541871921182266, train_loss: 1.2106214151688943, val_loss: 1.1437185515323882 (29 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.4433497536945813, train_loss: 1.188889549158707, val_loss: 1.2454943974029842 (30 / 80)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.4827586206896552, train_loss: 1.142151001136294, val_loss: 1.145571494924611 (31 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.5024630541871922, train_loss: 1.1449763079361508, val_loss: 1.1314082997185844 (32 / 80)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.49261083743842365, train_loss: 1.106393680731652, val_loss: 1.1596733267084132 (33 / 80)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.4729064039408867, train_loss: 1.0839582082662358, val_loss: 1.1841983160949106 (34 / 80)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5172413793103449, train_loss: 1.0682699404776612, val_loss: 1.1515559703845697 (35 / 80)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5221674876847291, train_loss: 1.0176640989164487, val_loss: 1.0990175234860386 (36 / 80)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5369458128078818, train_loss: 1.0176875025439174, val_loss: 1.1102534685228846 (37 / 80)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.4827586206896552, train_loss: 0.9844393548181531, val_loss: 1.1835616744797806 (38 / 80)\n",
            "train_acc: 0.595797280593325, val_acc: 0.5763546798029556, train_loss: 0.9485775696848172, val_loss: 1.0594536512356085 (39 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5172413793103449, train_loss: 0.927586193285118, val_loss: 1.1333699288039372 (40 / 80)\n",
            "train_acc: 0.6637824474660075, val_acc: 0.5566502463054187, train_loss: 0.8683675810492083, val_loss: 1.0564792737584983 (41 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5566502463054187, train_loss: 0.8714758255720433, val_loss: 1.2522004296626952 (42 / 80)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.5270935960591133, train_loss: 0.8474766792561421, val_loss: 1.087948281776729 (43 / 80)\n",
            "train_acc: 0.688504326328801, val_acc: 0.5862068965517241, train_loss: 0.7707816268074498, val_loss: 0.997999136083819 (44 / 80)\n",
            "train_acc: 0.6847960444993819, val_acc: 0.5714285714285714, train_loss: 0.7343268505722395, val_loss: 1.0875994789189305 (45 / 80)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.5862068965517241, train_loss: 0.6892400689708582, val_loss: 1.151689569351121 (46 / 80)\n",
            "train_acc: 0.723114956736712, val_acc: 0.625615763546798, train_loss: 0.7282105621654996, val_loss: 1.0770345509345896 (47 / 80)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.5862068965517241, train_loss: 0.6285560884051329, val_loss: 1.084771000105759 (48 / 80)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.6206896551724138, train_loss: 0.4791004715213375, val_loss: 1.0109444636429472 (49 / 80)\n",
            "train_acc: 0.8726823238566132, val_acc: 0.645320197044335, train_loss: 0.40177820348474386, val_loss: 1.0160301753452845 (50 / 80)\n",
            "train_acc: 0.861557478368356, val_acc: 0.6354679802955665, train_loss: 0.4090761588368339, val_loss: 1.0337259687226394 (51 / 80)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.6354679802955665, train_loss: 0.3957240791307539, val_loss: 1.0483422343954076 (52 / 80)\n",
            "train_acc: 0.8788627935723115, val_acc: 0.6403940886699507, train_loss: 0.35914032818802505, val_loss: 1.047302991885857 (53 / 80)\n",
            "train_acc: 0.8862793572311496, val_acc: 0.645320197044335, train_loss: 0.33931027358335675, val_loss: 1.0650087060599491 (54 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.25328356482186243\n",
            "lr 0.0008652828929293144, batch 12, decay 0.00015810245434232114, gamma 0.056134226755877197, val accuracy 0.645320197044335, val loss 1.0160301753452845 [37 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00038041059192815333, 'batch_size': 9, 'weight_decay': 3.8372561126798785e-05, 'gamma': 0.057680309789029396}\n",
            "train_acc: 0.16440049443757726, val_acc: 0.2413793103448276, train_loss: 1.789699145978402, val_loss: 1.7833059532889004 (1 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7810269087295154, val_loss: 1.773933797047056 (2 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7694724599274776, val_loss: 1.7606091511073372 (3 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.762833270213218, val_loss: 1.7518095629555839 (4 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.756026119914721, val_loss: 1.743641816923771 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7483977110335795, val_loss: 1.7338300549925254 (6 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.2660098522167488, train_loss: 1.7370697995198818, val_loss: 1.7191161293114348 (7 / 80)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.23645320197044334, train_loss: 1.7213686611802674, val_loss: 1.6981421603357851 (8 / 80)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.30049261083743845, train_loss: 1.6925509071762688, val_loss: 1.6457968762355486 (9 / 80)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.30049261083743845, train_loss: 1.6514953033001667, val_loss: 1.5798468008417215 (10 / 80)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3054187192118227, train_loss: 1.58606943344451, val_loss: 1.6242469226198244 (11 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3399014778325123, train_loss: 1.550743426321758, val_loss: 1.4665952938530833 (12 / 80)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3842364532019704, train_loss: 1.523548985293828, val_loss: 1.4593934032130125 (13 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.4187192118226601, train_loss: 1.4858193323845033, val_loss: 1.4002782455806075 (14 / 80)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.30049261083743845, train_loss: 1.4825138260319148, val_loss: 1.5071833662211602 (15 / 80)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.39408866995073893, train_loss: 1.4516359367240934, val_loss: 1.4175154270209702 (16 / 80)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.42857142857142855, train_loss: 1.4140656191132714, val_loss: 1.3528993652371937 (17 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4187192118226601, train_loss: 1.4258037532215802, val_loss: 1.372227030434632 (18 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4187192118226601, train_loss: 1.4167322206261426, val_loss: 1.3982642378125871 (19 / 80)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.4236453201970443, train_loss: 1.3783770673649274, val_loss: 1.3286990003632795 (20 / 80)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.39408866995073893, train_loss: 1.4010589791758836, val_loss: 1.3357034123002602 (21 / 80)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.43842364532019706, train_loss: 1.3622694155489117, val_loss: 1.287375793668437 (22 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.43842364532019706, train_loss: 1.3719997668295767, val_loss: 1.2912643158377097 (23 / 80)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.41379310344827586, train_loss: 1.3514800223490806, val_loss: 1.289079248611563 (24 / 80)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.41379310344827586, train_loss: 1.3514914391804096, val_loss: 1.3695918729739824 (25 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.3842364532019704, train_loss: 1.3232598751967564, val_loss: 1.3076786155183915 (26 / 80)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.45320197044334976, train_loss: 1.3564520120915435, val_loss: 1.267128479304572 (27 / 80)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4433497536945813, train_loss: 1.2938227598245713, val_loss: 1.2717401038836964 (28 / 80)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.458128078817734, train_loss: 1.2894013779714464, val_loss: 1.2283997104085724 (29 / 80)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4975369458128079, train_loss: 1.2727721500750377, val_loss: 1.2238688281016985 (30 / 80)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.4876847290640394, train_loss: 1.2753340598237235, val_loss: 1.1902123578076291 (31 / 80)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.43349753694581283, train_loss: 1.2579303232789483, val_loss: 1.3301458323530375 (32 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.3891625615763547, train_loss: 1.2524179988650073, val_loss: 1.3812076836971228 (33 / 80)\n",
            "train_acc: 0.484548825710754, val_acc: 0.4729064039408867, train_loss: 1.2013437782583485, val_loss: 1.2122017406477716 (34 / 80)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.5073891625615764, train_loss: 1.232530011013795, val_loss: 1.1953774088709226 (35 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.4630541871921182, train_loss: 1.1668575372183132, val_loss: 1.283944638345042 (36 / 80)\n",
            "train_acc: 0.484548825710754, val_acc: 0.4729064039408867, train_loss: 1.1986657029618735, val_loss: 1.1431085097378697 (37 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.47783251231527096, train_loss: 1.178603492428552, val_loss: 1.168318121450875 (38 / 80)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.45320197044334976, train_loss: 1.121105963942147, val_loss: 1.160601230090475 (39 / 80)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4630541871921182, train_loss: 1.1458943884805932, val_loss: 1.3820407000081292 (40 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.49261083743842365, train_loss: 1.131248204463492, val_loss: 1.14056606686174 (41 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5566502463054187, train_loss: 1.1180136631092124, val_loss: 1.0755397163588425 (42 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.5320197044334976, train_loss: 1.1385461866708269, val_loss: 1.123633583778231 (43 / 80)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.49261083743842365, train_loss: 1.0979731450564192, val_loss: 1.1619535060645325 (44 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5369458128078818, train_loss: 1.074384482519883, val_loss: 1.1025877031199451 (45 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5270935960591133, train_loss: 1.0798022662311313, val_loss: 1.0570786157852323 (46 / 80)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5221674876847291, train_loss: 1.0378121127304247, val_loss: 1.1163154223869587 (47 / 80)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5270935960591133, train_loss: 1.0163203236199132, val_loss: 1.0591257919231658 (48 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5566502463054187, train_loss: 0.9471913743741138, val_loss: 1.0057028452751084 (49 / 80)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5665024630541872, train_loss: 0.9215139929016382, val_loss: 1.0007456935978876 (50 / 80)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5615763546798029, train_loss: 0.8984559644359004, val_loss: 0.9791356471959006 (51 / 80)\n",
            "train_acc: 0.6563658838071693, val_acc: 0.5566502463054187, train_loss: 0.8668078715706933, val_loss: 1.0032379293970286 (52 / 80)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.5517241379310345, train_loss: 0.8779582401509632, val_loss: 1.018571289595712 (53 / 80)\n",
            "train_acc: 0.6637824474660075, val_acc: 0.5763546798029556, train_loss: 0.8801031286180093, val_loss: 0.9801630712495062 (54 / 80)\n",
            "train_acc: 0.6477132262051916, val_acc: 0.5615763546798029, train_loss: 0.8924079467766954, val_loss: 1.0021135011330027 (55 / 80)\n",
            "train_acc: 0.688504326328801, val_acc: 0.5467980295566502, train_loss: 0.8497784337021954, val_loss: 1.0126683300939099 (56 / 80)\n",
            "train_acc: 0.6563658838071693, val_acc: 0.5615763546798029, train_loss: 0.8474863544382772, val_loss: 0.9945154545342394 (57 / 80)\n",
            "train_acc: 0.6699629171817059, val_acc: 0.5566502463054187, train_loss: 0.8424974243042643, val_loss: 1.0033998090058125 (58 / 80)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.5763546798029556, train_loss: 0.8416622982847382, val_loss: 0.9933995161150476 (59 / 80)\n",
            "train_acc: 0.6847960444993819, val_acc: 0.5615763546798029, train_loss: 0.8071522274329724, val_loss: 0.9976960787632195 (60 / 80)\n",
            "train_acc: 0.6946847960444994, val_acc: 0.5566502463054187, train_loss: 0.8215282994641362, val_loss: 1.0091240811230513 (61 / 80)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5763546798029556, train_loss: 0.7955283780843572, val_loss: 1.0005435509047484 (62 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.5714285714285714, train_loss: 0.7980869770123725, val_loss: 1.000019727375707 (63 / 80)\n",
            "train_acc: 0.69221260815822, val_acc: 0.5812807881773399, train_loss: 0.8149194189880333, val_loss: 0.9898994650159564 (64 / 80)\n",
            "train_acc: 0.6724351050679852, val_acc: 0.5714285714285714, train_loss: 0.8111194465010069, val_loss: 0.9930276863387065 (65 / 80)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.5862068965517241, train_loss: 0.8254295859407583, val_loss: 0.9829945702270921 (66 / 80)\n",
            "train_acc: 0.6736711990111248, val_acc: 0.5862068965517241, train_loss: 0.7989088730479053, val_loss: 0.9851430111330718 (67 / 80)\n",
            "train_acc: 0.6934487021013597, val_acc: 0.5960591133004927, train_loss: 0.782064136232817, val_loss: 0.9901883309991489 (68 / 80)\n",
            "train_acc: 0.6847960444993819, val_acc: 0.5960591133004927, train_loss: 0.7883396537695886, val_loss: 0.9816824876028916 (69 / 80)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.6009852216748769, train_loss: 0.7872109420514667, val_loss: 0.9719738892733757 (70 / 80)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.6059113300492611, train_loss: 0.8180236025484295, val_loss: 0.978402114120023 (71 / 80)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5862068965517241, train_loss: 0.7783310677492427, val_loss: 0.9927063170324992 (72 / 80)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.6059113300492611, train_loss: 0.7877881621253505, val_loss: 0.9804931332912351 (73 / 80)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.6059113300492611, train_loss: 0.781498365260762, val_loss: 0.9793838459282673 (74 / 80)\n",
            "train_acc: 0.7119901112484549, val_acc: 0.6059113300492611, train_loss: 0.7491387907595216, val_loss: 0.9748054339087068 (75 / 80)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5911330049261084, train_loss: 0.7470781526105807, val_loss: 1.0032081430768731 (76 / 80)\n",
            "train_acc: 0.7070457354758962, val_acc: 0.5960591133004927, train_loss: 0.753423026303573, val_loss: 0.9681589782531625 (77 / 80)\n",
            "train_acc: 0.7391841779975278, val_acc: 0.6108374384236454, train_loss: 0.7085875446628433, val_loss: 0.9877617955207825 (78 / 80)\n",
            "train_acc: 0.7045735475896168, val_acc: 0.6009852216748769, train_loss: 0.7331925435325566, val_loss: 0.982825829477733 (79 / 80)\n",
            "train_acc: 0.7107540173053152, val_acc: 0.5665024630541872, train_loss: 0.7379149193743103, val_loss: 1.0088042766589838 (80 / 80)\n",
            "lr 0.00038041059192815333, batch 9, decay 3.8372561126798785e-05, gamma 0.057680309789029396, val accuracy 0.6108374384236454, val loss 0.9877617955207825 [38 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.5131305519230423e-05, 'batch_size': 12, 'weight_decay': 1.4860241847080794e-06, 'gamma': 0.18665953494772602}\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7913136166901464, val_loss: 1.7917295324391331 (1 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7916342562297072, val_loss: 1.7912572240594573 (2 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.790546337223171, val_loss: 1.7908374030014564 (3 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7900246274191312, val_loss: 1.7904171450384732 (4 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7900346046030449, val_loss: 1.7899431524605587 (5 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.78993772694148, val_loss: 1.78950681122653 (6 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7892567950803948, val_loss: 1.7890726380747528 (7 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.788844946583063, val_loss: 1.7886488384801178 (8 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.787718929378005, val_loss: 1.7882174881808277 (9 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7881658476569007, val_loss: 1.7878291236943211 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18294190358467244\n",
            "lr 1.5131305519230423e-05, batch 12, decay 1.4860241847080794e-06, gamma 0.18665953494772602, val accuracy 0.18226600985221675, val loss 1.7917295324391331 [39 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 9.143832457268922e-05, 'batch_size': 8, 'weight_decay': 1.7412576566860286e-06, 'gamma': 0.12497460919416367}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.2019704433497537, train_loss: 1.7909984790497864, val_loss: 1.7895606098503902 (1 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18719211822660098, train_loss: 1.7884146748720788, val_loss: 1.7865227942396267 (2 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7865664185345984, val_loss: 1.783679689679827 (3 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7834547184895821, val_loss: 1.7810627862150445 (4 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.7818947768181894, val_loss: 1.7781750856361953 (5 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7800667405275832, val_loss: 1.7754626244746994 (6 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7754740712079777, val_loss: 1.771985479763576 (7 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7740626812570617, val_loss: 1.7688473057864336 (8 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7709772703232076, val_loss: 1.766038359092374 (9 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7667479130482056, val_loss: 1.7624604061906561 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18541409147095178\n",
            "lr 9.143832457268922e-05, batch 8, decay 1.7412576566860286e-06, gamma 0.12497460919416367, val accuracy 0.2019704433497537, val loss 1.7895606098503902 [40 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005577795740508891, 'batch_size': 9, 'weight_decay': 6.486576310917708e-05, 'gamma': 0.04377479936680016}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7860448111415057, val_loss: 1.7749524093026599 (1 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.768044903929655, val_loss: 1.7553815448225425 (2 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2512315270935961, train_loss: 1.753446543319853, val_loss: 1.7429047182862982 (3 / 80)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.22660098522167488, train_loss: 1.7498038439874448, val_loss: 1.737780574507314 (4 / 80)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.3399014778325123, train_loss: 1.7406670600728436, val_loss: 1.715461546564337 (5 / 80)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.2660098522167488, train_loss: 1.7030418059145123, val_loss: 1.6508275475995293 (6 / 80)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3054187192118227, train_loss: 1.6241465353111106, val_loss: 1.6159488937537658 (7 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.29064039408866993, train_loss: 1.6062922574975729, val_loss: 1.4895335406505417 (8 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3842364532019704, train_loss: 1.5619810723845833, val_loss: 1.4690268803112612 (9 / 80)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.3645320197044335, train_loss: 1.5388092580625536, val_loss: 1.4589095056937833 (10 / 80)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.3645320197044335, train_loss: 1.5439506674873815, val_loss: 1.4598229512792502 (11 / 80)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.35960591133004927, train_loss: 1.4966882977114324, val_loss: 1.4138836731464404 (12 / 80)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.37438423645320196, train_loss: 1.4551516691745432, val_loss: 1.3803074218956708 (13 / 80)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.39408866995073893, train_loss: 1.4365363617615292, val_loss: 1.3558785979970922 (14 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3497536945812808, train_loss: 1.4319692710863499, val_loss: 1.4497304133006506 (15 / 80)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.41379310344827586, train_loss: 1.408156399968528, val_loss: 1.3381615275232663 (16 / 80)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.39408866995073893, train_loss: 1.394780603857948, val_loss: 1.3109844881912758 (17 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.35960591133004927, train_loss: 1.3807137508327498, val_loss: 1.4584460698912296 (18 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.43349753694581283, train_loss: 1.3571739618946213, val_loss: 1.2997960827033508 (19 / 80)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4630541871921182, train_loss: 1.3623128954058672, val_loss: 1.2790987609055242 (20 / 80)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.458128078817734, train_loss: 1.3460216067630075, val_loss: 1.3520245969001883 (21 / 80)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.46798029556650245, train_loss: 1.324893816071476, val_loss: 1.3157438406803337 (22 / 80)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.45320197044334976, train_loss: 1.3196409707163703, val_loss: 1.25650506154657 (23 / 80)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.4630541871921182, train_loss: 1.2877370354861057, val_loss: 1.2648951014861685 (24 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.43349753694581283, train_loss: 1.2636452234719682, val_loss: 1.2182318441973532 (25 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.4433497536945813, train_loss: 1.2869304369200292, val_loss: 1.3513341096821676 (26 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.4827586206896552, train_loss: 1.2588890806411488, val_loss: 1.16028305051362 (27 / 80)\n",
            "train_acc: 0.484548825710754, val_acc: 0.5270935960591133, train_loss: 1.2123961188589834, val_loss: 1.1844387163082366 (28 / 80)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.47783251231527096, train_loss: 1.1833183229043251, val_loss: 1.1625927087708647 (29 / 80)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.46798029556650245, train_loss: 1.1785187511641546, val_loss: 1.1630036933668728 (30 / 80)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.4876847290640394, train_loss: 1.1678708786575402, val_loss: 1.16511981592977 (31 / 80)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.458128078817734, train_loss: 1.199310521702242, val_loss: 1.2572202010107745 (32 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4827586206896552, train_loss: 1.1594068340966375, val_loss: 1.2239406795924521 (33 / 80)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4630541871921182, train_loss: 1.1190215200369968, val_loss: 1.1852889025739848 (34 / 80)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.5320197044334976, train_loss: 1.0706860112171386, val_loss: 1.1690910966525525 (35 / 80)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.5024630541871922, train_loss: 1.0931753814588814, val_loss: 1.1547145482354564 (36 / 80)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.47783251231527096, train_loss: 1.0665078894022222, val_loss: 1.1968908497852644 (37 / 80)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.5221674876847291, train_loss: 1.058805494284895, val_loss: 1.0853376341570775 (38 / 80)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.541871921182266, train_loss: 1.0053871414717401, val_loss: 1.074749557842762 (39 / 80)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.5862068965517241, train_loss: 1.001449574904035, val_loss: 1.0439184857119481 (40 / 80)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.5172413793103449, train_loss: 0.9892408337596026, val_loss: 1.0857425666794989 (41 / 80)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.5123152709359606, train_loss: 0.9270585697646194, val_loss: 1.2296441784633205 (42 / 80)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.4729064039408867, train_loss: 0.9360625100297892, val_loss: 1.2094108048330974 (43 / 80)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.5665024630541872, train_loss: 0.9113006388448519, val_loss: 1.1658721392965081 (44 / 80)\n",
            "train_acc: 0.6477132262051916, val_acc: 0.625615763546798, train_loss: 0.8544824382357014, val_loss: 1.0536775315923643 (45 / 80)\n",
            "train_acc: 0.6823238566131026, val_acc: 0.541871921182266, train_loss: 0.8083807205682337, val_loss: 1.2325139145545772 (46 / 80)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.5665024630541872, train_loss: 0.8281174911777817, val_loss: 1.1548321948850095 (47 / 80)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.5862068965517241, train_loss: 0.8308740752957513, val_loss: 1.039291438798012 (48 / 80)\n",
            "train_acc: 0.788627935723115, val_acc: 0.6403940886699507, train_loss: 0.6001268172146216, val_loss: 0.9633257086641096 (49 / 80)\n",
            "train_acc: 0.7713226205191595, val_acc: 0.6403940886699507, train_loss: 0.6047877709856729, val_loss: 0.9532934399367553 (50 / 80)\n",
            "train_acc: 0.7688504326328801, val_acc: 0.6403940886699507, train_loss: 0.5861179459153942, val_loss: 0.9715526011483423 (51 / 80)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.6305418719211823, train_loss: 0.5559189968888633, val_loss: 0.966982281854 (52 / 80)\n",
            "train_acc: 0.8170580964153276, val_acc: 0.645320197044335, train_loss: 0.5298969560983154, val_loss: 0.9754152801530115 (53 / 80)\n",
            "train_acc: 0.8331273176761433, val_acc: 0.6206896551724138, train_loss: 0.47407404989998775, val_loss: 0.9826424810393103 (54 / 80)\n",
            "train_acc: 0.8244746600741656, val_acc: 0.6157635467980296, train_loss: 0.4847969062101414, val_loss: 0.9889489189157346 (55 / 80)\n",
            "train_acc: 0.8467243510506799, val_acc: 0.6157635467980296, train_loss: 0.4754638935454254, val_loss: 0.985907159121753 (56 / 80)\n",
            "train_acc: 0.8195302843016069, val_acc: 0.625615763546798, train_loss: 0.5044974766865059, val_loss: 0.9764502259164021 (57 / 80)\n",
            "train_acc: 0.8257107540173053, val_acc: 0.6108374384236454, train_loss: 0.48907609800583646, val_loss: 0.9831406924818537 (58 / 80)\n",
            "train_acc: 0.8257107540173053, val_acc: 0.625615763546798, train_loss: 0.48556999501177056, val_loss: 0.982388881149844 (59 / 80)\n",
            "train_acc: 0.8071693448702101, val_acc: 0.6059113300492611, train_loss: 0.4915835602008663, val_loss: 0.9938770186137683 (60 / 80)\n",
            "train_acc: 0.8393077873918418, val_acc: 0.6305418719211823, train_loss: 0.44375110674552776, val_loss: 0.9938391640855762 (61 / 80)\n",
            "train_acc: 0.8368355995055624, val_acc: 0.6305418719211823, train_loss: 0.4374901921256953, val_loss: 1.0017071245926354 (62 / 80)\n",
            "train_acc: 0.8529048207663782, val_acc: 0.6157635467980296, train_loss: 0.43561697597483034, val_loss: 1.0253871817306932 (63 / 80)\n",
            "train_acc: 0.8467243510506799, val_acc: 0.625615763546798, train_loss: 0.4339170210772598, val_loss: 1.0160069668968323 (64 / 80)\n",
            "train_acc: 0.8504326328800988, val_acc: 0.625615763546798, train_loss: 0.4450492737780248, val_loss: 1.0178608427494031 (65 / 80)\n",
            "train_acc: 0.8529048207663782, val_acc: 0.625615763546798, train_loss: 0.4264867572327995, val_loss: 1.0157744885959061 (66 / 80)\n",
            "overfit -> train_accuracy-val_accuracy = 0.2532104952291645\n",
            "lr 0.0005577795740508891, batch 9, decay 6.486576310917708e-05, gamma 0.04377479936680016, val accuracy 0.645320197044335, val loss 0.9754152801530115 [41 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00026532122590550535, 'batch_size': 14, 'weight_decay': 1.2757375261150867e-05, 'gamma': 0.8065857126536472}\n",
            "train_acc: 0.15822002472187885, val_acc: 0.18226600985221675, train_loss: 1.7893748239180067, val_loss: 1.7841870044839794 (1 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.78139954856948, val_loss: 1.7782690689481537 (2 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.7771753053582644, val_loss: 1.77241810847973 (3 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7712282658507414, val_loss: 1.7655865776127782 (4 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7639643835048888, val_loss: 1.7584578620976414 (5 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7581502941836533, val_loss: 1.753539800643921 (6 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7599983343529908, val_loss: 1.74990556568935 (7 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7595228263267924, val_loss: 1.7463781381475514 (8 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7540618266693888, val_loss: 1.743560840343607 (9 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7468488895701537, val_loss: 1.7374842660180454 (10 / 80)\n",
            "underfit -> train_accuracy = 0.2088998763906057\n",
            "lr 0.00026532122590550535, batch 14, decay 1.2757375261150867e-05, gamma 0.8065857126536472, val accuracy 0.18226600985221675, val loss 1.7841870044839794 [42 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00043660847130590896, 'batch_size': 10, 'weight_decay': 0.00025031720443271155, 'gamma': 0.011678955740792939}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7865880147193653, val_loss: 1.7789650227635951 (1 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7760614719614847, val_loss: 1.7664478899810114 (2 / 80)\n",
            "train_acc: 0.1681087762669963, val_acc: 0.18226600985221675, train_loss: 1.7671138506442565, val_loss: 1.7545707219927182 (3 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7531603143005936, val_loss: 1.7451333670780576 (4 / 80)\n",
            "train_acc: 0.21755253399258342, val_acc: 0.18226600985221675, train_loss: 1.749959611774817, val_loss: 1.7375876551191207 (5 / 80)\n",
            "train_acc: 0.2200247218788628, val_acc: 0.20689655172413793, train_loss: 1.7368352427912879, val_loss: 1.7206326640885452 (6 / 80)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.33004926108374383, train_loss: 1.726372303862507, val_loss: 1.689153160954931 (7 / 80)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.31527093596059114, train_loss: 1.7025232994364867, val_loss: 1.6429129927029162 (8 / 80)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.3251231527093596, train_loss: 1.6331978560378142, val_loss: 1.5847470032170488 (9 / 80)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3054187192118227, train_loss: 1.582550078446255, val_loss: 1.5166796416484665 (10 / 80)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3103448275862069, train_loss: 1.5564956551576574, val_loss: 1.5067604856538068 (11 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.31527093596059114, train_loss: 1.5321827565489063, val_loss: 1.4870198618602284 (12 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3251231527093596, train_loss: 1.4876633346154458, val_loss: 1.4330977039971375 (13 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.35960591133004927, train_loss: 1.49422907917697, val_loss: 1.4592336322286446 (14 / 80)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.4039408866995074, train_loss: 1.4581500459807766, val_loss: 1.3600162317600157 (15 / 80)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.4187192118226601, train_loss: 1.425563830085679, val_loss: 1.342789138479186 (16 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.41379310344827586, train_loss: 1.455768857220342, val_loss: 1.3467571359549837 (17 / 80)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.39408866995073893, train_loss: 1.413513377658811, val_loss: 1.310821002340082 (18 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3891625615763547, train_loss: 1.4110905957605104, val_loss: 1.349714102416203 (19 / 80)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.42857142857142855, train_loss: 1.3709391964086055, val_loss: 1.3067080211169615 (20 / 80)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.4039408866995074, train_loss: 1.3774743752072856, val_loss: 1.402068326625918 (21 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.4482758620689655, train_loss: 1.379337641453124, val_loss: 1.2778329687752747 (22 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.41379310344827586, train_loss: 1.3427660120432396, val_loss: 1.2605051454064882 (23 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.41379310344827586, train_loss: 1.3138643806738082, val_loss: 1.2793012463987754 (24 / 80)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.35960591133004927, train_loss: 1.342376893103049, val_loss: 1.4518167367709682 (25 / 80)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.4039408866995074, train_loss: 1.3623130147625107, val_loss: 1.280281174946301 (26 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.4630541871921182, train_loss: 1.3118372784262093, val_loss: 1.2754234380909961 (27 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.39408866995073893, train_loss: 1.3325150515446704, val_loss: 1.2922262076673836 (28 / 80)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.4236453201970443, train_loss: 1.3037390386218342, val_loss: 1.3866954413540844 (29 / 80)\n",
            "train_acc: 0.484548825710754, val_acc: 0.458128078817734, train_loss: 1.2526851087919124, val_loss: 1.1928403066296882 (30 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.4088669950738916, train_loss: 1.2760934428172588, val_loss: 1.2526105821426279 (31 / 80)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.5221674876847291, train_loss: 1.2742468373589817, val_loss: 1.2056354836290106 (32 / 80)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.4975369458128079, train_loss: 1.2058338769728822, val_loss: 1.1916915424938859 (33 / 80)\n",
            "train_acc: 0.5043263288009888, val_acc: 0.49261083743842365, train_loss: 1.2408383633798663, val_loss: 1.1750614402329393 (34 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.5024630541871922, train_loss: 1.210724065050354, val_loss: 1.190560412524369 (35 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4630541871921182, train_loss: 1.2031614968302224, val_loss: 1.2203293454470894 (36 / 80)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.5073891625615764, train_loss: 1.2193914034457967, val_loss: 1.1375359936887994 (37 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4827586206896552, train_loss: 1.1718380538141182, val_loss: 1.2002016188475886 (38 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.4876847290640394, train_loss: 1.177525452247214, val_loss: 1.1422432032711987 (39 / 80)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.4630541871921182, train_loss: 1.1585505388133752, val_loss: 1.2511093532804198 (40 / 80)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.4876847290640394, train_loss: 1.136339764070452, val_loss: 1.1453341898953386 (41 / 80)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.4729064039408867, train_loss: 1.1248007545659804, val_loss: 1.1960834740417932 (42 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.4827586206896552, train_loss: 1.111083389802091, val_loss: 1.1411251704681096 (43 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.4729064039408867, train_loss: 1.083899395206508, val_loss: 1.214334006379978 (44 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.39408866995073893, train_loss: 1.0924274184647833, val_loss: 1.4907411331026426 (45 / 80)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5073891625615764, train_loss: 1.0699524634848123, val_loss: 1.1050394788164224 (46 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5073891625615764, train_loss: 1.0911380972791513, val_loss: 1.102385232014022 (47 / 80)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.47783251231527096, train_loss: 1.0023885936613284, val_loss: 1.160236198913875 (48 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5221674876847291, train_loss: 0.9668443525677411, val_loss: 1.1036699373146583 (49 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5221674876847291, train_loss: 0.9793192358924667, val_loss: 1.0719547665177895 (50 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5517241379310345, train_loss: 0.9443867468863394, val_loss: 1.059858798980713 (51 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5517241379310345, train_loss: 0.9485395886694692, val_loss: 1.0547647024023121 (52 / 80)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.5517241379310345, train_loss: 0.9263313146692566, val_loss: 1.0497129321685565 (53 / 80)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.5517241379310345, train_loss: 0.9462585055783889, val_loss: 1.0518917197664384 (54 / 80)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5517241379310345, train_loss: 0.9186390404795539, val_loss: 1.052727241234239 (55 / 80)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5517241379310345, train_loss: 0.9151708715778346, val_loss: 1.051168212749688 (56 / 80)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5517241379310345, train_loss: 0.9113011545834346, val_loss: 1.0467483627385106 (57 / 80)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.5517241379310345, train_loss: 0.9180373103715875, val_loss: 1.0489145156197948 (58 / 80)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5467980295566502, train_loss: 0.9056265963464791, val_loss: 1.052746930733103 (59 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5566502463054187, train_loss: 0.9134039458886655, val_loss: 1.0403598074255318 (60 / 80)\n",
            "train_acc: 0.6625463535228677, val_acc: 0.5467980295566502, train_loss: 0.8844312122195259, val_loss: 1.049438250035488 (61 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.5517241379310345, train_loss: 0.8934468386789187, val_loss: 1.0503384036383605 (62 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5467980295566502, train_loss: 0.9119024471977291, val_loss: 1.0473307553183269 (63 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5517241379310345, train_loss: 0.8841800624861558, val_loss: 1.0419107047207836 (64 / 80)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.5517241379310345, train_loss: 0.9022341716127431, val_loss: 1.0446846391179878 (65 / 80)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5566502463054187, train_loss: 0.8901169461431845, val_loss: 1.0450495813280491 (66 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5566502463054187, train_loss: 0.8691373782782679, val_loss: 1.0485897472339312 (67 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5615763546798029, train_loss: 0.904204496715508, val_loss: 1.0453474251507537 (68 / 80)\n",
            "train_acc: 0.65389369592089, val_acc: 0.5566502463054187, train_loss: 0.8988655392996903, val_loss: 1.0463739806795356 (69 / 80)\n",
            "train_acc: 0.6477132262051916, val_acc: 0.5566502463054187, train_loss: 0.8742586683725987, val_loss: 1.0428755929317381 (70 / 80)\n",
            "train_acc: 0.6786155747836835, val_acc: 0.5517241379310345, train_loss: 0.8832794573015277, val_loss: 1.039697878466451 (71 / 80)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.5467980295566502, train_loss: 0.8740419040356932, val_loss: 1.0386262615326003 (72 / 80)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.5566502463054187, train_loss: 0.8966043037448737, val_loss: 1.0455158722811733 (73 / 80)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.5615763546798029, train_loss: 0.8756257213827117, val_loss: 1.0453196388160066 (74 / 80)\n",
            "train_acc: 0.6625463535228677, val_acc: 0.5566502463054187, train_loss: 0.8501732182149098, val_loss: 1.0444753921677914 (75 / 80)\n",
            "train_acc: 0.6440049443757726, val_acc: 0.5566502463054187, train_loss: 0.8732267002240099, val_loss: 1.039204795665929 (76 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5566502463054187, train_loss: 0.8827303660520075, val_loss: 1.0417535992091513 (77 / 80)\n",
            "train_acc: 0.6600741656365884, val_acc: 0.5566502463054187, train_loss: 0.8608777470730143, val_loss: 1.0455184044509098 (78 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.5517241379310345, train_loss: 0.8584172122263348, val_loss: 1.049813800551034 (79 / 80)\n",
            "train_acc: 0.6477132262051916, val_acc: 0.5615763546798029, train_loss: 0.8481491452683919, val_loss: 1.0495871452275167 (80 / 80)\n",
            "lr 0.00043660847130590896, batch 10, decay 0.00025031720443271155, gamma 0.011678955740792939, val accuracy 0.5615763546798029, val loss 1.0453474251507537 [43 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00027531434783290124, 'batch_size': 9, 'weight_decay': 4.3783604017624755e-06, 'gamma': 0.11844128056704877}\n",
            "train_acc: 0.1681087762669963, val_acc: 0.26108374384236455, train_loss: 1.789515652084822, val_loss: 1.7829278208352075 (1 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.7810920618373178, val_loss: 1.7727671667860059 (2 / 80)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.18226600985221675, train_loss: 1.7706783784482034, val_loss: 1.7611288067155284 (3 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7633650280783881, val_loss: 1.753210654986903 (4 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7555340460705373, val_loss: 1.7459585637294601 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.19704433497536947, train_loss: 1.7517901311256683, val_loss: 1.737717559772172 (6 / 80)\n",
            "train_acc: 0.2558714462299135, val_acc: 0.21674876847290642, train_loss: 1.745882660850459, val_loss: 1.7295560578407325 (7 / 80)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.2857142857142857, train_loss: 1.7323077327683476, val_loss: 1.7146044893217791 (8 / 80)\n",
            "train_acc: 0.276885043263288, val_acc: 0.2857142857142857, train_loss: 1.7225249067077826, val_loss: 1.691358398334146 (9 / 80)\n",
            "train_acc: 0.2830655129789864, val_acc: 0.32019704433497537, train_loss: 1.6924087344052912, val_loss: 1.6664038415025608 (10 / 80)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.3103448275862069, train_loss: 1.6600630376188659, val_loss: 1.5860737227453974 (11 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.35467980295566504, train_loss: 1.6022330992596112, val_loss: 1.557460825431523 (12 / 80)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.3399014778325123, train_loss: 1.5895940504498476, val_loss: 1.550816316909978 (13 / 80)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3103448275862069, train_loss: 1.5452831526769253, val_loss: 1.5292246605962367 (14 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3399014778325123, train_loss: 1.5332631413515183, val_loss: 1.4713326651474525 (15 / 80)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.3251231527093596, train_loss: 1.5137683993069586, val_loss: 1.542964786144313 (16 / 80)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.39408866995073893, train_loss: 1.5008339943785602, val_loss: 1.4470047334144855 (17 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.23645320197044334, train_loss: 1.5244160892789531, val_loss: 1.6598917463142884 (18 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.2561576354679803, train_loss: 1.4812518724404984, val_loss: 1.5297598040162637 (19 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.39408866995073893, train_loss: 1.4722146404393672, val_loss: 1.4157374988635774 (20 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3793103448275862, train_loss: 1.489987768702513, val_loss: 1.3927446216198023 (21 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.35467980295566504, train_loss: 1.4284748409233519, val_loss: 1.413456614381574 (22 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.39408866995073893, train_loss: 1.4169367466338338, val_loss: 1.378267019546678 (23 / 80)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3251231527093596, train_loss: 1.4110574097509585, val_loss: 1.4149605300038905 (24 / 80)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.3251231527093596, train_loss: 1.4075280731481734, val_loss: 1.403992269426731 (25 / 80)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.3694581280788177, train_loss: 1.4484783191468718, val_loss: 1.3654452979271048 (26 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.42857142857142855, train_loss: 1.381077248764274, val_loss: 1.352748716406047 (27 / 80)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.42857142857142855, train_loss: 1.3532433822216887, val_loss: 1.3134895342911406 (28 / 80)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.45320197044334976, train_loss: 1.3340060757323455, val_loss: 1.3354991918126937 (29 / 80)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.41379310344827586, train_loss: 1.36679592290237, val_loss: 1.3198121395604363 (30 / 80)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.4039408866995074, train_loss: 1.368385611859476, val_loss: 1.4025142063648242 (31 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.43842364532019706, train_loss: 1.338058414137997, val_loss: 1.2938189342104156 (32 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4236453201970443, train_loss: 1.3082242378198319, val_loss: 1.306677850890042 (33 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4236453201970443, train_loss: 1.3092440587775815, val_loss: 1.2718447487929772 (34 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.39901477832512317, train_loss: 1.2949707618602568, val_loss: 1.3612370215026028 (35 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.46798029556650245, train_loss: 1.2985837160435831, val_loss: 1.2404561621214956 (36 / 80)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.3891625615763547, train_loss: 1.2931225710952532, val_loss: 1.3150361368221601 (37 / 80)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.4433497536945813, train_loss: 1.27908716876663, val_loss: 1.2999562491924304 (38 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.3793103448275862, train_loss: 1.2285350802802333, val_loss: 1.3283260887479547 (39 / 80)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.46798029556650245, train_loss: 1.2538710513574673, val_loss: 1.286630124000493 (40 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.49261083743842365, train_loss: 1.2668776942419329, val_loss: 1.2448265018134281 (41 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.4827586206896552, train_loss: 1.2361403646221563, val_loss: 1.2686525518671046 (42 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.4630541871921182, train_loss: 1.2208834751722102, val_loss: 1.2055285534835214 (43 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5073891625615764, train_loss: 1.1847897735602777, val_loss: 1.2476826404115837 (44 / 80)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.5123152709359606, train_loss: 1.2074148743350073, val_loss: 1.256341669359818 (45 / 80)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.5320197044334976, train_loss: 1.1792495755388945, val_loss: 1.1656013330802542 (46 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.4236453201970443, train_loss: 1.170576975283723, val_loss: 1.2556593101012883 (47 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.4236453201970443, train_loss: 1.1577209319702921, val_loss: 1.3716240472394257 (48 / 80)\n",
            "train_acc: 0.519159456118665, val_acc: 0.5172413793103449, train_loss: 1.1544162574303607, val_loss: 1.1603963991691326 (49 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5369458128078818, train_loss: 1.0748470403502692, val_loss: 1.147549316800874 (50 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5369458128078818, train_loss: 1.0928303353276625, val_loss: 1.1402344019542188 (51 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5270935960591133, train_loss: 1.0693184270699623, val_loss: 1.1441263218818627 (52 / 80)\n",
            "train_acc: 0.5661310259579728, val_acc: 0.5369458128078818, train_loss: 1.0706590219171734, val_loss: 1.1288006114842268 (53 / 80)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5320197044334976, train_loss: 1.0598957618912601, val_loss: 1.1571698209335064 (54 / 80)\n",
            "train_acc: 0.588380716934487, val_acc: 0.5270935960591133, train_loss: 1.0499888457385513, val_loss: 1.1640510946659033 (55 / 80)\n",
            "train_acc: 0.5760197775030902, val_acc: 0.5270935960591133, train_loss: 1.0609526715260944, val_loss: 1.1408732562816788 (56 / 80)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.5270935960591133, train_loss: 1.0413378379106226, val_loss: 1.1850912154014475 (57 / 80)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5270935960591133, train_loss: 1.0608248656848158, val_loss: 1.1462025557245528 (58 / 80)\n",
            "train_acc: 0.5797280593325093, val_acc: 0.5270935960591133, train_loss: 1.0244926930358, val_loss: 1.1515151356241387 (59 / 80)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5123152709359606, train_loss: 1.0172668704291061, val_loss: 1.1530074254045346 (60 / 80)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.5467980295566502, train_loss: 1.0450125163506223, val_loss: 1.1246963169774398 (61 / 80)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5270935960591133, train_loss: 1.0201862737333818, val_loss: 1.1182484694302375 (62 / 80)\n",
            "train_acc: 0.588380716934487, val_acc: 0.541871921182266, train_loss: 1.0194475634578426, val_loss: 1.136789337167599 (63 / 80)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5172413793103449, train_loss: 1.0144589517555662, val_loss: 1.184902832425874 (64 / 80)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5467980295566502, train_loss: 1.006585879143148, val_loss: 1.1321259927867082 (65 / 80)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5270935960591133, train_loss: 0.9915826521786241, val_loss: 1.158678709286187 (66 / 80)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5270935960591133, train_loss: 1.0038738089379922, val_loss: 1.1465877347391815 (67 / 80)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5221674876847291, train_loss: 1.0104232778213227, val_loss: 1.1611234716006689 (68 / 80)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5172413793103449, train_loss: 0.9898606665128535, val_loss: 1.1474649095770173 (69 / 80)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.5221674876847291, train_loss: 0.9735330383400392, val_loss: 1.1444096251074316 (70 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5467980295566502, train_loss: 0.9466300395643166, val_loss: 1.1339150050590778 (71 / 80)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.5369458128078818, train_loss: 0.936907581883691, val_loss: 1.1345155920301164 (72 / 80)\n",
            "train_acc: 0.619283065512979, val_acc: 0.541871921182266, train_loss: 0.9346323846223475, val_loss: 1.128802098664157 (73 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5123152709359606, train_loss: 0.97086488382778, val_loss: 1.1715287055288042 (74 / 80)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.5517241379310345, train_loss: 0.9465435934891954, val_loss: 1.117455956383879 (75 / 80)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.541871921182266, train_loss: 0.9602093534136584, val_loss: 1.129639339858088 (76 / 80)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.5270935960591133, train_loss: 0.9647477379319694, val_loss: 1.1538458713169755 (77 / 80)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5467980295566502, train_loss: 0.9651626690724872, val_loss: 1.1178476833944837 (78 / 80)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.541871921182266, train_loss: 0.932879262271122, val_loss: 1.1078027715823922 (79 / 80)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.5369458128078818, train_loss: 0.9112830362449618, val_loss: 1.1398767940516543 (80 / 80)\n",
            "lr 0.00027531434783290124, batch 9, decay 4.3783604017624755e-06, gamma 0.11844128056704877, val accuracy 0.5517241379310345, val loss 1.117455956383879 [44 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 6.0813156817757295e-05, 'batch_size': 15, 'weight_decay': 0.000659304406044606, 'gamma': 0.10670005341228928}\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7918708655978606, val_loss: 1.7914425363681588 (1 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7906590010533374, val_loss: 1.7902440384690985 (2 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7901348643308812, val_loss: 1.7890720020961293 (3 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7886088626788486, val_loss: 1.787948562593883 (4 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7881470364604803, val_loss: 1.7868905707533136 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7869382489596957, val_loss: 1.78584486803985 (6 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7861583025110668, val_loss: 1.7848686819593307 (7 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.1921182266009852, train_loss: 1.7846108929925266, val_loss: 1.7837896799219066 (8 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7854589942948633, val_loss: 1.782853931041774 (9 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.21674876847290642, train_loss: 1.783212407115658, val_loss: 1.7818187322522618 (10 / 80)\n",
            "underfit -> train_accuracy = 0.20519159456118666\n",
            "lr 6.0813156817757295e-05, batch 15, decay 0.000659304406044606, gamma 0.10670005341228928, val accuracy 0.21674876847290642, val loss 1.7818187322522618 [45 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00012146518694585026, 'batch_size': 14, 'weight_decay': 8.797099892896007e-06, 'gamma': 0.3126384411676614}\n",
            "train_acc: 0.18912237330037082, val_acc: 0.22167487684729065, train_loss: 1.7900188971214153, val_loss: 1.7874682319575343 (1 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.2561576354679803, train_loss: 1.7866180514817773, val_loss: 1.7844944082457443 (2 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7849692828280963, val_loss: 1.7812803983688354 (3 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18719211822660098, train_loss: 1.7808360847171363, val_loss: 1.7783180968514805 (4 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7777517367941782, val_loss: 1.774883664887527 (5 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7769926556550675, val_loss: 1.7719902457862065 (6 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.774203565418352, val_loss: 1.7687244415283203 (7 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7696981027777616, val_loss: 1.765359405813546 (8 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7663015029928446, val_loss: 1.7620141177341855 (9 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7647812590463494, val_loss: 1.7586647765389805 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18046971569839307\n",
            "lr 0.00012146518694585026, batch 14, decay 8.797099892896007e-06, gamma 0.3126384411676614, val accuracy 0.2561576354679803, val loss 1.7844944082457443 [46 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.7386471743748322e-05, 'batch_size': 14, 'weight_decay': 2.4519700674687268e-06, 'gamma': 0.07270305616738851}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.17733990147783252, train_loss: 1.7915779733834662, val_loss: 1.7917469369954075 (1 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.17733990147783252, train_loss: 1.7911120532322284, val_loss: 1.7913520911644245 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.79158278890829, val_loss: 1.790965668086348 (3 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7905581003361197, val_loss: 1.7905865661029159 (4 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7903872956746294, val_loss: 1.7902300686671817 (5 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.789474595462436, val_loss: 1.78988071556749 (6 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7903331833510523, val_loss: 1.7895434108273736 (7 / 80)\n",
            "train_acc: 0.1433868974042027, val_acc: 0.18226600985221675, train_loss: 1.7902729556940689, val_loss: 1.789189470225367 (8 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.789244303891921, val_loss: 1.7888570900621086 (9 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7883611460698696, val_loss: 1.7884881249789535 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19283065512978986\n",
            "lr 1.7386471743748322e-05, batch 14, decay 2.4519700674687268e-06, gamma 0.07270305616738851, val accuracy 0.18226600985221675, val loss 1.790965668086348 [47 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.6379064077905427e-05, 'batch_size': 13, 'weight_decay': 1.1422900535947354e-06, 'gamma': 0.08452315467353534}\n",
            "train_acc: 0.15451174289245984, val_acc: 0.18226600985221675, train_loss: 1.7916661484721859, val_loss: 1.7916029568376213 (1 / 80)\n",
            "train_acc: 0.15822002472187885, val_acc: 0.18226600985221675, train_loss: 1.7928943878640646, val_loss: 1.791131357254066 (2 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.791210895121024, val_loss: 1.7906875099454607 (3 / 80)\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.7910018222146336, val_loss: 1.7902416548705453 (4 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7901018709128513, val_loss: 1.7898384033165542 (5 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7900355752230575, val_loss: 1.789391761930118 (6 / 80)\n",
            "train_acc: 0.1631644004944376, val_acc: 0.18226600985221675, train_loss: 1.789932271311398, val_loss: 1.7889231672427925 (7 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7891915643170972, val_loss: 1.7885129475241224 (8 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7890028003119716, val_loss: 1.7880609552261277 (9 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7885267077329279, val_loss: 1.7876615747442386 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18541409147095178\n",
            "lr 1.6379064077905427e-05, batch 13, decay 1.1422900535947354e-06, gamma 0.08452315467353534, val accuracy 0.18226600985221675, val loss 1.7916029568376213 [48 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0007220498435995008, 'batch_size': 14, 'weight_decay': 2.228552014354877e-05, 'gamma': 0.08113961287843949}\n",
            "train_acc: 0.18046971569839307, val_acc: 0.2955665024630542, train_loss: 1.7881970287695508, val_loss: 1.7805508909554317 (1 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.775877832187563, val_loss: 1.7660183084422145 (2 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.20689655172413793, train_loss: 1.76493245326397, val_loss: 1.7530682744651005 (3 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.19704433497536947, train_loss: 1.7583734504371993, val_loss: 1.7459202552663868 (4 / 80)\n",
            "train_acc: 0.24103831891223734, val_acc: 0.2561576354679803, train_loss: 1.757315963690891, val_loss: 1.7366750774712398 (5 / 80)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.22167487684729065, train_loss: 1.7372464476468683, val_loss: 1.7187977412651325 (6 / 80)\n",
            "train_acc: 0.273176761433869, val_acc: 0.3891625615763547, train_loss: 1.7118799634858026, val_loss: 1.6686303862209977 (7 / 80)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.33004926108374383, train_loss: 1.665375268798234, val_loss: 1.5936569879794944 (8 / 80)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.33497536945812806, train_loss: 1.6005170250999914, val_loss: 1.6105702539970135 (9 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3103448275862069, train_loss: 1.5750990248433738, val_loss: 1.510849693725849 (10 / 80)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.39901477832512317, train_loss: 1.5665613473272146, val_loss: 1.4846715474950856 (11 / 80)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.31527093596059114, train_loss: 1.5260466774845005, val_loss: 1.478164792060852 (12 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3793103448275862, train_loss: 1.5009620886650603, val_loss: 1.4024047974882454 (13 / 80)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.32019704433497537, train_loss: 1.4656078075743724, val_loss: 1.525628768164536 (14 / 80)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.3891625615763547, train_loss: 1.5044236673854927, val_loss: 1.4119674953921089 (15 / 80)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.33004926108374383, train_loss: 1.4549992346793081, val_loss: 1.5255034175412407 (16 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.43349753694581283, train_loss: 1.4796075916702873, val_loss: 1.4034416675567627 (17 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.43842364532019706, train_loss: 1.4345085261336659, val_loss: 1.3707676016051193 (18 / 80)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3891625615763547, train_loss: 1.3792150058911374, val_loss: 1.4897505373790347 (19 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.43349753694581283, train_loss: 1.3999692891230542, val_loss: 1.3983055312058021 (20 / 80)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.4433497536945813, train_loss: 1.3954120967237853, val_loss: 1.4204003769775917 (21 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4088669950738916, train_loss: 1.350277659330144, val_loss: 1.2965024134208416 (22 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.4236453201970443, train_loss: 1.3599289568746635, val_loss: 1.3509461838623573 (23 / 80)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.3891625615763547, train_loss: 1.3310955210286106, val_loss: 1.2754795427980095 (24 / 80)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.47783251231527096, train_loss: 1.3305153770116704, val_loss: 1.2360254526138306 (25 / 80)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.46798029556650245, train_loss: 1.3392909202351706, val_loss: 1.259647733178632 (26 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.4630541871921182, train_loss: 1.2971242791495305, val_loss: 1.2817159726701934 (27 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.46798029556650245, train_loss: 1.3142431644338317, val_loss: 1.2284786660095741 (28 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.43349753694581283, train_loss: 1.2683400857286489, val_loss: 1.2541539874570122 (29 / 80)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.4236453201970443, train_loss: 1.2605556270248073, val_loss: 1.28880290327401 (30 / 80)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.4187192118226601, train_loss: 1.231080527800712, val_loss: 1.272082859072192 (31 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.4433497536945813, train_loss: 1.2163227696353927, val_loss: 1.2302645198230087 (32 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4975369458128079, train_loss: 1.213291444796125, val_loss: 1.1701111526324832 (33 / 80)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4975369458128079, train_loss: 1.1799366930948643, val_loss: 1.1393290264853115 (34 / 80)\n",
            "train_acc: 0.522867737948084, val_acc: 0.45320197044334976, train_loss: 1.1732677683989403, val_loss: 1.296565109285815 (35 / 80)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4827586206896552, train_loss: 1.2006441194135857, val_loss: 1.2015130108800427 (36 / 80)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.5221674876847291, train_loss: 1.1510368142788137, val_loss: 1.1549516011928689 (37 / 80)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4876847290640394, train_loss: 1.124926025404771, val_loss: 1.1613649376507462 (38 / 80)\n",
            "train_acc: 0.519159456118665, val_acc: 0.47783251231527096, train_loss: 1.1733023370299558, val_loss: 1.1711093516185367 (39 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.5024630541871922, train_loss: 1.1045166707893532, val_loss: 1.1394754504335338 (40 / 80)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.4876847290640394, train_loss: 1.0825195467221576, val_loss: 1.1942935318782413 (41 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.46798029556650245, train_loss: 1.0936420548831576, val_loss: 1.2374129685862312 (42 / 80)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5073891625615764, train_loss: 1.047066808041595, val_loss: 1.1634983358712032 (43 / 80)\n",
            "train_acc: 0.5859085290482077, val_acc: 0.5369458128078818, train_loss: 1.0322085857686065, val_loss: 1.1045475499383335 (44 / 80)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5714285714285714, train_loss: 1.0053027321587977, val_loss: 1.082403540611267 (45 / 80)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5665024630541872, train_loss: 0.9484147845740961, val_loss: 0.9977504323268759 (46 / 80)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5566502463054187, train_loss: 0.9787143197725671, val_loss: 1.0958263586307395 (47 / 80)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5270935960591133, train_loss: 0.9524291649884435, val_loss: 1.0535995425849125 (48 / 80)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.5911330049261084, train_loss: 0.8420271270796749, val_loss: 0.9512410616052562 (49 / 80)\n",
            "train_acc: 0.6983930778739185, val_acc: 0.5665024630541872, train_loss: 0.8039952395725604, val_loss: 0.959685572262468 (50 / 80)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5763546798029556, train_loss: 0.7713249922535476, val_loss: 0.9783378531192911 (51 / 80)\n",
            "train_acc: 0.7045735475896168, val_acc: 0.6009852216748769, train_loss: 0.7579518233889849, val_loss: 0.9631050002985987 (52 / 80)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.6009852216748769, train_loss: 0.7237698729754378, val_loss: 0.977959316352318 (53 / 80)\n",
            "train_acc: 0.6983930778739185, val_acc: 0.6009852216748769, train_loss: 0.7471811640247868, val_loss: 0.9632335839600399 (54 / 80)\n",
            "train_acc: 0.7379480840543882, val_acc: 0.5862068965517241, train_loss: 0.7029766685735752, val_loss: 0.9887880909031835 (55 / 80)\n",
            "train_acc: 0.7391841779975278, val_acc: 0.5911330049261084, train_loss: 0.7040955469251711, val_loss: 0.9962217458363237 (56 / 80)\n",
            "train_acc: 0.73053152039555, val_acc: 0.6009852216748769, train_loss: 0.6985282924472918, val_loss: 0.9615138728043129 (57 / 80)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5911330049261084, train_loss: 0.6754857798294615, val_loss: 0.9604118137524046 (58 / 80)\n",
            "train_acc: 0.7379480840543882, val_acc: 0.5862068965517241, train_loss: 0.6628412305940362, val_loss: 0.9806778019872205 (59 / 80)\n",
            "train_acc: 0.7589616810877626, val_acc: 0.5812807881773399, train_loss: 0.6337335777592158, val_loss: 0.994507986923744 (60 / 80)\n",
            "train_acc: 0.7564894932014833, val_acc: 0.5714285714285714, train_loss: 0.6584987179899982, val_loss: 0.9917906974924022 (61 / 80)\n",
            "train_acc: 0.7552533992583437, val_acc: 0.5911330049261084, train_loss: 0.6337540800992874, val_loss: 0.9899602326853522 (62 / 80)\n",
            "train_acc: 0.7466007416563659, val_acc: 0.5714285714285714, train_loss: 0.6674106027861902, val_loss: 0.9973794242431377 (63 / 80)\n",
            "train_acc: 0.7626699629171817, val_acc: 0.5862068965517241, train_loss: 0.6207023555843438, val_loss: 1.0072453309749734 (64 / 80)\n",
            "train_acc: 0.7428924598269468, val_acc: 0.5960591133004927, train_loss: 0.6432984572995284, val_loss: 0.9858952966229669 (65 / 80)\n",
            "train_acc: 0.7824474660074165, val_acc: 0.625615763546798, train_loss: 0.598874320500566, val_loss: 0.9968108699239534 (66 / 80)\n",
            "train_acc: 0.792336217552534, val_acc: 0.6108374384236454, train_loss: 0.5732729586373153, val_loss: 0.9976336791597563 (67 / 80)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.6059113300492611, train_loss: 0.5831800087347019, val_loss: 1.0018430352210999 (68 / 80)\n",
            "train_acc: 0.7824474660074165, val_acc: 0.6059113300492611, train_loss: 0.5881076389543795, val_loss: 0.981618949051561 (69 / 80)\n",
            "train_acc: 0.7861557478368356, val_acc: 0.5665024630541872, train_loss: 0.5517931265206213, val_loss: 0.993649096324526 (70 / 80)\n",
            "train_acc: 0.7725587144622992, val_acc: 0.5911330049261084, train_loss: 0.6014265656029191, val_loss: 0.9785787596784788 (71 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.5862068965517241, train_loss: 0.5513273769315005, val_loss: 1.0378426580593503 (72 / 80)\n",
            "train_acc: 0.788627935723115, val_acc: 0.5812807881773399, train_loss: 0.5692256344263574, val_loss: 1.0177200066632237 (73 / 80)\n",
            "train_acc: 0.7775030902348579, val_acc: 0.5960591133004927, train_loss: 0.5741170822321559, val_loss: 1.0088841421850796 (74 / 80)\n",
            "train_acc: 0.8084054388133498, val_acc: 0.6059113300492611, train_loss: 0.5550223060679819, val_loss: 1.0167614221572876 (75 / 80)\n",
            "train_acc: 0.8170580964153276, val_acc: 0.625615763546798, train_loss: 0.5294333023326506, val_loss: 1.001431810444799 (76 / 80)\n",
            "train_acc: 0.8096415327564895, val_acc: 0.5960591133004927, train_loss: 0.5307225883375434, val_loss: 1.0052972579824513 (77 / 80)\n",
            "train_acc: 0.8207663782447466, val_acc: 0.5812807881773399, train_loss: 0.5245843454550754, val_loss: 1.036936474257502 (78 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.625615763546798, train_loss: 0.523579870630401, val_loss: 1.0161522061660373 (79 / 80)\n",
            "train_acc: 0.830655129789864, val_acc: 0.6157635467980296, train_loss: 0.4774454846812414, val_loss: 1.0500169910233597 (80 / 80)\n",
            "lr 0.0007220498435995008, batch 14, decay 2.228552014354877e-05, gamma 0.08113961287843949, val accuracy 0.625615763546798, val loss 0.9968108699239534 [49 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.6661047485897464e-05, 'batch_size': 8, 'weight_decay': 1.5264111438721608e-05, 'gamma': 0.02284163656975739}\n",
            "train_acc: 0.18541409147095178, val_acc: 0.1724137931034483, train_loss: 1.790871512315182, val_loss: 1.7889578841589941 (1 / 80)\n",
            "train_acc: 0.15822002472187885, val_acc: 0.17733990147783252, train_loss: 1.789294233722946, val_loss: 1.7873982819430347 (2 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7880759194990614, val_loss: 1.7861518900969933 (3 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7865162426225925, val_loss: 1.7846857755642218 (4 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7859108079643862, val_loss: 1.7833868464812856 (5 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.7837074984726122, val_loss: 1.7819899391070964 (6 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7826298109827878, val_loss: 1.7804657138627151 (7 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7818842388054055, val_loss: 1.7791601548641187 (8 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18719211822660098, train_loss: 1.7807903942572614, val_loss: 1.777679783957345 (9 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.1921182266009852, train_loss: 1.7783244463657715, val_loss: 1.7761882937013223 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19901112484548825\n",
            "lr 3.6661047485897464e-05, batch 8, decay 1.5264111438721608e-05, gamma 0.02284163656975739, val accuracy 0.1921182266009852, val loss 1.7761882937013223 [50 / 50]\n",
            "--------------------------------------------\n",
            "\n",
            "{'lr': 0.000953839039916152, 'batch_size': 9, 'weight_decay': 0.00015319613136737035, 'gamma': 0.9262521929212527}, best val accuracy 0.6650246305418719, best val loss 1.0745352168975792\n",
            "val accuracies\n",
            "[0.19704433497536947, 0.5172413793103449, 0.20689655172413793, 0.6650246305418719, 0.6305418719211823, 0.24630541871921183, 0.20689655172413793, 0.6403940886699507, 0.19704433497536947, 0.21674876847290642, 0.1921182266009852, 0.645320197044335, 0.6157635467980296, 0.18719211822660098, 0.2413793103448276, 0.6551724137931034, 0.2857142857142857, 0.21674876847290642, 0.5566502463054187, 0.2019704433497537, 0.22167487684729065, 0.23645320197044334, 0.270935960591133, 0.24630541871921183, 0.24630541871921183, 0.2512315270935961, 0.2413793103448276, 0.18226600985221675, 0.17733990147783252, 0.18719211822660098, 0.20689655172413793, 0.18226600985221675, 0.18226600985221675, 0.541871921182266, 0.3103448275862069, 0.27586206896551724, 0.645320197044335, 0.6108374384236454, 0.18226600985221675, 0.2019704433497537, 0.645320197044335, 0.18226600985221675, 0.5615763546798029, 0.5517241379310345, 0.21674876847290642, 0.2561576354679803, 0.18226600985221675, 0.18226600985221675, 0.625615763546798, 0.1921182266009852]\n",
            "val losses\n",
            "[1.782029298138736, 1.1399509746746477, 1.7793491139200521, 1.0745352168975792, 1.0403618915327664, 1.7889860991773934, 1.7895073068553005, 0.9407640683827142, 1.7806962082538698, 1.784052419545028, 1.7816807748061683, 1.0584736058277449, 1.0746936818649029, 1.7819292927023225, 1.7827796489734369, 0.9024412734755154, 1.784512523359853, 1.7868574845967033, 1.1655204400346784, 1.7855143999231273, 1.7332626827831925, 1.7826859375526165, 1.786708316779489, 1.7879804173126597, 1.7853131300122866, 1.7821070014549594, 1.7808871592206907, 1.7875813492413224, 1.789126704479086, 1.7889673110886748, 1.7925488778523035, 1.789510677600729, 1.7924881515831783, 1.1236164769515615, 1.7242449345847068, 1.7857967808916064, 1.0160301753452845, 0.9877617955207825, 1.7917295324391331, 1.7895606098503902, 0.9754152801530115, 1.7841870044839794, 1.0453474251507537, 1.117455956383879, 1.7818187322522618, 1.7844944082457443, 1.790965668086348, 1.7916029568376213, 0.9968108699239534, 1.7761882937013223]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "6ad460b4-7665-4692-a14d-30f82ea5c96a",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "'''\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "'''\n",
        "\n",
        "# lr 0.0006444500508054211, batch 14, decay 2.1280582227123365e-05, gamma 0.19924404264743992, val accuracy 0.6305418719211823, val loss 1.0403618915327664 [5 / 50]\n",
        "# lr 0.00038041059192815333, batch 9, decay 3.8372561126798785e-05, gamma 0.057680309789029396, val accuracy 0.6108374384236454, val loss 0.9877617955207825 [38 / 50]\n",
        "# lr 0.00043660847130590896, batch 10, decay 0.00025031720443271155, gamma 0.011678955740792939, val accuracy 0.5615763546798029, val loss 1.0453474251507537 [43 / 50]\n",
        "# lr 0.00027531434783290124, batch 9, decay 4.3783604017624755e-06, gamma 0.11844128056704877, val accuracy 0.5517241379310345, val loss 1.117455956383879 [44 / 50]\n",
        "# lr 0.0007220498435995008, batch 14, decay 2.228552014354877e-05, gamma 0.08113961287843949, val accuracy 0.625615763546798, val loss 0.9968108699239534 [49 / 50]\n",
        "# lr 0.0008377019231346562, batch 8, decay 2.4427015675775187e-06, gamma 0.00903130010323455, val accuracy 0.5849802371541502, val loss 1.0701400147596367 [1 / 50]\n",
        "# lr 0.0010316163585472981, batch 8, decay 1.8309942558988887e-05, gamma 0.002673690056313373, val accuracy 0.5592885375494071, val loss 1.0480610431418589 [5 / 50]\n",
        "# lr 0.0016661746592012004, batch 8, decay 3.3763075569909223e-06, gamma 0.006052773438030023, val accuracy 0.6067193675889329, val loss 1.0441360360548901 [6 / 50]\n",
        "\n",
        "hyperparameters_sets = []\n",
        "lr_list = [0.0006444500508054211, 0.00038041059192815333, 0.00043660847130590896, 0.00027531434783290124, 0.0007220498435995008, 0.0008377019231346562, 0.0010316163585472981, 0.0016661746592012004]\n",
        "bs_list = [14, 9, 10, 9, 14, 8, 8, 8]\n",
        "wd_list = [2.1280582227123365e-05, 3.8372561126798785e-05, 0.00025031720443271155, 4.3783604017624755e-06, 2.228552014354877e-05, 2.4427015675775187e-06, 1.8309942558988887e-05, 3.3763075569909223e-06]\n",
        "g_list = [0.19924404264743992, 0.057680309789029396, 0.011678955740792939, 0.11844128056704877, 0.08113961287843949, 0.00903130010323455, 0.002673690056313373, 0.006052773438030023]\n",
        "\n",
        "for i in range(8):\n",
        "  set = {\"lr\": lr_list[i], \"batch_size\": bs_list[i], \"weight_decay\": wd_list[i], \"gamma\": g_list[i]}\n",
        "  hyperparameters_sets.append(set)\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg11()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}\n",
            "{'lr': 0.00038041059192815333, 'batch_size': 9, 'weight_decay': 3.8372561126798785e-05, 'gamma': 0.057680309789029396}\n",
            "{'lr': 0.00043660847130590896, 'batch_size': 10, 'weight_decay': 0.00025031720443271155, 'gamma': 0.011678955740792939}\n",
            "{'lr': 0.00027531434783290124, 'batch_size': 9, 'weight_decay': 4.3783604017624755e-06, 'gamma': 0.11844128056704877}\n",
            "{'lr': 0.0007220498435995008, 'batch_size': 14, 'weight_decay': 2.228552014354877e-05, 'gamma': 0.08113961287843949}\n",
            "{'lr': 0.0008377019231346562, 'batch_size': 8, 'weight_decay': 2.4427015675775187e-06, 'gamma': 0.00903130010323455}\n",
            "{'lr': 0.0010316163585472981, 'batch_size': 8, 'weight_decay': 1.8309942558988887e-05, 'gamma': 0.002673690056313373}\n",
            "{'lr': 0.0016661746592012004, 'batch_size': 8, 'weight_decay': 3.3763075569909223e-06, 'gamma': 0.006052773438030023}\n",
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.1631644004944376, val_acc: 0.24630541871921183, train_loss: 1.7884624719030335, val_loss: 1.7780668283330983 (1 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7762182489755864, val_loss: 1.761735566731157 (2 / 100)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.2315270935960591, train_loss: 1.765151120234184, val_loss: 1.7517185663354808 (3 / 100)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18719211822660098, train_loss: 1.7573147917854772, val_loss: 1.7428574068792935 (4 / 100)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.19704433497536947, train_loss: 1.740918589905549, val_loss: 1.7291672969686573 (5 / 100)\n",
            "train_acc: 0.21755253399258342, val_acc: 0.23645320197044334, train_loss: 1.7268930153440043, val_loss: 1.707409850482283 (6 / 100)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.22660098522167488, train_loss: 1.7097183853498348, val_loss: 1.6822798786492184 (7 / 100)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.3103448275862069, train_loss: 1.6804155400126473, val_loss: 1.6053958679067677 (8 / 100)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.24630541871921183, train_loss: 1.6269609041060742, val_loss: 1.7415842023389092 (9 / 100)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.2561576354679803, train_loss: 1.602861644605771, val_loss: 1.5625590332623185 (10 / 100)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3645320197044335, train_loss: 1.5437707805220955, val_loss: 1.4718270178498893 (11 / 100)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.27586206896551724, train_loss: 1.5215288405070642, val_loss: 1.525423395222631 (12 / 100)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.3645320197044335, train_loss: 1.52429416256281, val_loss: 1.4526919208723923 (13 / 100)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3694581280788177, train_loss: 1.5154324152560994, val_loss: 1.4946990506402378 (14 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3645320197044335, train_loss: 1.4752913608833944, val_loss: 1.398850128568452 (15 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.35960591133004927, train_loss: 1.468066865198397, val_loss: 1.5048202152909904 (16 / 100)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3891625615763547, train_loss: 1.4265516256667186, val_loss: 1.3730006752343014 (17 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.4236453201970443, train_loss: 1.438744650046227, val_loss: 1.3728838953478584 (18 / 100)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.4433497536945813, train_loss: 1.4159497613517846, val_loss: 1.342049426045911 (19 / 100)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.35960591133004927, train_loss: 1.408417783797303, val_loss: 1.4138103641312698 (20 / 100)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.41379310344827586, train_loss: 1.3888356947928335, val_loss: 1.3190908986946632 (21 / 100)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.4088669950738916, train_loss: 1.3691667022162817, val_loss: 1.2787498482342423 (22 / 100)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.3891625615763547, train_loss: 1.3669536237516273, val_loss: 1.3502171943927634 (23 / 100)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.3891625615763547, train_loss: 1.3507476212509777, val_loss: 1.3741901907427558 (24 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.45320197044334976, train_loss: 1.336004283578493, val_loss: 1.3324303750334114 (25 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4729064039408867, train_loss: 1.3107269874167236, val_loss: 1.2434375039462386 (26 / 100)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.4433497536945813, train_loss: 1.2661423073121438, val_loss: 1.3612194061279297 (27 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.3891625615763547, train_loss: 1.2796992795871127, val_loss: 1.3661508683500618 (28 / 100)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4827586206896552, train_loss: 1.2464627195495022, val_loss: 1.2000112328036079 (29 / 100)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4729064039408867, train_loss: 1.2435796319775292, val_loss: 1.2370559573173523 (30 / 100)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.39901477832512317, train_loss: 1.2416154560258863, val_loss: 1.258893218533746 (31 / 100)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4729064039408867, train_loss: 1.233259210480453, val_loss: 1.147438016431085 (32 / 100)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.4187192118226601, train_loss: 1.184270169443194, val_loss: 1.2101151326607014 (33 / 100)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.4975369458128079, train_loss: 1.1433234631794198, val_loss: 1.2463793137977863 (34 / 100)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.4482758620689655, train_loss: 1.1400483569639133, val_loss: 1.3609504864133637 (35 / 100)\n",
            "train_acc: 0.5043263288009888, val_acc: 0.42857142857142855, train_loss: 1.159693206196515, val_loss: 1.2185336721354518 (36 / 100)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.4630541871921182, train_loss: 1.1136915873832844, val_loss: 1.215857851094213 (37 / 100)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.4876847290640394, train_loss: 1.1517983468707618, val_loss: 1.2047548088534126 (38 / 100)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.5024630541871922, train_loss: 1.1291397454859446, val_loss: 1.1413521150062824 (39 / 100)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5172413793103449, train_loss: 1.0693977935647199, val_loss: 1.1541155124532765 (40 / 100)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.5221674876847291, train_loss: 1.0598543163283056, val_loss: 1.1513619299592643 (41 / 100)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.5517241379310345, train_loss: 0.9984264376726375, val_loss: 1.0316946485946918 (42 / 100)\n",
            "train_acc: 0.5797280593325093, val_acc: 0.4975369458128079, train_loss: 1.0154174885290073, val_loss: 1.137585343985722 (43 / 100)\n",
            "train_acc: 0.580964153275649, val_acc: 0.541871921182266, train_loss: 0.991314868549776, val_loss: 1.0998305781134243 (44 / 100)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.5517241379310345, train_loss: 0.9397612245032755, val_loss: 1.0461972129756008 (45 / 100)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.5221674876847291, train_loss: 0.9433143639888693, val_loss: 1.1500761529494976 (46 / 100)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.5714285714285714, train_loss: 0.8614258987205138, val_loss: 1.141740453654322 (47 / 100)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.5615763546798029, train_loss: 0.877108706384713, val_loss: 1.034519520299188 (48 / 100)\n",
            "train_acc: 0.6625463535228677, val_acc: 0.5665024630541872, train_loss: 0.8504429050664819, val_loss: 1.1503878544116843 (49 / 100)\n",
            "train_acc: 0.695920889987639, val_acc: 0.5615763546798029, train_loss: 0.7729598058316263, val_loss: 1.1299637103902882 (50 / 100)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.5615763546798029, train_loss: 0.7881372024308618, val_loss: 1.1531948591100758 (51 / 100)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5763546798029556, train_loss: 0.7695499850144639, val_loss: 1.0107625763991783 (52 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5467980295566502, train_loss: 0.6761920237718023, val_loss: 1.2023830989311481 (53 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5517241379310345, train_loss: 0.7170405300939628, val_loss: 1.3127360549466363 (54 / 100)\n",
            "train_acc: 0.7268232385661311, val_acc: 0.5566502463054187, train_loss: 0.6978098579183939, val_loss: 1.2528192277612358 (55 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.6059113300492611, train_loss: 0.6773908091858674, val_loss: 1.0663570556147346 (56 / 100)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.6157635467980296, train_loss: 0.6052045357242061, val_loss: 0.9814269419374138 (57 / 100)\n",
            "train_acc: 0.7787391841779975, val_acc: 0.6059113300492611, train_loss: 0.6143527805289468, val_loss: 1.0143652619986698 (58 / 100)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6059113300492611, train_loss: 0.48178179287645223, val_loss: 1.1143867106273257 (59 / 100)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.5615763546798029, train_loss: 0.5768713376430705, val_loss: 1.3537237274235692 (60 / 100)\n",
            "train_acc: 0.857849196538937, val_acc: 0.6354679802955665, train_loss: 0.4049408536390557, val_loss: 1.184126299003075 (61 / 100)\n",
            "overfit -> train_accuracy 0.9085290482076638, val_accuracy 0.625615763546798\n",
            "({'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}), val accuracy 0.6354679802955665, val loss 1.184126299003075\n",
            "train_acc: 0.19901112484548825, val_acc: 0.21674876847290642, train_loss: 1.7891148825363705, val_loss: 1.7784887364345232 (1 / 100)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.18226600985221675, train_loss: 1.7756192927307488, val_loss: 1.7639182471289423 (2 / 100)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18719211822660098, train_loss: 1.768019373396271, val_loss: 1.7541294039176603 (3 / 100)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.762815254285692, val_loss: 1.7466669123748253 (4 / 100)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.2413793103448276, train_loss: 1.7558923480831943, val_loss: 1.7385847362978706 (5 / 100)\n",
            "train_acc: 0.2200247218788628, val_acc: 0.21182266009852216, train_loss: 1.7453733681158907, val_loss: 1.7257111653905783 (6 / 100)\n",
            "train_acc: 0.24103831891223734, val_acc: 0.3645320197044335, train_loss: 1.7327855501245657, val_loss: 1.705118711358808 (7 / 100)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.2857142857142857, train_loss: 1.7101358738169534, val_loss: 1.666725022452218 (8 / 100)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.3448275862068966, train_loss: 1.661352815675205, val_loss: 1.6150279949451316 (9 / 100)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3399014778325123, train_loss: 1.6123670083188597, val_loss: 1.5280259900492401 (10 / 100)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.2660098522167488, train_loss: 1.5682877347849502, val_loss: 1.5491662782988525 (11 / 100)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3891625615763547, train_loss: 1.5605206955201252, val_loss: 1.470330566021022 (12 / 100)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.2857142857142857, train_loss: 1.5204190552160972, val_loss: 1.673977729134959 (13 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.33004926108374383, train_loss: 1.5183635702533982, val_loss: 1.4612639255711597 (14 / 100)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.2955665024630542, train_loss: 1.4668820875389468, val_loss: 1.449787735351788 (15 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.37438423645320196, train_loss: 1.4677988807998865, val_loss: 1.4595167586956117 (16 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.43842364532019706, train_loss: 1.432524057637039, val_loss: 1.3917927401406425 (17 / 100)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.41379310344827586, train_loss: 1.4214629866136756, val_loss: 1.3563815049937207 (18 / 100)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.4088669950738916, train_loss: 1.412855513900408, val_loss: 1.3467608144130614 (19 / 100)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4433497536945813, train_loss: 1.395363854168372, val_loss: 1.3831884173924112 (20 / 100)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.4433497536945813, train_loss: 1.40243988079842, val_loss: 1.3298603372620832 (21 / 100)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4630541871921182, train_loss: 1.3685415264849905, val_loss: 1.3318593231915252 (22 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.39408866995073893, train_loss: 1.364181043117391, val_loss: 1.3148329528094513 (23 / 100)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.45320197044334976, train_loss: 1.3395948510971587, val_loss: 1.3187429021144736 (24 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.43842364532019706, train_loss: 1.3277300533611782, val_loss: 1.325089781742378 (25 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4433497536945813, train_loss: 1.3198950567705228, val_loss: 1.3234102494023703 (26 / 100)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4187192118226601, train_loss: 1.3296454833965514, val_loss: 1.3991435742730578 (27 / 100)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.4729064039408867, train_loss: 1.2994400402082058, val_loss: 1.2406305826356259 (28 / 100)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.45320197044334976, train_loss: 1.2983575198057997, val_loss: 1.2982472060936425 (29 / 100)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.43842364532019706, train_loss: 1.2748158563052767, val_loss: 1.2330965296975498 (30 / 100)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4236453201970443, train_loss: 1.2632387192788612, val_loss: 1.3422023307513722 (31 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.43349753694581283, train_loss: 1.2542069766518507, val_loss: 1.261213159619881 (32 / 100)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.4729064039408867, train_loss: 1.2306029109931258, val_loss: 1.1851815666471208 (33 / 100)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4630541871921182, train_loss: 1.2212548225712865, val_loss: 1.2126403122112668 (34 / 100)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.5024630541871922, train_loss: 1.206245101352852, val_loss: 1.2029175846447497 (35 / 100)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.5172413793103449, train_loss: 1.204453103548222, val_loss: 1.1596574495578635 (36 / 100)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.5024630541871922, train_loss: 1.166698439748974, val_loss: 1.1582569083556753 (37 / 100)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.4876847290640394, train_loss: 1.143673043684258, val_loss: 1.2156796232232907 (38 / 100)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.5024630541871922, train_loss: 1.2017850022675522, val_loss: 1.1529041376019933 (39 / 100)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.5270935960591133, train_loss: 1.1206648162622534, val_loss: 1.1362929752307573 (40 / 100)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.5123152709359606, train_loss: 1.1148665008792475, val_loss: 1.1178221887555615 (41 / 100)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5073891625615764, train_loss: 1.0708457701580487, val_loss: 1.1577162158313057 (42 / 100)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5221674876847291, train_loss: 1.1200013598346592, val_loss: 1.173779844063256 (43 / 100)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.5024630541871922, train_loss: 1.088092957276791, val_loss: 1.1461840374716397 (44 / 100)\n",
            "train_acc: 0.5797280593325093, val_acc: 0.5369458128078818, train_loss: 1.0552687804100687, val_loss: 1.1553835839473556 (45 / 100)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.4630541871921182, train_loss: 1.0876690240666658, val_loss: 1.305040488395785 (46 / 100)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.5073891625615764, train_loss: 1.0307825336644911, val_loss: 1.0895418172399398 (47 / 100)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.5517241379310345, train_loss: 1.0434228149421136, val_loss: 1.0416595526223111 (48 / 100)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.4975369458128079, train_loss: 0.9783495173908134, val_loss: 1.1240254443854534 (49 / 100)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5123152709359606, train_loss: 0.9512317182107084, val_loss: 1.1131347823025557 (50 / 100)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.5123152709359606, train_loss: 0.9354166704217347, val_loss: 1.0950127528806037 (51 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5024630541871922, train_loss: 0.9043847593963514, val_loss: 1.1927389916528035 (52 / 100)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5467980295566502, train_loss: 0.8909032001115188, val_loss: 1.151468945841484 (53 / 100)\n",
            "train_acc: 0.6353522867737948, val_acc: 0.5123152709359606, train_loss: 0.8625007810345097, val_loss: 1.2266088703583027 (54 / 100)\n",
            "train_acc: 0.6699629171817059, val_acc: 0.5320197044334976, train_loss: 0.8551176066967406, val_loss: 1.1496746995178937 (55 / 100)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.5517241379310345, train_loss: 0.8607518628000181, val_loss: 1.144329738147153 (56 / 100)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.5665024630541872, train_loss: 0.8089937460510929, val_loss: 1.092580628806147 (57 / 100)\n",
            "train_acc: 0.6872682323856613, val_acc: 0.5270935960591133, train_loss: 0.8131854043092362, val_loss: 1.205059069718046 (58 / 100)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.5862068965517241, train_loss: 0.791464987032493, val_loss: 0.9952375825696391 (59 / 100)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5911330049261084, train_loss: 0.6981427295983059, val_loss: 1.2161554976049902 (60 / 100)\n",
            "train_acc: 0.7787391841779975, val_acc: 0.6305418719211823, train_loss: 0.5910432733438807, val_loss: 1.0297611266227777 (61 / 100)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.625615763546798, train_loss: 0.5514615230234651, val_loss: 1.046541812384657 (62 / 100)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6305418719211823, train_loss: 0.5279385959925257, val_loss: 1.0574216032263093 (63 / 100)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6206896551724138, train_loss: 0.5038151099946354, val_loss: 1.040954604524697 (64 / 100)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6157635467980296, train_loss: 0.4709521956714181, val_loss: 1.047750658002393 (65 / 100)\n",
            "train_acc: 0.8096415327564895, val_acc: 0.6108374384236454, train_loss: 0.5133232189934097, val_loss: 1.055483494926556 (66 / 100)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.6305418719211823, train_loss: 0.5004771274269291, val_loss: 1.0648049494903076 (67 / 100)\n",
            "train_acc: 0.8479604449938195, val_acc: 0.6305418719211823, train_loss: 0.45556876448769357, val_loss: 1.0704302607205114 (68 / 100)\n",
            "train_acc: 0.8343634116192831, val_acc: 0.6305418719211823, train_loss: 0.47138182942298495, val_loss: 1.0910180070130109 (69 / 100)\n",
            "train_acc: 0.826946847960445, val_acc: 0.6354679802955665, train_loss: 0.46674030411376055, val_loss: 1.079340939451321 (70 / 100)\n",
            "train_acc: 0.8195302843016069, val_acc: 0.625615763546798, train_loss: 0.4666695391347146, val_loss: 1.0901843001102578 (71 / 100)\n",
            "train_acc: 0.8405438813349815, val_acc: 0.6206896551724138, train_loss: 0.4372240635295881, val_loss: 1.0618710536968532 (72 / 100)\n",
            "train_acc: 0.8257107540173053, val_acc: 0.6157635467980296, train_loss: 0.44393066789296415, val_loss: 1.0986043982611502 (73 / 100)\n",
            "train_acc: 0.8343634116192831, val_acc: 0.6157635467980296, train_loss: 0.4496418740162891, val_loss: 1.0690593071318613 (74 / 100)\n",
            "train_acc: 0.8331273176761433, val_acc: 0.6157635467980296, train_loss: 0.4494287472480749, val_loss: 1.058240971835376 (75 / 100)\n",
            "train_acc: 0.8467243510506799, val_acc: 0.6305418719211823, train_loss: 0.4041763757561576, val_loss: 1.0870156163358924 (76 / 100)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.6157635467980296, train_loss: 0.4217470680652428, val_loss: 1.1457954479996206 (77 / 100)\n",
            "train_acc: 0.8553770086526576, val_acc: 0.6157635467980296, train_loss: 0.40652282451301336, val_loss: 1.1070149992707328 (78 / 100)\n",
            "train_acc: 0.8504326328800988, val_acc: 0.6157635467980296, train_loss: 0.4235502999777847, val_loss: 1.0975643066056255 (79 / 100)\n",
            "train_acc: 0.865265760197775, val_acc: 0.6157635467980296, train_loss: 0.3908255220896234, val_loss: 1.099475364086076 (80 / 100)\n",
            "overfit -> train_accuracy 0.8751545117428925, val_accuracy 0.6108374384236454\n",
            "({'lr': 0.00038041059192815333, 'batch_size': 9, 'weight_decay': 3.8372561126798785e-05, 'gamma': 0.057680309789029396}), val accuracy 0.6354679802955665, val loss 1.079340939451321\n",
            "train_acc: 0.1668726823238566, val_acc: 0.1921182266009852, train_loss: 1.787705167851725, val_loss: 1.7756978179433662 (1 / 100)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7740485397051233, val_loss: 1.7603647773488988 (2 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7634500708656642, val_loss: 1.7516450159655417 (3 / 100)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.2561576354679803, train_loss: 1.757274150258973, val_loss: 1.7451680540451275 (4 / 100)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.21182266009852216, train_loss: 1.7480964734321471, val_loss: 1.7337807046956029 (5 / 100)\n",
            "train_acc: 0.23980222496909764, val_acc: 0.3448275862068966, train_loss: 1.7392911028360996, val_loss: 1.7207623673190038 (6 / 100)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.2955665024630542, train_loss: 1.71983166545519, val_loss: 1.704022926062786 (7 / 100)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.3399014778325123, train_loss: 1.6991209966143217, val_loss: 1.645808872330952 (8 / 100)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.32019704433497537, train_loss: 1.637397143395781, val_loss: 1.5675361473572078 (9 / 100)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.3842364532019704, train_loss: 1.561016476787949, val_loss: 1.6085688738987363 (10 / 100)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3891625615763547, train_loss: 1.5539554815799255, val_loss: 1.4453033402635547 (11 / 100)\n",
            "train_acc: 0.34610630407911, val_acc: 0.41379310344827586, train_loss: 1.5561598848795566, val_loss: 1.4495422305731938 (12 / 100)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.270935960591133, train_loss: 1.5065100526043451, val_loss: 1.4644456632031595 (13 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3497536945812808, train_loss: 1.4942878581979513, val_loss: 1.4213304907230322 (14 / 100)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.37438423645320196, train_loss: 1.4821688941736304, val_loss: 1.3933441057581033 (15 / 100)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.4236453201970443, train_loss: 1.4285573847361637, val_loss: 1.3431786272326127 (16 / 100)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3891625615763547, train_loss: 1.4702793616152223, val_loss: 1.3857698240890879 (17 / 100)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4187192118226601, train_loss: 1.4402966637841261, val_loss: 1.384358461854493 (18 / 100)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3448275862068966, train_loss: 1.410860639714782, val_loss: 1.4727998449297375 (19 / 100)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.39901477832512317, train_loss: 1.3542995924413277, val_loss: 1.379844299090907 (20 / 100)\n",
            "train_acc: 0.43016069221260816, val_acc: 0.3645320197044335, train_loss: 1.367824070533215, val_loss: 1.4510293582390095 (21 / 100)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4630541871921182, train_loss: 1.3716608358107332, val_loss: 1.291879586398308 (22 / 100)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.4187192118226601, train_loss: 1.3339588709903147, val_loss: 1.3674284290210368 (23 / 100)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.4039408866995074, train_loss: 1.3340750817757454, val_loss: 1.2796084258356706 (24 / 100)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4630541871921182, train_loss: 1.3069061083610922, val_loss: 1.2983905464557592 (25 / 100)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.45320197044334976, train_loss: 1.297305841675795, val_loss: 1.292083867077757 (26 / 100)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.458128078817734, train_loss: 1.3088086623933317, val_loss: 1.287034331284133 (27 / 100)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4482758620689655, train_loss: 1.2832207054968081, val_loss: 1.312576413154602 (28 / 100)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.458128078817734, train_loss: 1.2825376190272781, val_loss: 1.3882871672437695 (29 / 100)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.4729064039408867, train_loss: 1.2583243499138153, val_loss: 1.2504619086904478 (30 / 100)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4729064039408867, train_loss: 1.2547843002418357, val_loss: 1.2256536495509407 (31 / 100)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.42857142857142855, train_loss: 1.2317415357962231, val_loss: 1.3100699057132739 (32 / 100)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.5123152709359606, train_loss: 1.259856466899254, val_loss: 1.1629358964600587 (33 / 100)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.43349753694581283, train_loss: 1.2153741292222615, val_loss: 1.3056488982562362 (34 / 100)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.49261083743842365, train_loss: 1.185084504751104, val_loss: 1.2087180670259035 (35 / 100)\n",
            "train_acc: 0.515451174289246, val_acc: 0.5073891625615764, train_loss: 1.161875944055055, val_loss: 1.1374610624289865 (36 / 100)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.46798029556650245, train_loss: 1.1748387037013164, val_loss: 1.2926600901364105 (37 / 100)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.5123152709359606, train_loss: 1.0944530666242867, val_loss: 1.1575799510983997 (38 / 100)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.458128078817734, train_loss: 1.177858060753095, val_loss: 1.2472978941912722 (39 / 100)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.45320197044334976, train_loss: 1.123841676782766, val_loss: 1.2504914564452148 (40 / 100)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4630541871921182, train_loss: 1.0841081932979106, val_loss: 1.2339444935615427 (41 / 100)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5172413793103449, train_loss: 1.093310103428231, val_loss: 1.160422863631413 (42 / 100)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.5369458128078818, train_loss: 1.0570866849425402, val_loss: 1.1199225837667588 (43 / 100)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5270935960591133, train_loss: 1.0572728219226795, val_loss: 1.1671834394262341 (44 / 100)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.4482758620689655, train_loss: 1.0336496682632692, val_loss: 1.1799616288081767 (45 / 100)\n",
            "train_acc: 0.5797280593325093, val_acc: 0.49261083743842365, train_loss: 1.0084428877117313, val_loss: 1.158156088420323 (46 / 100)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5270935960591133, train_loss: 1.0068709281525299, val_loss: 1.0889295979673639 (47 / 100)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.458128078817734, train_loss: 0.9767030715500321, val_loss: 1.314897245961457 (48 / 100)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5123152709359606, train_loss: 0.9634784646470408, val_loss: 1.1623849416601246 (49 / 100)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.46798029556650245, train_loss: 0.9761640314929123, val_loss: 1.0845603625762639 (50 / 100)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5123152709359606, train_loss: 0.883069262516366, val_loss: 1.3400535971073095 (51 / 100)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5714285714285714, train_loss: 0.9245984720063888, val_loss: 1.1615300413422984 (52 / 100)\n",
            "train_acc: 0.6563658838071693, val_acc: 0.5812807881773399, train_loss: 0.8720343722990623, val_loss: 1.1611530305129554 (53 / 100)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.5763546798029556, train_loss: 0.8615145629504408, val_loss: 1.0505766921442719 (54 / 100)\n",
            "train_acc: 0.6711990111248455, val_acc: 0.46798029556650245, train_loss: 0.8397453920213489, val_loss: 1.3274785227376251 (55 / 100)\n",
            "train_acc: 0.6983930778739185, val_acc: 0.5369458128078818, train_loss: 0.8102250453568213, val_loss: 1.1312550388533493 (56 / 100)\n",
            "train_acc: 0.6736711990111248, val_acc: 0.5123152709359606, train_loss: 0.798808201539649, val_loss: 1.19398351549515 (57 / 100)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.5911330049261084, train_loss: 0.7547280520974338, val_loss: 1.0229622571926398 (58 / 100)\n",
            "train_acc: 0.715698393077874, val_acc: 0.6206896551724138, train_loss: 0.7465859436060501, val_loss: 1.130705727512026 (59 / 100)\n",
            "train_acc: 0.7280593325092707, val_acc: 0.5369458128078818, train_loss: 0.7218040167474924, val_loss: 1.5372824815693746 (60 / 100)\n",
            "train_acc: 0.7478368355995055, val_acc: 0.5862068965517241, train_loss: 0.648344841706296, val_loss: 1.1883552281433725 (61 / 100)\n",
            "train_acc: 0.7935723114956736, val_acc: 0.6305418719211823, train_loss: 0.5532905977352882, val_loss: 1.1012205736977714 (62 / 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "outputId": "3faa7a3e-7dce-418a-8a16-5ac13471f165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 24421 (delta 28), reused 33 (delta 14), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24421/24421), 2.15 GiB | 48.26 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Checking out files: 100% (24638/24638), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing mean/std: 100%|██████████| 1012/1012 [47:31<00:00,  2.82s/samples]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[45.6068733   0.81077038 57.85301916]\n",
            "[66.92374056  9.88349788 49.96761776]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}