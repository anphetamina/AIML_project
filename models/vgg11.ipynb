{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg11\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()#,\n",
        "          #transforms.Normalize((45.6068733, 0.81077038, 57.85301916), (66.92374056, 9.88349788, 49.96761776))\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg11()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            acc_diff = train_accuracy-val_accuracy\n",
        "            if acc_diff > 0.25:\n",
        "              print(\"overfit -> train_accuracy {}, val_accuracy {}\".format(train_accuracy, val_accuracy))\n",
        "              return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "        \n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "        \n",
        "\n",
        "        if train_accuracy < 0.25 and epoch > num_epochs*0.1 or train_accuracy < 0.35 and epoch > num_epochs*0.5:\n",
        "          print(\"underfit -> train_accuracy = {}\".format(train_accuracy))\n",
        "          return best_net, best_val_accuracy, best_val_loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "8664ff1e-a00a-4183-d992-6989e9b5ccd2",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "source": [
        "# lr 0.0006444500508054211, batch 14, decay 2.1280582227123365e-05, gamma 0.19924404264743992, val accuracy 0.6305418719211823, val loss 1.0403618915327664 [5 / 50]\n",
        "# lr 0.00038041059192815333, batch 9, decay 3.8372561126798785e-05, gamma 0.057680309789029396, val accuracy 0.6108374384236454, val loss 0.9877617955207825 [38 / 50]\n",
        "# lr 0.00043660847130590896, batch 10, decay 0.00025031720443271155, gamma 0.011678955740792939, val accuracy 0.5615763546798029, val loss 1.0453474251507537 [43 / 50]\n",
        "# lr 0.00027531434783290124, batch 9, decay 4.3783604017624755e-06, gamma 0.11844128056704877, val accuracy 0.5517241379310345, val loss 1.117455956383879 [44 / 50]\n",
        "# lr 0.0007220498435995008, batch 14, decay 2.228552014354877e-05, gamma 0.08113961287843949, val accuracy 0.625615763546798, val loss 0.9968108699239534 [49 / 50]\n",
        "# lr 0.0008377019231346562, batch 8, decay 2.4427015675775187e-06, gamma 0.00903130010323455, val accuracy 0.5849802371541502, val loss 1.0701400147596367 [1 / 50]\n",
        "# lr 0.0010316163585472981, batch 8, decay 1.8309942558988887e-05, gamma 0.002673690056313373, val accuracy 0.5592885375494071, val loss 1.0480610431418589 [5 / 50]\n",
        "# lr 0.0016661746592012004, batch 8, decay 3.3763075569909223e-06, gamma 0.006052773438030023, val accuracy 0.6067193675889329, val loss 1.0441360360548901 [6 / 50]\n",
        "# lr 0.0005075392266021225, batch 12, decay 0.00015097107216674634, gamma 0.23307879269069465, val accuracy 0.6650246305418719, val loss 1.0321336309310838 [12 / 50]\n",
        "# lr 0.0005293020727186627, batch 11, decay 0.0001569197221403604, gamma 0.0797979883084818, val accuracy 0.6059113300492611, val loss 1.0818345975406065 [13 / 50]\n",
        "# \n",
        "BATCH_SIZE = 8\n",
        "LR = 0.0016661746592012004\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 3.3763075569909223e-06\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.006052773438030023\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg11()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7769966431984354, val_loss: 1.7528151361813098 (1 / 100)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.1921182266009852, train_loss: 1.7568124678579926, val_loss: 1.7314458903420735 (2 / 100)\n",
            "train_acc: 0.2719406674907293, val_acc: 0.3251231527093596, train_loss: 1.7148307454306058, val_loss: 1.6364169150150467 (3 / 100)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.2315270935960591, train_loss: 1.648387673758753, val_loss: 1.561875629894839 (4 / 100)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.39408866995073893, train_loss: 1.56933183634679, val_loss: 1.436902018603433 (5 / 100)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.4039408866995074, train_loss: 1.5394843022519784, val_loss: 1.4288246478940465 (6 / 100)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3645320197044335, train_loss: 1.4916156366817441, val_loss: 1.3596990043893824 (7 / 100)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.41379310344827586, train_loss: 1.4428927871883284, val_loss: 1.3270727284436155 (8 / 100)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3842364532019704, train_loss: 1.411518293346551, val_loss: 1.3296967738954892 (9 / 100)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3891625615763547, train_loss: 1.3613156567987317, val_loss: 1.2983370396891252 (10 / 100)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4482758620689655, train_loss: 1.3432683703041783, val_loss: 1.259992968859931 (11 / 100)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.43842364532019706, train_loss: 1.3129778674565376, val_loss: 1.2544936106122773 (12 / 100)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4236453201970443, train_loss: 1.3063071949962337, val_loss: 1.4105484456264328 (13 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.4482758620689655, train_loss: 1.3039696788316308, val_loss: 1.267802991890555 (14 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4187192118226601, train_loss: 1.263734789065584, val_loss: 1.314446323610879 (15 / 100)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.458128078817734, train_loss: 1.2437363972033204, val_loss: 1.1985695454581031 (16 / 100)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.47783251231527096, train_loss: 1.2486410804083674, val_loss: 1.1965558828391465 (17 / 100)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.5221674876847291, train_loss: 1.169055448326988, val_loss: 1.1332845270927316 (18 / 100)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.5615763546798029, train_loss: 1.1472546671170682, val_loss: 1.1594826276666426 (19 / 100)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.5615763546798029, train_loss: 1.1164602343319963, val_loss: 1.0693567850319623 (20 / 100)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.5320197044334976, train_loss: 1.081999367924939, val_loss: 1.1094918538784158 (21 / 100)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.4729064039408867, train_loss: 1.0941730590332277, val_loss: 1.3222907382279194 (22 / 100)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5172413793103449, train_loss: 1.0122847919558418, val_loss: 1.1025436300362272 (23 / 100)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5714285714285714, train_loss: 0.9248830971523327, val_loss: 1.083101467252365 (24 / 100)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.5911330049261084, train_loss: 0.8862506285291373, val_loss: 1.1043619638299706 (25 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.5812807881773399, train_loss: 0.9004518521583567, val_loss: 1.010627460597184 (26 / 100)\n",
            "train_acc: 0.6934487021013597, val_acc: 0.5320197044334976, train_loss: 0.7789959004252449, val_loss: 1.1348916779597993 (27 / 100)\n",
            "train_acc: 0.715698393077874, val_acc: 0.5024630541871922, train_loss: 0.721549032055698, val_loss: 1.3024715822318504 (28 / 100)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.541871921182266, train_loss: 0.6912205371043296, val_loss: 1.2295159942704468 (29 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5862068965517241, train_loss: 0.7459482757653235, val_loss: 1.0907015298387688 (30 / 100)\n",
            "train_acc: 0.788627935723115, val_acc: 0.5960591133004927, train_loss: 0.5587861644028144, val_loss: 1.2297278278566934 (31 / 100)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.5960591133004927, train_loss: 0.528735946665883, val_loss: 1.3495030156497299 (32 / 100)\n",
            "train_acc: 0.8430160692212608, val_acc: 0.5960591133004927, train_loss: 0.4486924691312245, val_loss: 1.1350680566186389 (33 / 100)\n",
            "overfit -> train_accuracy 0.8442521631644005, val_accuracy 0.5566502463054187\n",
            "val accuracy 0.5960591133004927\n",
            "val loss 1.2297278278566934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUIpGmogDgOC",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eOsPQVDgG6",
        "colab_type": "code",
        "outputId": "bb519e2d-06d1-4172-d011-62d1cf9291c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# best scores\n",
        "# \n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = vgg11()\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = 10**random.uniform(-5, -3)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-6, -3)\n",
        "  NUM_EPOCHS = 80\n",
        "  STEP_SIZE = 48\n",
        "  GAMMA = 10**random.uniform(-2, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"-------------------------------------\")\n",
        "  print(set)\n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "\n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "-------------------------------------\n",
            "{'lr': 2.397162900043265e-05, 'batch_size': 10, 'weight_decay': 2.870145136124758e-05, 'gamma': 0.27059565867294294}\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18719211822660098, train_loss: 1.7913651988002366, val_loss: 1.7910951728304032 (1 / 80)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.18719211822660098, train_loss: 1.789856628228177, val_loss: 1.7903695182847272 (2 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.1921182266009852, train_loss: 1.790490361904479, val_loss: 1.789692710185873 (3 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.21182266009852216, train_loss: 1.7897921950914362, val_loss: 1.7890779091219597 (4 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.21182266009852216, train_loss: 1.7885920111416886, val_loss: 1.7883885546858087 (5 / 80)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.22167487684729065, train_loss: 1.7887940766342785, val_loss: 1.787672977142146 (6 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2315270935960591, train_loss: 1.7874750476537735, val_loss: 1.7869898139549594 (7 / 80)\n",
            "train_acc: 0.22744128553770088, val_acc: 0.27586206896551724, train_loss: 1.7865419807775944, val_loss: 1.7862589171367327 (8 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.27586206896551724, train_loss: 1.7875135190996752, val_loss: 1.785610015169153 (9 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.28078817733990147, train_loss: 1.7870910944249043, val_loss: 1.784969039151234 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19901112484548825\n",
            "lr 2.397162900043265e-05, batch 10, decay 2.870145136124758e-05, gamma 0.27059565867294294, val accuracy 0.28078817733990147, val loss 1.784969039151234 [1 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.7570663343001636e-05, 'batch_size': 10, 'weight_decay': 3.686551243246764e-06, 'gamma': 0.017211837317068136}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.23645320197044334, train_loss: 1.7898025465542071, val_loss: 1.7891659096544013 (1 / 80)\n",
            "train_acc: 0.17058096415327564, val_acc: 0.2315270935960591, train_loss: 1.7892050146319811, val_loss: 1.7879000121149524 (2 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.19704433497536947, train_loss: 1.788151406239815, val_loss: 1.7866776905623563 (3 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.787549506159147, val_loss: 1.7855172057457158 (4 / 80)\n",
            "train_acc: 0.207663782447466, val_acc: 0.18226600985221675, train_loss: 1.7854175135880082, val_loss: 1.7842600327994436 (5 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7839830990038048, val_loss: 1.7830976776301568 (6 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7846723707998344, val_loss: 1.781862624173094 (7 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.781786903462687, val_loss: 1.7806047694436435 (8 / 80)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.7819298660504657, val_loss: 1.779479311604805 (9 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.779583712443433, val_loss: 1.778168665364458 (10 / 80)\n",
            "underfit -> train_accuracy = 0.21631644004944375\n",
            "lr 3.7570663343001636e-05, batch 10, decay 3.686551243246764e-06, gamma 0.017211837317068136, val accuracy 0.23645320197044334, val loss 1.7891659096544013 [2 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 8.307767259600181e-05, 'batch_size': 12, 'weight_decay': 3.440549674266629e-05, 'gamma': 0.018220795738137646}\n",
            "train_acc: 0.18788627935723115, val_acc: 0.17733990147783252, train_loss: 1.7898363045915242, val_loss: 1.7892515706311305 (1 / 80)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.17733990147783252, train_loss: 1.7895484084104578, val_loss: 1.788393995444763 (2 / 80)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7882879648279348, val_loss: 1.7874768361669455 (3 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.7882494658268573, val_loss: 1.7866140034398421 (4 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.786679649529852, val_loss: 1.7856957554229962 (5 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.785849502561119, val_loss: 1.784775002249356 (6 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.1921182266009852, train_loss: 1.7852537089726244, val_loss: 1.783956576450705 (7 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18719211822660098, train_loss: 1.7842169138056092, val_loss: 1.7830860074517763 (8 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.22660098522167488, train_loss: 1.7838310115269589, val_loss: 1.7821994655825235 (9 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.24630541871921183, train_loss: 1.7834101239005185, val_loss: 1.7813721343214288 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1903584672435105\n",
            "lr 8.307767259600181e-05, batch 12, decay 3.440549674266629e-05, gamma 0.018220795738137646, val accuracy 0.24630541871921183, val loss 1.7813721343214288 [3 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0009169561952276829, 'batch_size': 15, 'weight_decay': 1.1581342628725813e-06, 'gamma': 0.04477921669069501}\n",
            "train_acc: 0.14956736711990112, val_acc: 0.18226600985221675, train_loss: 1.788146951584645, val_loss: 1.7737414637222666 (1 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7673328672852298, val_loss: 1.7547631169774849 (2 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.19704433497536947, train_loss: 1.7616212345908393, val_loss: 1.7422862405260209 (3 / 80)\n",
            "train_acc: 0.24474660074165636, val_acc: 0.2561576354679803, train_loss: 1.7472605189522648, val_loss: 1.7248431044846333 (4 / 80)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.3842364532019704, train_loss: 1.7267786538497774, val_loss: 1.6890626476316029 (5 / 80)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.3103448275862069, train_loss: 1.6676843313705199, val_loss: 1.5978564781508422 (6 / 80)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3448275862068966, train_loss: 1.6357700499085472, val_loss: 1.5548060744854029 (7 / 80)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3891625615763547, train_loss: 1.5994218829535731, val_loss: 1.5406313717658884 (8 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.30049261083743845, train_loss: 1.5622591228213976, val_loss: 1.5642094899868142 (9 / 80)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.35467980295566504, train_loss: 1.5415299279138686, val_loss: 1.4917323712644905 (10 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3448275862068966, train_loss: 1.5028556532264492, val_loss: 1.496799340976283 (11 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3251231527093596, train_loss: 1.4928682379433782, val_loss: 1.5063514521556536 (12 / 80)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.37438423645320196, train_loss: 1.5010366619591071, val_loss: 1.405845958023823 (13 / 80)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4039408866995074, train_loss: 1.4635986925202924, val_loss: 1.4012746335250403 (14 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3399014778325123, train_loss: 1.438453747698639, val_loss: 1.4478182686960757 (15 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.2857142857142857, train_loss: 1.4345022531316072, val_loss: 1.4768320639145198 (16 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.4482758620689655, train_loss: 1.4158220205672445, val_loss: 1.3335645386738142 (17 / 80)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.3793103448275862, train_loss: 1.3863321351179823, val_loss: 1.4078157787839767 (18 / 80)\n",
            "train_acc: 0.415327564894932, val_acc: 0.3842364532019704, train_loss: 1.3605665928501134, val_loss: 1.3430699133520643 (19 / 80)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.37438423645320196, train_loss: 1.3802527971703868, val_loss: 1.365239621970454 (20 / 80)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.45320197044334976, train_loss: 1.3161226583941759, val_loss: 1.2952502490264441 (21 / 80)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.4187192118226601, train_loss: 1.3614491687716896, val_loss: 1.284294190665184 (22 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.5024630541871922, train_loss: 1.3301995578596117, val_loss: 1.2576580963698514 (23 / 80)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.45320197044334976, train_loss: 1.3120141442685547, val_loss: 1.260261322477181 (24 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.4630541871921182, train_loss: 1.2933451735192383, val_loss: 1.2473478484623537 (25 / 80)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.4876847290640394, train_loss: 1.23683482253802, val_loss: 1.2233585078140785 (26 / 80)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4827586206896552, train_loss: 1.2770601634778846, val_loss: 1.2136326693548944 (27 / 80)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.43842364532019706, train_loss: 1.2348319413635434, val_loss: 1.2074461197618194 (28 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4729064039408867, train_loss: 1.206826497656748, val_loss: 1.164731118185767 (29 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4433497536945813, train_loss: 1.1962460089378215, val_loss: 1.213804723887608 (30 / 80)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.5024630541871922, train_loss: 1.2285424953485449, val_loss: 1.199230929607241 (31 / 80)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.45320197044334976, train_loss: 1.2191531104122015, val_loss: 1.2759531143263643 (32 / 80)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.458128078817734, train_loss: 1.1449485581796455, val_loss: 1.2115472484691976 (33 / 80)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.49261083743842365, train_loss: 1.156135478037397, val_loss: 1.15778864868756 (34 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5123152709359606, train_loss: 1.0898722832370895, val_loss: 1.2325632064213305 (35 / 80)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.5073891625615764, train_loss: 1.0088200692930092, val_loss: 1.16767685078635 (36 / 80)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.5320197044334976, train_loss: 1.063139023827976, val_loss: 1.1783757726547166 (37 / 80)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.5073891625615764, train_loss: 0.990120483196268, val_loss: 1.1738317555981903 (38 / 80)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5467980295566502, train_loss: 0.9783086352354222, val_loss: 1.106851821756128 (39 / 80)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5123152709359606, train_loss: 0.9327321096020664, val_loss: 1.0857329764976877 (40 / 80)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5517241379310345, train_loss: 0.8694280661522826, val_loss: 1.0383694515439676 (41 / 80)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5665024630541872, train_loss: 0.8566508030861948, val_loss: 1.052139577019978 (42 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.5517241379310345, train_loss: 0.8137511314066732, val_loss: 1.2571118943796957 (43 / 80)\n",
            "train_acc: 0.65389369592089, val_acc: 0.5517241379310345, train_loss: 0.8027293990436384, val_loss: 1.2021456404859796 (44 / 80)\n",
            "train_acc: 0.6983930778739185, val_acc: 0.4975369458128079, train_loss: 0.7572926712787638, val_loss: 1.6119314593634582 (45 / 80)\n",
            "train_acc: 0.688504326328801, val_acc: 0.5714285714285714, train_loss: 0.7802656737924064, val_loss: 1.0149576003328333 (46 / 80)\n",
            "train_acc: 0.7342398022249691, val_acc: 0.5615763546798029, train_loss: 0.6635453698440594, val_loss: 1.2979606216764215 (47 / 80)\n",
            "train_acc: 0.7527812113720643, val_acc: 0.5960591133004927, train_loss: 0.6455117122941317, val_loss: 1.0298696039932702 (48 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.645320197044335, train_loss: 0.508798143569707, val_loss: 0.9528749385490793 (49 / 80)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6600985221674877, train_loss: 0.4397563589333898, val_loss: 0.9788913393549143 (50 / 80)\n",
            "train_acc: 0.8751545117428925, val_acc: 0.6502463054187192, train_loss: 0.3934786583680305, val_loss: 0.981017461844853 (51 / 80)\n",
            "train_acc: 0.8788627935723115, val_acc: 0.6551724137931034, train_loss: 0.4042407865872047, val_loss: 1.0081347062669952 (52 / 80)\n",
            "train_acc: 0.8541409147095179, val_acc: 0.6305418719211823, train_loss: 0.38566762926367804, val_loss: 1.0001312597044583 (53 / 80)\n",
            "train_acc: 0.865265760197775, val_acc: 0.6699507389162561, train_loss: 0.36920207493900514, val_loss: 1.014952057981726 (54 / 80)\n",
            "train_acc: 0.8887515451174289, val_acc: 0.6551724137931034, train_loss: 0.32912344300408003, val_loss: 1.023289046557666 (55 / 80)\n",
            "train_acc: 0.8714462299134734, val_acc: 0.6600985221674877, train_loss: 0.36361542303571004, val_loss: 1.0250795533504393 (56 / 80)\n",
            "train_acc: 0.8850432632880099, val_acc: 0.6551724137931034, train_loss: 0.3376306006949676, val_loss: 1.0432059453625984 (57 / 80)\n",
            "train_acc: 0.899876390605686, val_acc: 0.6699507389162561, train_loss: 0.32531549957464595, val_loss: 1.0645415671353269 (58 / 80)\n",
            "train_acc: 0.8887515451174289, val_acc: 0.6600985221674877, train_loss: 0.31378380996629834, val_loss: 1.1045163934453954 (59 / 80)\n",
            "train_acc: 0.8887515451174289, val_acc: 0.6600985221674877, train_loss: 0.30978609093813725, val_loss: 1.0644595637697305 (60 / 80)\n",
            "train_acc: 0.8887515451174289, val_acc: 0.6551724137931034, train_loss: 0.3046488389557018, val_loss: 1.0980015866862143 (61 / 80)\n",
            "train_acc: 0.9122373300370828, val_acc: 0.6699507389162561, train_loss: 0.28283519290010034, val_loss: 1.0963586919707031 (62 / 80)\n",
            "train_acc: 0.892459826946848, val_acc: 0.6650246305418719, train_loss: 0.30838821103568426, val_loss: 1.119131234185449 (63 / 80)\n",
            "train_acc: 0.8949320148331273, val_acc: 0.6650246305418719, train_loss: 0.29033256358983933, val_loss: 1.115649331232597 (64 / 80)\n",
            "train_acc: 0.9097651421508035, val_acc: 0.6600985221674877, train_loss: 0.2678208719519956, val_loss: 1.1331723438107908 (65 / 80)\n",
            "overfit -> train_accuracy 0.9221260815822002, val_accuracy 0.6551724137931034\n",
            "lr 0.0009169561952276829, batch 15, decay 1.1581342628725813e-06, gamma 0.04477921669069501, val accuracy 0.6699507389162561, val loss 1.014952057981726 [4 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 3.262060721356589e-05, 'batch_size': 12, 'weight_decay': 0.0002861287564329187, 'gamma': 0.1028255498383413}\n",
            "train_acc: 0.15945611866501855, val_acc: 0.1477832512315271, train_loss: 1.7920526948346491, val_loss: 1.7917522873197282 (1 / 80)\n",
            "train_acc: 0.1508034610630408, val_acc: 0.1477832512315271, train_loss: 1.791924471908211, val_loss: 1.791110069880932 (2 / 80)\n",
            "train_acc: 0.1631644004944376, val_acc: 0.1724137931034483, train_loss: 1.79188671660217, val_loss: 1.7905303515824191 (3 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.17733990147783252, train_loss: 1.7913920516873467, val_loss: 1.7899804326701048 (4 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.17733990147783252, train_loss: 1.7904537540431076, val_loss: 1.789400168240364 (5 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7891726675080724, val_loss: 1.7888037788456883 (6 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7893454586472293, val_loss: 1.7882763482079718 (7 / 80)\n",
            "train_acc: 0.14956736711990112, val_acc: 0.18226600985221675, train_loss: 1.7897305146725422, val_loss: 1.7877419852270868 (8 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7880283342156333, val_loss: 1.7871464925446534 (9 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7878288861700278, val_loss: 1.786575850594807 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1903584672435105\n",
            "lr 3.262060721356589e-05, batch 12, decay 0.0002861287564329187, gamma 0.1028255498383413, val accuracy 0.18226600985221675, val loss 1.7888037788456883 [5 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.544749636966516e-05, 'batch_size': 9, 'weight_decay': 2.3853754635815763e-06, 'gamma': 0.04073716926548914}\n",
            "train_acc: 0.1792336217552534, val_acc: 0.15270935960591134, train_loss: 1.7905151287026988, val_loss: 1.7907619887384876 (1 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.15270935960591134, train_loss: 1.790307134279362, val_loss: 1.790088337630474 (2 / 80)\n",
            "train_acc: 0.15698393077873918, val_acc: 0.1625615763546798, train_loss: 1.7908902944828877, val_loss: 1.789457585424038 (3 / 80)\n",
            "train_acc: 0.15945611866501855, val_acc: 0.17733990147783252, train_loss: 1.7891451014281792, val_loss: 1.7889339735942522 (4 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.7887019834058688, val_loss: 1.788309776137028 (5 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18719211822660098, train_loss: 1.7878926575404899, val_loss: 1.7877392639667529 (6 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7867827546611263, val_loss: 1.7871071546535773 (7 / 80)\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.788775685691126, val_loss: 1.7865549073430704 (8 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7868824628433868, val_loss: 1.7859383774508397 (9 / 80)\n",
            "train_acc: 0.16563658838071693, val_acc: 0.18226600985221675, train_loss: 1.786922580084783, val_loss: 1.7854120854673714 (10 / 80)\n",
            "underfit -> train_accuracy = 0.16563658838071693\n",
            "lr 1.544749636966516e-05, batch 9, decay 2.3853754635815763e-06, gamma 0.04073716926548914, val accuracy 0.18719211822660098, val loss 1.7877392639667529 [6 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005586727976157491, 'batch_size': 13, 'weight_decay': 0.0004782867063121473, 'gamma': 0.03248410434649776}\n",
            "train_acc: 0.18912237330037082, val_acc: 0.19704433497536947, train_loss: 1.7883566072756338, val_loss: 1.7808088134662272 (1 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.7761684650249032, val_loss: 1.7667045757688324 (2 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.768245147538863, val_loss: 1.7570735521504444 (3 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7551451675382033, val_loss: 1.747964302894517 (4 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.3054187192118227, train_loss: 1.7528849236013273, val_loss: 1.7397319953429875 (5 / 80)\n",
            "train_acc: 0.2521631644004944, val_acc: 0.3103448275862069, train_loss: 1.7491694839097955, val_loss: 1.7250892135310056 (6 / 80)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.32019704433497537, train_loss: 1.7252400920476547, val_loss: 1.6970550168323986 (7 / 80)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.2955665024630542, train_loss: 1.7106655335102152, val_loss: 1.6544952891730322 (8 / 80)\n",
            "train_acc: 0.3164400494437577, val_acc: 0.3251231527093596, train_loss: 1.6428313791678184, val_loss: 1.5499109476070685 (9 / 80)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.270935960591133, train_loss: 1.62146046518248, val_loss: 1.5863542404080846 (10 / 80)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.3399014778325123, train_loss: 1.5620779876213875, val_loss: 1.5691092566316351 (11 / 80)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.3497536945812808, train_loss: 1.5742069348711314, val_loss: 1.4875324136517905 (12 / 80)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3497536945812808, train_loss: 1.5520512900040089, val_loss: 1.5023018967341908 (13 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.26108374384236455, train_loss: 1.5168662855150674, val_loss: 1.6106564246962223 (14 / 80)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3842364532019704, train_loss: 1.5277581374046976, val_loss: 1.440731810231514 (15 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.39408866995073893, train_loss: 1.4798193270402726, val_loss: 1.46762650059949 (16 / 80)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.4039408866995074, train_loss: 1.4804177148675153, val_loss: 1.4492191733985111 (17 / 80)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3399014778325123, train_loss: 1.4977854845403005, val_loss: 1.4446630659949016 (18 / 80)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.35467980295566504, train_loss: 1.4604633611123847, val_loss: 1.48986893393136 (19 / 80)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3251231527093596, train_loss: 1.4484396013252814, val_loss: 1.5248289208106807 (20 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.4187192118226601, train_loss: 1.4457133668020128, val_loss: 1.4012764709923655 (21 / 80)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.3694581280788177, train_loss: 1.4208714699715708, val_loss: 1.4024442763164127 (22 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.41379310344827586, train_loss: 1.3959020909626492, val_loss: 1.361166453713854 (23 / 80)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.41379310344827586, train_loss: 1.390724925013496, val_loss: 1.3686409953779775 (24 / 80)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.3891625615763547, train_loss: 1.396222798432349, val_loss: 1.3528541972484496 (25 / 80)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.4433497536945813, train_loss: 1.4004535789984855, val_loss: 1.3237135046221353 (26 / 80)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.4433497536945813, train_loss: 1.3599045359160018, val_loss: 1.3251536937769999 (27 / 80)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.42857142857142855, train_loss: 1.3639958039644475, val_loss: 1.3261033325946976 (28 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.3891625615763547, train_loss: 1.3418643451002237, val_loss: 1.3024473345925656 (29 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.42857142857142855, train_loss: 1.2936944070056873, val_loss: 1.2639254907081867 (30 / 80)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.43349753694581283, train_loss: 1.3049635294783395, val_loss: 1.2980805999539755 (31 / 80)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4482758620689655, train_loss: 1.303059039658168, val_loss: 1.260243481603162 (32 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.46798029556650245, train_loss: 1.2670815362329093, val_loss: 1.2469668658496125 (33 / 80)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.458128078817734, train_loss: 1.2637771572848628, val_loss: 1.239791146346501 (34 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.458128078817734, train_loss: 1.2852213171268128, val_loss: 1.2596468349982952 (35 / 80)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.458128078817734, train_loss: 1.2408675258917037, val_loss: 1.2749537998819587 (36 / 80)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.4236453201970443, train_loss: 1.2313723300384503, val_loss: 1.266188967991345 (37 / 80)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4827586206896552, train_loss: 1.2036794183133412, val_loss: 1.180496428106806 (38 / 80)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.43842364532019706, train_loss: 1.21643531569297, val_loss: 1.2072896555139514 (39 / 80)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.43842364532019706, train_loss: 1.196734681633406, val_loss: 1.2197617154403273 (40 / 80)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.45320197044334976, train_loss: 1.190564458906577, val_loss: 1.2306436000786392 (41 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.4630541871921182, train_loss: 1.154803624185555, val_loss: 1.2456253781694497 (42 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4482758620689655, train_loss: 1.130912368833945, val_loss: 1.317691035458607 (43 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.5123152709359606, train_loss: 1.1715715529008024, val_loss: 1.1077068521471447 (44 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.47783251231527096, train_loss: 1.1370336657990927, val_loss: 1.2422458171257245 (45 / 80)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.4827586206896552, train_loss: 1.0977094915358185, val_loss: 1.2489889032147787 (46 / 80)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.5270935960591133, train_loss: 1.0574534908950108, val_loss: 1.1193072120544358 (47 / 80)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.4876847290640394, train_loss: 1.0715925221242775, val_loss: 1.1623274187736323 (48 / 80)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5073891625615764, train_loss: 1.0103960813786397, val_loss: 1.084950049522475 (49 / 80)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.541871921182266, train_loss: 0.9704146311515931, val_loss: 1.075914998947106 (50 / 80)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5467980295566502, train_loss: 0.9614144728711274, val_loss: 1.063438501851312 (51 / 80)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5467980295566502, train_loss: 0.9345310090940874, val_loss: 1.0703232940194642 (52 / 80)\n",
            "train_acc: 0.630407911001236, val_acc: 0.5369458128078818, train_loss: 0.9615447188189946, val_loss: 1.073977383486743 (53 / 80)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.5369458128078818, train_loss: 0.9273337412013112, val_loss: 1.0780038645702044 (54 / 80)\n",
            "train_acc: 0.6687268232385661, val_acc: 0.5517241379310345, train_loss: 0.9071342381101898, val_loss: 1.0735029275781416 (55 / 80)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5517241379310345, train_loss: 0.9442143636227244, val_loss: 1.0682848421810882 (56 / 80)\n",
            "train_acc: 0.6118665018541409, val_acc: 0.5467980295566502, train_loss: 0.9296537808641073, val_loss: 1.077147511132245 (57 / 80)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5467980295566502, train_loss: 0.9298614304425248, val_loss: 1.0708560130279052 (58 / 80)\n",
            "train_acc: 0.6600741656365884, val_acc: 0.5566502463054187, train_loss: 0.8922724393006456, val_loss: 1.0790590335582864 (59 / 80)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.541871921182266, train_loss: 0.878356758647855, val_loss: 1.0890127038720794 (60 / 80)\n",
            "train_acc: 0.657601977750309, val_acc: 0.5467980295566502, train_loss: 0.8656313109530507, val_loss: 1.0759003840643784 (61 / 80)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.5517241379310345, train_loss: 0.9047786771367006, val_loss: 1.0778685714223701 (62 / 80)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5615763546798029, train_loss: 0.9077253811733684, val_loss: 1.0756745784740729 (63 / 80)\n",
            "train_acc: 0.6786155747836835, val_acc: 0.5615763546798029, train_loss: 0.8725780081395313, val_loss: 1.0731910105996532 (64 / 80)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5615763546798029, train_loss: 0.9029381594934923, val_loss: 1.0687782139026474 (65 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5615763546798029, train_loss: 0.8946487588257666, val_loss: 1.0689356139140764 (66 / 80)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.5566502463054187, train_loss: 0.8624956543719665, val_loss: 1.0742160460631835 (67 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.5467980295566502, train_loss: 0.871178933657586, val_loss: 1.0952297278812952 (68 / 80)\n",
            "train_acc: 0.6501854140914709, val_acc: 0.5517241379310345, train_loss: 0.8915659132492999, val_loss: 1.0784248157675043 (69 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.5467980295566502, train_loss: 0.8988179442540677, val_loss: 1.0659307693612987 (70 / 80)\n",
            "train_acc: 0.6514215080346106, val_acc: 0.5517241379310345, train_loss: 0.8838053149331191, val_loss: 1.0819821815772597 (71 / 80)\n",
            "train_acc: 0.657601977750309, val_acc: 0.5467980295566502, train_loss: 0.8627662841410219, val_loss: 1.089670069699217 (72 / 80)\n",
            "train_acc: 0.6711990111248455, val_acc: 0.541871921182266, train_loss: 0.8485545964706666, val_loss: 1.0827641149459801 (73 / 80)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5615763546798029, train_loss: 0.8724889050160703, val_loss: 1.0821165013783083 (74 / 80)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5615763546798029, train_loss: 0.8529569223725751, val_loss: 1.0772525171928218 (75 / 80)\n",
            "train_acc: 0.6637824474660075, val_acc: 0.541871921182266, train_loss: 0.8448669767866028, val_loss: 1.0796823853929642 (76 / 80)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5517241379310345, train_loss: 0.8750940016821966, val_loss: 1.0765295750989115 (77 / 80)\n",
            "train_acc: 0.6563658838071693, val_acc: 0.5517241379310345, train_loss: 0.8422701509096124, val_loss: 1.0766782704832518 (78 / 80)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.5467980295566502, train_loss: 0.8306239491192755, val_loss: 1.0770122843422913 (79 / 80)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5566502463054187, train_loss: 0.8457414535126374, val_loss: 1.0719763905250381 (80 / 80)\n",
            "lr 0.0005586727976157491, batch 13, decay 0.0004782867063121473, gamma 0.03248410434649776, val accuracy 0.5615763546798029, val loss 1.0756745784740729 [7 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.3386900077545868e-05, 'batch_size': 12, 'weight_decay': 0.00015223015929261748, 'gamma': 0.14338829767042233}\n",
            "train_acc: 0.13102595797280595, val_acc: 0.08866995073891626, train_loss: 1.7941898129631768, val_loss: 1.7937641507886313 (1 / 80)\n",
            "train_acc: 0.1508034610630408, val_acc: 0.09852216748768473, train_loss: 1.7934225411586031, val_loss: 1.7931452378850852 (2 / 80)\n",
            "train_acc: 0.14585908529048208, val_acc: 0.18719211822660098, train_loss: 1.7920542438186438, val_loss: 1.7925441899323111 (3 / 80)\n",
            "train_acc: 0.14956736711990112, val_acc: 0.22660098522167488, train_loss: 1.7919558260143171, val_loss: 1.7919272384032827 (4 / 80)\n",
            "train_acc: 0.15327564894932014, val_acc: 0.18226600985221675, train_loss: 1.7916057053838288, val_loss: 1.7912705684530323 (5 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7902931778038977, val_loss: 1.790611563057735 (6 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7907057058973277, val_loss: 1.7899697055957589 (7 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7895335636858003, val_loss: 1.789373761327396 (8 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7891115978710141, val_loss: 1.7887396783077072 (9 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7891857142206764, val_loss: 1.7882029111749433 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18665018541409148\n",
            "lr 2.3386900077545868e-05, batch 12, decay 0.00015223015929261748, gamma 0.14338829767042233, val accuracy 0.22660098522167488, val loss 1.7919272384032827 [8 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005333458088361308, 'batch_size': 8, 'weight_decay': 3.0292876762612556e-06, 'gamma': 0.05924716479234754}\n",
            "train_acc: 0.1668726823238566, val_acc: 0.22660098522167488, train_loss: 1.7872043323457905, val_loss: 1.7774901131691017 (1 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7730456558234613, val_loss: 1.759588165823462 (2 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7605284823770133, val_loss: 1.745332137117245 (3 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.18226600985221675, train_loss: 1.752495544655214, val_loss: 1.7328712059359246 (4 / 80)\n",
            "train_acc: 0.24598269468479605, val_acc: 0.24630541871921183, train_loss: 1.7407549890805822, val_loss: 1.7052614759341838 (5 / 80)\n",
            "train_acc: 0.2880098887515451, val_acc: 0.3103448275862069, train_loss: 1.6962061006442284, val_loss: 1.6407112822744059 (6 / 80)\n",
            "train_acc: 0.315203955500618, val_acc: 0.31527093596059114, train_loss: 1.6552062877471132, val_loss: 1.626056588342037 (7 / 80)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.3891625615763547, train_loss: 1.6305425037412324, val_loss: 1.5095337858341011 (8 / 80)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.3497536945812808, train_loss: 1.5726445310637447, val_loss: 1.595349235487689 (9 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.3497536945812808, train_loss: 1.5445679993505679, val_loss: 1.4591311421887627 (10 / 80)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3842364532019704, train_loss: 1.4786390039623152, val_loss: 1.4651934008292964 (11 / 80)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.41379310344827586, train_loss: 1.5299981212144433, val_loss: 1.4777492513797554 (12 / 80)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3891625615763547, train_loss: 1.4987193923650772, val_loss: 1.4232104488194282 (13 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.41379310344827586, train_loss: 1.4278188613790221, val_loss: 1.3617165076908806 (14 / 80)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.3793103448275862, train_loss: 1.405399613828388, val_loss: 1.5359480662886145 (15 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4088669950738916, train_loss: 1.4117715650494815, val_loss: 1.350942127810323 (16 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.3891625615763547, train_loss: 1.378732748173076, val_loss: 1.3067012625962056 (17 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.39901477832512317, train_loss: 1.3635945751876266, val_loss: 1.414296693402558 (18 / 80)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.39901477832512317, train_loss: 1.3820612336266027, val_loss: 1.3884793625676572 (19 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4482758620689655, train_loss: 1.3299098589511678, val_loss: 1.3258513420673426 (20 / 80)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.458128078817734, train_loss: 1.3336194924577351, val_loss: 1.2613801879835833 (21 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4039408866995074, train_loss: 1.3432430720005106, val_loss: 1.3163520174073469 (22 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4630541871921182, train_loss: 1.3235685907866073, val_loss: 1.247654988260692 (23 / 80)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.4482758620689655, train_loss: 1.2706310078593797, val_loss: 1.2868593179533634 (24 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.43349753694581283, train_loss: 1.2843547968104094, val_loss: 1.3216810103120475 (25 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4827586206896552, train_loss: 1.268046965557801, val_loss: 1.2517535727599571 (26 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.41379310344827586, train_loss: 1.2795927347741993, val_loss: 1.215111050699732 (27 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.47783251231527096, train_loss: 1.2840709553660805, val_loss: 1.1669067661163255 (28 / 80)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.46798029556650245, train_loss: 1.1907906324518627, val_loss: 1.2365640172817436 (29 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.4630541871921182, train_loss: 1.1970293483569094, val_loss: 1.2152986821576293 (30 / 80)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.4975369458128079, train_loss: 1.2357031482701248, val_loss: 1.226075379425669 (31 / 80)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.47783251231527096, train_loss: 1.1868656215031155, val_loss: 1.2232293815448367 (32 / 80)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.4975369458128079, train_loss: 1.1815666845908712, val_loss: 1.1239689964378996 (33 / 80)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.43842364532019706, train_loss: 1.1102054381400015, val_loss: 1.2109232694644647 (34 / 80)\n",
            "train_acc: 0.522867737948084, val_acc: 0.43349753694581283, train_loss: 1.1466018478714197, val_loss: 1.4502571733127088 (35 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5517241379310345, train_loss: 1.1423243969421009, val_loss: 1.1057285005823145 (36 / 80)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.4975369458128079, train_loss: 1.089043321951358, val_loss: 1.0806195979635116 (37 / 80)\n",
            "train_acc: 0.553770086526576, val_acc: 0.49261083743842365, train_loss: 1.0467127073827869, val_loss: 1.0746715726523564 (38 / 80)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.4975369458128079, train_loss: 1.0669461331055103, val_loss: 1.168794641353814 (39 / 80)\n",
            "train_acc: 0.5859085290482077, val_acc: 0.5123152709359606, train_loss: 1.0164364103333765, val_loss: 1.1049411490632983 (40 / 80)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.5320197044334976, train_loss: 0.9782441290111565, val_loss: 1.1256526979466377 (41 / 80)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.5862068965517241, train_loss: 0.9863460635667384, val_loss: 1.035098979332177 (42 / 80)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.5714285714285714, train_loss: 0.9197632450108475, val_loss: 1.0500107066971915 (43 / 80)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5812807881773399, train_loss: 0.9768028783857159, val_loss: 1.0246652276645154 (44 / 80)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.4827586206896552, train_loss: 0.9288869383013882, val_loss: 1.2042875912389144 (45 / 80)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.5763546798029556, train_loss: 0.843372269820224, val_loss: 1.0517546977902867 (46 / 80)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.5911330049261084, train_loss: 0.8103096203692027, val_loss: 1.0305746999280205 (47 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.6059113300492611, train_loss: 0.7947641930857164, val_loss: 1.0242517015029644 (48 / 80)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.6305418719211823, train_loss: 0.6465959907020126, val_loss: 0.9712443754003552 (49 / 80)\n",
            "train_acc: 0.7750309023485785, val_acc: 0.6206896551724138, train_loss: 0.5958129527100232, val_loss: 0.990268739573474 (50 / 80)\n",
            "train_acc: 0.8071693448702101, val_acc: 0.6206896551724138, train_loss: 0.5249521254903748, val_loss: 1.0040148749140096 (51 / 80)\n",
            "train_acc: 0.8158220024721878, val_acc: 0.6206896551724138, train_loss: 0.5219686234689909, val_loss: 1.0206724276096362 (52 / 80)\n",
            "train_acc: 0.8108776266996292, val_acc: 0.6157635467980296, train_loss: 0.5293432233949527, val_loss: 1.0006749826699055 (53 / 80)\n",
            "train_acc: 0.8121137206427689, val_acc: 0.625615763546798, train_loss: 0.5025518862956534, val_loss: 1.0094692530890403 (54 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.6403940886699507, train_loss: 0.5284268565761439, val_loss: 0.990062849568616 (55 / 80)\n",
            "train_acc: 0.8009888751545118, val_acc: 0.6108374384236454, train_loss: 0.5094819693689145, val_loss: 1.0035409940581017 (56 / 80)\n",
            "train_acc: 0.8195302843016069, val_acc: 0.6157635467980296, train_loss: 0.5040777479614993, val_loss: 1.020770866882625 (57 / 80)\n",
            "train_acc: 0.8318912237330037, val_acc: 0.6059113300492611, train_loss: 0.45512168000743475, val_loss: 1.041428950032577 (58 / 80)\n",
            "train_acc: 0.823238566131026, val_acc: 0.6108374384236454, train_loss: 0.4852795281133192, val_loss: 1.0234161815032583 (59 / 80)\n",
            "train_acc: 0.8467243510506799, val_acc: 0.6108374384236454, train_loss: 0.43423530551500167, val_loss: 1.0559920172385981 (60 / 80)\n",
            "train_acc: 0.8504326328800988, val_acc: 0.6305418719211823, train_loss: 0.4353119319095305, val_loss: 1.044010780127765 (61 / 80)\n",
            "train_acc: 0.8220024721878862, val_acc: 0.625615763546798, train_loss: 0.45923799180571906, val_loss: 1.0432418179629472 (62 / 80)\n",
            "train_acc: 0.8430160692212608, val_acc: 0.6206896551724138, train_loss: 0.43596645662899514, val_loss: 1.0456167180549922 (63 / 80)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.6206896551724138, train_loss: 0.43618610541811687, val_loss: 1.0770058667131246 (64 / 80)\n",
            "train_acc: 0.8442521631644005, val_acc: 0.6108374384236454, train_loss: 0.4118509282287767, val_loss: 1.1071816556559408 (65 / 80)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.6108374384236454, train_loss: 0.42594104305333347, val_loss: 1.0583323479579587 (66 / 80)\n",
            "train_acc: 0.8491965389369592, val_acc: 0.6206896551724138, train_loss: 0.40260892509677354, val_loss: 1.0960866137972018 (67 / 80)\n",
            "train_acc: 0.8677379480840544, val_acc: 0.625615763546798, train_loss: 0.3918209027300954, val_loss: 1.0812304947763829 (68 / 80)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.625615763546798, train_loss: 0.3939267812464824, val_loss: 1.0556690610688308 (69 / 80)\n",
            "train_acc: 0.8714462299134734, val_acc: 0.6305418719211823, train_loss: 0.35260951430600124, val_loss: 1.0872556000507523 (70 / 80)\n",
            "overfit -> train_accuracy 0.8516687268232386, val_accuracy 0.5862068965517241\n",
            "lr 0.0005333458088361308, batch 8, decay 3.0292876762612556e-06, gamma 0.05924716479234754, val accuracy 0.6403940886699507, val loss 0.990062849568616 [9 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.9606364327821473e-05, 'batch_size': 13, 'weight_decay': 0.0005102652443826991, 'gamma': 0.13712160921444644}\n",
            "train_acc: 0.14833127317676142, val_acc: 0.18226600985221675, train_loss: 1.7920884580635759, val_loss: 1.7921835430737199 (1 / 80)\n",
            "train_acc: 0.16440049443757726, val_acc: 0.18226600985221675, train_loss: 1.7927399172329048, val_loss: 1.7913961592566203 (2 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7908599675806844, val_loss: 1.7906553457523215 (3 / 80)\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.7915497670509613, val_loss: 1.7899852315780564 (4 / 80)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.789687818148817, val_loss: 1.7891613732417817 (5 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7897241576787715, val_loss: 1.78840322388804 (6 / 80)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7881673424146673, val_loss: 1.7877114488573498 (7 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7886508433574209, val_loss: 1.787044542176383 (8 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.786606273191379, val_loss: 1.7862752452859738 (9 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.7868841282369474, val_loss: 1.7855514064798215 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19406674907292953\n",
            "lr 2.9606364327821473e-05, batch 13, decay 0.0005102652443826991, gamma 0.13712160921444644, val accuracy 0.18226600985221675, val loss 1.7921835430737199 [10 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 8.745344744272692e-05, 'batch_size': 8, 'weight_decay': 5.2648918446318146e-05, 'gamma': 0.01116456072041907}\n",
            "train_acc: 0.14956736711990112, val_acc: 0.1625615763546798, train_loss: 1.7935935926378437, val_loss: 1.790119615094415 (1 / 80)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.1921182266009852, train_loss: 1.789423338120299, val_loss: 1.786359283724442 (2 / 80)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.1724137931034483, train_loss: 1.7856521018503329, val_loss: 1.782806201521399 (3 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.783765217724483, val_loss: 1.7794027557513985 (4 / 80)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7795704365955443, val_loss: 1.7757460712799298 (5 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7752749258272433, val_loss: 1.7712912283507474 (6 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.773700630414324, val_loss: 1.7679108557442726 (7 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7684532772330626, val_loss: 1.7636334314722146 (8 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7668839203854574, val_loss: 1.7597726342713305 (9 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7634339532981844, val_loss: 1.7563976301935507 (10 / 80)\n",
            "underfit -> train_accuracy = 0.18788627935723115\n",
            "lr 8.745344744272692e-05, batch 8, decay 5.2648918446318146e-05, gamma 0.01116456072041907, val accuracy 0.1921182266009852, val loss 1.786359283724442 [11 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005075392266021225, 'batch_size': 12, 'weight_decay': 0.00015097107216674634, 'gamma': 0.23307879269069465}\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7876705004936095, val_loss: 1.783001598466206 (1 / 80)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7795818515112727, val_loss: 1.772416100126182 (2 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7724928882419695, val_loss: 1.7618645335653145 (3 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7612569650407186, val_loss: 1.7506759125610878 (4 / 80)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7546657673065977, val_loss: 1.7420349502798371 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.21674876847290642, train_loss: 1.7485545547989891, val_loss: 1.7311581514151813 (6 / 80)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.23645320197044334, train_loss: 1.7406838939275375, val_loss: 1.7176544989271116 (7 / 80)\n",
            "train_acc: 0.2546353522867738, val_acc: 0.3793103448275862, train_loss: 1.7279035040120996, val_loss: 1.6946427011724763 (8 / 80)\n",
            "train_acc: 0.30778739184178, val_acc: 0.27586206896551724, train_loss: 1.6840240930302623, val_loss: 1.6608046563388092 (9 / 80)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.3054187192118227, train_loss: 1.6483612841522444, val_loss: 1.6472234831654966 (10 / 80)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.3399014778325123, train_loss: 1.5956657752118388, val_loss: 1.5378475177464226 (11 / 80)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3448275862068966, train_loss: 1.5596317858866915, val_loss: 1.486498295379977 (12 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.33497536945812806, train_loss: 1.5280486224460956, val_loss: 1.5145227950194786 (13 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.39408866995073893, train_loss: 1.494768549691614, val_loss: 1.4616689118258472 (14 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.35960591133004927, train_loss: 1.510751248437483, val_loss: 1.4331299800590929 (15 / 80)\n",
            "train_acc: 0.380716934487021, val_acc: 0.4088669950738916, train_loss: 1.4764423090388954, val_loss: 1.4251210319584813 (16 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.2955665024630542, train_loss: 1.4441952507929101, val_loss: 1.501256735454052 (17 / 80)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.4039408866995074, train_loss: 1.450340751369745, val_loss: 1.380306142891569 (18 / 80)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.42857142857142855, train_loss: 1.4296225131073752, val_loss: 1.3908085276927855 (19 / 80)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.41379310344827586, train_loss: 1.405698676339186, val_loss: 1.3420445678269335 (20 / 80)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.4630541871921182, train_loss: 1.426186043340874, val_loss: 1.3430737579984617 (21 / 80)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.42857142857142855, train_loss: 1.402798579414047, val_loss: 1.3224907056451431 (22 / 80)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.4482758620689655, train_loss: 1.35423677960786, val_loss: 1.3426187114762556 (23 / 80)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.39408866995073893, train_loss: 1.3636171910612487, val_loss: 1.3349386982142633 (24 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.45320197044334976, train_loss: 1.3704325407190876, val_loss: 1.338983626788473 (25 / 80)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.3497536945812808, train_loss: 1.3583803381701778, val_loss: 1.3886213549252213 (26 / 80)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4433497536945813, train_loss: 1.311902478981961, val_loss: 1.2984948487117374 (27 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4433497536945813, train_loss: 1.3239798902433795, val_loss: 1.26486501963855 (28 / 80)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.45320197044334976, train_loss: 1.2998958444418511, val_loss: 1.2532801610495656 (29 / 80)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4482758620689655, train_loss: 1.2760504460600015, val_loss: 1.2801425010699945 (30 / 80)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4482758620689655, train_loss: 1.2982607858879458, val_loss: 1.2270072534166534 (31 / 80)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.4827586206896552, train_loss: 1.295387205293653, val_loss: 1.2135629636313527 (32 / 80)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.4876847290640394, train_loss: 1.2504437635796621, val_loss: 1.1947711130668377 (33 / 80)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.4729064039408867, train_loss: 1.215406623994759, val_loss: 1.2750533096896017 (34 / 80)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.45320197044334976, train_loss: 1.2183639337164804, val_loss: 1.1878423767136823 (35 / 80)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5073891625615764, train_loss: 1.1875457480752425, val_loss: 1.1789400424863317 (36 / 80)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.5172413793103449, train_loss: 1.2210410028806575, val_loss: 1.1460830002582718 (37 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.5369458128078818, train_loss: 1.1560132476985823, val_loss: 1.1438992246618411 (38 / 80)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.5320197044334976, train_loss: 1.182365597620588, val_loss: 1.1214445500538266 (39 / 80)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.5270935960591133, train_loss: 1.1508258622420586, val_loss: 1.1470347363960567 (40 / 80)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5221674876847291, train_loss: 1.1138215157835387, val_loss: 1.1333909610222126 (41 / 80)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.47783251231527096, train_loss: 1.116514691353139, val_loss: 1.321312271315476 (42 / 80)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.43842364532019706, train_loss: 1.105074759172126, val_loss: 1.3030661162484456 (43 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5320197044334976, train_loss: 1.1007077629840272, val_loss: 1.1079812669401685 (44 / 80)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.49261083743842365, train_loss: 1.0754237109415317, val_loss: 1.159621512361348 (45 / 80)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.47783251231527096, train_loss: 1.0403390220275472, val_loss: 1.1923857222636933 (46 / 80)\n",
            "train_acc: 0.5797280593325093, val_acc: 0.5270935960591133, train_loss: 1.0303320187720735, val_loss: 1.0636073403757782 (47 / 80)\n",
            "train_acc: 0.580964153275649, val_acc: 0.541871921182266, train_loss: 1.0170550572562718, val_loss: 1.0617272372316258 (48 / 80)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.541871921182266, train_loss: 0.9047094372058534, val_loss: 1.061978510154292 (49 / 80)\n",
            "train_acc: 0.6600741656365884, val_acc: 0.5812807881773399, train_loss: 0.8916652971793458, val_loss: 1.0090828884411327 (50 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.5862068965517241, train_loss: 0.8475254097739315, val_loss: 1.0145004224307432 (51 / 80)\n",
            "train_acc: 0.6909765142150803, val_acc: 0.5517241379310345, train_loss: 0.8210879008761148, val_loss: 1.0651557239992866 (52 / 80)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.5960591133004927, train_loss: 0.8305984013454876, val_loss: 1.0078299808971987 (53 / 80)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.5566502463054187, train_loss: 0.80653896868892, val_loss: 1.0839586663128706 (54 / 80)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.5172413793103449, train_loss: 0.8019193975238776, val_loss: 1.11252826246722 (55 / 80)\n",
            "train_acc: 0.7268232385661311, val_acc: 0.5615763546798029, train_loss: 0.7557771658278514, val_loss: 1.0801279301126603 (56 / 80)\n",
            "train_acc: 0.7070457354758962, val_acc: 0.6108374384236454, train_loss: 0.7466736315060015, val_loss: 0.9693556225358559 (57 / 80)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.625615763546798, train_loss: 0.7322627893926481, val_loss: 0.9961491520768904 (58 / 80)\n",
            "train_acc: 0.7243510506798516, val_acc: 0.5714285714285714, train_loss: 0.7264427838130993, val_loss: 1.0462782876244907 (59 / 80)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5665024630541872, train_loss: 0.7081118036701594, val_loss: 1.024894800385818 (60 / 80)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.6059113300492611, train_loss: 0.7046851417042859, val_loss: 1.0254401174084893 (61 / 80)\n",
            "train_acc: 0.7564894932014833, val_acc: 0.6059113300492611, train_loss: 0.6581258307981255, val_loss: 0.9816818181517089 (62 / 80)\n",
            "train_acc: 0.7564894932014833, val_acc: 0.5862068965517241, train_loss: 0.6302269112194424, val_loss: 1.2123515887800695 (63 / 80)\n",
            "train_acc: 0.7725587144622992, val_acc: 0.5911330049261084, train_loss: 0.6017225719942298, val_loss: 1.0546623236440085 (64 / 80)\n",
            "train_acc: 0.765142150803461, val_acc: 0.6206896551724138, train_loss: 0.599695677294572, val_loss: 0.9527475619550996 (65 / 80)\n",
            "train_acc: 0.761433868974042, val_acc: 0.6059113300492611, train_loss: 0.6267132671418679, val_loss: 1.0033183991909027 (66 / 80)\n",
            "train_acc: 0.7725587144622992, val_acc: 0.6059113300492611, train_loss: 0.5940047903320256, val_loss: 1.0086279203151833 (67 / 80)\n",
            "train_acc: 0.792336217552534, val_acc: 0.6108374384236454, train_loss: 0.5989944996365216, val_loss: 1.0459554371575417 (68 / 80)\n",
            "train_acc: 0.7935723114956736, val_acc: 0.6305418719211823, train_loss: 0.5676008576736756, val_loss: 0.976982173954912 (69 / 80)\n",
            "train_acc: 0.8145859085290482, val_acc: 0.6305418719211823, train_loss: 0.5140605309358781, val_loss: 1.0757946327989325 (70 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.5615763546798029, train_loss: 0.5393839513489284, val_loss: 1.097831929845763 (71 / 80)\n",
            "train_acc: 0.8046971569839307, val_acc: 0.6305418719211823, train_loss: 0.5266370502184289, val_loss: 1.204856032221188 (72 / 80)\n",
            "train_acc: 0.8108776266996292, val_acc: 0.5763546798029556, train_loss: 0.5069053598917901, val_loss: 1.2374703345334002 (73 / 80)\n",
            "train_acc: 0.8207663782447466, val_acc: 0.6403940886699507, train_loss: 0.5063369520220385, val_loss: 1.0463533513064456 (74 / 80)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.6551724137931034, train_loss: 0.47173270638410475, val_loss: 0.9953934752882407 (75 / 80)\n",
            "train_acc: 0.8318912237330037, val_acc: 0.6403940886699507, train_loss: 0.4514213504064805, val_loss: 1.309099330690694 (76 / 80)\n",
            "train_acc: 0.8257107540173053, val_acc: 0.6354679802955665, train_loss: 0.4620603708313186, val_loss: 1.0693832174897782 (77 / 80)\n",
            "train_acc: 0.8430160692212608, val_acc: 0.6502463054187192, train_loss: 0.4528982414966461, val_loss: 1.046748649310596 (78 / 80)\n",
            "train_acc: 0.8640296662546354, val_acc: 0.6650246305418719, train_loss: 0.3804754459371673, val_loss: 1.0321336309310838 (79 / 80)\n",
            "train_acc: 0.8516687268232386, val_acc: 0.6108374384236454, train_loss: 0.41431558795264095, val_loss: 1.181466212413581 (80 / 80)\n",
            "lr 0.0005075392266021225, batch 12, decay 0.00015097107216674634, gamma 0.23307879269069465, val accuracy 0.6650246305418719, val loss 1.0321336309310838 [12 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0005293020727186627, 'batch_size': 11, 'weight_decay': 0.0001569197221403604, 'gamma': 0.0797979883084818}\n",
            "train_acc: 0.18294190358467244, val_acc: 0.2019704433497537, train_loss: 1.7878479477206914, val_loss: 1.78216747697351 (1 / 80)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.18226600985221675, train_loss: 1.777981831794616, val_loss: 1.7704985259201726 (2 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.18226600985221675, train_loss: 1.7682217381645928, val_loss: 1.757249024701236 (3 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7680429488383649, val_loss: 1.7520663861570687 (4 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.753956943566189, val_loss: 1.7414918773867227 (5 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.746056871007488, val_loss: 1.7321609293886007 (6 / 80)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.2019704433497537, train_loss: 1.737889314611409, val_loss: 1.7149486459534744 (7 / 80)\n",
            "train_acc: 0.2484548825710754, val_acc: 0.270935960591133, train_loss: 1.7202728624249566, val_loss: 1.6739987328721972 (8 / 80)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.26108374384236455, train_loss: 1.6659932198424274, val_loss: 1.6430701945215611 (9 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.23645320197044334, train_loss: 1.6112244600713326, val_loss: 1.6824264256237762 (10 / 80)\n",
            "train_acc: 0.311495673671199, val_acc: 0.2561576354679803, train_loss: 1.6074496687416389, val_loss: 1.5585617320290928 (11 / 80)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3054187192118227, train_loss: 1.5588641826832397, val_loss: 1.5230638111753416 (12 / 80)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.32019704433497537, train_loss: 1.5247452897106024, val_loss: 1.503764584146697 (13 / 80)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.35467980295566504, train_loss: 1.5490359306630157, val_loss: 1.461435591058778 (14 / 80)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.33497536945812806, train_loss: 1.5286331262223063, val_loss: 1.4996504677927553 (15 / 80)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.4039408866995074, train_loss: 1.4934111242683326, val_loss: 1.4243839133549205 (16 / 80)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.35467980295566504, train_loss: 1.4614546739568817, val_loss: 1.437896220554859 (17 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.3645320197044335, train_loss: 1.4535898007038055, val_loss: 1.4494956150430764 (18 / 80)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.4187192118226601, train_loss: 1.4053216214085686, val_loss: 1.3415593161371542 (19 / 80)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.3645320197044335, train_loss: 1.429009923534134, val_loss: 1.3708445550185706 (20 / 80)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.4433497536945813, train_loss: 1.4310996865459955, val_loss: 1.3515972909081746 (21 / 80)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.45320197044334976, train_loss: 1.414539031988316, val_loss: 1.3477484686621304 (22 / 80)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.4433497536945813, train_loss: 1.3671524540160878, val_loss: 1.2866977981745904 (23 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4088669950738916, train_loss: 1.3945820478927367, val_loss: 1.2968583890957197 (24 / 80)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.4187192118226601, train_loss: 1.3290950054733361, val_loss: 1.2964368121964591 (25 / 80)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.42857142857142855, train_loss: 1.3558989594539694, val_loss: 1.3154637778333842 (26 / 80)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.41379310344827586, train_loss: 1.362426003876369, val_loss: 1.2796060310795976 (27 / 80)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.42857142857142855, train_loss: 1.2961845342691514, val_loss: 1.2630188412266998 (28 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4482758620689655, train_loss: 1.3157473819512224, val_loss: 1.240008494536865 (29 / 80)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4482758620689655, train_loss: 1.2999041672100684, val_loss: 1.227413730374698 (30 / 80)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.46798029556650245, train_loss: 1.2655207150798793, val_loss: 1.2295947685617532 (31 / 80)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4729064039408867, train_loss: 1.3108178738168497, val_loss: 1.2266304997975015 (32 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.4433497536945813, train_loss: 1.2269498864269375, val_loss: 1.3335631571967026 (33 / 80)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4827586206896552, train_loss: 1.267681863237223, val_loss: 1.1843983360699244 (34 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.46798029556650245, train_loss: 1.192831177794005, val_loss: 1.1897908096830245 (35 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4236453201970443, train_loss: 1.2138715793824166, val_loss: 1.2727001012839707 (36 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.458128078817734, train_loss: 1.206267278553971, val_loss: 1.251004145356822 (37 / 80)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.5073891625615764, train_loss: 1.2177772571336207, val_loss: 1.207648276695477 (38 / 80)\n",
            "train_acc: 0.515451174289246, val_acc: 0.4827586206896552, train_loss: 1.1533216383902192, val_loss: 1.158814564714291 (39 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.5024630541871922, train_loss: 1.132148301866647, val_loss: 1.1593263727690786 (40 / 80)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5024630541871922, train_loss: 1.1160384462259902, val_loss: 1.148973837861874 (41 / 80)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.4482758620689655, train_loss: 1.1014952732547105, val_loss: 1.5156164970891228 (42 / 80)\n",
            "train_acc: 0.546353522867738, val_acc: 0.541871921182266, train_loss: 1.0931963592730878, val_loss: 1.115989766978278 (43 / 80)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.49261083743842365, train_loss: 1.0875503915202043, val_loss: 1.189322917919441 (44 / 80)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.5024630541871922, train_loss: 1.1080266984343086, val_loss: 1.2498912077231947 (45 / 80)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5467980295566502, train_loss: 1.030530783942957, val_loss: 1.11142723959655 (46 / 80)\n",
            "train_acc: 0.61557478368356, val_acc: 0.5172413793103449, train_loss: 0.9734724140800858, val_loss: 1.1802070265626672 (47 / 80)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.541871921182266, train_loss: 0.999419488077258, val_loss: 1.0949503870433188 (48 / 80)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5714285714285714, train_loss: 0.8945797447515801, val_loss: 1.0368465534571945 (49 / 80)\n",
            "train_acc: 0.69221260815822, val_acc: 0.5763546798029556, train_loss: 0.8298114344422396, val_loss: 1.0412362479223993 (50 / 80)\n",
            "train_acc: 0.6736711990111248, val_acc: 0.5763546798029556, train_loss: 0.8375334021334889, val_loss: 1.046132158176065 (51 / 80)\n",
            "train_acc: 0.6699629171817059, val_acc: 0.5763546798029556, train_loss: 0.831364851578499, val_loss: 1.0733758958396067 (52 / 80)\n",
            "train_acc: 0.681087762669963, val_acc: 0.5517241379310345, train_loss: 0.8172785404733438, val_loss: 1.065130350771796 (53 / 80)\n",
            "train_acc: 0.6983930778739185, val_acc: 0.5763546798029556, train_loss: 0.7865697062207093, val_loss: 1.050643796110388 (54 / 80)\n",
            "train_acc: 0.6909765142150803, val_acc: 0.5615763546798029, train_loss: 0.805804488943298, val_loss: 1.0680753635655482 (55 / 80)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5763546798029556, train_loss: 0.7913078982175796, val_loss: 1.052317728843595 (56 / 80)\n",
            "train_acc: 0.715698393077874, val_acc: 0.5566502463054187, train_loss: 0.7626952571686177, val_loss: 1.0400562080843696 (57 / 80)\n",
            "train_acc: 0.6872682323856613, val_acc: 0.5566502463054187, train_loss: 0.7827791531463194, val_loss: 1.0589191085599325 (58 / 80)\n",
            "train_acc: 0.7206427688504327, val_acc: 0.5665024630541872, train_loss: 0.7380578197419128, val_loss: 1.0534580555455437 (59 / 80)\n",
            "train_acc: 0.7132262051915945, val_acc: 0.6009852216748769, train_loss: 0.7363721454983442, val_loss: 1.0445536689218042 (60 / 80)\n",
            "train_acc: 0.7243510506798516, val_acc: 0.5665024630541872, train_loss: 0.737302773630958, val_loss: 1.0498741540709153 (61 / 80)\n",
            "train_acc: 0.7280593325092707, val_acc: 0.5714285714285714, train_loss: 0.7340946330128258, val_loss: 1.0715292620247807 (62 / 80)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.5566502463054187, train_loss: 0.7118702839567281, val_loss: 1.0906521381415757 (63 / 80)\n",
            "train_acc: 0.7095179233621756, val_acc: 0.5763546798029556, train_loss: 0.7007572664171273, val_loss: 1.1193276288474134 (64 / 80)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5812807881773399, train_loss: 0.6864692157661665, val_loss: 1.1022112654347724 (65 / 80)\n",
            "train_acc: 0.7503090234857849, val_acc: 0.5763546798029556, train_loss: 0.6901812839640675, val_loss: 1.0858193003191736 (66 / 80)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.5763546798029556, train_loss: 0.6850946228053278, val_loss: 1.0929376340558377 (67 / 80)\n",
            "train_acc: 0.7169344870210136, val_acc: 0.5763546798029556, train_loss: 0.727360999849435, val_loss: 1.0455313251523548 (68 / 80)\n",
            "train_acc: 0.7527812113720643, val_acc: 0.5763546798029556, train_loss: 0.6513911555665091, val_loss: 1.0744814950550718 (69 / 80)\n",
            "train_acc: 0.7342398022249691, val_acc: 0.5862068965517241, train_loss: 0.6812569567719555, val_loss: 1.1004241286533807 (70 / 80)\n",
            "train_acc: 0.765142150803461, val_acc: 0.5615763546798029, train_loss: 0.6530468073778306, val_loss: 1.0961568787180145 (71 / 80)\n",
            "train_acc: 0.7453646477132262, val_acc: 0.5812807881773399, train_loss: 0.6714805810170061, val_loss: 1.0401845938466452 (72 / 80)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.6059113300492611, train_loss: 0.6402158343931947, val_loss: 1.0818345975406065 (73 / 80)\n",
            "train_acc: 0.7775030902348579, val_acc: 0.5763546798029556, train_loss: 0.6038371842488075, val_loss: 1.0635134426537405 (74 / 80)\n",
            "train_acc: 0.7589616810877626, val_acc: 0.5862068965517241, train_loss: 0.6429202570608726, val_loss: 1.053699353351969 (75 / 80)\n",
            "train_acc: 0.7552533992583437, val_acc: 0.5960591133004927, train_loss: 0.6526738380177501, val_loss: 1.0881846216805462 (76 / 80)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.5911330049261084, train_loss: 0.5970178427743381, val_loss: 1.1221947467385842 (77 / 80)\n",
            "train_acc: 0.7775030902348579, val_acc: 0.6009852216748769, train_loss: 0.6205677801492188, val_loss: 1.0364463468784182 (78 / 80)\n",
            "train_acc: 0.7762669962917181, val_acc: 0.5763546798029556, train_loss: 0.5943927961794201, val_loss: 1.1486759544006122 (79 / 80)\n",
            "train_acc: 0.7688504326328801, val_acc: 0.5812807881773399, train_loss: 0.5992443617916815, val_loss: 1.082687848894467 (80 / 80)\n",
            "lr 0.0005293020727186627, batch 11, decay 0.0001569197221403604, gamma 0.0797979883084818, val accuracy 0.6059113300492611, val loss 1.0818345975406065 [13 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 2.1271127828085018e-05, 'batch_size': 8, 'weight_decay': 7.020402076103384e-05, 'gamma': 0.01919356194543807}\n",
            "train_acc: 0.14833127317676142, val_acc: 0.18226600985221675, train_loss: 1.7926507815442363, val_loss: 1.7919712636271135 (1 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.7926440856365398, val_loss: 1.7910991584138918 (2 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7909811382977423, val_loss: 1.7902755925220808 (3 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7914211915066864, val_loss: 1.7894085070182537 (4 / 80)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.7899829349647494, val_loss: 1.7885772741486874 (5 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18719211822660098, train_loss: 1.789769671903405, val_loss: 1.7877727923134865 (6 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.1921182266009852, train_loss: 1.7881432423927581, val_loss: 1.7870008980699361 (7 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.19704433497536947, train_loss: 1.7883741373774147, val_loss: 1.7862327774169997 (8 / 80)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.24630541871921183, train_loss: 1.787158428517496, val_loss: 1.7854919944490706 (9 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.3054187192118227, train_loss: 1.7847971369515834, val_loss: 1.7846888644354684 (10 / 80)\n",
            "underfit -> train_accuracy = 0.21631644004944375\n",
            "lr 2.1271127828085018e-05, batch 8, decay 7.020402076103384e-05, gamma 0.01919356194543807, val accuracy 0.3054187192118227, val loss 1.7846888644354684 [14 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 1.3376264853374775e-05, 'batch_size': 13, 'weight_decay': 0.00022000766436248444, 'gamma': 0.039308958899966676}\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 1.7917233220726363, val_loss: 1.791199515605795 (1 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7915451716728352, val_loss: 1.7909132794206366 (2 / 80)\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7910689704939815, val_loss: 1.7906282999245404 (3 / 80)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.790410710648347, val_loss: 1.7903206319057297 (4 / 80)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7915320375793797, val_loss: 1.7900379232585137 (5 / 80)\n",
            "train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.7907280145381084, val_loss: 1.7897546890333955 (6 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.789508125101238, val_loss: 1.7894419008875129 (7 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7901748554373553, val_loss: 1.7891496737015071 (8 / 80)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7899473775891939, val_loss: 1.7888626835029113 (9 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7889879648706084, val_loss: 1.7885867609766317 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1792336217552534\n",
            "lr 1.3376264853374775e-05, batch 13, decay 0.00022000766436248444, gamma 0.039308958899966676, val accuracy 0.18226600985221675, val loss 1.791199515605795 [15 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 6.867976047596005e-05, 'batch_size': 14, 'weight_decay': 1.5814679024684855e-06, 'gamma': 0.02350552137048179}\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18719211822660098, train_loss: 1.7904275399350706, val_loss: 1.790122287026767 (1 / 80)\n",
            "train_acc: 0.15945611866501855, val_acc: 0.1921182266009852, train_loss: 1.7904966474316175, val_loss: 1.7882529168293393 (2 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7880827988623393, val_loss: 1.7863716709202733 (3 / 80)\n",
            "train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.78657904101538, val_loss: 1.7847801446914673 (4 / 80)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7863941182312182, val_loss: 1.7830344931832676 (5 / 80)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.20689655172413793, train_loss: 1.782437351489686, val_loss: 1.7810183557970771 (6 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.22167487684729065, train_loss: 1.7817938395572093, val_loss: 1.7792872765968586 (7 / 80)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.19704433497536947, train_loss: 1.7801423650442154, val_loss: 1.777378768756472 (8 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.17733990147783252, train_loss: 1.7795319512983778, val_loss: 1.7757165843042835 (9 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7776523265614645, val_loss: 1.7737657982727577 (10 / 80)\n",
            "underfit -> train_accuracy = 0.1965389369592089\n",
            "lr 6.867976047596005e-05, batch 14, decay 1.5814679024684855e-06, gamma 0.02350552137048179, val accuracy 0.22167487684729065, val loss 1.7792872765968586 [16 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00012551965509945687, 'batch_size': 8, 'weight_decay': 1.9080575326334764e-05, 'gamma': 0.11597548836996273}\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7887582725883266, val_loss: 1.7875173168229352 (1 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18719211822660098, train_loss: 1.7876841562198031, val_loss: 1.7840351964452583 (2 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.22660098522167488, train_loss: 1.7835559411750295, val_loss: 1.7802184062638307 (3 / 80)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18719211822660098, train_loss: 1.7801535266586228, val_loss: 1.776030422431495 (4 / 80)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.1921182266009852, train_loss: 1.7749275872380241, val_loss: 1.771082283240821 (5 / 80)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 1.7706986401962261, val_loss: 1.7655693985558496 (6 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7674758927931156, val_loss: 1.760267894843529 (7 / 80)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.18226600985221675, train_loss: 1.761433678592828, val_loss: 1.7553588034484187 (8 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.754902614061853, val_loss: 1.7506939630790297 (9 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7541299328963158, val_loss: 1.7463754315681645 (10 / 80)\n",
            "underfit -> train_accuracy = 0.19901112484548825\n",
            "lr 0.00012551965509945687, batch 8, decay 1.9080575326334764e-05, gamma 0.11597548836996273, val accuracy 0.22660098522167488, val loss 1.7802184062638307 [17 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.00018670737030924246, 'batch_size': 8, 'weight_decay': 7.355079410033403e-06, 'gamma': 0.022803227405398172}\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18719211822660098, train_loss: 1.7869948138412646, val_loss: 1.7801093420958871 (1 / 80)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7763787659785362, val_loss: 1.7695669546503152 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.767140999712667, val_loss: 1.7577032925460139 (3 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7591344208004154, val_loss: 1.7491836876704776 (4 / 80)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7583874509714736, val_loss: 1.7438139921338687 (5 / 80)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7439401158590988, val_loss: 1.736883536348202 (6 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2413793103448276, train_loss: 1.7452578152655376, val_loss: 1.7282906823557587 (7 / 80)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.2561576354679803, train_loss: 1.7330518820966572, val_loss: 1.7151427973667388 (8 / 80)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.33004926108374383, train_loss: 1.7216934870435812, val_loss: 1.699027077317825 (9 / 80)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.2561576354679803, train_loss: 1.7040727817820678, val_loss: 1.6810398424787474 (10 / 80)\n",
            "train_acc: 0.315203955500618, val_acc: 0.31527093596059114, train_loss: 1.659517503049966, val_loss: 1.6177810794614218 (11 / 80)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.33497536945812806, train_loss: 1.6217916763315094, val_loss: 1.5625578552631323 (12 / 80)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.35467980295566504, train_loss: 1.5938201598979633, val_loss: 1.544869270230749 (13 / 80)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.3399014778325123, train_loss: 1.5714388822006207, val_loss: 1.503533983465486 (14 / 80)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.3694581280788177, train_loss: 1.576243582997835, val_loss: 1.495641651999187 (15 / 80)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3054187192118227, train_loss: 1.5269900377660217, val_loss: 1.5193168512118862 (16 / 80)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3645320197044335, train_loss: 1.5169057160873791, val_loss: 1.4909668814372548 (17 / 80)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3793103448275862, train_loss: 1.525287376198692, val_loss: 1.462333083152771 (18 / 80)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.32019704433497537, train_loss: 1.513311902141689, val_loss: 1.48820465069099 (19 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3842364532019704, train_loss: 1.501152180476006, val_loss: 1.4551505484604483 (20 / 80)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.4039408866995074, train_loss: 1.4863355548773767, val_loss: 1.4363101574000467 (21 / 80)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3694581280788177, train_loss: 1.4735771124383574, val_loss: 1.4360188239900937 (22 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.39901477832512317, train_loss: 1.4824876440470238, val_loss: 1.419195400670244 (23 / 80)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.270935960591133, train_loss: 1.4630047894820883, val_loss: 1.622883540949798 (24 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4236453201970443, train_loss: 1.4506589526446405, val_loss: 1.4059840323302546 (25 / 80)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.3694581280788177, train_loss: 1.459093038761719, val_loss: 1.4240237509675802 (26 / 80)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.33497536945812806, train_loss: 1.4562573726156587, val_loss: 1.429265231334517 (27 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3891625615763547, train_loss: 1.4523164732347165, val_loss: 1.4288569800372195 (28 / 80)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.3645320197044335, train_loss: 1.4331680187041445, val_loss: 1.398470333644322 (29 / 80)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.3842364532019704, train_loss: 1.4260607240226566, val_loss: 1.376321154568583 (30 / 80)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3793103448275862, train_loss: 1.4063050511151516, val_loss: 1.416628922147704 (31 / 80)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.43349753694581283, train_loss: 1.381625462521434, val_loss: 1.367262001695304 (32 / 80)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.45320197044334976, train_loss: 1.397630277905977, val_loss: 1.3680403802195207 (33 / 80)\n",
            "train_acc: 0.449938195302843, val_acc: 0.3793103448275862, train_loss: 1.372152699233575, val_loss: 1.3942254558572629 (34 / 80)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.4482758620689655, train_loss: 1.3816582290144874, val_loss: 1.3231257946033197 (35 / 80)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.4039408866995074, train_loss: 1.3541241944646658, val_loss: 1.3730466841476892 (36 / 80)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4039408866995074, train_loss: 1.3517545510281443, val_loss: 1.352813448224749 (37 / 80)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4482758620689655, train_loss: 1.3488785604611315, val_loss: 1.32279286361093 (38 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4482758620689655, train_loss: 1.33635650960123, val_loss: 1.291680693039166 (39 / 80)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.45320197044334976, train_loss: 1.3503547638691547, val_loss: 1.2594912345773481 (40 / 80)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.4482758620689655, train_loss: 1.3029567423208683, val_loss: 1.3009966300626106 (41 / 80)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.3694581280788177, train_loss: 1.2873694382432954, val_loss: 1.437871515457266 (42 / 80)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4482758620689655, train_loss: 1.2957232525970497, val_loss: 1.2565374086643089 (43 / 80)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4630541871921182, train_loss: 1.2861232458439982, val_loss: 1.2752396323410748 (44 / 80)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.46798029556650245, train_loss: 1.264532880818446, val_loss: 1.279277089781362 (45 / 80)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.46798029556650245, train_loss: 1.2605071957827498, val_loss: 1.3057285130317575 (46 / 80)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.4630541871921182, train_loss: 1.2688918588187992, val_loss: 1.2288866319092624 (47 / 80)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4630541871921182, train_loss: 1.2510504016770125, val_loss: 1.2480867243752691 (48 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4876847290640394, train_loss: 1.1935568751746557, val_loss: 1.2222330188516326 (49 / 80)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.4827586206896552, train_loss: 1.1950394330714336, val_loss: 1.2147462567672354 (50 / 80)\n",
            "train_acc: 0.519159456118665, val_acc: 0.4827586206896552, train_loss: 1.1926443796370028, val_loss: 1.2128112163449742 (51 / 80)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.4827586206896552, train_loss: 1.1881782171605397, val_loss: 1.2150365804216545 (52 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4975369458128079, train_loss: 1.1806534045411572, val_loss: 1.210935711273419 (53 / 80)\n",
            "train_acc: 0.522867737948084, val_acc: 0.4975369458128079, train_loss: 1.2075779635472998, val_loss: 1.2102674084343934 (54 / 80)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.5024630541871922, train_loss: 1.185839446424996, val_loss: 1.211825401912182 (55 / 80)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.5024630541871922, train_loss: 1.1671672198916838, val_loss: 1.2098608204883894 (56 / 80)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.49261083743842365, train_loss: 1.1947884777715092, val_loss: 1.206984092155701 (57 / 80)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.5073891625615764, train_loss: 1.1846400449243553, val_loss: 1.2089697102020527 (58 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.5123152709359606, train_loss: 1.1797043767346735, val_loss: 1.2072136525450081 (59 / 80)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.5024630541871922, train_loss: 1.1704038580504277, val_loss: 1.2083016011515275 (60 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.49261083743842365, train_loss: 1.1745710735415351, val_loss: 1.2068199888238766 (61 / 80)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.49261083743842365, train_loss: 1.1853298804963328, val_loss: 1.2080411223942422 (62 / 80)\n",
            "train_acc: 0.5401730531520396, val_acc: 0.5024630541871922, train_loss: 1.1591453362159587, val_loss: 1.2097711842048344 (63 / 80)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.49261083743842365, train_loss: 1.1737554088069129, val_loss: 1.2086850668996425 (64 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5123152709359606, train_loss: 1.1656858923998104, val_loss: 1.2086207945945815 (65 / 80)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.5172413793103449, train_loss: 1.1736398998680162, val_loss: 1.2061314013203963 (66 / 80)\n",
            "train_acc: 0.5179233621755254, val_acc: 0.5024630541871922, train_loss: 1.1943815349795763, val_loss: 1.2076780520049222 (67 / 80)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.5073891625615764, train_loss: 1.1654519197819997, val_loss: 1.2100323931924228 (68 / 80)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.5172413793103449, train_loss: 1.1758839123328626, val_loss: 1.2092064313700635 (69 / 80)\n",
            "train_acc: 0.5142150803461063, val_acc: 0.5123152709359606, train_loss: 1.1659070106018312, val_loss: 1.2116286695884366 (70 / 80)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.5172413793103449, train_loss: 1.1713809359943026, val_loss: 1.2121636274412935 (71 / 80)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.5172413793103449, train_loss: 1.1552237556655562, val_loss: 1.2093875977793351 (72 / 80)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.4975369458128079, train_loss: 1.186509056645359, val_loss: 1.2083677696477015 (73 / 80)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.5123152709359606, train_loss: 1.157826319023764, val_loss: 1.2075062940273378 (74 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5073891625615764, train_loss: 1.160708027216059, val_loss: 1.2049661557662663 (75 / 80)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.5024630541871922, train_loss: 1.1504372816592712, val_loss: 1.205529914994545 (76 / 80)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.5221674876847291, train_loss: 1.1813632024380716, val_loss: 1.208155997281004 (77 / 80)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.5123152709359606, train_loss: 1.1707214864134345, val_loss: 1.2048348805000042 (78 / 80)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.5024630541871922, train_loss: 1.1648100680856976, val_loss: 1.2043994996935277 (79 / 80)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.5024630541871922, train_loss: 1.1560885850225007, val_loss: 1.203182549312197 (80 / 80)\n",
            "lr 0.00018670737030924246, batch 8, decay 7.355079410033403e-06, gamma 0.022803227405398172, val accuracy 0.5221674876847291, val loss 1.208155997281004 [18 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0002647849225141225, 'batch_size': 12, 'weight_decay': 5.322963977179352e-06, 'gamma': 0.31100368141950957}\n",
            "train_acc: 0.1631644004944376, val_acc: 0.2561576354679803, train_loss: 1.7908308850820045, val_loss: 1.7865434444596615 (1 / 80)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.22660098522167488, train_loss: 1.7847984962911334, val_loss: 1.779785882076019 (2 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7807988280566278, val_loss: 1.7732917927756098 (3 / 80)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7732117140690977, val_loss: 1.766619735163421 (4 / 80)\n",
            "train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7676397392570016, val_loss: 1.759406951847922 (5 / 80)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7631215792798582, val_loss: 1.7533666517934188 (6 / 80)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.18226600985221675, train_loss: 1.7574053842146111, val_loss: 1.74851045585031 (7 / 80)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18719211822660098, train_loss: 1.7594806800224578, val_loss: 1.744736670860516 (8 / 80)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.19704433497536947, train_loss: 1.7468186700889294, val_loss: 1.7388466937201363 (9 / 80)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.20689655172413793, train_loss: 1.7450274439765732, val_loss: 1.730122743568984 (10 / 80)\n",
            "underfit -> train_accuracy = 0.21631644004944375\n",
            "lr 0.0002647849225141225, batch 12, decay 5.322963977179352e-06, gamma 0.31100368141950957, val accuracy 0.2561576354679803, val loss 1.7865434444596615 [19 / 50]\n",
            "-------------------------------------\n",
            "{'lr': 0.0008855392357118734, 'batch_size': 14, 'weight_decay': 1.425303159816243e-05, 'gamma': 0.025748054655449888}\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.7869626326378256, val_loss: 1.774606231985421 (1 / 80)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.1921182266009852, train_loss: 1.7702639572994672, val_loss: 1.756248667322356 (2 / 80)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7583005244121859, val_loss: 1.7424829006195068 (3 / 80)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.2019704433497537, train_loss: 1.7488828910738046, val_loss: 1.7279039292499936 (4 / 80)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.29064039408866993, train_loss: 1.7253468683535147, val_loss: 1.702056231169865 (5 / 80)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.33497536945812806, train_loss: 1.695277471035461, val_loss: 1.652913003132261 (6 / 80)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.35467980295566504, train_loss: 1.641252822133313, val_loss: 1.5794478490434845 (7 / 80)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.3694581280788177, train_loss: 1.5974721444404612, val_loss: 1.5008567037253544 (8 / 80)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.26108374384236455, train_loss: 1.5320731762460489, val_loss: 1.604683600623032 (9 / 80)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3054187192118227, train_loss: 1.5318133652725974, val_loss: 1.4855975159283341 (10 / 80)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.35960591133004927, train_loss: 1.5027462892390888, val_loss: 1.4334679965315194 (11 / 80)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.4187192118226601, train_loss: 1.5082845260539957, val_loss: 1.416795064663065 (12 / 80)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.4039408866995074, train_loss: 1.4545036334779264, val_loss: 1.3449191348306064 (13 / 80)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3793103448275862, train_loss: 1.4154059300463928, val_loss: 1.3521389098002994 (14 / 80)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.2955665024630542, train_loss: 1.4524457099558543, val_loss: 1.4226303758292362 (15 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4039408866995074, train_loss: 1.3885568636751588, val_loss: 1.3576031018947732 (16 / 80)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4433497536945813, train_loss: 1.3714231815562112, val_loss: 1.356778703886887 (17 / 80)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.4630541871921182, train_loss: 1.3591833026211695, val_loss: 1.235507412203427 (18 / 80)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4433497536945813, train_loss: 1.3348557496689748, val_loss: 1.2839040139625812 (19 / 80)\n",
            "train_acc: 0.44128553770086526, val_acc: 0.458128078817734, train_loss: 1.3258818824152716, val_loss: 1.2665070295333862 (20 / 80)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.39901477832512317, train_loss: 1.3004353876019585, val_loss: 1.3065934880026455 (21 / 80)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.4433497536945813, train_loss: 1.3017299428711127, val_loss: 1.2585610644570713 (22 / 80)\n",
            "train_acc: 0.446229913473424, val_acc: 0.47783251231527096, train_loss: 1.291148321000843, val_loss: 1.2796871251073376 (23 / 80)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.4433497536945813, train_loss: 1.2802637442670146, val_loss: 1.2818836097059578 (24 / 80)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4433497536945813, train_loss: 1.2528747998003023, val_loss: 1.173022722375804 (25 / 80)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.46798029556650245, train_loss: 1.226045573744992, val_loss: 1.2044353341234142 (26 / 80)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.458128078817734, train_loss: 1.2311953864669327, val_loss: 1.217372594208553 (27 / 80)\n",
            "train_acc: 0.5055624227441285, val_acc: 0.4482758620689655, train_loss: 1.1898340013324846, val_loss: 1.1719233989715576 (28 / 80)\n",
            "train_acc: 0.511742892459827, val_acc: 0.49261083743842365, train_loss: 1.1831937577432696, val_loss: 1.2238870735826164 (29 / 80)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.5172413793103449, train_loss: 1.1653431686394293, val_loss: 1.1096865555335735 (30 / 80)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.4482758620689655, train_loss: 1.125648731206934, val_loss: 1.2126964782846386 (31 / 80)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.5073891625615764, train_loss: 1.142172978230843, val_loss: 1.1501685730342208 (32 / 80)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.5270935960591133, train_loss: 1.131965386705434, val_loss: 1.0706029842639793 (33 / 80)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.5320197044334976, train_loss: 1.10632077754649, val_loss: 1.0798994960456059 (34 / 80)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.541871921182266, train_loss: 1.0853067875203155, val_loss: 1.046062405767112 (35 / 80)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.5073891625615764, train_loss: 1.0417779305367298, val_loss: 1.162408861620673 (36 / 80)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5467980295566502, train_loss: 1.0397837142861819, val_loss: 1.0340902764221718 (37 / 80)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.4975369458128079, train_loss: 1.0239222962570427, val_loss: 1.1276885908225487 (38 / 80)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5960591133004927, train_loss: 0.956481800238488, val_loss: 1.0259456860608067 (39 / 80)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.5369458128078818, train_loss: 0.9345185843622139, val_loss: 1.1151350120018269 (40 / 80)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.5665024630541872, train_loss: 0.9766943120985891, val_loss: 0.9851007872614367 (41 / 80)\n",
            "train_acc: 0.6440049443757726, val_acc: 0.5714285714285714, train_loss: 0.863937105325008, val_loss: 0.9991164156075182 (42 / 80)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5665024630541872, train_loss: 0.8589407720583478, val_loss: 0.9877346939054029 (43 / 80)\n",
            "train_acc: 0.657601977750309, val_acc: 0.6059113300492611, train_loss: 0.8709017198961067, val_loss: 0.9058192475088711 (44 / 80)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.5911330049261084, train_loss: 0.8131129419700471, val_loss: 1.0168521568692963 (45 / 80)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.5763546798029556, train_loss: 0.7311546972714484, val_loss: 1.1720782847240054 (46 / 80)\n",
            "train_acc: 0.7107540173053152, val_acc: 0.6059113300492611, train_loss: 0.7245686620068639, val_loss: 1.1099455767664417 (47 / 80)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e0857660dbc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mcurrent_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-e187b98eb2aa>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset, verbosity, plot)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0msum_train_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "9e0bc70f-78da-4995-b35e-f46070fab2b8",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "'''\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "'''\n",
        "\n",
        "# lr 0.0006444500508054211, batch 14, decay 2.1280582227123365e-05, gamma 0.19924404264743992, val accuracy 0.6305418719211823, val loss 1.0403618915327664 [5 / 50]\n",
        "# lr 0.00038041059192815333, batch 9, decay 3.8372561126798785e-05, gamma 0.057680309789029396, val accuracy 0.6108374384236454, val loss 0.9877617955207825 [38 / 50]\n",
        "# lr 0.00043660847130590896, batch 10, decay 0.00025031720443271155, gamma 0.011678955740792939, val accuracy 0.5615763546798029, val loss 1.0453474251507537 [43 / 50]\n",
        "# lr 0.00027531434783290124, batch 9, decay 4.3783604017624755e-06, gamma 0.11844128056704877, val accuracy 0.5517241379310345, val loss 1.117455956383879 [44 / 50]\n",
        "# lr 0.0007220498435995008, batch 14, decay 2.228552014354877e-05, gamma 0.08113961287843949, val accuracy 0.625615763546798, val loss 0.9968108699239534 [49 / 50]\n",
        "# lr 0.0008377019231346562, batch 8, decay 2.4427015675775187e-06, gamma 0.00903130010323455, val accuracy 0.5849802371541502, val loss 1.0701400147596367 [1 / 50]\n",
        "# lr 0.0010316163585472981, batch 8, decay 1.8309942558988887e-05, gamma 0.002673690056313373, val accuracy 0.5592885375494071, val loss 1.0480610431418589 [5 / 50]\n",
        "# lr 0.0016661746592012004, batch 8, decay 3.3763075569909223e-06, gamma 0.006052773438030023, val accuracy 0.6067193675889329, val loss 1.0441360360548901 [6 / 50]\n",
        "\n",
        "hyperparameters_sets = []\n",
        "lr_list = [0.0006444500508054211, 0.00038041059192815333, 0.00043660847130590896, 0.00027531434783290124, 0.0007220498435995008, 0.0008377019231346562, 0.0010316163585472981, 0.0016661746592012004]\n",
        "bs_list = [14, 9, 10, 9, 14, 8, 8, 8]\n",
        "wd_list = [2.1280582227123365e-05, 3.8372561126798785e-05, 0.00025031720443271155, 4.3783604017624755e-06, 2.228552014354877e-05, 2.4427015675775187e-06, 1.8309942558988887e-05, 3.3763075569909223e-06]\n",
        "g_list = [0.19924404264743992, 0.057680309789029396, 0.011678955740792939, 0.11844128056704877, 0.08113961287843949, 0.00903130010323455, 0.002673690056313373, 0.006052773438030023]\n",
        "\n",
        "for i in range(8):\n",
        "  set = {\"lr\": lr_list[i], \"batch_size\": bs_list[i], \"weight_decay\": wd_list[i], \"gamma\": g_list[i]}\n",
        "  hyperparameters_sets.append(set)\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg11()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "n = 0\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  n += 1\n",
        "  print(\"({}), val accuracy {}, val loss {} [{} / {}]\".format(set, val_accuracy, val_loss, n, len(hyperparameters_sets)))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}\n",
            "{'lr': 0.00038041059192815333, 'batch_size': 9, 'weight_decay': 3.8372561126798785e-05, 'gamma': 0.057680309789029396}\n",
            "{'lr': 0.00043660847130590896, 'batch_size': 10, 'weight_decay': 0.00025031720443271155, 'gamma': 0.011678955740792939}\n",
            "{'lr': 0.00027531434783290124, 'batch_size': 9, 'weight_decay': 4.3783604017624755e-06, 'gamma': 0.11844128056704877}\n",
            "{'lr': 0.0007220498435995008, 'batch_size': 14, 'weight_decay': 2.228552014354877e-05, 'gamma': 0.08113961287843949}\n",
            "{'lr': 0.0008377019231346562, 'batch_size': 8, 'weight_decay': 2.4427015675775187e-06, 'gamma': 0.00903130010323455}\n",
            "{'lr': 0.0010316163585472981, 'batch_size': 8, 'weight_decay': 1.8309942558988887e-05, 'gamma': 0.002673690056313373}\n",
            "{'lr': 0.0016661746592012004, 'batch_size': 8, 'weight_decay': 3.3763075569909223e-06, 'gamma': 0.006052773438030023}\n",
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.173053152039555, val_acc: 0.18226600985221675, train_loss: 1.7862234551768073, val_loss: 1.7795154925050407 (1 / 100)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7753021369316375, val_loss: 1.7675633101627743 (2 / 100)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.768649269535456, val_loss: 1.7580222138043107 (3 / 100)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.7633179278839357, val_loss: 1.7531074285507202 (4 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7577222226134632, val_loss: 1.7474955772531444 (5 / 100)\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7545714600861293, val_loss: 1.7431811916417088 (6 / 100)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.19704433497536947, train_loss: 1.7494169974651266, val_loss: 1.7369723854393795 (7 / 100)\n",
            "train_acc: 0.22126081582200247, val_acc: 0.23645320197044334, train_loss: 1.7439721078601549, val_loss: 1.7263395621858795 (8 / 100)\n",
            "train_acc: 0.27935723114956734, val_acc: 0.20689655172413793, train_loss: 1.7341709987194782, val_loss: 1.7090324738930012 (9 / 100)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.21674876847290642, train_loss: 1.7224935019119414, val_loss: 1.6904847334171165 (10 / 100)\n",
            "train_acc: 0.2669962917181706, val_acc: 0.32019704433497537, train_loss: 1.6945288285926188, val_loss: 1.6300613962370774 (11 / 100)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.22660098522167488, train_loss: 1.6604212404623608, val_loss: 1.7054822239382514 (12 / 100)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.3251231527093596, train_loss: 1.664362433814295, val_loss: 1.5818871300795982 (13 / 100)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.3497536945812808, train_loss: 1.6212048042837268, val_loss: 1.5631290468676338 (14 / 100)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.33497536945812806, train_loss: 1.6492813846236842, val_loss: 1.5348215432002628 (15 / 100)\n",
            "train_acc: 0.31025957972805934, val_acc: 0.3054187192118227, train_loss: 1.6093457589485443, val_loss: 1.540602499041064 (16 / 100)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.30049261083743845, train_loss: 1.5876217862436885, val_loss: 1.5530940170945793 (17 / 100)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.30049261083743845, train_loss: 1.5626992576643917, val_loss: 1.5631563622376015 (18 / 100)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.29064039408866993, train_loss: 1.5723912281217918, val_loss: 1.5165082504009377 (19 / 100)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.3251231527093596, train_loss: 1.5562335557784375, val_loss: 1.530579188774372 (20 / 100)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3448275862068966, train_loss: 1.5792912109231183, val_loss: 1.5303333422233318 (21 / 100)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.270935960591133, train_loss: 1.555518690381563, val_loss: 1.576153775741314 (22 / 100)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.33004926108374383, train_loss: 1.547411620395882, val_loss: 1.5221815890279309 (23 / 100)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3251231527093596, train_loss: 1.5472987511544056, val_loss: 1.6201243770533595 (24 / 100)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.35960591133004927, train_loss: 1.5440704651609782, val_loss: 1.4659623113171807 (25 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.32019704433497537, train_loss: 1.51856546761521, val_loss: 1.47112906390223 (26 / 100)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.2955665024630542, train_loss: 1.5225526539445366, val_loss: 1.461863505429235 (27 / 100)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.37438423645320196, train_loss: 1.5201985763825652, val_loss: 1.442565367139619 (28 / 100)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3793103448275862, train_loss: 1.4560831736575246, val_loss: 1.4206522250997609 (29 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3497536945812808, train_loss: 1.4926876077251174, val_loss: 1.4680830527996194 (30 / 100)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.31527093596059114, train_loss: 1.4522850864160488, val_loss: 1.4799481671431969 (31 / 100)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3842364532019704, train_loss: 1.50289146596628, val_loss: 1.407558223296856 (32 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.33004926108374383, train_loss: 1.4834878107231244, val_loss: 1.455953704899755 (33 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.39901477832512317, train_loss: 1.4111788854905496, val_loss: 1.4260368963767742 (34 / 100)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4236453201970443, train_loss: 1.4313970149963247, val_loss: 1.3792402785399864 (35 / 100)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.39408866995073893, train_loss: 1.4241694637812554, val_loss: 1.3863251784752155 (36 / 100)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.4039408866995074, train_loss: 1.4210392154191422, val_loss: 1.3951835303471005 (37 / 100)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.4236453201970443, train_loss: 1.4252224714116497, val_loss: 1.3814587305332053 (38 / 100)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.3793103448275862, train_loss: 1.40379174486521, val_loss: 1.3931798195016796 (39 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.3891625615763547, train_loss: 1.3641783570034984, val_loss: 1.3754376954045788 (40 / 100)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.4187192118226601, train_loss: 1.3725579738322236, val_loss: 1.4163036058688987 (41 / 100)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4088669950738916, train_loss: 1.3736871097821683, val_loss: 1.3294315297028114 (42 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.4236453201970443, train_loss: 1.3404310267552162, val_loss: 1.3235571014470067 (43 / 100)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.3793103448275862, train_loss: 1.3022197987446826, val_loss: 1.4262169352893173 (44 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.39901477832512317, train_loss: 1.332316825652152, val_loss: 1.3583365555467277 (45 / 100)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.37438423645320196, train_loss: 1.3090097946937949, val_loss: 1.3199768271939507 (46 / 100)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.39901477832512317, train_loss: 1.3093961696836947, val_loss: 1.3110748570540856 (47 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.3891625615763547, train_loss: 1.2977483353597126, val_loss: 1.3122564677534432 (48 / 100)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.45320197044334976, train_loss: 1.2476803584505514, val_loss: 1.3005824171263596 (49 / 100)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4433497536945813, train_loss: 1.2288342621476747, val_loss: 1.314315910997062 (50 / 100)\n",
            "train_acc: 0.484548825710754, val_acc: 0.47783251231527096, train_loss: 1.2414617842001143, val_loss: 1.3215967129016746 (51 / 100)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.46798029556650245, train_loss: 1.2413510386227677, val_loss: 1.2714984170321761 (52 / 100)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.45320197044334976, train_loss: 1.17698467175657, val_loss: 1.4073651905717521 (53 / 100)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.4876847290640394, train_loss: 1.1763107244694335, val_loss: 1.2603593900285919 (54 / 100)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.47783251231527096, train_loss: 1.1968526212482429, val_loss: 1.28347895885336 (55 / 100)\n",
            "train_acc: 0.519159456118665, val_acc: 0.4630541871921182, train_loss: 1.1914512148893661, val_loss: 1.4141594541483913 (56 / 100)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.4433497536945813, train_loss: 1.1451300308937196, val_loss: 1.339782871049026 (57 / 100)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.43349753694581283, train_loss: 1.1557640650658436, val_loss: 1.294190447905968 (58 / 100)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.4236453201970443, train_loss: 1.0972717345423988, val_loss: 1.3151261436528172 (59 / 100)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.4482758620689655, train_loss: 1.1001234803123143, val_loss: 1.2991117896704838 (60 / 100)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5221674876847291, train_loss: 1.0270199797798882, val_loss: 1.3104394715407799 (61 / 100)\n",
            "train_acc: 0.61557478368356, val_acc: 0.5123152709359606, train_loss: 0.9903782267210952, val_loss: 1.2803454892388706 (62 / 100)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.4975369458128079, train_loss: 0.9618690145030452, val_loss: 1.301558523342527 (63 / 100)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.5024630541871922, train_loss: 0.9400523800785079, val_loss: 1.2633350882036933 (64 / 100)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.4827586206896552, train_loss: 0.9088630471447637, val_loss: 1.3166613332156478 (65 / 100)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5024630541871922, train_loss: 0.9209719165441279, val_loss: 1.31769178242519 (66 / 100)\n",
            "train_acc: 0.688504326328801, val_acc: 0.5123152709359606, train_loss: 0.8907585224350834, val_loss: 1.335598871625703 (67 / 100)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.4975369458128079, train_loss: 0.8766973966868463, val_loss: 1.4251203495880653 (68 / 100)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.5320197044334976, train_loss: 0.887015393844199, val_loss: 1.3442578932334637 (69 / 100)\n",
            "train_acc: 0.6699629171817059, val_acc: 0.5024630541871922, train_loss: 0.900962598170574, val_loss: 1.3290299608789642 (70 / 100)\n",
            "train_acc: 0.6872682323856613, val_acc: 0.5024630541871922, train_loss: 0.851704263274543, val_loss: 1.3531044865476674 (71 / 100)\n",
            "train_acc: 0.7045735475896168, val_acc: 0.5221674876847291, train_loss: 0.8169086505515024, val_loss: 1.3565081892342403 (72 / 100)\n",
            "train_acc: 0.6699629171817059, val_acc: 0.5172413793103449, train_loss: 0.8447445693652621, val_loss: 1.2958588476838737 (73 / 100)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5221674876847291, train_loss: 0.8272735220834853, val_loss: 1.3256680184397205 (74 / 100)\n",
            "train_acc: 0.7058096415327565, val_acc: 0.5172413793103449, train_loss: 0.7770020074691112, val_loss: 1.4711154000512485 (75 / 100)\n",
            "train_acc: 0.7033374536464772, val_acc: 0.49261083743842365, train_loss: 0.7928200960896071, val_loss: 1.3512210393774098 (76 / 100)\n",
            "train_acc: 0.7082818294190358, val_acc: 0.5320197044334976, train_loss: 0.7738178038626577, val_loss: 1.4033225384251824 (77 / 100)\n",
            "train_acc: 0.7379480840543882, val_acc: 0.5172413793103449, train_loss: 0.7259849243612019, val_loss: 1.3890230902310075 (78 / 100)\n",
            "train_acc: 0.7453646477132262, val_acc: 0.5024630541871922, train_loss: 0.7119516286036582, val_loss: 1.4068726301193237 (79 / 100)\n",
            "train_acc: 0.7292954264524104, val_acc: 0.5024630541871922, train_loss: 0.7151297702924873, val_loss: 1.3775327452297867 (80 / 100)\n",
            "train_acc: 0.7330037082818294, val_acc: 0.5073891625615764, train_loss: 0.7012386506950605, val_loss: 1.4823426748144215 (81 / 100)\n",
            "train_acc: 0.7503090234857849, val_acc: 0.5566502463054187, train_loss: 0.7153541706548485, val_loss: 1.3541624217197812 (82 / 100)\n",
            "overfit -> train_accuracy 0.757725587144623, val_accuracy 0.4876847290640394\n",
            "({'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}), val accuracy 0.5566502463054187, val loss 1.3541624217197812 [1 / 8]\n",
            "train_acc: 0.15327564894932014, val_acc: 0.18226600985221675, train_loss: 1.7889878251791296, val_loss: 1.780834421148441 (1 / 100)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7787700946015688, val_loss: 1.767925506154892 (2 / 100)\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.766851466429985, val_loss: 1.7583666164886775 (3 / 100)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7626344765661968, val_loss: 1.7542896887351727 (4 / 100)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.19704433497536947, train_loss: 1.7569039016777859, val_loss: 1.7488717745090354 (5 / 100)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7582658850513075, val_loss: 1.7433960508243205 (6 / 100)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18719211822660098, train_loss: 1.7558194499080644, val_loss: 1.7345495687916948 (7 / 100)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.19704433497536947, train_loss: 1.7470682118230756, val_loss: 1.7249257541055163 (8 / 100)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.2315270935960591, train_loss: 1.7422814818630996, val_loss: 1.7120840531851858 (9 / 100)\n",
            "train_acc: 0.24721878862793573, val_acc: 0.24630541871921183, train_loss: 1.7136114028239868, val_loss: 1.6773910369779088 (10 / 100)\n",
            "train_acc: 0.2830655129789864, val_acc: 0.29064039408866993, train_loss: 1.687194741405869, val_loss: 1.6494636600240697 (11 / 100)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.3251231527093596, train_loss: 1.6794057810409697, val_loss: 1.5735995710776944 (12 / 100)\n",
            "train_acc: 0.30778739184178, val_acc: 0.31527093596059114, train_loss: 1.6592737582174897, val_loss: 1.5892485879324927 (13 / 100)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.31527093596059114, train_loss: 1.6510339472880322, val_loss: 1.595882510904021 (14 / 100)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.3645320197044335, train_loss: 1.6152950893668516, val_loss: 1.524122645702268 (15 / 100)\n",
            "train_acc: 0.311495673671199, val_acc: 0.29064039408866993, train_loss: 1.59112913190066, val_loss: 1.5628099136164624 (16 / 100)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.31527093596059114, train_loss: 1.582060621901702, val_loss: 1.5375669560408944 (17 / 100)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.33497536945812806, train_loss: 1.5921327366375069, val_loss: 1.5337167819732516 (18 / 100)\n",
            "train_acc: 0.30778739184178, val_acc: 0.33497536945812806, train_loss: 1.5987103708889634, val_loss: 1.512908300742727 (19 / 100)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.3448275862068966, train_loss: 1.5569926908490683, val_loss: 1.4991680060701418 (20 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.27586206896551724, train_loss: 1.541245191000006, val_loss: 1.54535508919232 (21 / 100)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3497536945812808, train_loss: 1.5646132862906816, val_loss: 1.4707113463303139 (22 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3399014778325123, train_loss: 1.5019470802491026, val_loss: 1.4564788899398202 (23 / 100)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.35960591133004927, train_loss: 1.5180306138450048, val_loss: 1.483212680652224 (24 / 100)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.32019704433497537, train_loss: 1.5053371335431582, val_loss: 1.4568400347761332 (25 / 100)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.3103448275862069, train_loss: 1.5004304323267141, val_loss: 1.5609304129783743 (26 / 100)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.31527093596059114, train_loss: 1.515598572523544, val_loss: 1.4635147343715424 (27 / 100)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.41379310344827586, train_loss: 1.4692571552191735, val_loss: 1.422322514609163 (28 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.2955665024630542, train_loss: 1.462878286175439, val_loss: 1.5144307660351832 (29 / 100)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.4039408866995074, train_loss: 1.4757583848625533, val_loss: 1.4160100204016774 (30 / 100)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3793103448275862, train_loss: 1.4683783014566258, val_loss: 1.411042264529637 (31 / 100)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.3842364532019704, train_loss: 1.4086768678740607, val_loss: 1.4166151120744903 (32 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.4088669950738916, train_loss: 1.4609956900475198, val_loss: 1.383501643617752 (33 / 100)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.4236453201970443, train_loss: 1.4360395553527567, val_loss: 1.380808062154084 (34 / 100)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.33004926108374383, train_loss: 1.4228118525447304, val_loss: 1.4781385102295523 (35 / 100)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.39901477832512317, train_loss: 1.397171830659449, val_loss: 1.3918997889081832 (36 / 100)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.37438423645320196, train_loss: 1.4332588726864168, val_loss: 1.413560742227902 (37 / 100)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.45320197044334976, train_loss: 1.4039469486556035, val_loss: 1.3558927104978138 (38 / 100)\n",
            "train_acc: 0.411619283065513, val_acc: 0.43842364532019706, train_loss: 1.3664261319286597, val_loss: 1.3624212057719678 (39 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4433497536945813, train_loss: 1.38170673791204, val_loss: 1.3348620067089063 (40 / 100)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.3793103448275862, train_loss: 1.3484324561650733, val_loss: 1.3998724909251548 (41 / 100)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.3694581280788177, train_loss: 1.3629197676485343, val_loss: 1.419548515615792 (42 / 100)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4088669950738916, train_loss: 1.332977025485304, val_loss: 1.3360376604672135 (43 / 100)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.42857142857142855, train_loss: 1.345008532771074, val_loss: 1.3146831243496222 (44 / 100)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.43842364532019706, train_loss: 1.3013360810515613, val_loss: 1.3233833406946343 (45 / 100)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.458128078817734, train_loss: 1.2924598683827593, val_loss: 1.329693503567738 (46 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4088669950738916, train_loss: 1.2870029488069608, val_loss: 1.3063922506835073 (47 / 100)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.45320197044334976, train_loss: 1.2536369414795168, val_loss: 1.2808215439025992 (48 / 100)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.45320197044334976, train_loss: 1.2748750697991758, val_loss: 1.2701200176342367 (49 / 100)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.4236453201970443, train_loss: 1.2470222869968532, val_loss: 1.3019364440969645 (50 / 100)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.42857142857142855, train_loss: 1.226240205823712, val_loss: 1.3588363983361005 (51 / 100)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4630541871921182, train_loss: 1.1779224858590494, val_loss: 1.290090707135318 (52 / 100)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.43842364532019706, train_loss: 1.190067638204478, val_loss: 1.364774578016967 (53 / 100)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.47783251231527096, train_loss: 1.2070089951433858, val_loss: 1.2450794192957761 (54 / 100)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.37438423645320196, train_loss: 1.2116156236645024, val_loss: 1.4073354181984963 (55 / 100)\n",
            "train_acc: 0.5352286773794809, val_acc: 0.458128078817734, train_loss: 1.1682792450353152, val_loss: 1.3261996537006546 (56 / 100)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4630541871921182, train_loss: 1.1303936599653643, val_loss: 1.370417629850322 (57 / 100)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.4482758620689655, train_loss: 1.1517118596470695, val_loss: 1.2729347257191324 (58 / 100)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.4729064039408867, train_loss: 1.0985234656793668, val_loss: 1.2536036715718912 (59 / 100)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.49261083743842365, train_loss: 1.0998073982072554, val_loss: 1.3473975629054855 (60 / 100)\n",
            "train_acc: 0.61557478368356, val_acc: 0.4729064039408867, train_loss: 1.0068683787093617, val_loss: 1.243010787247437 (61 / 100)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.4729064039408867, train_loss: 0.9943776499797741, val_loss: 1.2338687337090817 (62 / 100)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.47783251231527096, train_loss: 0.9939430662153383, val_loss: 1.2629986514011626 (63 / 100)\n",
            "train_acc: 0.61557478368356, val_acc: 0.4729064039408867, train_loss: 1.0061729959268653, val_loss: 1.2453934556157717 (64 / 100)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.4729064039408867, train_loss: 0.9753502871845797, val_loss: 1.2519497210756312 (65 / 100)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.4729064039408867, train_loss: 0.9196342280680229, val_loss: 1.2578404222803163 (66 / 100)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.47783251231527096, train_loss: 0.960038479864229, val_loss: 1.2639153265013483 (67 / 100)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.4729064039408867, train_loss: 0.9307206968589236, val_loss: 1.2886274562680662 (68 / 100)\n",
            "train_acc: 0.6353522867737948, val_acc: 0.4729064039408867, train_loss: 0.9296316610573249, val_loss: 1.2948866037312399 (69 / 100)\n",
            "train_acc: 0.6650185414091471, val_acc: 0.4729064039408867, train_loss: 0.9121697356070223, val_loss: 1.2938044720095367 (70 / 100)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.4827586206896552, train_loss: 0.9233152567971917, val_loss: 1.2827747477392846 (71 / 100)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.4827586206896552, train_loss: 0.9408757788657552, val_loss: 1.2634942152817261 (72 / 100)\n",
            "train_acc: 0.6724351050679852, val_acc: 0.4876847290640394, train_loss: 0.8774960739135153, val_loss: 1.30075593476225 (73 / 100)\n",
            "train_acc: 0.65389369592089, val_acc: 0.4827586206896552, train_loss: 0.8898516917700231, val_loss: 1.2940581383669905 (74 / 100)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.47783251231527096, train_loss: 0.8983023287486677, val_loss: 1.2866618536376013 (75 / 100)\n",
            "train_acc: 0.681087762669963, val_acc: 0.4827586206896552, train_loss: 0.8927202322353391, val_loss: 1.29005816593546 (76 / 100)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.47783251231527096, train_loss: 0.9068045081992084, val_loss: 1.282265129934978 (77 / 100)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.49261083743842365, train_loss: 0.8839522321675115, val_loss: 1.3169158708873054 (78 / 100)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.4975369458128079, train_loss: 0.8725103107459465, val_loss: 1.286271485789069 (79 / 100)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.47783251231527096, train_loss: 0.9053879965957812, val_loss: 1.3110832433982436 (80 / 100)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.4827586206896552, train_loss: 0.8891674679864028, val_loss: 1.2883481406813184 (81 / 100)\n",
            "train_acc: 0.6711990111248455, val_acc: 0.4975369458128079, train_loss: 0.8732005079980244, val_loss: 1.3171813752263637 (82 / 100)\n",
            "train_acc: 0.6798516687268232, val_acc: 0.4975369458128079, train_loss: 0.862403800740967, val_loss: 1.3032033810474601 (83 / 100)\n",
            "train_acc: 0.6736711990111248, val_acc: 0.4876847290640394, train_loss: 0.8778581710990486, val_loss: 1.312554189430669 (84 / 100)\n",
            "train_acc: 0.6773794808405439, val_acc: 0.4876847290640394, train_loss: 0.8747806148638094, val_loss: 1.2787691231431633 (85 / 100)\n",
            "train_acc: 0.6823238566131026, val_acc: 0.47783251231527096, train_loss: 0.8455022319285626, val_loss: 1.306925951847302 (86 / 100)\n",
            "train_acc: 0.6749072929542645, val_acc: 0.4975369458128079, train_loss: 0.8546522300971305, val_loss: 1.3057975642786825 (87 / 100)\n",
            "train_acc: 0.6823238566131026, val_acc: 0.4827586206896552, train_loss: 0.8719989154188535, val_loss: 1.317641092932283 (88 / 100)\n",
            "train_acc: 0.6946847960444994, val_acc: 0.4876847290640394, train_loss: 0.8308012352148888, val_loss: 1.2904629713208804 (89 / 100)\n",
            "train_acc: 0.6872682323856613, val_acc: 0.4975369458128079, train_loss: 0.8574709369166672, val_loss: 1.3029718343260253 (90 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5073891625615764, train_loss: 0.8029738367340621, val_loss: 1.309272113985616 (91 / 100)\n",
            "train_acc: 0.7082818294190358, val_acc: 0.4876847290640394, train_loss: 0.8275238235374022, val_loss: 1.287531813083611 (92 / 100)\n",
            "train_acc: 0.69221260815822, val_acc: 0.5024630541871922, train_loss: 0.8112039983051522, val_loss: 1.3361052304065872 (93 / 100)\n",
            "train_acc: 0.7194066749072929, val_acc: 0.4975369458128079, train_loss: 0.7966210054710268, val_loss: 1.3345131881424945 (94 / 100)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5221674876847291, train_loss: 0.7814892935664456, val_loss: 1.34345588249526 (95 / 100)\n",
            "train_acc: 0.6946847960444994, val_acc: 0.5123152709359606, train_loss: 0.8089941758823631, val_loss: 1.3340887342180525 (96 / 100)\n",
            "train_acc: 0.6996291718170581, val_acc: 0.5024630541871922, train_loss: 0.7956507151073814, val_loss: 1.3276637904162478 (97 / 100)\n",
            "train_acc: 0.695920889987639, val_acc: 0.5073891625615764, train_loss: 0.7843726665260471, val_loss: 1.3253116789709758 (98 / 100)\n",
            "train_acc: 0.7243510506798516, val_acc: 0.4975369458128079, train_loss: 0.8100123051807229, val_loss: 1.3263510574260955 (99 / 100)\n",
            "train_acc: 0.723114956736712, val_acc: 0.5123152709359606, train_loss: 0.7645042988808989, val_loss: 1.343534636086431 (100 / 100)\n",
            "({'lr': 0.00038041059192815333, 'batch_size': 9, 'weight_decay': 3.8372561126798785e-05, 'gamma': 0.057680309789029396}), val accuracy 0.5221674876847291, val loss 1.34345588249526 [2 / 8]\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7889252286611588, val_loss: 1.7847846675976156 (1 / 100)\n",
            "train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7811227328108326, val_loss: 1.7765625879682343 (2 / 100)\n",
            "train_acc: 0.19530284301606923, val_acc: 0.18226600985221675, train_loss: 1.7690881361035982, val_loss: 1.7658698306295084 (3 / 100)\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7677115287415324, val_loss: 1.75939460634598 (4 / 100)\n",
            "train_acc: 0.16934487021013597, val_acc: 0.18226600985221675, train_loss: 1.7635342532536302, val_loss: 1.7566013406650187 (5 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.759589360582519, val_loss: 1.752849178948426 (6 / 100)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7517162503948613, val_loss: 1.7474477296979556 (7 / 100)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.19704433497536947, train_loss: 1.752858533258049, val_loss: 1.7431960511090132 (8 / 100)\n",
            "train_acc: 0.23980222496909764, val_acc: 0.19704433497536947, train_loss: 1.7406878714508416, val_loss: 1.7339284425885806 (9 / 100)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.24630541871921183, train_loss: 1.7424869282431301, val_loss: 1.7253259302947321 (10 / 100)\n",
            "train_acc: 0.2484548825710754, val_acc: 0.31527093596059114, train_loss: 1.7319466472408827, val_loss: 1.7053300242118647 (11 / 100)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.33497536945812806, train_loss: 1.7113556922292532, val_loss: 1.6665411976170657 (12 / 100)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.3251231527093596, train_loss: 1.6831602451975178, val_loss: 1.6227554206190438 (13 / 100)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.26108374384236455, train_loss: 1.6612514058503292, val_loss: 1.606940444467103 (14 / 100)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.31527093596059114, train_loss: 1.6444508165894687, val_loss: 1.559741618598036 (15 / 100)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.28078817733990147, train_loss: 1.6321942125468967, val_loss: 1.5608311251466498 (16 / 100)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.27586206896551724, train_loss: 1.6139199609956871, val_loss: 1.5714852322498565 (17 / 100)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.33497536945812806, train_loss: 1.5863491373392207, val_loss: 1.5162320642048501 (18 / 100)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3251231527093596, train_loss: 1.608746210046398, val_loss: 1.5505559368086566 (19 / 100)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.29064039408866993, train_loss: 1.5612347019912285, val_loss: 1.577541231521832 (20 / 100)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.3645320197044335, train_loss: 1.594206557285653, val_loss: 1.510656773750418 (21 / 100)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.3399014778325123, train_loss: 1.5702912251940468, val_loss: 1.50422975934785 (22 / 100)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.3645320197044335, train_loss: 1.5734494979066225, val_loss: 1.49772797958017 (23 / 100)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.33497536945812806, train_loss: 1.5594383478164673, val_loss: 1.5045603801464211 (24 / 100)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.37438423645320196, train_loss: 1.535032663121359, val_loss: 1.481818139846689 (25 / 100)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3694581280788177, train_loss: 1.516695396861865, val_loss: 1.4859090714619076 (26 / 100)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.32019704433497537, train_loss: 1.5400164072828917, val_loss: 1.506372771239633 (27 / 100)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.3448275862068966, train_loss: 1.5417137502592486, val_loss: 1.5016371798632768 (28 / 100)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.32019704433497537, train_loss: 1.5330188340692792, val_loss: 1.4716010628075435 (29 / 100)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3399014778325123, train_loss: 1.483124681544687, val_loss: 1.4878683982811538 (30 / 100)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3793103448275862, train_loss: 1.491090437979869, val_loss: 1.4329255508084602 (31 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3694581280788177, train_loss: 1.4775976897464842, val_loss: 1.4593922287372534 (32 / 100)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.41379310344827586, train_loss: 1.4651019229877127, val_loss: 1.4225289392941103 (33 / 100)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3645320197044335, train_loss: 1.4533088264712886, val_loss: 1.424196812319638 (34 / 100)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.39408866995073893, train_loss: 1.4541224189682855, val_loss: 1.4072188444325489 (35 / 100)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.39901477832512317, train_loss: 1.432884059082003, val_loss: 1.4218825107724795 (36 / 100)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.35960591133004927, train_loss: 1.4097544002002484, val_loss: 1.4313116173438838 (37 / 100)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.35960591133004927, train_loss: 1.4382734191137723, val_loss: 1.4134899442419042 (38 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3793103448275862, train_loss: 1.4271525679471613, val_loss: 1.424003970446845 (39 / 100)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.42857142857142855, train_loss: 1.428450406702841, val_loss: 1.377811147661632 (40 / 100)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.39901477832512317, train_loss: 1.396956944642462, val_loss: 1.3576337339842848 (41 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.4039408866995074, train_loss: 1.405928736711462, val_loss: 1.3595811175595363 (42 / 100)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.3842364532019704, train_loss: 1.3848136707643053, val_loss: 1.3786097368583303 (43 / 100)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.4236453201970443, train_loss: 1.3700653520885888, val_loss: 1.3499554771507902 (44 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.3891625615763547, train_loss: 1.3517530425664668, val_loss: 1.336894724756626 (45 / 100)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.4236453201970443, train_loss: 1.3219228620434869, val_loss: 1.4158774910889236 (46 / 100)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.4482758620689655, train_loss: 1.3257637654600392, val_loss: 1.3761434349520454 (47 / 100)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.458128078817734, train_loss: 1.3123649755131328, val_loss: 1.361233451683533 (48 / 100)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.4729064039408867, train_loss: 1.282755246710571, val_loss: 1.3314848874002843 (49 / 100)\n",
            "train_acc: 0.4783683559950556, val_acc: 0.458128078817734, train_loss: 1.3032461531524753, val_loss: 1.3281891181551178 (50 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.39901477832512317, train_loss: 1.279197435591218, val_loss: 1.3360355434746578 (51 / 100)\n",
            "train_acc: 0.49443757725587145, val_acc: 0.43842364532019706, train_loss: 1.268572748959875, val_loss: 1.2975852286874368 (52 / 100)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.4482758620689655, train_loss: 1.2343275202219506, val_loss: 1.273424846785409 (53 / 100)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4827586206896552, train_loss: 1.2333409856954227, val_loss: 1.3075898110572928 (54 / 100)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.4187192118226601, train_loss: 1.224392974774534, val_loss: 1.347468872962914 (55 / 100)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.4630541871921182, train_loss: 1.2102851378460897, val_loss: 1.3108007931356946 (56 / 100)\n",
            "train_acc: 0.5142150803461063, val_acc: 0.4482758620689655, train_loss: 1.1942080714646612, val_loss: 1.321346582450303 (57 / 100)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.43842364532019706, train_loss: 1.1718951855660664, val_loss: 1.2977585786669126 (58 / 100)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.46798029556650245, train_loss: 1.1802341709620283, val_loss: 1.3268870552772372 (59 / 100)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.47783251231527096, train_loss: 1.1199525940256154, val_loss: 1.337830789570738 (60 / 100)\n",
            "train_acc: 0.5661310259579728, val_acc: 0.4827586206896552, train_loss: 1.0656725924890327, val_loss: 1.3202153215267387 (61 / 100)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.49261083743842365, train_loss: 1.0854062668619993, val_loss: 1.3070618918376604 (62 / 100)\n",
            "train_acc: 0.5784919653893696, val_acc: 0.4827586206896552, train_loss: 1.0298078814602016, val_loss: 1.3064727577669868 (63 / 100)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.47783251231527096, train_loss: 1.0715215449280144, val_loss: 1.3041728864162427 (64 / 100)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.47783251231527096, train_loss: 1.0801203915451012, val_loss: 1.2977234709439018 (65 / 100)\n",
            "train_acc: 0.6217552533992583, val_acc: 0.47783251231527096, train_loss: 1.0284365047188417, val_loss: 1.2961420930665115 (66 / 100)\n",
            "train_acc: 0.588380716934487, val_acc: 0.4729064039408867, train_loss: 1.059618371084093, val_loss: 1.295122396769782 (67 / 100)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.47783251231527096, train_loss: 1.0528788184942803, val_loss: 1.2894698977470398 (68 / 100)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.4729064039408867, train_loss: 1.0775019334184814, val_loss: 1.2865256652456198 (69 / 100)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.4729064039408867, train_loss: 1.0326006518600899, val_loss: 1.2862080737875012 (70 / 100)\n",
            "train_acc: 0.6118665018541409, val_acc: 0.47783251231527096, train_loss: 1.0221995206639558, val_loss: 1.2882876302221138 (71 / 100)\n",
            "train_acc: 0.619283065512979, val_acc: 0.47783251231527096, train_loss: 1.033353226146533, val_loss: 1.2861599963286827 (72 / 100)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.4729064039408867, train_loss: 0.9855448056947168, val_loss: 1.2867308473352141 (73 / 100)\n",
            "train_acc: 0.588380716934487, val_acc: 0.46798029556650245, train_loss: 1.0380183433278087, val_loss: 1.2837223504564446 (74 / 100)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.4729064039408867, train_loss: 1.017902004925076, val_loss: 1.2817397740086898 (75 / 100)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.4729064039408867, train_loss: 0.9821261177841016, val_loss: 1.2863217192917622 (76 / 100)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.47783251231527096, train_loss: 1.023525935463027, val_loss: 1.2869674607450738 (77 / 100)\n",
            "train_acc: 0.61557478368356, val_acc: 0.4827586206896552, train_loss: 1.0101917973260208, val_loss: 1.2909649716222227 (78 / 100)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.47783251231527096, train_loss: 1.0222740916740172, val_loss: 1.2893279729218319 (79 / 100)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.4876847290640394, train_loss: 1.038738663544319, val_loss: 1.28564546730718 (80 / 100)\n",
            "train_acc: 0.6365883807169345, val_acc: 0.47783251231527096, train_loss: 0.9950480263666405, val_loss: 1.2883565044168181 (81 / 100)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.47783251231527096, train_loss: 0.988473687095312, val_loss: 1.2841350697531488 (82 / 100)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.4729064039408867, train_loss: 1.0119144579830806, val_loss: 1.2794552101877523 (83 / 100)\n",
            "train_acc: 0.6217552533992583, val_acc: 0.4729064039408867, train_loss: 0.9848654917055656, val_loss: 1.2825565608264191 (84 / 100)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.47783251231527096, train_loss: 1.003305890062094, val_loss: 1.2822397869502382 (85 / 100)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.47783251231527096, train_loss: 0.9905433634892382, val_loss: 1.2838600307262589 (86 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.4827586206896552, train_loss: 0.9979837390194717, val_loss: 1.2862012042787863 (87 / 100)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.4876847290640394, train_loss: 0.9946833557192564, val_loss: 1.2892598888556945 (88 / 100)\n",
            "train_acc: 0.622991347342398, val_acc: 0.49261083743842365, train_loss: 1.014927112864623, val_loss: 1.2859966452485823 (89 / 100)\n",
            "train_acc: 0.6489493201483313, val_acc: 0.4876847290640394, train_loss: 0.9802434216028975, val_loss: 1.287016691245469 (90 / 100)\n",
            "train_acc: 0.619283065512979, val_acc: 0.4729064039408867, train_loss: 0.9819803234967961, val_loss: 1.2852377427622603 (91 / 100)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.47783251231527096, train_loss: 1.0145865843086808, val_loss: 1.2813611494496537 (92 / 100)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.4827586206896552, train_loss: 0.9637179240602792, val_loss: 1.2808174423396295 (93 / 100)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.4729064039408867, train_loss: 0.9793687258721577, val_loss: 1.279297319245456 (94 / 100)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.49261083743842365, train_loss: 0.9582632862593247, val_loss: 1.2847976473164675 (95 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.4827586206896552, train_loss: 0.989684894294173, val_loss: 1.2851395201800493 (96 / 100)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.4827586206896552, train_loss: 0.9586887648432747, val_loss: 1.2857492249000249 (97 / 100)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.4827586206896552, train_loss: 0.984617411574563, val_loss: 1.282018936326351 (98 / 100)\n",
            "train_acc: 0.6254635352286774, val_acc: 0.4876847290640394, train_loss: 0.9950734891172393, val_loss: 1.2812725176364916 (99 / 100)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.49261083743842365, train_loss: 1.0071809498871802, val_loss: 1.283952041799799 (100 / 100)\n",
            "({'lr': 0.00043660847130590896, 'batch_size': 10, 'weight_decay': 0.00025031720443271155, 'gamma': 0.011678955740792939}), val accuracy 0.49261083743842365, val loss 1.3070618918376604 [3 / 8]\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7896751214016795, val_loss: 1.7836480434304975 (1 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.7805867887692635, val_loss: 1.7748527579706879 (2 / 100)\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 1.7750417468574344, val_loss: 1.7672475159461862 (3 / 100)\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7670053601707014, val_loss: 1.761302996738791 (4 / 100)\n",
            "train_acc: 0.207663782447466, val_acc: 0.17733990147783252, train_loss: 1.7656165451290287, val_loss: 1.7581329052084185 (5 / 100)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7636665835221412, val_loss: 1.7542565743911442 (6 / 100)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7574671383104454, val_loss: 1.7505318372707648 (7 / 100)\n",
            "train_acc: 0.19406674907292953, val_acc: 0.18226600985221675, train_loss: 1.759245326993492, val_loss: 1.74786423755984 (8 / 100)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7509824481087062, val_loss: 1.7430962770443243 (9 / 100)\n",
            "train_acc: 0.22249690976514216, val_acc: 0.18226600985221675, train_loss: 1.7490354300429412, val_loss: 1.7378453345134341 (10 / 100)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.18719211822660098, train_loss: 1.7461120528255316, val_loss: 1.7318490843467524 (11 / 100)\n",
            "train_acc: 0.22620519159456118, val_acc: 0.1921182266009852, train_loss: 1.736988491858776, val_loss: 1.724260116445607 (12 / 100)\n",
            "underfit -> train_accuracy = 0.22620519159456118\n",
            "({'lr': 0.00027531434783290124, 'batch_size': 9, 'weight_decay': 4.3783604017624755e-06, 'gamma': 0.11844128056704877}), val accuracy 0.1921182266009852, val loss 1.724260116445607 [4 / 8]\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7861666676435246, val_loss: 1.7797195746980865 (1 / 100)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7770210115517615, val_loss: 1.7665413782514374 (2 / 100)\n",
            "train_acc: 0.17799752781211373, val_acc: 0.18226600985221675, train_loss: 1.76658577146872, val_loss: 1.7571329289469226 (3 / 100)\n",
            "train_acc: 0.17676143386897405, val_acc: 0.18226600985221675, train_loss: 1.7614888660103194, val_loss: 1.750835052851973 (4 / 100)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.2315270935960591, train_loss: 1.7579491670405762, val_loss: 1.746975199929599 (5 / 100)\n",
            "train_acc: 0.2126081582200247, val_acc: 0.18719211822660098, train_loss: 1.7496424293046533, val_loss: 1.7389411926269531 (6 / 100)\n",
            "train_acc: 0.2200247218788628, val_acc: 0.18719211822660098, train_loss: 1.7504148664521642, val_loss: 1.7292535839409664 (7 / 100)\n",
            "train_acc: 0.2323856613102596, val_acc: 0.2857142857142857, train_loss: 1.7432391289874856, val_loss: 1.7163076113010276 (8 / 100)\n",
            "train_acc: 0.2311495673671199, val_acc: 0.2660098522167488, train_loss: 1.7386996146332938, val_loss: 1.7062354745536015 (9 / 100)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.3497536945812808, train_loss: 1.7100398910355068, val_loss: 1.653443406368124 (10 / 100)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.33004926108374383, train_loss: 1.6846110346290768, val_loss: 1.599790651222755 (11 / 100)\n",
            "train_acc: 0.29913473423980225, val_acc: 0.23645320197044334, train_loss: 1.640645495009216, val_loss: 1.620114536120974 (12 / 100)\n",
            "train_acc: 0.315203955500618, val_acc: 0.2857142857142857, train_loss: 1.6389602580382885, val_loss: 1.6640174676632058 (13 / 100)\n",
            "train_acc: 0.2954264524103832, val_acc: 0.3251231527093596, train_loss: 1.6365082098910186, val_loss: 1.5494744489932883 (14 / 100)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.3054187192118227, train_loss: 1.5896497151465587, val_loss: 1.5286641573083812 (15 / 100)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.2857142857142857, train_loss: 1.611700435356687, val_loss: 1.5454529194996274 (16 / 100)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.3103448275862069, train_loss: 1.5990852099855986, val_loss: 1.5186776580481693 (17 / 100)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.3448275862068966, train_loss: 1.5791886141627327, val_loss: 1.4922222885592231 (18 / 100)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.30049261083743845, train_loss: 1.5688163152583892, val_loss: 1.4945474287559246 (19 / 100)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.30049261083743845, train_loss: 1.562727175772706, val_loss: 1.514878379887548 (20 / 100)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3645320197044335, train_loss: 1.4920681407041987, val_loss: 1.4502703444711094 (21 / 100)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3103448275862069, train_loss: 1.5418740111611535, val_loss: 1.5266990209447926 (22 / 100)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.37438423645320196, train_loss: 1.5354687065364994, val_loss: 1.4599989118247196 (23 / 100)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.2857142857142857, train_loss: 1.485948089616113, val_loss: 1.5392364181321243 (24 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3103448275862069, train_loss: 1.5124971648523922, val_loss: 1.4574490210105633 (25 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.30049261083743845, train_loss: 1.500265139879196, val_loss: 1.4788668936696545 (26 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3891625615763547, train_loss: 1.4898451901189476, val_loss: 1.4403603159148117 (27 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3694581280788177, train_loss: 1.4690941519141933, val_loss: 1.4253489354561115 (28 / 100)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.4088669950738916, train_loss: 1.4479748881496812, val_loss: 1.4070462975008735 (29 / 100)\n",
            "train_acc: 0.377008652657602, val_acc: 0.37438423645320196, train_loss: 1.4569640828593553, val_loss: 1.402541288014116 (30 / 100)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.35960591133004927, train_loss: 1.440074267729251, val_loss: 1.4020368066327324 (31 / 100)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3645320197044335, train_loss: 1.417559366143678, val_loss: 1.4018188632767776 (32 / 100)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.4088669950738916, train_loss: 1.4061566134465786, val_loss: 1.4132417892587597 (33 / 100)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.3645320197044335, train_loss: 1.4305003088690589, val_loss: 1.416400333930706 (34 / 100)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.39408866995073893, train_loss: 1.4061868397060815, val_loss: 1.408303404676503 (35 / 100)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.35960591133004927, train_loss: 1.3933755906462226, val_loss: 1.4247817458777592 (36 / 100)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.4187192118226601, train_loss: 1.3694114642325967, val_loss: 1.349530709200892 (37 / 100)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.39901477832512317, train_loss: 1.365113873122207, val_loss: 1.3744847774505615 (38 / 100)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.43349753694581283, train_loss: 1.3617152243815778, val_loss: 1.353116039572091 (39 / 100)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.41379310344827586, train_loss: 1.3410656323981078, val_loss: 1.375543606692347 (40 / 100)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.4433497536945813, train_loss: 1.3427542926943936, val_loss: 1.3291631114893947 (41 / 100)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4236453201970443, train_loss: 1.3035583851216603, val_loss: 1.347035995845137 (42 / 100)\n",
            "train_acc: 0.484548825710754, val_acc: 0.43349753694581283, train_loss: 1.2813908402498337, val_loss: 1.4910176663563168 (43 / 100)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4630541871921182, train_loss: 1.2557095413007606, val_loss: 1.3312593123008465 (44 / 100)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.4630541871921182, train_loss: 1.291922358411499, val_loss: 1.38007233471706 (45 / 100)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4187192118226601, train_loss: 1.2486591891688381, val_loss: 1.3520402127298816 (46 / 100)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.42857142857142855, train_loss: 1.1975854014878808, val_loss: 1.3440350417433113 (47 / 100)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.4630541871921182, train_loss: 1.2019917209009894, val_loss: 1.3071334773096546 (48 / 100)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.43349753694581283, train_loss: 1.1978855326090225, val_loss: 1.3005435631192963 (49 / 100)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.47783251231527096, train_loss: 1.1684207923627459, val_loss: 1.3293308307384621 (50 / 100)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.47783251231527096, train_loss: 1.1851064108210825, val_loss: 1.2618018594281426 (51 / 100)\n",
            "train_acc: 0.546353522867738, val_acc: 0.3891625615763547, train_loss: 1.1435144643111637, val_loss: 1.3558119782086075 (52 / 100)\n",
            "train_acc: 0.553770086526576, val_acc: 0.46798029556650245, train_loss: 1.1175305256884827, val_loss: 1.3537893829674557 (53 / 100)\n",
            "train_acc: 0.5611866501854141, val_acc: 0.4876847290640394, train_loss: 1.0911868378906815, val_loss: 1.441941129750219 (54 / 100)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.43842364532019706, train_loss: 1.0898243342106069, val_loss: 1.3467519159974723 (55 / 100)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.4876847290640394, train_loss: 1.0543216319549806, val_loss: 1.3778414479617416 (56 / 100)\n",
            "train_acc: 0.6118665018541409, val_acc: 0.47783251231527096, train_loss: 1.0376828056478087, val_loss: 1.3004726377026787 (57 / 100)\n",
            "train_acc: 0.5784919653893696, val_acc: 0.4827586206896552, train_loss: 1.0598260622531432, val_loss: 1.3493875347334763 (58 / 100)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.4827586206896552, train_loss: 0.980230483932165, val_loss: 1.3492565463329185 (59 / 100)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.4482758620689655, train_loss: 0.9627706161682921, val_loss: 1.3364048744070118 (60 / 100)\n",
            "train_acc: 0.6847960444993819, val_acc: 0.49261083743842365, train_loss: 0.8361430118051536, val_loss: 1.3428011187191666 (61 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5024630541871922, train_loss: 0.7838759533554426, val_loss: 1.3304991681000282 (62 / 100)\n",
            "train_acc: 0.6946847960444994, val_acc: 0.5073891625615764, train_loss: 0.7985873563475309, val_loss: 1.310949913386641 (63 / 100)\n",
            "train_acc: 0.7144622991347342, val_acc: 0.5073891625615764, train_loss: 0.7824390019636661, val_loss: 1.3298773457264077 (64 / 100)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.5172413793103449, train_loss: 0.73653025960156, val_loss: 1.35627242614483 (65 / 100)\n",
            "train_acc: 0.7058096415327565, val_acc: 0.5270935960591133, train_loss: 0.7330933869695486, val_loss: 1.3716695925285076 (66 / 100)\n",
            "train_acc: 0.7268232385661311, val_acc: 0.5123152709359606, train_loss: 0.7632930639058315, val_loss: 1.349660688433154 (67 / 100)\n",
            "train_acc: 0.7391841779975278, val_acc: 0.5221674876847291, train_loss: 0.7166492982464756, val_loss: 1.3819818373384147 (68 / 100)\n",
            "train_acc: 0.7367119901112484, val_acc: 0.5221674876847291, train_loss: 0.7126379726254306, val_loss: 1.3682339520289981 (69 / 100)\n",
            "train_acc: 0.761433868974042, val_acc: 0.541871921182266, train_loss: 0.6970092858313335, val_loss: 1.408677471095118 (70 / 100)\n",
            "train_acc: 0.7428924598269468, val_acc: 0.5172413793103449, train_loss: 0.6994938392500647, val_loss: 1.3691240055807705 (71 / 100)\n",
            "train_acc: 0.7626699629171817, val_acc: 0.5172413793103449, train_loss: 0.697907956885761, val_loss: 1.424883431401746 (72 / 100)\n",
            "train_acc: 0.757725587144623, val_acc: 0.5270935960591133, train_loss: 0.6880681301813633, val_loss: 1.4193689268210838 (73 / 100)\n",
            "train_acc: 0.7688504326328801, val_acc: 0.541871921182266, train_loss: 0.6622876076969434, val_loss: 1.4288614536153859 (74 / 100)\n",
            "train_acc: 0.7589616810877626, val_acc: 0.5369458128078818, train_loss: 0.6602585435060989, val_loss: 1.413916713204877 (75 / 100)\n",
            "overfit -> train_accuracy 0.788627935723115, val_accuracy 0.5172413793103449\n",
            "({'lr': 0.0007220498435995008, 'batch_size': 14, 'weight_decay': 2.228552014354877e-05, 'gamma': 0.08113961287843949}), val accuracy 0.541871921182266, val loss 1.408677471095118 [5 / 8]\n",
            "train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7818211063613703, val_loss: 1.7647145305361067 (1 / 100)\n",
            "train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7682946442968324, val_loss: 1.7513694264031396 (2 / 100)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.23645320197044334, train_loss: 1.7560919831208746, val_loss: 1.749696900691892 (3 / 100)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.21182266009852216, train_loss: 1.7565025212001446, val_loss: 1.730656121751945 (4 / 100)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.2561576354679803, train_loss: 1.7366777002737754, val_loss: 1.716879397777501 (5 / 100)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.3103448275862069, train_loss: 1.7009117376377025, val_loss: 1.6334610085182002 (6 / 100)\n",
            "train_acc: 0.2669962917181706, val_acc: 0.29064039408866993, train_loss: 1.721392325918813, val_loss: 1.724266503832023 (7 / 100)\n",
            "train_acc: 0.2954264524103832, val_acc: 0.3793103448275862, train_loss: 1.6643545520025662, val_loss: 1.568325483740257 (8 / 100)\n",
            "train_acc: 0.315203955500618, val_acc: 0.28078817733990147, train_loss: 1.63107955986254, val_loss: 1.6194747016934925 (9 / 100)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.3054187192118227, train_loss: 1.6260548709202167, val_loss: 1.543332562070762 (10 / 100)\n",
            "train_acc: 0.2694684796044499, val_acc: 0.2561576354679803, train_loss: 1.6046412598217374, val_loss: 1.6182195277049625 (11 / 100)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.2561576354679803, train_loss: 1.5813496310277686, val_loss: 1.7060172181998567 (12 / 100)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3497536945812808, train_loss: 1.5656615345380804, val_loss: 1.4755384164490724 (13 / 100)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.33497536945812806, train_loss: 1.5571980831502248, val_loss: 1.5338737594670262 (14 / 100)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.35960591133004927, train_loss: 1.534064902068658, val_loss: 1.4758642459737843 (15 / 100)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.3694581280788177, train_loss: 1.535166447920027, val_loss: 1.4489088810136166 (16 / 100)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3448275862068966, train_loss: 1.494519933634547, val_loss: 1.4668560309950354 (17 / 100)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.35467980295566504, train_loss: 1.4828642811557124, val_loss: 1.4441546013789812 (18 / 100)\n",
            "train_acc: 0.3856613102595797, val_acc: 0.3399014778325123, train_loss: 1.4623146662753357, val_loss: 1.48071006307461 (19 / 100)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3645320197044335, train_loss: 1.458672186352856, val_loss: 1.4758451824705001 (20 / 100)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.39408866995073893, train_loss: 1.4200228822540737, val_loss: 1.4756163026898952 (21 / 100)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.3399014778325123, train_loss: 1.414640766728499, val_loss: 1.434823790794523 (22 / 100)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.39408866995073893, train_loss: 1.3783538107229547, val_loss: 1.3883914301548097 (23 / 100)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.41379310344827586, train_loss: 1.381150230636408, val_loss: 1.372382567433888 (24 / 100)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.4236453201970443, train_loss: 1.3569961968988953, val_loss: 1.4425065188572324 (25 / 100)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.35960591133004927, train_loss: 1.3258067593438958, val_loss: 1.3626915251680196 (26 / 100)\n",
            "train_acc: 0.446229913473424, val_acc: 0.39408866995073893, train_loss: 1.3157715815106783, val_loss: 1.3497652508355127 (27 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.3793103448275862, train_loss: 1.292302116917444, val_loss: 1.381402952330453 (28 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.458128078817734, train_loss: 1.2449283484917488, val_loss: 1.3569896494226503 (29 / 100)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.4088669950738916, train_loss: 1.2735979890057123, val_loss: 1.3047296701393691 (30 / 100)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4187192118226601, train_loss: 1.2002969949295552, val_loss: 1.3272160426736466 (31 / 100)\n",
            "train_acc: 0.5265760197775031, val_acc: 0.4433497536945813, train_loss: 1.1746609352427744, val_loss: 1.3452060466329452 (32 / 100)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.41379310344827586, train_loss: 1.188621943312316, val_loss: 1.3155493237114892 (33 / 100)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.4482758620689655, train_loss: 1.1495362595368375, val_loss: 1.2869190353478117 (34 / 100)\n",
            "train_acc: 0.553770086526576, val_acc: 0.43349753694581283, train_loss: 1.1336733917665422, val_loss: 1.3157043709543539 (35 / 100)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.4236453201970443, train_loss: 1.074478788929905, val_loss: 1.3213418322830952 (36 / 100)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.43349753694581283, train_loss: 1.0350455649850985, val_loss: 1.3961987539465204 (37 / 100)\n",
            "train_acc: 0.6390605686032138, val_acc: 0.45320197044334976, train_loss: 0.9894883716651625, val_loss: 1.4679504145542388 (38 / 100)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.49261083743842365, train_loss: 1.0558017965300268, val_loss: 1.2173933687762086 (39 / 100)\n",
            "train_acc: 0.6415327564894932, val_acc: 0.4876847290640394, train_loss: 0.9066119650827792, val_loss: 1.3396403537007975 (40 / 100)\n",
            "train_acc: 0.6786155747836835, val_acc: 0.5172413793103449, train_loss: 0.8607781496271951, val_loss: 1.3202849993564811 (41 / 100)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.5369458128078818, train_loss: 0.8167170461529707, val_loss: 1.2331452410796593 (42 / 100)\n",
            "train_acc: 0.6946847960444994, val_acc: 0.45320197044334976, train_loss: 0.7949860535092348, val_loss: 1.3899892746227716 (43 / 100)\n",
            "train_acc: 0.7268232385661311, val_acc: 0.5073891625615764, train_loss: 0.7124589523956714, val_loss: 1.2568137325676791 (44 / 100)\n",
            "train_acc: 0.7466007416563659, val_acc: 0.5123152709359606, train_loss: 0.7314317662577399, val_loss: 1.3832288269926174 (45 / 100)\n",
            "train_acc: 0.7490729295426453, val_acc: 0.5073891625615764, train_loss: 0.6745059854167943, val_loss: 1.382282345459379 (46 / 100)\n",
            "overfit -> train_accuracy 0.788627935723115, val_accuracy 0.5320197044334976\n",
            "({'lr': 0.0008377019231346562, 'batch_size': 8, 'weight_decay': 2.4427015675775187e-06, 'gamma': 0.00903130010323455}), val accuracy 0.5369458128078818, val loss 1.2331452410796593 [6 / 8]\n",
            "train_acc: 0.1631644004944376, val_acc: 0.18226600985221675, train_loss: 1.7766925758130765, val_loss: 1.7539880821857545 (1 / 100)\n",
            "train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7596699351580682, val_loss: 1.7438263446826654 (2 / 100)\n",
            "train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7552002472400077, val_loss: 1.7404161362812436 (3 / 100)\n",
            "train_acc: 0.23980222496909764, val_acc: 0.28078817733990147, train_loss: 1.7384143696432504, val_loss: 1.7143891151315473 (4 / 100)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.30049261083743845, train_loss: 1.7122499581762534, val_loss: 1.6220136622489967 (5 / 100)\n",
            "train_acc: 0.2558714462299135, val_acc: 0.22660098522167488, train_loss: 1.709246553508254, val_loss: 1.7155815503867389 (6 / 100)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.27586206896551724, train_loss: 1.66151555109083, val_loss: 1.5941098399937446 (7 / 100)\n",
            "train_acc: 0.29913473423980225, val_acc: 0.3103448275862069, train_loss: 1.653239645091506, val_loss: 1.603086013512071 (8 / 100)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.31527093596059114, train_loss: 1.599515911380499, val_loss: 1.526085434876052 (9 / 100)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3399014778325123, train_loss: 1.5732850948871286, val_loss: 1.5342815163100294 (10 / 100)\n",
            "train_acc: 0.30778739184178, val_acc: 0.27586206896551724, train_loss: 1.5748609531353077, val_loss: 1.5317456810345202 (11 / 100)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.31527093596059114, train_loss: 1.5477011520576713, val_loss: 1.5252825491534079 (12 / 100)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.30049261083743845, train_loss: 1.5342656790989144, val_loss: 1.490433931350708 (13 / 100)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.37438423645320196, train_loss: 1.5124600652711206, val_loss: 1.44714960030147 (14 / 100)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3645320197044335, train_loss: 1.4860571792305473, val_loss: 1.4459439363385655 (15 / 100)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.35467980295566504, train_loss: 1.4675435104829861, val_loss: 1.4120907243249452 (16 / 100)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.31527093596059114, train_loss: 1.461762725496469, val_loss: 1.482680203879408 (17 / 100)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.4039408866995074, train_loss: 1.4442971572003642, val_loss: 1.498663428381746 (18 / 100)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.3694581280788177, train_loss: 1.4117927087104807, val_loss: 1.473797311630155 (19 / 100)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.3793103448275862, train_loss: 1.3613594344578803, val_loss: 1.413333345516562 (20 / 100)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4039408866995074, train_loss: 1.3928982415806377, val_loss: 1.3569276045108665 (21 / 100)\n",
            "train_acc: 0.411619283065513, val_acc: 0.43349753694581283, train_loss: 1.3785852050899132, val_loss: 1.342154352535755 (22 / 100)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.39901477832512317, train_loss: 1.3111867198837996, val_loss: 1.3979129391938008 (23 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.35960591133004927, train_loss: 1.2748218254636332, val_loss: 1.4062273461243202 (24 / 100)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4433497536945813, train_loss: 1.2341257921697477, val_loss: 1.4092442314025804 (25 / 100)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.46798029556650245, train_loss: 1.268781963325991, val_loss: 1.3221571204697558 (26 / 100)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4088669950738916, train_loss: 1.2048794194705996, val_loss: 1.3081591619646609 (27 / 100)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.3694581280788177, train_loss: 1.1711495618148258, val_loss: 1.5107391315140748 (28 / 100)\n",
            "train_acc: 0.48331273176761436, val_acc: 0.4039408866995074, train_loss: 1.1932269041558867, val_loss: 1.4026355044595127 (29 / 100)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.4482758620689655, train_loss: 1.1358668018772518, val_loss: 1.4358925073604865 (30 / 100)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.41379310344827586, train_loss: 1.0778652382427447, val_loss: 1.3335260913289826 (31 / 100)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.458128078817734, train_loss: 1.0747713683120106, val_loss: 1.334182380455468 (32 / 100)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.4482758620689655, train_loss: 1.0337582761778672, val_loss: 1.3569612608754575 (33 / 100)\n",
            "train_acc: 0.6217552533992583, val_acc: 0.4729064039408867, train_loss: 0.9941877452345802, val_loss: 1.3541251644125125 (34 / 100)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.4630541871921182, train_loss: 0.9266162067467556, val_loss: 1.399338897225892 (35 / 100)\n",
            "train_acc: 0.6316440049443758, val_acc: 0.4482758620689655, train_loss: 0.9438230067454693, val_loss: 1.4723531595004604 (36 / 100)\n",
            "train_acc: 0.6526576019777504, val_acc: 0.4876847290640394, train_loss: 0.8838422512094524, val_loss: 1.2692955503322807 (37 / 100)\n",
            "train_acc: 0.657601977750309, val_acc: 0.49261083743842365, train_loss: 0.913736150644913, val_loss: 1.3009560190398117 (38 / 100)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.49261083743842365, train_loss: 0.8611669599346826, val_loss: 1.5212284843322679 (39 / 100)\n",
            "train_acc: 0.7218788627935723, val_acc: 0.5172413793103449, train_loss: 0.7409040273635732, val_loss: 1.4521554445691884 (40 / 100)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5369458128078818, train_loss: 0.7377173862292239, val_loss: 1.343754017294334 (41 / 100)\n",
            "overfit -> train_accuracy 0.7725587144622992, val_accuracy 0.4827586206896552\n",
            "({'lr': 0.0010316163585472981, 'batch_size': 8, 'weight_decay': 1.8309942558988887e-05, 'gamma': 0.002673690056313373}), val accuracy 0.5369458128078818, val loss 1.343754017294334 [7 / 8]\n",
            "train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7771501181594227, val_loss: 1.7548545828006539 (1 / 100)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.7654944232426704, val_loss: 1.7531483108774195 (2 / 100)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.18226600985221675, train_loss: 1.7499043114842532, val_loss: 1.727023784162963 (3 / 100)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.28078817733990147, train_loss: 1.7288300428166525, val_loss: 1.6796269105573005 (4 / 100)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.26108374384236455, train_loss: 1.7285280756661565, val_loss: 1.6600043485904563 (5 / 100)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.28078817733990147, train_loss: 1.699261367836753, val_loss: 1.636972661676078 (6 / 100)\n",
            "train_acc: 0.24721878862793573, val_acc: 0.21674876847290642, train_loss: 1.672389029277712, val_loss: 1.669879928598263 (7 / 100)\n",
            "train_acc: 0.276885043263288, val_acc: 0.29064039408866993, train_loss: 1.6376952738932833, val_loss: 1.5834552977472691 (8 / 100)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.33497536945812806, train_loss: 1.5902059505542807, val_loss: 1.5211945754553884 (9 / 100)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.33004926108374383, train_loss: 1.578896675180593, val_loss: 1.5219833657072095 (10 / 100)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.33497536945812806, train_loss: 1.5753891341323758, val_loss: 1.534960998690187 (11 / 100)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.33497536945812806, train_loss: 1.576653564816205, val_loss: 1.4723006663064064 (12 / 100)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.2955665024630542, train_loss: 1.5250024894259326, val_loss: 1.5390588714571423 (13 / 100)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.32019704433497537, train_loss: 1.5144119754857275, val_loss: 1.4842161826899487 (14 / 100)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.33497536945812806, train_loss: 1.487132582440512, val_loss: 1.4402958683192437 (15 / 100)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.35960591133004927, train_loss: 1.4395528737045777, val_loss: 1.4646280998079648 (16 / 100)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3054187192118227, train_loss: 1.4443730412071802, val_loss: 1.4728366576979313 (17 / 100)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.39408866995073893, train_loss: 1.383141069093947, val_loss: 1.4096101915895058 (18 / 100)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.3497536945812808, train_loss: 1.4027006299003535, val_loss: 1.4220207988334994 (19 / 100)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.3103448275862069, train_loss: 1.3607075843587058, val_loss: 1.4451146783499882 (20 / 100)\n",
            "train_acc: 0.415327564894932, val_acc: 0.3497536945812808, train_loss: 1.3524714808528886, val_loss: 1.421655544506505 (21 / 100)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.39901477832512317, train_loss: 1.276603008819599, val_loss: 1.3974204042862202 (22 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.3645320197044335, train_loss: 1.2597652163876887, val_loss: 1.411207056397875 (23 / 100)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4039408866995074, train_loss: 1.2422341827409082, val_loss: 1.3416415652618032 (24 / 100)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.458128078817734, train_loss: 1.1933199914335761, val_loss: 1.3026082762356461 (25 / 100)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.39901477832512317, train_loss: 1.1758836630100962, val_loss: 1.4438523256719993 (26 / 100)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.39901477832512317, train_loss: 1.1260489972471748, val_loss: 1.4162683287277598 (27 / 100)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.4729064039408867, train_loss: 1.0764345004325744, val_loss: 1.260308179362067 (28 / 100)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.4088669950738916, train_loss: 1.0364619052896393, val_loss: 1.2856104227122416 (29 / 100)\n",
            "train_acc: 0.580964153275649, val_acc: 0.4482758620689655, train_loss: 1.0357003559730256, val_loss: 1.2996841263888506 (30 / 100)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.49261083743842365, train_loss: 1.0061518674433159, val_loss: 1.2977427631763403 (31 / 100)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.4827586206896552, train_loss: 0.9387034547638392, val_loss: 1.2701738561902727 (32 / 100)\n",
            "train_acc: 0.6860321384425216, val_acc: 0.49261083743842365, train_loss: 0.8141766475658629, val_loss: 1.405986180446418 (33 / 100)\n",
            "overfit -> train_accuracy 0.7021013597033374, val_accuracy 0.43842364532019706\n",
            "({'lr': 0.0016661746592012004, 'batch_size': 8, 'weight_decay': 3.3763075569909223e-06, 'gamma': 0.006052773438030023}), val accuracy 0.49261083743842365, val loss 1.2977427631763403 [8 / 8]\n",
            "\n",
            "\n",
            "({'lr': 0.0006444500508054211, 'batch_size': 14, 'weight_decay': 2.1280582227123365e-05, 'gamma': 0.19924404264743992}), best val accuracy 0.5566502463054187, best val loss 1.3541624217197812\n",
            "\n",
            "\n",
            "val_accuracies\n",
            "[0.5566502463054187, 0.5221674876847291, 0.49261083743842365, 0.1921182266009852, 0.541871921182266, 0.5369458128078818, 0.5369458128078818, 0.49261083743842365]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "outputId": "3faa7a3e-7dce-418a-8a16-5ac13471f165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 24421 (delta 28), reused 33 (delta 14), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24421/24421), 2.15 GiB | 48.26 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Checking out files: 100% (24638/24638), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing mean/std: 100%|██████████| 1012/1012 [47:31<00:00,  2.82s/samples]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[45.6068733   0.81077038 57.85301916]\n",
            "[66.92374056  9.88349788 49.96761776]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}