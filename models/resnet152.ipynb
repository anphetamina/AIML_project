{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet152\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "    best_net = best_net.to(DEVICE)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "3ed57a25-91ea-4505-993c-17fefeb4cad5",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "# ({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.2976923220850565\n",
        "# lr 0.002473823281245263, batch 12, decay 1.8559777801775264e-05, gamma 0.5778758084832141, val accuracy 0.5665024630541872, val loss 1.2077535097234942 [4 / 50]\n",
        "BATCH_SIZE = 12\n",
        "LR = 0.002473823281245263\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1.8559777801775264e-05\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.5778758084832141\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/72)\u001b[K\rremote: Counting objects:   2% (2/72)\u001b[K\rremote: Counting objects:   4% (3/72)\u001b[K\rremote: Counting objects:   5% (4/72)\u001b[K\rremote: Counting objects:   6% (5/72)\u001b[K\rremote: Counting objects:   8% (6/72)\u001b[K\rremote: Counting objects:   9% (7/72)\u001b[K\rremote: Counting objects:  11% (8/72)\u001b[K\rremote: Counting objects:  12% (9/72)\u001b[K\rremote: Counting objects:  13% (10/72)\u001b[K\rremote: Counting objects:  15% (11/72)\u001b[K\rremote: Counting objects:  16% (12/72)\u001b[K\rremote: Counting objects:  18% (13/72)\u001b[K\rremote: Counting objects:  19% (14/72)\u001b[K\rremote: Counting objects:  20% (15/72)\u001b[K\rremote: Counting objects:  22% (16/72)\u001b[K\rremote: Counting objects:  23% (17/72)\u001b[K\rremote: Counting objects:  25% (18/72)\u001b[K\rremote: Counting objects:  26% (19/72)\u001b[K\rremote: Counting objects:  27% (20/72)\u001b[K\rremote: Counting objects:  29% (21/72)\u001b[K\rremote: Counting objects:  30% (22/72)\u001b[K\rremote: Counting objects:  31% (23/72)\u001b[K\rremote: Counting objects:  33% (24/72)\u001b[K\rremote: Counting objects:  34% (25/72)\u001b[K\rremote: Counting objects:  36% (26/72)\u001b[K\rremote: Counting objects:  37% (27/72)\u001b[K\rremote: Counting objects:  38% (28/72)\u001b[K\rremote: Counting objects:  40% (29/72)\u001b[K\rremote: Counting objects:  41% (30/72)\u001b[K\rremote: Counting objects:  43% (31/72)\u001b[K\rremote: Counting objects:  44% (32/72)\u001b[K\rremote: Counting objects:  45% (33/72)\u001b[K\rremote: Counting objects:  47% (34/72)\u001b[K\rremote: Counting objects:  48% (35/72)\u001b[K\rremote: Counting objects:  50% (36/72)\u001b[K\rremote: Counting objects:  51% (37/72)\u001b[K\rremote: Counting objects:  52% (38/72)\u001b[K\rremote: Counting objects:  54% (39/72)\u001b[K\rremote: Counting objects:  55% (40/72)\u001b[K\rremote: Counting objects:  56% (41/72)\u001b[K\rremote: Counting objects:  58% (42/72)\u001b[K\rremote: Counting objects:  59% (43/72)\u001b[K\rremote: Counting objects:  61% (44/72)\u001b[K\rremote: Counting objects:  62% (45/72)\u001b[K\rremote: Counting objects:  63% (46/72)\u001b[K\rremote: Counting objects:  65% (47/72)\u001b[K\rremote: Counting objects:  66% (48/72)\u001b[K\rremote: Counting objects:  68% (49/72)\u001b[K\rremote: Counting objects:  69% (50/72)\u001b[K\rremote: Counting objects:  70% (51/72)\u001b[K\rremote: Counting objects:  72% (52/72)\u001b[K\rremote: Counting objects:  73% (53/72)\u001b[K\rremote: Counting objects:  75% (54/72)\u001b[K\rremote: Counting objects:  76% (55/72)\u001b[K\rremote: Counting objects:  77% (56/72)\u001b[K\rremote: Counting objects:  79% (57/72)\u001b[K\rremote: Counting objects:  80% (58/72)\u001b[K\rremote: Counting objects:  81% (59/72)\u001b[K\rremote: Counting objects:  83% (60/72)\u001b[K\rremote: Counting objects:  84% (61/72)\u001b[K\rremote: Counting objects:  86% (62/72)\u001b[K\rremote: Counting objects:  87% (63/72)\u001b[K\rremote: Counting objects:  88% (64/72)\u001b[K\rremote: Counting objects:  90% (65/72)\u001b[K\rremote: Counting objects:  91% (66/72)\u001b[K\rremote: Counting objects:  93% (67/72)\u001b[K\rremote: Counting objects:  94% (68/72)\u001b[K\rremote: Counting objects:  95% (69/72)\u001b[K\rremote: Counting objects:  97% (70/72)\u001b[K\rremote: Counting objects:  98% (71/72)\u001b[K\rremote: Counting objects: 100% (72/72)\u001b[K\rremote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 24445 (delta 32), reused 52 (delta 15), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24445/24445), 2.15 GiB | 49.46 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Checking out files: 100% (24651/24651), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.173053152039555, val_acc: 0.19704433497536947, train_loss: 2.5948880511544394, val_loss: 2.393463465086932 (1 / 100)\n",
            "train_acc: 0.23856613102595797, val_acc: 0.2660098522167488, train_loss: 2.2305923866842527, val_loss: 1.7655680079765508 (2 / 100)\n",
            "train_acc: 0.2880098887515451, val_acc: 0.28078817733990147, train_loss: 1.7974337405710492, val_loss: 1.75191620594175 (3 / 100)\n",
            "train_acc: 0.28553770086526575, val_acc: 0.3103448275862069, train_loss: 1.7144738640567134, val_loss: 1.5102488143103463 (4 / 100)\n",
            "train_acc: 0.2880098887515451, val_acc: 0.31527093596059114, train_loss: 1.6970341179073225, val_loss: 1.5102602131848264 (5 / 100)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3793103448275862, train_loss: 1.5422761511006962, val_loss: 1.4681221845701997 (6 / 100)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.30049261083743845, train_loss: 1.5971082650834167, val_loss: 1.578458030822829 (7 / 100)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.3251231527093596, train_loss: 1.6522426024650319, val_loss: 1.5384502287568718 (8 / 100)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.3694581280788177, train_loss: 1.552951767948561, val_loss: 1.6279677129144152 (9 / 100)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.37438423645320196, train_loss: 1.525631328301023, val_loss: 1.577218839100429 (10 / 100)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.39408866995073893, train_loss: 1.5421239732959215, val_loss: 1.705312552710472 (11 / 100)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.35960591133004927, train_loss: 1.5816574170356628, val_loss: 1.4528301449244834 (12 / 100)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3399014778325123, train_loss: 1.5239844176324249, val_loss: 1.4698800306602064 (13 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.3891625615763547, train_loss: 1.4182074402996576, val_loss: 1.3707291310643914 (14 / 100)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3694581280788177, train_loss: 1.3865702511795666, val_loss: 1.5299993066364908 (15 / 100)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.3793103448275862, train_loss: 1.3736411349293034, val_loss: 1.480917689248259 (16 / 100)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3497536945812808, train_loss: 1.4429508832240723, val_loss: 1.6344384095938922 (17 / 100)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.3891625615763547, train_loss: 1.400158546321619, val_loss: 1.6307478232923986 (18 / 100)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.42857142857142855, train_loss: 1.340793098595882, val_loss: 1.4441052507884398 (19 / 100)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3694581280788177, train_loss: 1.4195521831217743, val_loss: 1.922608240484604 (20 / 100)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.43349753694581283, train_loss: 1.3688956680345006, val_loss: 1.3370991363901223 (21 / 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N9hKn1aB5Ow",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSE19H6PB5h3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13f1c82f-10f2-40e5-ea6d-2dba35a6f520"
      },
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = random.uniform(0.0008, 0.006)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-6, -3)\n",
        "  NUM_EPOCHS = 35\n",
        "  STEP_SIZE = 21\n",
        "  GAMMA = 10**random.uniform(-2, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"---------------------------------------------\")\n",
        "  \n",
        "  net = resnet152(num_classes=NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "---------------------------------------------\n",
            "train_acc: 0.1619283065512979, val_acc: 0.18226600985221675, train_loss: 3.166720857726334, val_loss: 2.069903163487101 (1 / 35)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.2315270935960591, train_loss: 2.3992031899606636, val_loss: 1.7359340525613043 (2 / 35)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.30049261083743845, train_loss: 1.8197766355295264, val_loss: 1.558691875100723 (3 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.3103448275862069, train_loss: 1.6822842493634877, val_loss: 1.5872535482416013 (4 / 35)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.3497536945812808, train_loss: 1.6710456238394173, val_loss: 1.5791248875885762 (5 / 35)\n",
            "train_acc: 0.30902348578491967, val_acc: 0.35467980295566504, train_loss: 1.62646744926132, val_loss: 1.4208326950449075 (6 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.33004926108374383, train_loss: 1.5786261695571824, val_loss: 1.4646097715265058 (7 / 35)\n",
            "train_acc: 0.2892459826946848, val_acc: 0.35960591133004927, train_loss: 1.5603476133570535, val_loss: 1.4564361871756943 (8 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3497536945812808, train_loss: 1.5954471309341223, val_loss: 1.4343913969735207 (9 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.37438423645320196, train_loss: 1.565011317119905, val_loss: 1.4125007666977756 (10 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3054187192118227, train_loss: 1.4870321775691029, val_loss: 1.4385640533099622 (11 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.3645320197044335, train_loss: 1.5131274586997014, val_loss: 1.3588810883132107 (12 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.33497536945812806, train_loss: 1.5139242680317393, val_loss: 1.4618351844143984 (13 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.37438423645320196, train_loss: 1.5207744290124354, val_loss: 1.4039877870399964 (14 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3842364532019704, train_loss: 1.4487123398020476, val_loss: 1.4245190602805227 (15 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3645320197044335, train_loss: 1.4697960226143836, val_loss: 1.3927893967464053 (16 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3645320197044335, train_loss: 1.4845784255689096, val_loss: 1.377412121284184 (17 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3497536945812808, train_loss: 1.453533912618611, val_loss: 1.4040470634187971 (18 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3891625615763547, train_loss: 1.4404730547785907, val_loss: 1.3993065932701374 (19 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.39901477832512317, train_loss: 1.4258754092771722, val_loss: 1.3142689724861107 (20 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.37438423645320196, train_loss: 1.416149381359369, val_loss: 1.3406085633291986 (21 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.42857142857142855, train_loss: 1.3674678466523387, val_loss: 1.3263795129184066 (22 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.42857142857142855, train_loss: 1.2994091248482798, val_loss: 1.29471044117594 (23 / 35)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4433497536945813, train_loss: 1.2752116903828454, val_loss: 1.2973774466021308 (24 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.41379310344827586, train_loss: 1.269038428924287, val_loss: 1.3189376046504881 (25 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.39901477832512317, train_loss: 1.2472694229578647, val_loss: 1.2950228206042587 (26 / 35)\n",
            "train_acc: 0.44870210135970334, val_acc: 0.41379310344827586, train_loss: 1.2803578292778308, val_loss: 1.2972302425083855 (27 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.4236453201970443, train_loss: 1.2335962198573374, val_loss: 1.3001995251096528 (28 / 35)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.42857142857142855, train_loss: 1.2485432318320822, val_loss: 1.2912913243758855 (29 / 35)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.4236453201970443, train_loss: 1.2802267839351602, val_loss: 1.290480195595126 (30 / 35)\n",
            "train_acc: 0.47342398022249693, val_acc: 0.4187192118226601, train_loss: 1.2390579611468227, val_loss: 1.3076233176762246 (31 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4236453201970443, train_loss: 1.2489407622475264, val_loss: 1.2881994147606084 (32 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4236453201970443, train_loss: 1.2425161955235768, val_loss: 1.2878473914902786 (33 / 35)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4187192118226601, train_loss: 1.2290695521091797, val_loss: 1.2824507945864072 (34 / 35)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.43349753694581283, train_loss: 1.2335406706860688, val_loss: 1.2880180158051364 (35 / 35)\n",
            "lr 0.004861998123620297, batch 12, decay 0.00033453413586395197, gamma 0.021586485404212274, val accuracy 0.4433497536945813, val loss 1.2973774466021308 [1 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 3.0927048967264787, val_loss: 1.886184514449735 (1 / 35)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.2315270935960591, train_loss: 1.9952152680112936, val_loss: 1.6828551515569827 (2 / 35)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.2315270935960591, train_loss: 1.7901192745850025, val_loss: 2.091120969485767 (3 / 35)\n",
            "train_acc: 0.27935723114956734, val_acc: 0.3842364532019704, train_loss: 1.7477646929077224, val_loss: 1.469043991248596 (4 / 35)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.37438423645320196, train_loss: 1.6232251782057754, val_loss: 1.5228034448741106 (5 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.33497536945812806, train_loss: 1.5705435290766883, val_loss: 1.5435463477825295 (6 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.41379310344827586, train_loss: 1.5511917220647315, val_loss: 1.3943375736621801 (7 / 35)\n",
            "train_acc: 0.30902348578491967, val_acc: 0.3054187192118227, train_loss: 1.5811971076781435, val_loss: 1.6875073246180718 (8 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.3054187192118227, train_loss: 1.5434945823235624, val_loss: 1.8660294140500975 (9 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.4187192118226601, train_loss: 1.5210932845385614, val_loss: 1.3552990071291995 (10 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.43842364532019706, train_loss: 1.4962576216613996, val_loss: 1.344887649190837 (11 / 35)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3842364532019704, train_loss: 1.5024252621588219, val_loss: 1.367308371466369 (12 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.4236453201970443, train_loss: 1.5040665403726812, val_loss: 1.3963571487389175 (13 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3448275862068966, train_loss: 1.4070904212180704, val_loss: 1.402203015212355 (14 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.41379310344827586, train_loss: 1.383302180227744, val_loss: 2.9023306131950153 (15 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4187192118226601, train_loss: 1.3991390942643098, val_loss: 1.31429028334876 (16 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3497536945812808, train_loss: 1.3527284614529982, val_loss: 1.5905870915633704 (17 / 35)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.4187192118226601, train_loss: 1.385264876967455, val_loss: 1.4280828208171676 (18 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.3891625615763547, train_loss: 1.341277880854306, val_loss: 1.3810874367582386 (19 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.46798029556650245, train_loss: 1.3204568068972329, val_loss: 1.8118114086794737 (20 / 35)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4187192118226601, train_loss: 1.3009335602759136, val_loss: 1.6248013045400234 (21 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.4630541871921182, train_loss: 1.205361066627856, val_loss: 1.225801797923196 (22 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4630541871921182, train_loss: 1.1355555959331385, val_loss: 1.5285826281373724 (23 / 35)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.49261083743842365, train_loss: 1.0855173070734305, val_loss: 1.2892017793185606 (24 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.43842364532019706, train_loss: 1.1139952356942062, val_loss: 1.3783032988092583 (25 / 35)\n",
            "train_acc: 0.5550061804697157, val_acc: 0.4975369458128079, train_loss: 1.0658741574941666, val_loss: 1.2755880737539582 (26 / 35)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.541871921182266, train_loss: 1.0354720763723988, val_loss: 1.2867493620647 (27 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4729064039408867, train_loss: 1.0674403731990951, val_loss: 1.2327316559007016 (28 / 35)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.43842364532019706, train_loss: 1.0317164727282908, val_loss: 1.3301339701478705 (29 / 35)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5172413793103449, train_loss: 1.0049161663456223, val_loss: 1.3819004899175296 (30 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.47783251231527096, train_loss: 1.042667674193129, val_loss: 1.2323460188405266 (31 / 35)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.45320197044334976, train_loss: 0.9756660268392198, val_loss: 1.6696615594948454 (32 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.46798029556650245, train_loss: 1.0233524231003006, val_loss: 1.3882050555327843 (33 / 35)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5123152709359606, train_loss: 0.93513508618099, val_loss: 1.7670642680722504 (34 / 35)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5024630541871922, train_loss: 0.9399892701796165, val_loss: 1.3376983703650864 (35 / 35)\n",
            "lr 0.005839865959536235, batch 12, decay 3.155641213695049e-05, gamma 0.37416088885708915, val accuracy 0.541871921182266, val loss 1.2867493620647 [2 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.19777503090234858, val_acc: 0.2413793103448276, train_loss: 2.995183911989587, val_loss: 1.7651265495516397 (1 / 35)\n",
            "train_acc: 0.276885043263288, val_acc: 0.2660098522167488, train_loss: 1.8137190537930123, val_loss: 2.272130388931688 (2 / 35)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.28078817733990147, train_loss: 2.0354375308759427, val_loss: 1.5924452158617857 (3 / 35)\n",
            "train_acc: 0.30902348578491967, val_acc: 0.35467980295566504, train_loss: 1.7296758673541772, val_loss: 1.485662852014814 (4 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.33004926108374383, train_loss: 1.6608828676056362, val_loss: 1.5289233291677653 (5 / 35)\n",
            "train_acc: 0.3164400494437577, val_acc: 0.35467980295566504, train_loss: 1.6183777988620094, val_loss: 1.439341400938081 (6 / 35)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.35960591133004927, train_loss: 1.5204365929802799, val_loss: 1.467930418517202 (7 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.32019704433497537, train_loss: 1.5516501184004936, val_loss: 1.4449351300746935 (8 / 35)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3645320197044335, train_loss: 1.5329812348846747, val_loss: 1.5297937817467844 (9 / 35)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.3497536945812808, train_loss: 1.5178946874050334, val_loss: 3.0157646673359895 (10 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.39408866995073893, train_loss: 1.5230001354099647, val_loss: 1.4346762772264152 (11 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3645320197044335, train_loss: 1.4747600632780709, val_loss: 1.6749780885691714 (12 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.4088669950738916, train_loss: 1.4299173263006364, val_loss: 1.6043016625742608 (13 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.3399014778325123, train_loss: 1.425293095990076, val_loss: 1.5811910385568742 (14 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.35960591133004927, train_loss: 1.4271248548817723, val_loss: 1.518615771396994 (15 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.3645320197044335, train_loss: 1.4386511924682353, val_loss: 1.503816413761947 (16 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3891625615763547, train_loss: 1.4487389159585695, val_loss: 1.5615324745037285 (17 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.39408866995073893, train_loss: 1.4195460027316298, val_loss: 1.8420752278102444 (18 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.39408866995073893, train_loss: 1.3689250184962127, val_loss: 1.5952633688308921 (19 / 35)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.42857142857142855, train_loss: 1.345263635345973, val_loss: 1.6948584738036094 (20 / 35)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.45320197044334976, train_loss: 1.3775324530448254, val_loss: 1.3666170635834116 (21 / 35)\n",
            "train_acc: 0.449938195302843, val_acc: 0.41379310344827586, train_loss: 1.2912949742875965, val_loss: 1.4238612372886958 (22 / 35)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.42857142857142855, train_loss: 1.2418469080818892, val_loss: 1.3060068372141551 (23 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.43842364532019706, train_loss: 1.2372798823897713, val_loss: 1.597124588900599 (24 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.4187192118226601, train_loss: 1.2577543522430439, val_loss: 1.3986961254345371 (25 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.43842364532019706, train_loss: 1.1691873831713597, val_loss: 1.2882334948173297 (26 / 35)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.43842364532019706, train_loss: 1.1975375402106343, val_loss: 1.5722692506066684 (27 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4482758620689655, train_loss: 1.1867832469262358, val_loss: 1.522935276695073 (28 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4187192118226601, train_loss: 1.1254120183226795, val_loss: 1.306805616822736 (29 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.49261083743842365, train_loss: 1.1327865268155581, val_loss: 1.3078075955654014 (30 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.4630541871921182, train_loss: 1.1164698733387535, val_loss: 1.547329277240584 (31 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.4482758620689655, train_loss: 1.130283471164656, val_loss: 1.2858290660557488 (32 / 35)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.4482758620689655, train_loss: 1.0700655230338258, val_loss: 1.3854164733675314 (33 / 35)\n",
            "train_acc: 0.5661310259579728, val_acc: 0.458128078817734, train_loss: 1.0937954076877778, val_loss: 1.3941845752188724 (34 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.4876847290640394, train_loss: 1.0658415809402655, val_loss: 1.2569265864752783 (35 / 35)\n",
            "lr 0.005126933603678469, batch 9, decay 0.0009356296674348153, gamma 0.5250778372755658, val accuracy 0.49261083743842365, val loss 1.3078075955654014 [3 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2138442521631644, val_acc: 0.18226600985221675, train_loss: 2.5041617349582195, val_loss: 2.4917081236252057 (1 / 35)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.2955665024630542, train_loss: 2.2142871478284687, val_loss: 1.7814740993706464 (2 / 35)\n",
            "train_acc: 0.2311495673671199, val_acc: 0.33004926108374383, train_loss: 1.9266136529566478, val_loss: 2.107068189846471 (3 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3054187192118227, train_loss: 1.7539253118453715, val_loss: 2.616755031599787 (4 / 35)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.3694581280788177, train_loss: 1.6766232788489097, val_loss: 1.4340072071611 (5 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.33004926108374383, train_loss: 1.618033211811806, val_loss: 1.9168548815943338 (6 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.35960591133004927, train_loss: 1.5177825855825682, val_loss: 2.246269670026056 (7 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.33004926108374383, train_loss: 1.5960323008972281, val_loss: 1.644360304466022 (8 / 35)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.35960591133004927, train_loss: 1.5181940922188966, val_loss: 1.4276262756638927 (9 / 35)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.33004926108374383, train_loss: 1.5581953669950015, val_loss: 1.5159461471834794 (10 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3399014778325123, train_loss: 1.502225470778674, val_loss: 1.9250827091080802 (11 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.37438423645320196, train_loss: 1.5294220421016584, val_loss: 1.3649735574064583 (12 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.37438423645320196, train_loss: 1.5068306388018011, val_loss: 1.4318778696905803 (13 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.33004926108374383, train_loss: 1.4558219305517057, val_loss: 1.4940282030058611 (14 / 35)\n",
            "train_acc: 0.41409147095179233, val_acc: 0.4187192118226601, train_loss: 1.3723101151741037, val_loss: 1.4840339475077362 (15 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.3793103448275862, train_loss: 1.3954124437421744, val_loss: 1.8061086598581868 (16 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.4039408866995074, train_loss: 1.4503380721814847, val_loss: 1.3286997573129062 (17 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.39408866995073893, train_loss: 1.3344722812343734, val_loss: 1.5437190494513864 (18 / 35)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.3842364532019704, train_loss: 1.3351485236318799, val_loss: 1.4710040063106369 (19 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.3694581280788177, train_loss: 1.3812202109099907, val_loss: 1.6485893767455528 (20 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.43349753694581283, train_loss: 1.3483894267689311, val_loss: 1.2691349760064938 (21 / 35)\n",
            "train_acc: 0.4721878862793572, val_acc: 0.4187192118226601, train_loss: 1.2656430611651672, val_loss: 1.3072760754030914 (22 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.458128078817734, train_loss: 1.26341547836332, val_loss: 1.3045712204402304 (23 / 35)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.4630541871921182, train_loss: 1.126986023227423, val_loss: 1.2163960974791954 (24 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.458128078817734, train_loss: 1.1286957616122308, val_loss: 1.2489839880337268 (25 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.4187192118226601, train_loss: 1.1435461633727046, val_loss: 1.3603122751113816 (26 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.4827586206896552, train_loss: 1.1259491672032549, val_loss: 1.2843328232835667 (27 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4630541871921182, train_loss: 1.112767774478172, val_loss: 1.1898765252728767 (28 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4827586206896552, train_loss: 1.1266232945568335, val_loss: 1.2260655076632947 (29 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.5024630541871922, train_loss: 1.0535318041024604, val_loss: 1.266550882990137 (30 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5221674876847291, train_loss: 1.1166533387930344, val_loss: 1.2152879273362935 (31 / 35)\n",
            "train_acc: 0.5834363411619283, val_acc: 0.4482758620689655, train_loss: 1.0959351291173174, val_loss: 1.3291740714035598 (32 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5073891625615764, train_loss: 1.036149840419755, val_loss: 1.1903340569857894 (33 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.4827586206896552, train_loss: 0.9832797688518378, val_loss: 1.3305066271955743 (34 / 35)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.5665024630541872, train_loss: 0.9759813362942048, val_loss: 1.2077535097234942 (35 / 35)\n",
            "lr 0.002473823281245263, batch 12, decay 1.8559777801775264e-05, gamma 0.5778758084832141, val accuracy 0.5665024630541872, val loss 1.2077535097234942 [4 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.15945611866501855, val_acc: 0.29064039408866993, train_loss: 2.9925308606238534, val_loss: 2.8145439511743087 (1 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.22167487684729065, train_loss: 2.1487072264160894, val_loss: 2.1623939149485434 (2 / 35)\n",
            "train_acc: 0.25339925834363414, val_acc: 0.33497536945812806, train_loss: 1.913622534466615, val_loss: 1.6711560901749898 (3 / 35)\n",
            "train_acc: 0.315203955500618, val_acc: 0.3251231527093596, train_loss: 1.729874194184104, val_loss: 1.603720173166303 (4 / 35)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.33004926108374383, train_loss: 1.6342913996893338, val_loss: 1.7018983631298459 (5 / 35)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3251231527093596, train_loss: 1.5778915708233017, val_loss: 1.6072683739544722 (6 / 35)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.3497536945812808, train_loss: 1.625972833562693, val_loss: 1.5894120072789968 (7 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3497536945812808, train_loss: 1.6564394082362925, val_loss: 1.945574966410698 (8 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.35467980295566504, train_loss: 1.4624104799682043, val_loss: 1.7999457959177458 (9 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.33004926108374383, train_loss: 1.5218822854411027, val_loss: 2.0035320444060076 (10 / 35)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.3645320197044335, train_loss: 1.4906524782275092, val_loss: 1.3872764772675894 (11 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.35467980295566504, train_loss: 1.4568977376586574, val_loss: 1.7484054349619766 (12 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.35467980295566504, train_loss: 1.4460177764904367, val_loss: 1.3982155904394065 (13 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.39408866995073893, train_loss: 1.4317792298914622, val_loss: 2.1664748801092797 (14 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3891625615763547, train_loss: 1.4205946786736676, val_loss: 1.3523933874268836 (15 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.41379310344827586, train_loss: 1.3860840519662252, val_loss: 1.30208299459495 (16 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.41379310344827586, train_loss: 1.43921715175855, val_loss: 1.36498244128791 (17 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.41379310344827586, train_loss: 1.4207226417415368, val_loss: 1.3234549323326261 (18 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.41379310344827586, train_loss: 1.3718653756696892, val_loss: 1.4201759273195502 (19 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3497536945812808, train_loss: 1.314267191736601, val_loss: 2.075386356544025 (20 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.37438423645320196, train_loss: 1.391839016279567, val_loss: 1.6067973040594843 (21 / 35)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4975369458128079, train_loss: 1.2703843768064407, val_loss: 1.2799735236637697 (22 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.4975369458128079, train_loss: 1.2266618204205233, val_loss: 1.1973396193217762 (23 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.4482758620689655, train_loss: 1.1422767602321686, val_loss: 1.334226730421846 (24 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.49261083743842365, train_loss: 1.1528414392058723, val_loss: 1.2278898035364199 (25 / 35)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.541871921182266, train_loss: 1.065067688746859, val_loss: 1.2940100105525238 (26 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.46798029556650245, train_loss: 1.0706430115128036, val_loss: 1.2943327779253129 (27 / 35)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.45320197044334976, train_loss: 1.0650257040897317, val_loss: 1.2645384824921932 (28 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.49261083743842365, train_loss: 1.0488684873645768, val_loss: 1.2714406718761462 (29 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5320197044334976, train_loss: 1.0665949341393224, val_loss: 1.2588138496640868 (30 / 35)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.5024630541871922, train_loss: 0.9931351983060943, val_loss: 1.169695769624757 (31 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.4827586206896552, train_loss: 0.9592841460619338, val_loss: 1.3219607299184564 (32 / 35)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.4827586206896552, train_loss: 0.9921302502912703, val_loss: 1.364290933597264 (33 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5024630541871922, train_loss: 0.9926324286331205, val_loss: 1.262733770561923 (34 / 35)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5221674876847291, train_loss: 0.9662589263562367, val_loss: 1.32682354344523 (35 / 35)\n",
            "lr 0.003937533213557532, batch 13, decay 2.582481179039313e-06, gamma 0.20509383566558675, val accuracy 0.541871921182266, val loss 1.2940100105525238 [5 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.15327564894932014, val_acc: 0.18226600985221675, train_loss: 3.601896806317295, val_loss: 1.8226347098796827 (1 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.27586206896551724, train_loss: 2.003881826094261, val_loss: 1.731202166655968 (2 / 35)\n",
            "train_acc: 0.2669962917181706, val_acc: 0.2315270935960591, train_loss: 1.9010808582801018, val_loss: 1.6723785441497276 (3 / 35)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.33004926108374383, train_loss: 1.7025718314685987, val_loss: 1.5470225781642746 (4 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.3448275862068966, train_loss: 1.6704793070685877, val_loss: 1.4648441193726263 (5 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.32019704433497537, train_loss: 1.6296812379905408, val_loss: 1.5447982869712003 (6 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.35467980295566504, train_loss: 1.5423763393619006, val_loss: 1.4470922477139627 (7 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3497536945812808, train_loss: 1.5254009011649379, val_loss: 1.4771755411119885 (8 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.32019704433497537, train_loss: 1.523692854697389, val_loss: 1.452263248084214 (9 / 35)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.33004926108374383, train_loss: 1.5315048995212512, val_loss: 1.4311403018500417 (10 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.4236453201970443, train_loss: 1.5037309252582167, val_loss: 1.3799154153598354 (11 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3645320197044335, train_loss: 1.4423656129129738, val_loss: 1.420467144750022 (12 / 35)\n",
            "train_acc: 0.377008652657602, val_acc: 0.3645320197044335, train_loss: 1.4906982886334432, val_loss: 1.3887102630338057 (13 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.33497536945812806, train_loss: 1.450235727690943, val_loss: 1.385106014500698 (14 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.3891625615763547, train_loss: 1.437117984474663, val_loss: 1.3858718320066705 (15 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.3694581280788177, train_loss: 1.4382146690478284, val_loss: 1.429879192354644 (16 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.3793103448275862, train_loss: 1.4205302738288719, val_loss: 1.3548135325826447 (17 / 35)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.33497536945812806, train_loss: 1.3993968584923573, val_loss: 1.4110016402939858 (18 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.42857142857142855, train_loss: 1.3543399406599321, val_loss: 1.4016366832949259 (19 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.42857142857142855, train_loss: 1.3450829380816964, val_loss: 1.3924443660111263 (20 / 35)\n",
            "train_acc: 0.411619283065513, val_acc: 0.39408866995073893, train_loss: 1.3821951760202462, val_loss: 1.3707428850563876 (21 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4630541871921182, train_loss: 1.2901080679539845, val_loss: 1.2759810665558124 (22 / 35)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4876847290640394, train_loss: 1.24185214533352, val_loss: 1.2547681017462256 (23 / 35)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.4630541871921182, train_loss: 1.2200738316855413, val_loss: 1.2505157857105649 (24 / 35)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.5024630541871922, train_loss: 1.2143766278094796, val_loss: 1.2374419255796911 (25 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4876847290640394, train_loss: 1.2098521009658558, val_loss: 1.236571002182702 (26 / 35)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.4876847290640394, train_loss: 1.1668503260140954, val_loss: 1.2353779655959218 (27 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5073891625615764, train_loss: 1.1390302476688428, val_loss: 1.2303224346907855 (28 / 35)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4876847290640394, train_loss: 1.149875838323341, val_loss: 1.2363233442964225 (29 / 35)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.47783251231527096, train_loss: 1.1348754311226796, val_loss: 1.2266300555520457 (30 / 35)\n",
            "train_acc: 0.515451174289246, val_acc: 0.4975369458128079, train_loss: 1.124970282111386, val_loss: 1.2232835235560469 (31 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.5073891625615764, train_loss: 1.1389158815329685, val_loss: 1.2225932522947565 (32 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4827586206896552, train_loss: 1.1052689369588318, val_loss: 1.2221542790605517 (33 / 35)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4975369458128079, train_loss: 1.1118921059171114, val_loss: 1.2426534251039252 (34 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.4975369458128079, train_loss: 1.064774928193157, val_loss: 1.2234632193748587 (35 / 35)\n",
            "lr 0.005882025598713124, batch 15, decay 0.0004841708661961014, gamma 0.04014267338331728, val accuracy 0.5073891625615764, val loss 1.2303224346907855 [6 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.20024721878862795, val_acc: 0.22167487684729065, train_loss: 2.8942805250141914, val_loss: 5.8617546338165925 (1 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.270935960591133, train_loss: 2.342803857235148, val_loss: 1.7596311346063473 (2 / 35)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.30049261083743845, train_loss: 1.751107581318972, val_loss: 2.228747118282788 (3 / 35)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.37438423645320196, train_loss: 1.6851028679917268, val_loss: 2.261265072329291 (4 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.24630541871921183, train_loss: 1.630625831771398, val_loss: 2.0822677092599164 (5 / 35)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.32019704433497537, train_loss: 1.6887107962288874, val_loss: 1.573628069878799 (6 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.35467980295566504, train_loss: 1.557581391263804, val_loss: 1.4595364578839005 (7 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.31527093596059114, train_loss: 1.447129905592231, val_loss: 1.5662608607649215 (8 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3645320197044335, train_loss: 1.4263423806509954, val_loss: 1.5311659871063796 (9 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.37438423645320196, train_loss: 1.6136885232330105, val_loss: 1.517624337684932 (10 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.33004926108374383, train_loss: 1.4583967651513363, val_loss: 1.5577562266382678 (11 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.39408866995073893, train_loss: 1.432918148812906, val_loss: 1.330676089219859 (12 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3645320197044335, train_loss: 1.3618060014451243, val_loss: 1.4019120803901128 (13 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.35960591133004927, train_loss: 1.4396956290391232, val_loss: 1.4193274449245097 (14 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.35960591133004927, train_loss: 1.4455405445711869, val_loss: 1.3474658667453991 (15 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.37438423645320196, train_loss: 1.386378678535796, val_loss: 1.4135650336889212 (16 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.3694581280788177, train_loss: 1.3500923175452224, val_loss: 1.3407221750672815 (17 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.43349753694581283, train_loss: 1.3321633017696763, val_loss: 1.32570583773364 (18 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.43349753694581283, train_loss: 1.3116787657307458, val_loss: 1.2865576553227278 (19 / 35)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.35960591133004927, train_loss: 1.3036809114207444, val_loss: 1.2934803581002898 (20 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.3842364532019704, train_loss: 1.2854472492327649, val_loss: 1.4406849775701909 (21 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.41379310344827586, train_loss: 1.275748918466132, val_loss: 1.3931651012650852 (22 / 35)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.46798029556650245, train_loss: 1.1705935333656292, val_loss: 1.416358670284008 (23 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.43842364532019706, train_loss: 1.1355490573993867, val_loss: 1.5142294984732942 (24 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.4630541871921182, train_loss: 1.101002881641883, val_loss: 1.3427102997385223 (25 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.458128078817734, train_loss: 1.1110893771586519, val_loss: 1.2641979664417322 (26 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.4630541871921182, train_loss: 1.053999677208357, val_loss: 1.3773613619099696 (27 / 35)\n",
            "train_acc: 0.5488257107540173, val_acc: 0.4630541871921182, train_loss: 1.0606744562002872, val_loss: 1.307844473223381 (28 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.47783251231527096, train_loss: 1.0887351285099836, val_loss: 1.2859172230870852 (29 / 35)\n",
            "train_acc: 0.5142150803461063, val_acc: 0.458128078817734, train_loss: 1.0810718226197034, val_loss: 1.2982284737925225 (30 / 35)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4975369458128079, train_loss: 1.1127572856815842, val_loss: 1.2803263582032303 (31 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.4433497536945813, train_loss: 0.9857448360828593, val_loss: 1.4377556005722196 (32 / 35)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.4482758620689655, train_loss: 0.9865449894638675, val_loss: 1.459725188797918 (33 / 35)\n",
            "train_acc: 0.5698393077873919, val_acc: 0.43842364532019706, train_loss: 1.0174903971303084, val_loss: 1.377792316704548 (34 / 35)\n",
            "train_acc: 0.622991347342398, val_acc: 0.5073891625615764, train_loss: 0.9206128741887355, val_loss: 1.2716951443643993 (35 / 35)\n",
            "lr 0.003182708276352076, batch 15, decay 1.7506452348750447e-06, gamma 0.6295983398150945, val accuracy 0.5073891625615764, val loss 1.2716951443643993 [7 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 2.0850457402478044, val_loss: 1.9886436256869087 (1 / 35)\n",
            "train_acc: 0.19901112484548825, val_acc: 0.23645320197044334, train_loss: 2.0280732725400417, val_loss: 1.697827306287042 (2 / 35)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.33497536945812806, train_loss: 1.8793814823270876, val_loss: 1.8983272108538398 (3 / 35)\n",
            "train_acc: 0.26328800988875156, val_acc: 0.3054187192118227, train_loss: 1.832614927857709, val_loss: 1.6367710664354522 (4 / 35)\n",
            "train_acc: 0.27935723114956734, val_acc: 0.3448275862068966, train_loss: 1.7500537938918408, val_loss: 1.5749466172580062 (5 / 35)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.2660098522167488, train_loss: 1.7728368008534605, val_loss: 2.168049997296827 (6 / 35)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.35960591133004927, train_loss: 1.6739300268394839, val_loss: 1.474493063729385 (7 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.3793103448275862, train_loss: 1.7106815703277682, val_loss: 1.7933456681925675 (8 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.3694581280788177, train_loss: 1.526077814833048, val_loss: 1.612300676518473 (9 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3793103448275862, train_loss: 1.4858398950291505, val_loss: 1.459144666277129 (10 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.3793103448275862, train_loss: 1.5378337164302396, val_loss: 1.4213393104487453 (11 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.35960591133004927, train_loss: 1.5191682753957836, val_loss: 1.7019778305086597 (12 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.4088669950738916, train_loss: 1.475704303483291, val_loss: 1.5277886678432595 (13 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.39901477832512317, train_loss: 1.3979510659782495, val_loss: 1.4170341758892453 (14 / 35)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.4088669950738916, train_loss: 1.3812298158780016, val_loss: 1.4582347602679813 (15 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.3645320197044335, train_loss: 1.4356774585356082, val_loss: 1.4599598235097424 (16 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.3842364532019704, train_loss: 1.4622074854830729, val_loss: 1.4030162178236862 (17 / 35)\n",
            "train_acc: 0.415327564894932, val_acc: 0.3891625615763547, train_loss: 1.415801016745078, val_loss: 1.7557541522486457 (18 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.4039408866995074, train_loss: 1.4229274437070925, val_loss: 1.4867595865808685 (19 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.39408866995073893, train_loss: 1.339339593874362, val_loss: 1.4107110479782368 (20 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4482758620689655, train_loss: 1.231386358717316, val_loss: 1.3780254454448306 (21 / 35)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.42857142857142855, train_loss: 1.2214386582521926, val_loss: 1.3890197688135608 (22 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.4827586206896552, train_loss: 1.1271849565659229, val_loss: 1.3238375577433357 (23 / 35)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.458128078817734, train_loss: 1.1505449998511372, val_loss: 1.3049347523985237 (24 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.45320197044334976, train_loss: 1.0807073990111002, val_loss: 1.3124016400041252 (25 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.4729064039408867, train_loss: 1.0864664978533063, val_loss: 1.2932667218405625 (26 / 35)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.4975369458128079, train_loss: 1.091759060015637, val_loss: 1.2860368120259251 (27 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.4729064039408867, train_loss: 1.056087637934903, val_loss: 1.2618982648027355 (28 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.43842364532019706, train_loss: 1.0590679079699428, val_loss: 1.359864485674891 (29 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.49261083743842365, train_loss: 1.0584824584765251, val_loss: 1.301413922474302 (30 / 35)\n",
            "train_acc: 0.5747836835599506, val_acc: 0.4975369458128079, train_loss: 1.0647097771483092, val_loss: 1.2974277323689953 (31 / 35)\n",
            "train_acc: 0.595797280593325, val_acc: 0.5221674876847291, train_loss: 0.9971593135808985, val_loss: 1.2812564085269798 (32 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.4975369458128079, train_loss: 1.0128128042327165, val_loss: 1.2874781571585556 (33 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5073891625615764, train_loss: 1.0309939973875972, val_loss: 1.255830715442526 (34 / 35)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5073891625615764, train_loss: 0.982791975564214, val_loss: 1.2501259363930801 (35 / 35)\n",
            "lr 0.0012615413108172137, batch 14, decay 1.3869770040109782e-06, gamma 0.13564963306470465, val accuracy 0.5221674876847291, val loss 1.2812564085269798 [8 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.16934487021013597, val_acc: 0.27586206896551724, train_loss: 2.9353381719518503, val_loss: 1.9367622527582893 (1 / 35)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.23645320197044334, train_loss: 2.595087134941252, val_loss: 11.7318436389633 (2 / 35)\n",
            "train_acc: 0.22373300370828184, val_acc: 0.2512315270935961, train_loss: 1.8913108789729247, val_loss: 1.6816924170320258 (3 / 35)\n",
            "train_acc: 0.29913473423980225, val_acc: 0.3054187192118227, train_loss: 1.6979803881332813, val_loss: 1.6119405495122148 (4 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.3399014778325123, train_loss: 1.551742258855822, val_loss: 1.719879710909181 (5 / 35)\n",
            "train_acc: 0.31025957972805934, val_acc: 0.3054187192118227, train_loss: 1.633342784915778, val_loss: 1.5696532462030797 (6 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.33004926108374383, train_loss: 1.52293342771872, val_loss: 1.5686173503622045 (7 / 35)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.35467980295566504, train_loss: 1.5064279103308584, val_loss: 1.8106270541111236 (8 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.32019704433497537, train_loss: 1.482665363142016, val_loss: 1.5961743461087419 (9 / 35)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.3103448275862069, train_loss: 1.548921026169738, val_loss: 2.1699388676089018 (10 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.3793103448275862, train_loss: 1.5795752921122113, val_loss: 1.402368931200704 (11 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.3842364532019704, train_loss: 1.4822444022806966, val_loss: 1.375982601213925 (12 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.33497536945812806, train_loss: 1.494869686322395, val_loss: 1.6496930498207731 (13 / 35)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.4039408866995074, train_loss: 1.4589143759387975, val_loss: 1.3817087461795714 (14 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.4187192118226601, train_loss: 1.4670860292885006, val_loss: 2.453427563893971 (15 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.39901477832512317, train_loss: 1.503776504465912, val_loss: 1.267837775164637 (16 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.39408866995073893, train_loss: 1.378972791476067, val_loss: 1.4141784788939753 (17 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.35467980295566504, train_loss: 1.4517115645561878, val_loss: 1.4354238521876594 (18 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.4088669950738916, train_loss: 1.4017406117783489, val_loss: 1.2702265521282046 (19 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.4482758620689655, train_loss: 1.3190323481306305, val_loss: 1.4692124551886996 (20 / 35)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4039408866995074, train_loss: 1.3920840959908494, val_loss: 1.4631945361644763 (21 / 35)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.4482758620689655, train_loss: 1.3382281696398561, val_loss: 1.3623261613211608 (22 / 35)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.45320197044334976, train_loss: 1.240883765099812, val_loss: 1.2512975415866363 (23 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.43842364532019706, train_loss: 1.2386980790585023, val_loss: 1.2411757289188836 (24 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.4729064039408867, train_loss: 1.1847286373929424, val_loss: 1.2753112548090555 (25 / 35)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.458128078817734, train_loss: 1.2696849645583974, val_loss: 1.271056573672835 (26 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4876847290640394, train_loss: 1.171912041008104, val_loss: 1.2177575235002733 (27 / 35)\n",
            "train_acc: 0.484548825710754, val_acc: 0.47783251231527096, train_loss: 1.1852957344025705, val_loss: 1.2319683420834282 (28 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.4729064039408867, train_loss: 1.1890187279697697, val_loss: 1.3242842124894334 (29 / 35)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.4729064039408867, train_loss: 1.1773613149067674, val_loss: 1.255840446855047 (30 / 35)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.49261083743842365, train_loss: 1.1666368095777533, val_loss: 1.2887451246454211 (31 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.47783251231527096, train_loss: 1.1585365345215768, val_loss: 1.3112552669541588 (32 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.5024630541871922, train_loss: 1.1578527168084134, val_loss: 1.214683779648372 (33 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.5073891625615764, train_loss: 1.1455797276773914, val_loss: 1.212128885273863 (34 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4975369458128079, train_loss: 1.1060131625427745, val_loss: 1.2017660230544989 (35 / 35)\n",
            "lr 0.0042371333087210545, batch 15, decay 6.77037946625307e-06, gamma 0.05301569104181634, val accuracy 0.5073891625615764, val loss 1.212128885273863 [9 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.18294190358467244, val_acc: 0.18226600985221675, train_loss: 3.0167008580913945, val_loss: 2.232881442666641 (1 / 35)\n",
            "train_acc: 0.18912237330037082, val_acc: 0.18226600985221675, train_loss: 2.3868500296353408, val_loss: 1.7798444772588795 (2 / 35)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.3054187192118227, train_loss: 2.338704763885187, val_loss: 1.7181046555194948 (3 / 35)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.32019704433497537, train_loss: 1.8798073207492145, val_loss: 1.601467353369802 (4 / 35)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.27586206896551724, train_loss: 1.807659110857913, val_loss: 1.61698046400042 (5 / 35)\n",
            "train_acc: 0.31025957972805934, val_acc: 0.35467980295566504, train_loss: 1.6791381555965126, val_loss: 1.4554501014390016 (6 / 35)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.35467980295566504, train_loss: 1.680566685750841, val_loss: 1.4464337455815282 (7 / 35)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.35960591133004927, train_loss: 1.6391469668988392, val_loss: 1.5283722031879894 (8 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.33004926108374383, train_loss: 1.6589103917993044, val_loss: 1.4544607342170377 (9 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3448275862068966, train_loss: 1.5540074367900418, val_loss: 1.4477224214910873 (10 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.3793103448275862, train_loss: 1.58630410658267, val_loss: 1.4102007679164117 (11 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.3842364532019704, train_loss: 1.5637556177429275, val_loss: 1.4047680171252472 (12 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.4039408866995074, train_loss: 1.5351772137419109, val_loss: 1.3584412917714987 (13 / 35)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3793103448275862, train_loss: 1.5218350375980618, val_loss: 1.4054149442118378 (14 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.4039408866995074, train_loss: 1.5055198955300122, val_loss: 1.309965218229247 (15 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.4236453201970443, train_loss: 1.4273721440908198, val_loss: 1.32085169418692 (16 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3891625615763547, train_loss: 1.4828690023740525, val_loss: 1.3876212089519782 (17 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3399014778325123, train_loss: 1.448462141311655, val_loss: 1.4594030145353871 (18 / 35)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.3793103448275862, train_loss: 1.392268005348696, val_loss: 1.4004764048923999 (19 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.39901477832512317, train_loss: 1.4894799691048186, val_loss: 1.3962152876290195 (20 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3842364532019704, train_loss: 1.396497075873046, val_loss: 1.4248947307394055 (21 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.3694581280788177, train_loss: 1.4041617427237691, val_loss: 1.4168375216681381 (22 / 35)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.43349753694581283, train_loss: 1.3448025263726195, val_loss: 1.2789959913404116 (23 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.4088669950738916, train_loss: 1.3785693188680264, val_loss: 1.3752752113812075 (24 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.4039408866995074, train_loss: 1.3217855871681525, val_loss: 1.3778805371575755 (25 / 35)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.4236453201970443, train_loss: 1.3367121487819074, val_loss: 1.3275454954560755 (26 / 35)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.458128078817734, train_loss: 1.3398906007243323, val_loss: 1.2907992313648093 (27 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4236453201970443, train_loss: 1.341967488248799, val_loss: 1.3050248484893385 (28 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4088669950738916, train_loss: 1.2866827516237502, val_loss: 1.381890487494727 (29 / 35)\n",
            "train_acc: 0.449938195302843, val_acc: 0.4187192118226601, train_loss: 1.3215496064116545, val_loss: 1.3345150043224465 (30 / 35)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.43842364532019706, train_loss: 1.2511212072796816, val_loss: 1.4782165362329907 (31 / 35)\n",
            "train_acc: 0.45859085290482077, val_acc: 0.43842364532019706, train_loss: 1.2989626359585926, val_loss: 1.2779732842750737 (32 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.43842364532019706, train_loss: 1.3040913981471869, val_loss: 1.3552947496545726 (33 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.3497536945812808, train_loss: 1.249532516571441, val_loss: 1.465473717069391 (34 / 35)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.49261083743842365, train_loss: 1.2337555166228003, val_loss: 1.1667960761803124 (35 / 35)\n",
            "lr 0.0018956433134261095, batch 12, decay 0.00010903900651330965, gamma 0.844148730341062, val accuracy 0.49261083743842365, val loss 1.1667960761803124 [10 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.15945611866501855, val_acc: 0.22660098522167488, train_loss: 2.879005316014048, val_loss: 1.7671963228967977 (1 / 35)\n",
            "train_acc: 0.22744128553770088, val_acc: 0.2512315270935961, train_loss: 2.1404364013259283, val_loss: 1.6264926001356153 (2 / 35)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.3251231527093596, train_loss: 1.7690590484475324, val_loss: 1.5782214922857989 (3 / 35)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.270935960591133, train_loss: 1.6677539123150857, val_loss: 1.6977114313341715 (4 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.33497536945812806, train_loss: 1.6776474684808398, val_loss: 1.4908937456572584 (5 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3645320197044335, train_loss: 1.6783285787874747, val_loss: 1.4421673446453263 (6 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.3645320197044335, train_loss: 1.6073507206106952, val_loss: 1.408165249037625 (7 / 35)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.33497536945812806, train_loss: 1.5690914218593734, val_loss: 1.5411006030190755 (8 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.33004926108374383, train_loss: 1.5340703319118107, val_loss: 1.4910329283751877 (9 / 35)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.33497536945812806, train_loss: 1.547816228291897, val_loss: 1.4439830782965486 (10 / 35)\n",
            "train_acc: 0.3522867737948084, val_acc: 0.3645320197044335, train_loss: 1.5143493135426336, val_loss: 2.2981975288520307 (11 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.39408866995073893, train_loss: 1.5285167427381272, val_loss: 1.3861793811098109 (12 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3645320197044335, train_loss: 1.479649660098096, val_loss: 1.3289222660029463 (13 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3793103448275862, train_loss: 1.4634509310586785, val_loss: 1.3762791795389993 (14 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.3842364532019704, train_loss: 1.4358072521070615, val_loss: 1.3390840653128224 (15 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3793103448275862, train_loss: 1.429112681647019, val_loss: 1.9079924635772634 (16 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3497536945812808, train_loss: 1.3918674929327663, val_loss: 1.5690085688248057 (17 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4187192118226601, train_loss: 1.3870355766105416, val_loss: 1.4762240105074615 (18 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.41379310344827586, train_loss: 1.4000036896232917, val_loss: 1.3129728868089874 (19 / 35)\n",
            "train_acc: 0.4227441285537701, val_acc: 0.3842364532019704, train_loss: 1.3578929025104225, val_loss: 1.4146649621683975 (20 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.39408866995073893, train_loss: 1.371081870993224, val_loss: 1.3490235555935375 (21 / 35)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.4187192118226601, train_loss: 1.3066560788856008, val_loss: 1.4152459606454877 (22 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.42857142857142855, train_loss: 1.3029974969414757, val_loss: 1.4889575458806137 (23 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.43842364532019706, train_loss: 1.2701222220958384, val_loss: 1.3667945979998029 (24 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.43842364532019706, train_loss: 1.2334219552530494, val_loss: 1.3449606972521748 (25 / 35)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.43349753694581283, train_loss: 1.2424912479221453, val_loss: 1.3701289003999362 (26 / 35)\n",
            "train_acc: 0.48084054388133496, val_acc: 0.45320197044334976, train_loss: 1.2326423979660195, val_loss: 1.2689177505488467 (27 / 35)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.41379310344827586, train_loss: 1.236413453359097, val_loss: 1.588906573140856 (28 / 35)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.43842364532019706, train_loss: 1.235836005991852, val_loss: 1.359313165319377 (29 / 35)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.43842364532019706, train_loss: 1.2064921726991868, val_loss: 1.2757012397050858 (30 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.43842364532019706, train_loss: 1.2017767705640332, val_loss: 1.3183314297440016 (31 / 35)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.458128078817734, train_loss: 1.2065622102197522, val_loss: 1.2588418247958122 (32 / 35)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.42857142857142855, train_loss: 1.2068987081313163, val_loss: 1.338857413072304 (33 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.458128078817734, train_loss: 1.1913258552698622, val_loss: 1.308893279489038 (34 / 35)\n",
            "train_acc: 0.5067985166872683, val_acc: 0.4236453201970443, train_loss: 1.1986842866439018, val_loss: 1.3548923851233985 (35 / 35)\n",
            "lr 0.004818645185792263, batch 9, decay 0.00035176299813821974, gamma 0.013584304298353304, val accuracy 0.458128078817734, val loss 1.2588418247958122 [11 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2088998763906057, val_acc: 0.08866995073891626, train_loss: 3.600015535342826, val_loss: 1.8155805612432545 (1 / 35)\n",
            "train_acc: 0.17181705809641531, val_acc: 0.31527093596059114, train_loss: 2.093885757130362, val_loss: 1.7587441951770502 (2 / 35)\n",
            "train_acc: 0.27070457354758964, val_acc: 0.3054187192118227, train_loss: 1.825113899628223, val_loss: 1.5604638665767725 (3 / 35)\n",
            "train_acc: 0.315203955500618, val_acc: 0.29064039408866993, train_loss: 1.685274132397325, val_loss: 1.5452053811162563 (4 / 35)\n",
            "train_acc: 0.2843016069221261, val_acc: 0.3448275862068966, train_loss: 1.7235383620515594, val_loss: 1.4517546865740434 (5 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.3497536945812808, train_loss: 1.640781086955878, val_loss: 1.4914987157718302 (6 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.37438423645320196, train_loss: 1.5880483399215528, val_loss: 1.4133720726802432 (7 / 35)\n",
            "train_acc: 0.3473423980222497, val_acc: 0.39408866995073893, train_loss: 1.514340457427045, val_loss: 1.450853894790405 (8 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3891625615763547, train_loss: 1.5668788324622496, val_loss: 1.3531594940007026 (9 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.4088669950738916, train_loss: 1.477054421185563, val_loss: 1.369182801011748 (10 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.41379310344827586, train_loss: 1.5631751047518698, val_loss: 1.3640274135350006 (11 / 35)\n",
            "train_acc: 0.3510506798516687, val_acc: 0.41379310344827586, train_loss: 1.4500698202620035, val_loss: 1.3645782259297488 (12 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.3891625615763547, train_loss: 1.453146581449379, val_loss: 1.2915686879839217 (13 / 35)\n",
            "train_acc: 0.37082818294190356, val_acc: 0.4236453201970443, train_loss: 1.4352437226822408, val_loss: 1.3213277062759023 (14 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.3891625615763547, train_loss: 1.3825529548529494, val_loss: 1.4863026083396573 (15 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3497536945812808, train_loss: 1.4319707958306311, val_loss: 1.3720621046761574 (16 / 35)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.458128078817734, train_loss: 1.4189847880152453, val_loss: 1.2676486011796397 (17 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.39901477832512317, train_loss: 1.3723830506297654, val_loss: 1.3354135927895607 (18 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.41379310344827586, train_loss: 1.4365551462868973, val_loss: 1.301881462482396 (19 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.4039408866995074, train_loss: 1.378476350504919, val_loss: 1.3390570579491226 (20 / 35)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.39901477832512317, train_loss: 1.3266521552289814, val_loss: 1.391938757426633 (21 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4876847290640394, train_loss: 1.2567057929316028, val_loss: 1.2768601114526759 (22 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4827586206896552, train_loss: 1.1912652794893357, val_loss: 1.2856099552708893 (23 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4482758620689655, train_loss: 1.2028665032758112, val_loss: 1.340288602072617 (24 / 35)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.5024630541871922, train_loss: 1.1706668968106377, val_loss: 1.2917806300623664 (25 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4827586206896552, train_loss: 1.127032505861761, val_loss: 1.2835575488987814 (26 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.47783251231527096, train_loss: 1.1441763007301924, val_loss: 1.2863659917427401 (27 / 35)\n",
            "train_acc: 0.522867737948084, val_acc: 0.49261083743842365, train_loss: 1.129100492769767, val_loss: 1.2604489990055854 (28 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.46798029556650245, train_loss: 1.0418607555007462, val_loss: 1.3080483328532704 (29 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.458128078817734, train_loss: 1.092032808971641, val_loss: 1.3026096547765684 (30 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.46798029556650245, train_loss: 1.0650143209287646, val_loss: 1.30059853504444 (31 / 35)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.4876847290640394, train_loss: 1.03855711509035, val_loss: 1.3049929224211594 (32 / 35)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.4827586206896552, train_loss: 0.9900337094429544, val_loss: 1.2861527533366763 (33 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.4876847290640394, train_loss: 1.009574679494346, val_loss: 1.2735859325953893 (34 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5123152709359606, train_loss: 0.9772548937827017, val_loss: 1.2573930195399694 (35 / 35)\n",
            "lr 0.0049887599500206496, batch 12, decay 1.7401539712346227e-06, gamma 0.08677145864971626, val accuracy 0.5123152709359606, val loss 1.2573930195399694 [12 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2200247218788628, val_acc: 0.18226600985221675, train_loss: 3.3109018354687025, val_loss: 3.7142658411282037 (1 / 35)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.2660098522167488, train_loss: 2.1457831423421134, val_loss: 1.8167659690227416 (2 / 35)\n",
            "train_acc: 0.2323856613102596, val_acc: 0.2955665024630542, train_loss: 1.8514720071820894, val_loss: 1.571032640381987 (3 / 35)\n",
            "train_acc: 0.2830655129789864, val_acc: 0.3497536945812808, train_loss: 1.6488025808805884, val_loss: 1.581856325929388 (4 / 35)\n",
            "train_acc: 0.30284301606922126, val_acc: 0.3694581280788177, train_loss: 1.6814107516197987, val_loss: 1.4408198007809117 (5 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3497536945812808, train_loss: 1.5881041295743548, val_loss: 1.5782029710966965 (6 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.3497536945812808, train_loss: 1.522972181936719, val_loss: 1.4036321880782179 (7 / 35)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.3448275862068966, train_loss: 1.5549189958937826, val_loss: 1.599843233089729 (8 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.39901477832512317, train_loss: 1.497463989316754, val_loss: 1.3685144403297913 (9 / 35)\n",
            "train_acc: 0.377008652657602, val_acc: 0.4088669950738916, train_loss: 1.4591164192546284, val_loss: 1.4166079783087293 (10 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3103448275862069, train_loss: 1.4818577383298368, val_loss: 1.6411931291589597 (11 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.3891625615763547, train_loss: 1.477728113108424, val_loss: 1.3680505024388505 (12 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.3399014778325123, train_loss: 1.4661434510140248, val_loss: 1.370886684051288 (13 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3497536945812808, train_loss: 1.428392597417749, val_loss: 1.5431991527820457 (14 / 35)\n",
            "train_acc: 0.41656365883807167, val_acc: 0.3103448275862069, train_loss: 1.4229933122179859, val_loss: 1.7848828725626904 (15 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.39408866995073893, train_loss: 1.4638681747710012, val_loss: 1.5175391799710654 (16 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.3891625615763547, train_loss: 1.4453664462557534, val_loss: 1.3815135773766805 (17 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.33497536945812806, train_loss: 1.3913773081653344, val_loss: 1.4866001975947414 (18 / 35)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.4187192118226601, train_loss: 1.3163170964815119, val_loss: 1.2845771876461987 (19 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.3645320197044335, train_loss: 1.3203832665538906, val_loss: 1.428610148981874 (20 / 35)\n",
            "train_acc: 0.4511742892459827, val_acc: 0.43842364532019706, train_loss: 1.3996135543097081, val_loss: 1.347862490879491 (21 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.49261083743842365, train_loss: 1.2109875920676478, val_loss: 1.2459011970482436 (22 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.4729064039408867, train_loss: 1.1653907846461415, val_loss: 1.237514048961583 (23 / 35)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.43349753694581283, train_loss: 1.1519699939543886, val_loss: 1.3604233714160074 (24 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.47783251231527096, train_loss: 1.092937628919321, val_loss: 1.2704309718362217 (25 / 35)\n",
            "train_acc: 0.5414091470951793, val_acc: 0.4827586206896552, train_loss: 1.0876582106494785, val_loss: 1.2807517562593733 (26 / 35)\n",
            "train_acc: 0.5562422744128553, val_acc: 0.47783251231527096, train_loss: 1.056179475872714, val_loss: 1.3670274665203002 (27 / 35)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.4975369458128079, train_loss: 1.078569902035745, val_loss: 1.3012194651101023 (28 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.4975369458128079, train_loss: 1.0240033567320137, val_loss: 1.220278175593597 (29 / 35)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.5123152709359606, train_loss: 0.9900447023371683, val_loss: 1.1973336294954047 (30 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5221674876847291, train_loss: 0.9741546776150302, val_loss: 1.2848423149785384 (31 / 35)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5320197044334976, train_loss: 1.0222232865609404, val_loss: 1.284154888444346 (32 / 35)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.5369458128078818, train_loss: 0.9639429865573039, val_loss: 1.2857303308148689 (33 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.47783251231527096, train_loss: 0.9968692048076352, val_loss: 1.365260783087444 (34 / 35)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.5172413793103449, train_loss: 0.9467162760285424, val_loss: 1.271035797783894 (35 / 35)\n",
            "lr 0.003529970083935975, batch 12, decay 8.294414812310763e-06, gamma 0.2713567051116348, val accuracy 0.5369458128078818, val loss 1.2857303308148689 [13 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.19406674907292953, val_acc: 0.2413793103448276, train_loss: 2.4469463782493204, val_loss: 2.1680976453379457 (1 / 35)\n",
            "train_acc: 0.22249690976514216, val_acc: 0.24630541871921183, train_loss: 2.209293946347514, val_loss: 1.7974484791896614 (2 / 35)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.35467980295566504, train_loss: 1.9740713093572553, val_loss: 1.6478701624377021 (3 / 35)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.39901477832512317, train_loss: 1.7840971410348183, val_loss: 1.4891861559722224 (4 / 35)\n",
            "train_acc: 0.3016069221260816, val_acc: 0.3448275862068966, train_loss: 1.632074257941417, val_loss: 1.5024512015246405 (5 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.32019704433497537, train_loss: 1.5870094125438827, val_loss: 1.6006023099857012 (6 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.3497536945812808, train_loss: 1.650365282342814, val_loss: 1.4831337412002639 (7 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.33497536945812806, train_loss: 1.597467620823675, val_loss: 1.4676623855318343 (8 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.3103448275862069, train_loss: 1.513188129597158, val_loss: 1.6036550796090676 (9 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.2857142857142857, train_loss: 1.51187731021709, val_loss: 2.112731360009151 (10 / 35)\n",
            "train_acc: 0.377008652657602, val_acc: 0.4039408866995074, train_loss: 1.4459841540186897, val_loss: 1.3435044232847655 (11 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.35960591133004927, train_loss: 1.406532750215165, val_loss: 1.4149692205372701 (12 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.4039408866995074, train_loss: 1.4702490119468443, val_loss: 1.385256255495137 (13 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.3891625615763547, train_loss: 1.463637916870848, val_loss: 1.4484132412325572 (14 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.39408866995073893, train_loss: 1.448887694014607, val_loss: 1.3858281818810354 (15 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3891625615763547, train_loss: 1.3993462818514726, val_loss: 1.4627860429251722 (16 / 35)\n",
            "train_acc: 0.4388133498145859, val_acc: 0.39408866995073893, train_loss: 1.3110410753817139, val_loss: 1.3463533526570926 (17 / 35)\n",
            "train_acc: 0.42398022249690975, val_acc: 0.4187192118226601, train_loss: 1.3553418935597754, val_loss: 1.3478835879875521 (18 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.4039408866995074, train_loss: 1.3964493284266724, val_loss: 1.4914422273048626 (19 / 35)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.4187192118226601, train_loss: 1.3752302996749783, val_loss: 1.470917586622567 (20 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.43349753694581283, train_loss: 1.3283705253830946, val_loss: 1.3368578655966397 (21 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4482758620689655, train_loss: 1.19945288036014, val_loss: 1.3573610606451927 (22 / 35)\n",
            "train_acc: 0.5018541409147095, val_acc: 0.45320197044334976, train_loss: 1.1500571311183265, val_loss: 1.3213747366895816 (23 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.458128078817734, train_loss: 1.1369982545985868, val_loss: 1.3045098485030564 (24 / 35)\n",
            "train_acc: 0.5389369592088998, val_acc: 0.4630541871921182, train_loss: 1.1004747349045922, val_loss: 1.3057097801433994 (25 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.47783251231527096, train_loss: 1.1028300469236998, val_loss: 1.2950125873969693 (26 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.46798029556650245, train_loss: 1.0991749266906192, val_loss: 1.311313647061146 (27 / 35)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.47783251231527096, train_loss: 1.1159032523558372, val_loss: 1.293425675096183 (28 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.45320197044334976, train_loss: 1.1057071217205674, val_loss: 1.2989292846524656 (29 / 35)\n",
            "train_acc: 0.515451174289246, val_acc: 0.46798029556650245, train_loss: 1.0908135891108046, val_loss: 1.2864504110049733 (30 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.4630541871921182, train_loss: 1.0698974833942314, val_loss: 1.291660492936966 (31 / 35)\n",
            "train_acc: 0.5599505562422744, val_acc: 0.46798029556650245, train_loss: 1.0538081464130886, val_loss: 1.2856481025371644 (32 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.4630541871921182, train_loss: 1.0904715366947046, val_loss: 1.276242459936095 (33 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.458128078817734, train_loss: 1.0495665037293074, val_loss: 1.2863475069623862 (34 / 35)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.4630541871921182, train_loss: 1.038767439620604, val_loss: 1.2883698508657258 (35 / 35)\n",
            "lr 0.0029827871484805575, batch 15, decay 1.3479926224514283e-05, gamma 0.02523567646269193, val accuracy 0.47783251231527096, val loss 1.2950125873969693 [14 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 2.648519032670482, val_loss: 2.829634753941315 (1 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.18719211822660098, train_loss: 2.3020764049994487, val_loss: 2.008009403209968 (2 / 35)\n",
            "train_acc: 0.26452410383189123, val_acc: 0.23645320197044334, train_loss: 1.9798124243214046, val_loss: 2.865188770693511 (3 / 35)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.3251231527093596, train_loss: 1.8285695525123398, val_loss: 1.6386010729033371 (4 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.3251231527093596, train_loss: 1.7330931982092275, val_loss: 2.124482928238479 (5 / 35)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.3103448275862069, train_loss: 1.6526469798259005, val_loss: 1.622619476811639 (6 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3251231527093596, train_loss: 1.5791087253721448, val_loss: 1.484459497364871 (7 / 35)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.3448275862068966, train_loss: 1.6256068781368223, val_loss: 1.6045035869617181 (8 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.35960591133004927, train_loss: 1.5151014516615897, val_loss: 1.859532683353706 (9 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.35467980295566504, train_loss: 1.563895973787909, val_loss: 1.6842111630980017 (10 / 35)\n",
            "train_acc: 0.3263288009888752, val_acc: 0.3694581280788177, train_loss: 1.5930598999278065, val_loss: 1.4780844464677896 (11 / 35)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.3694581280788177, train_loss: 1.4309286390453098, val_loss: 1.4705225640329822 (12 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3694581280788177, train_loss: 1.4686427658656325, val_loss: 2.85409092961861 (13 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.3891625615763547, train_loss: 1.4486964182152293, val_loss: 1.497101878004121 (14 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.35960591133004927, train_loss: 1.4990937270693785, val_loss: 1.4968532247496356 (15 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.3891625615763547, train_loss: 1.4332979444520288, val_loss: 1.528761006047573 (16 / 35)\n",
            "train_acc: 0.415327564894932, val_acc: 0.3694581280788177, train_loss: 1.4127967163128377, val_loss: 1.9248556462414745 (17 / 35)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.41379310344827586, train_loss: 1.3870894879434252, val_loss: 1.7894749817589821 (18 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.4187192118226601, train_loss: 1.4196668941394066, val_loss: 1.4486097173737775 (19 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.37438423645320196, train_loss: 1.3488960952782365, val_loss: 1.5557967330434639 (20 / 35)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.4482758620689655, train_loss: 1.2938489445355088, val_loss: 1.4451510794644284 (21 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4729064039408867, train_loss: 1.1628309902360914, val_loss: 1.3880793220303915 (22 / 35)\n",
            "train_acc: 0.5438813349814586, val_acc: 0.4729064039408867, train_loss: 1.1041131850668173, val_loss: 1.342423316293162 (23 / 35)\n",
            "train_acc: 0.5475896168108776, val_acc: 0.4827586206896552, train_loss: 1.06578030029245, val_loss: 1.3177677439938624 (24 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.4827586206896552, train_loss: 1.0517742091557298, val_loss: 1.2981683074547152 (25 / 35)\n",
            "train_acc: 0.595797280593325, val_acc: 0.4876847290640394, train_loss: 0.971468395591519, val_loss: 1.3921330033851962 (26 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.47783251231527096, train_loss: 1.0587110092082925, val_loss: 1.3419668562893796 (27 / 35)\n",
            "train_acc: 0.5772558714462299, val_acc: 0.4827586206896552, train_loss: 1.005311460223864, val_loss: 1.338243130392629 (28 / 35)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.43842364532019706, train_loss: 0.9402210055234553, val_loss: 1.4320978196383698 (29 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.4482758620689655, train_loss: 0.9752068151207584, val_loss: 1.3914405313031426 (30 / 35)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5024630541871922, train_loss: 0.8808689812941958, val_loss: 1.3191322974970776 (31 / 35)\n",
            "train_acc: 0.619283065512979, val_acc: 0.49261083743842365, train_loss: 0.8913826409022799, val_loss: 1.334081983331389 (32 / 35)\n",
            "train_acc: 0.6131025957972805, val_acc: 0.4975369458128079, train_loss: 0.9179882369613176, val_loss: 1.3576524110850443 (33 / 35)\n",
            "train_acc: 0.65389369592089, val_acc: 0.5123152709359606, train_loss: 0.9051719036031565, val_loss: 1.2692772619829977 (34 / 35)\n",
            "train_acc: 0.6551297898640297, val_acc: 0.4827586206896552, train_loss: 0.9062864176275114, val_loss: 1.3168199467541548 (35 / 35)\n",
            "lr 0.0015439063483967115, batch 8, decay 0.000448430108293592, gamma 0.09202375069479353, val accuracy 0.5123152709359606, val loss 1.2692772619829977 [15 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.1841779975278121, val_acc: 0.20689655172413793, train_loss: 2.6030384866504646, val_loss: 2.1053248638002744 (1 / 35)\n",
            "train_acc: 0.2249690976514215, val_acc: 0.3497536945812808, train_loss: 2.2684820063771363, val_loss: 1.5679922409245532 (2 / 35)\n",
            "train_acc: 0.26823238566131025, val_acc: 0.29064039408866993, train_loss: 1.8820718727241488, val_loss: 3.338661882677689 (3 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.37438423645320196, train_loss: 1.7566849310112236, val_loss: 2.0465608700155626 (4 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3251231527093596, train_loss: 1.8388611178462968, val_loss: 1.9479121093092293 (5 / 35)\n",
            "train_acc: 0.33498145859085293, val_acc: 0.3694581280788177, train_loss: 1.61020284205933, val_loss: 1.5067262132766799 (6 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3694581280788177, train_loss: 1.6607066851169128, val_loss: 1.6423093632524237 (7 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.3448275862068966, train_loss: 1.6614645638483563, val_loss: 1.5631471105984278 (8 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.37438423645320196, train_loss: 1.5807023319532019, val_loss: 1.487759862040064 (9 / 35)\n",
            "train_acc: 0.34239802224969096, val_acc: 0.3054187192118227, train_loss: 1.5344710002281463, val_loss: 2.199535811769551 (10 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3399014778325123, train_loss: 1.541823041159084, val_loss: 1.3504598372675516 (11 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.41379310344827586, train_loss: 1.4739823918996842, val_loss: 1.7415728668861201 (12 / 35)\n",
            "train_acc: 0.34981458590852904, val_acc: 0.43349753694581283, train_loss: 1.5524984403652669, val_loss: 1.916912946795008 (13 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3448275862068966, train_loss: 1.469258514116662, val_loss: 2.6703074195702086 (14 / 35)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.3842364532019704, train_loss: 1.412982131111607, val_loss: 1.5934104925305972 (15 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.35960591133004927, train_loss: 1.451939429576671, val_loss: 1.930618250017683 (16 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.41379310344827586, train_loss: 1.463037566879329, val_loss: 2.0215013502853845 (17 / 35)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.4088669950738916, train_loss: 1.4952135030065095, val_loss: 1.3394040524078707 (18 / 35)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.4482758620689655, train_loss: 1.4405657856072425, val_loss: 1.3661806471829343 (19 / 35)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4236453201970443, train_loss: 1.3822517722145147, val_loss: 1.9498535840969367 (20 / 35)\n",
            "train_acc: 0.44499381953028433, val_acc: 0.4187192118226601, train_loss: 1.340468823394021, val_loss: 1.5054459081494749 (21 / 35)\n",
            "train_acc: 0.4857849196538937, val_acc: 0.4729064039408867, train_loss: 1.227759572572555, val_loss: 1.547093483614804 (22 / 35)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4975369458128079, train_loss: 1.2035633775006118, val_loss: 1.3413823073720696 (23 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.4975369458128079, train_loss: 1.1083057750435488, val_loss: 1.459624259929939 (24 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.45320197044334976, train_loss: 1.089856308823905, val_loss: 1.6855794995876368 (25 / 35)\n",
            "train_acc: 0.5686032138442522, val_acc: 0.46798029556650245, train_loss: 1.074412116603592, val_loss: 1.3187065529705855 (26 / 35)\n",
            "train_acc: 0.553770086526576, val_acc: 0.5270935960591133, train_loss: 1.0127264510273786, val_loss: 1.2811367787751071 (27 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.5369458128078818, train_loss: 1.0308739994600766, val_loss: 1.2609765100948915 (28 / 35)\n",
            "train_acc: 0.5339925834363412, val_acc: 0.5073891625615764, train_loss: 1.0944576292898511, val_loss: 1.2874793871282944 (29 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.5862068965517241, train_loss: 1.0404488990274436, val_loss: 1.1111944620245195 (30 / 35)\n",
            "train_acc: 0.6044499381953028, val_acc: 0.4876847290640394, train_loss: 0.9998242589835036, val_loss: 1.3471279848972564 (31 / 35)\n",
            "train_acc: 0.6032138442521632, val_acc: 0.5615763546798029, train_loss: 1.0305887123268231, val_loss: 1.1962256202556816 (32 / 35)\n",
            "train_acc: 0.595797280593325, val_acc: 0.541871921182266, train_loss: 1.0319248480614096, val_loss: 1.451142040379529 (33 / 35)\n",
            "train_acc: 0.6019777503090235, val_acc: 0.4975369458128079, train_loss: 0.9737473456614981, val_loss: 1.2885485441226678 (34 / 35)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5566502463054187, train_loss: 0.9715771535123676, val_loss: 1.121930835869512 (35 / 35)\n",
            "lr 0.0019266130154419682, batch 8, decay 2.698290738787259e-05, gamma 0.2532070834261078, val accuracy 0.5862068965517241, val loss 1.1111944620245195 [16 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 2.504411677494921, val_loss: 2.101588088303364 (1 / 35)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 2.8241062025793995, val_loss: 1.744396988981463 (2 / 35)\n",
            "train_acc: 0.26328800988875156, val_acc: 0.32019704433497537, train_loss: 1.9366997386085973, val_loss: 1.5930879626955305 (3 / 35)\n",
            "train_acc: 0.26328800988875156, val_acc: 0.3103448275862069, train_loss: 1.841779750563453, val_loss: 1.5477893439126131 (4 / 35)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.3054187192118227, train_loss: 1.8224139496481462, val_loss: 1.547222424610495 (5 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.30049261083743845, train_loss: 1.7358961926107797, val_loss: 1.4873574270403445 (6 / 35)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.3103448275862069, train_loss: 1.7364544143488145, val_loss: 1.5615977319003327 (7 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.33004926108374383, train_loss: 1.5875126023227706, val_loss: 1.4250980850510997 (8 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3793103448275862, train_loss: 1.5912542543540926, val_loss: 1.428572056035103 (9 / 35)\n",
            "train_acc: 0.3189122373300371, val_acc: 0.3448275862068966, train_loss: 1.5685617054348675, val_loss: 1.468116854799205 (10 / 35)\n",
            "train_acc: 0.3646477132262052, val_acc: 0.3399014778325123, train_loss: 1.4844155202542602, val_loss: 1.4143488876925314 (11 / 35)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.42857142857142855, train_loss: 1.5064534594308314, val_loss: 1.3401619328066634 (12 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.4187192118226601, train_loss: 1.5065103259457941, val_loss: 1.3596840213085044 (13 / 35)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.39408866995073893, train_loss: 1.549158832346111, val_loss: 1.3252959418766603 (14 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3645320197044335, train_loss: 1.43305913450102, val_loss: 1.310424736567906 (15 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.39408866995073893, train_loss: 1.4302475042779308, val_loss: 1.4127773163941106 (16 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.4088669950738916, train_loss: 1.4397838183474925, val_loss: 1.3159929164524735 (17 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.41379310344827586, train_loss: 1.5064860225018524, val_loss: 1.3005515278266568 (18 / 35)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.4088669950738916, train_loss: 1.404007165040015, val_loss: 1.4471307661145778 (19 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.39408866995073893, train_loss: 1.4176663999504449, val_loss: 1.323148845158187 (20 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3891625615763547, train_loss: 1.4395654922804815, val_loss: 1.3840686443991261 (21 / 35)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.4482758620689655, train_loss: 1.2539572658291265, val_loss: 1.2776279411292428 (22 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.46798029556650245, train_loss: 1.266616911985376, val_loss: 1.2781092577379913 (23 / 35)\n",
            "train_acc: 0.449938195302843, val_acc: 0.45320197044334976, train_loss: 1.2331353016335826, val_loss: 1.2659425682622223 (24 / 35)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.46798029556650245, train_loss: 1.225365875014858, val_loss: 1.2535602789500664 (25 / 35)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.45320197044334976, train_loss: 1.221931700137696, val_loss: 1.255346060680051 (26 / 35)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.458128078817734, train_loss: 1.2232206036487527, val_loss: 1.2828352692091993 (27 / 35)\n",
            "train_acc: 0.46971569839307786, val_acc: 0.4630541871921182, train_loss: 1.2314042968419927, val_loss: 1.2699139309046892 (28 / 35)\n",
            "train_acc: 0.47095179233621753, val_acc: 0.4729064039408867, train_loss: 1.2028274099965326, val_loss: 1.2658128493231506 (29 / 35)\n",
            "train_acc: 0.4820766378244747, val_acc: 0.4729064039408867, train_loss: 1.1967941029699536, val_loss: 1.2648574213676265 (30 / 35)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.46798029556650245, train_loss: 1.1923937984685815, val_loss: 1.2574589474154223 (31 / 35)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.46798029556650245, train_loss: 1.1989418169476636, val_loss: 1.2595049295519374 (32 / 35)\n",
            "train_acc: 0.5030902348578492, val_acc: 0.45320197044334976, train_loss: 1.1830113082939968, val_loss: 1.2696660689532464 (33 / 35)\n",
            "train_acc: 0.4746600741656366, val_acc: 0.43349753694581283, train_loss: 1.2008106772625549, val_loss: 1.2736729142701098 (34 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.4482758620689655, train_loss: 1.1516604444889262, val_loss: 1.3124624179501838 (35 / 35)\n",
            "lr 0.0027049599307591246, batch 13, decay 2.8379633762947735e-05, gamma 0.03349645729453212, val accuracy 0.4729064039408867, val loss 1.2658128493231506 [17 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.18541409147095178, val_acc: 0.08866995073891626, train_loss: 2.0880806286933247, val_loss: 2.3673263706009964 (1 / 35)\n",
            "train_acc: 0.23485784919653893, val_acc: 0.3054187192118227, train_loss: 2.012980983195405, val_loss: 2.891664648878163 (2 / 35)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.2955665024630542, train_loss: 1.8609819192674162, val_loss: 2.152205668646714 (3 / 35)\n",
            "train_acc: 0.27564894932014833, val_acc: 0.32019704433497537, train_loss: 1.7913547290122995, val_loss: 1.550329796199141 (4 / 35)\n",
            "train_acc: 0.273176761433869, val_acc: 0.3251231527093596, train_loss: 1.7341945936122842, val_loss: 1.9414761395289981 (5 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.35467980295566504, train_loss: 1.6575300504898995, val_loss: 1.6596315688100354 (6 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.2955665024630542, train_loss: 1.7062088651916447, val_loss: 1.6854530326251327 (7 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.2955665024630542, train_loss: 1.6320587210955815, val_loss: 1.6257910317388073 (8 / 35)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.33497536945812806, train_loss: 1.7371816047189852, val_loss: 1.6852400960593388 (9 / 35)\n",
            "train_acc: 0.31025957972805934, val_acc: 0.2512315270935961, train_loss: 1.5647724718039646, val_loss: 1.7993038748872692 (10 / 35)\n",
            "train_acc: 0.32138442521631644, val_acc: 0.3448275862068966, train_loss: 1.644973309137323, val_loss: 1.6192612483583648 (11 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.3399014778325123, train_loss: 1.5015689672439443, val_loss: 1.4913187438044055 (12 / 35)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.3251231527093596, train_loss: 1.510191280408607, val_loss: 1.4481004229907333 (13 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.41379310344827586, train_loss: 1.4704621753232883, val_loss: 1.455376415417112 (14 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.37438423645320196, train_loss: 1.4297729256126583, val_loss: 1.8018053441212094 (15 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4187192118226601, train_loss: 1.4669927859630514, val_loss: 1.6093673336094823 (16 / 35)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.3399014778325123, train_loss: 1.4156997971540624, val_loss: 1.7332324159556423 (17 / 35)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.4187192118226601, train_loss: 1.3882736996166196, val_loss: 1.664821474716581 (18 / 35)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.39408866995073893, train_loss: 1.3894790652655848, val_loss: 1.480311496504422 (19 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.3645320197044335, train_loss: 1.3546284419497099, val_loss: 1.46011575337114 (20 / 35)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.35960591133004927, train_loss: 1.345581232543634, val_loss: 1.7682085962131107 (21 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.41379310344827586, train_loss: 1.2220389414187267, val_loss: 1.3982147471658115 (22 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.43349753694581283, train_loss: 1.2115973110399376, val_loss: 1.465592540543655 (23 / 35)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4039408866995074, train_loss: 1.2042800790741948, val_loss: 1.4368900348400246 (24 / 35)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.45320197044334976, train_loss: 1.2026265165567103, val_loss: 1.3737266228116791 (25 / 35)\n",
            "train_acc: 0.5105067985166872, val_acc: 0.43842364532019706, train_loss: 1.124256581399585, val_loss: 1.3851817229698444 (26 / 35)\n",
            "train_acc: 0.5290482076637825, val_acc: 0.43349753694581283, train_loss: 1.1201082038496275, val_loss: 1.3944758670083408 (27 / 35)\n",
            "train_acc: 0.5426452410383189, val_acc: 0.47783251231527096, train_loss: 1.0826280556149477, val_loss: 1.3600049142179818 (28 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.4482758620689655, train_loss: 1.0521013793456098, val_loss: 1.5031570155045082 (29 / 35)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.46798029556650245, train_loss: 1.070062318971042, val_loss: 1.4487589166082184 (30 / 35)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.41379310344827586, train_loss: 1.0992022860330173, val_loss: 1.5212558179066098 (31 / 35)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.4482758620689655, train_loss: 1.0196966413219721, val_loss: 1.3166870824221908 (32 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.43842364532019706, train_loss: 1.0410217546267326, val_loss: 1.4340587278892254 (33 / 35)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.43842364532019706, train_loss: 1.002979151398054, val_loss: 1.493157066147903 (34 / 35)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.5172413793103449, train_loss: 1.0056574002774006, val_loss: 1.377724289894104 (35 / 35)\n",
            "lr 0.0009854178054549464, batch 14, decay 1.8241161354847256e-05, gamma 0.39071635604292565, val accuracy 0.5172413793103449, val loss 1.377724289894104 [18 / 50]\n",
            "---------------------------------------------\n",
            "train_acc: 0.2200247218788628, val_acc: 0.28078817733990147, train_loss: 3.0419415830829086, val_loss: 1.8471898891655683 (1 / 35)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.23645320197044334, train_loss: 1.9464693670661841, val_loss: 5.231059281109589 (2 / 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "6f9b6113-ebc5-42e9-c6ea-e4fb357d30bf",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = resnet152(num_classes=NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = resnet152(num_classes=NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 24392 (delta 10), reused 13 (delta 5), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24392/24392), 2.15 GiB | 40.79 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (24636/24636), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5911330049261084, val loss 1.464456105467134\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5714285714285714, val loss 1.1493462312397698\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.2976923220850565\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5714285714285714, val loss 1.5292216216402101\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5517241379310345, val loss 2.2198262414321523\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.541871921182266, val loss 1.4739784601286714\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6354679802955665, val loss 1.4432697883380459\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5467980295566502, val loss 1.4287934297411313\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6157635467980296, val loss 1.2100772047277741\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5812807881773399, val loss 1.2167480200382288\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6206896551724138, val loss 1.2259140389012586\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6206896551724138, val loss 1.2343330753260646\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5911330049261084, val loss 1.668155833418146\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.5566502463054187, val loss 1.222032011436124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "1bd7620b-b85a-4ec4-adb1-a0b86857073d"
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6021e5c8a16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpixel_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Computing mean/std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b20803267196>\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m(train_data_dir, test_data_dir, compose)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/anphetamina/AIML_project.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     91\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     92\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Faster and available in Python 3.5 and above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AIML_project/ravdess-emotional-song-mel-672'"
          ]
        }
      ]
    }
  ]
}