{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg19\n",
        "from torchvision.models import vgg19_bn\n",
        "from torchvision.models import vgg16\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg19()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "fdf60c9f-ce6f-4d00-e343-ae7c6e2ba70e",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}), best val accuracy 0.7635467980295566, best val loss 1.4869063125161701\n",
        "# val_accuracies\n",
        "# [0.7635467980295566, 0.6945812807881774, 0.6798029556650246, 0.6995073891625616, 0.6354679802955665, 0.6354679802955665, 0.645320197044335, 0.6502463054187192, 0.6502463054187192, 0.6305418719211823, 0.6551724137931034, 0.6502463054187192, 0.6896551724137931, 0.6995073891625616, 0.6798029556650246, 0.6699507389162561]\n",
        "# ({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7881773399014779, val loss 1.4585814757887365\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-05\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "GAMMA = 0.1\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg19()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.7919360259260029, val_loss: 1.7858666116968165 (1 / 100)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.22167487684729065, train_loss: 1.7851173743624034, val_loss: 1.7772992861094734 (2 / 100)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.17733990147783252, train_loss: 1.77748153693007, val_loss: 1.7671665869322903 (3 / 100)\n",
            "train_acc: 0.18788627935723115, val_acc: 0.18226600985221675, train_loss: 1.7695785231879084, val_loss: 1.7569804232696007 (4 / 100)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7628635156287251, val_loss: 1.7495281684574822 (5 / 100)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7524694939626309, val_loss: 1.7437969052732871 (6 / 100)\n",
            "train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7469435953828696, val_loss: 1.7355443339042476 (7 / 100)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.23645320197044334, train_loss: 1.7439731340325808, val_loss: 1.726506340679864 (8 / 100)\n",
            "train_acc: 0.2484548825710754, val_acc: 0.2955665024630542, train_loss: 1.7284658115785407, val_loss: 1.708215721135069 (9 / 100)\n",
            "train_acc: 0.2867737948084054, val_acc: 0.27586206896551724, train_loss: 1.709317218240613, val_loss: 1.6849623812830508 (10 / 100)\n",
            "train_acc: 0.2892459826946848, val_acc: 0.30049261083743845, train_loss: 1.6905147047950546, val_loss: 1.6497271706905272 (11 / 100)\n",
            "train_acc: 0.2978986402966625, val_acc: 0.33497536945812806, train_loss: 1.6690871607977322, val_loss: 1.5873171913212742 (12 / 100)\n",
            "train_acc: 0.30284301606922126, val_acc: 0.3694581280788177, train_loss: 1.6311536436469947, val_loss: 1.5503545183266325 (13 / 100)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.33004926108374383, train_loss: 1.6148846153865197, val_loss: 1.6000008729878317 (14 / 100)\n",
            "train_acc: 0.3300370828182942, val_acc: 0.3497536945812808, train_loss: 1.576049417883563, val_loss: 1.494163995305893 (15 / 100)\n",
            "train_acc: 0.34610630407911, val_acc: 0.3399014778325123, train_loss: 1.530893135571804, val_loss: 1.4879443445816416 (16 / 100)\n",
            "train_acc: 0.34857849196538937, val_acc: 0.32019704433497537, train_loss: 1.5362152397558921, val_loss: 1.496649706892192 (17 / 100)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3793103448275862, train_loss: 1.4863255463070864, val_loss: 1.4922468409749674 (18 / 100)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3399014778325123, train_loss: 1.548157096645888, val_loss: 1.4593104764158502 (19 / 100)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.35467980295566504, train_loss: 1.4794971186976202, val_loss: 1.4414605871209958 (20 / 100)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.4236453201970443, train_loss: 1.5064038032359628, val_loss: 1.4147045030969705 (21 / 100)\n",
            "train_acc: 0.377008652657602, val_acc: 0.35467980295566504, train_loss: 1.4606601798490186, val_loss: 1.3960361175349194 (22 / 100)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.3497536945812808, train_loss: 1.4394966727870946, val_loss: 1.4800769102397224 (23 / 100)\n",
            "train_acc: 0.4079110012360939, val_acc: 0.3103448275862069, train_loss: 1.4510854942394864, val_loss: 1.4293916201943835 (24 / 100)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.3793103448275862, train_loss: 1.4292896567522668, val_loss: 1.3817235425188037 (25 / 100)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3694581280788177, train_loss: 1.4496593635957526, val_loss: 1.486911264546399 (26 / 100)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.43349753694581283, train_loss: 1.4331524937939732, val_loss: 1.3882109008986374 (27 / 100)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.4187192118226601, train_loss: 1.4268137215094454, val_loss: 1.3640675069076087 (28 / 100)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.4433497536945813, train_loss: 1.3982927746914227, val_loss: 1.37895180967641 (29 / 100)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.4187192118226601, train_loss: 1.3791867911594613, val_loss: 1.3253404442312682 (30 / 100)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4088669950738916, train_loss: 1.3488849865638723, val_loss: 1.3334079886892158 (31 / 100)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.42857142857142855, train_loss: 1.413028093586746, val_loss: 1.3356896674104513 (32 / 100)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.43842364532019706, train_loss: 1.3562986052080492, val_loss: 1.333793136873856 (33 / 100)\n",
            "train_acc: 0.43510506798516685, val_acc: 0.39408866995073893, train_loss: 1.3511746980351187, val_loss: 1.3190847641141543 (34 / 100)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4236453201970443, train_loss: 1.338973549741455, val_loss: 1.3547965752080156 (35 / 100)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.43349753694581283, train_loss: 1.3271965214289605, val_loss: 1.3631234850202287 (36 / 100)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4482758620689655, train_loss: 1.335207624105352, val_loss: 1.2967583642804563 (37 / 100)\n",
            "train_acc: 0.449938195302843, val_acc: 0.4876847290640394, train_loss: 1.3080920820919928, val_loss: 1.297953495838372 (38 / 100)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.458128078817734, train_loss: 1.288883757384952, val_loss: 1.2790994890804948 (39 / 100)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.39408866995073893, train_loss: 1.3033193274687778, val_loss: 1.4495419768864297 (40 / 100)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4187192118226601, train_loss: 1.290280471773466, val_loss: 1.284684795464201 (41 / 100)\n",
            "train_acc: 0.45488257107540175, val_acc: 0.4433497536945813, train_loss: 1.2764545683513024, val_loss: 1.25069360016602 (42 / 100)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.4630541871921182, train_loss: 1.2346501664266598, val_loss: 1.301280770102158 (43 / 100)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.47783251231527096, train_loss: 1.2854703253662336, val_loss: 1.2233352261811055 (44 / 100)\n",
            "train_acc: 0.4672435105067985, val_acc: 0.46798029556650245, train_loss: 1.2644142531346627, val_loss: 1.2641628607740543 (45 / 100)\n",
            "train_acc: 0.4684796044499382, val_acc: 0.4433497536945813, train_loss: 1.2732817488636163, val_loss: 1.2729744003911323 (46 / 100)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.45320197044334976, train_loss: 1.2789924975820761, val_loss: 1.2668251788674905 (47 / 100)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.5024630541871922, train_loss: 1.189872696903639, val_loss: 1.2359674258772375 (48 / 100)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.45320197044334976, train_loss: 1.2003422250559068, val_loss: 1.2468417486533743 (49 / 100)\n",
            "train_acc: 0.4919653893695921, val_acc: 0.4630541871921182, train_loss: 1.195237134826198, val_loss: 1.1909501112153378 (50 / 100)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.4876847290640394, train_loss: 1.1920011812735842, val_loss: 1.2422824422714158 (51 / 100)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4236453201970443, train_loss: 1.2018882852549606, val_loss: 1.3240937358640097 (52 / 100)\n",
            "train_acc: 0.5043263288009888, val_acc: 0.5320197044334976, train_loss: 1.1995863282341597, val_loss: 1.1813226535989734 (53 / 100)\n",
            "train_acc: 0.5302843016069221, val_acc: 0.47783251231527096, train_loss: 1.1818732516874637, val_loss: 1.215932529548119 (54 / 100)\n",
            "train_acc: 0.5092707045735476, val_acc: 0.5073891625615764, train_loss: 1.131536221032679, val_loss: 1.229335440790712 (55 / 100)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.5270935960591133, train_loss: 1.1400669894200763, val_loss: 1.1972490783982677 (56 / 100)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.47783251231527096, train_loss: 1.0966357708861418, val_loss: 1.1739717084785988 (57 / 100)\n",
            "train_acc: 0.5253399258343634, val_acc: 0.5024630541871922, train_loss: 1.1066952692563514, val_loss: 1.1735602373560075 (58 / 100)\n",
            "train_acc: 0.5278121137206427, val_acc: 0.4975369458128079, train_loss: 1.1474143047120573, val_loss: 1.1539784599407552 (59 / 100)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.4975369458128079, train_loss: 1.0853127756873227, val_loss: 1.256557924994107 (60 / 100)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5123152709359606, train_loss: 1.0593593631156148, val_loss: 1.1223670508473964 (61 / 100)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5073891625615764, train_loss: 1.02341136759969, val_loss: 1.1203434749189856 (62 / 100)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5270935960591133, train_loss: 1.0000696288345772, val_loss: 1.1142643193893245 (63 / 100)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5270935960591133, train_loss: 0.9783715720671806, val_loss: 1.11643640396043 (64 / 100)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.4975369458128079, train_loss: 0.9925998237135973, val_loss: 1.1266197154087385 (65 / 100)\n",
            "train_acc: 0.6365883807169345, val_acc: 0.5172413793103449, train_loss: 0.941962529834917, val_loss: 1.11515155008861 (66 / 100)\n",
            "train_acc: 0.646477132262052, val_acc: 0.5320197044334976, train_loss: 0.9524936699602011, val_loss: 1.1260978059815656 (67 / 100)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.5369458128078818, train_loss: 0.9641160259140731, val_loss: 1.1109588307700133 (68 / 100)\n",
            "train_acc: 0.6266996291718171, val_acc: 0.5221674876847291, train_loss: 0.9618220248240034, val_loss: 1.1137393974318293 (69 / 100)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5221674876847291, train_loss: 0.9482933579033473, val_loss: 1.1096914522166323 (70 / 100)\n",
            "train_acc: 0.6452410383189122, val_acc: 0.5024630541871922, train_loss: 0.9246025193754321, val_loss: 1.120763722898925 (71 / 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3373b1b37556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbest_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val accuracy {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c446edcbb070>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset, verbosity, plot)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c446edcbb070>\u001b[0m in \u001b[0;36mtest_network\u001b[0;34m(net, test_dataset, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0msum_test_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;31m# Update Corrects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "663dcdab-edc8-4ca0-af25-1fefaadc005f",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 1]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg19()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg19()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6798029556650246, val loss 2.0575794022658775\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.6600985221674877, val loss 2.22855053629194\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.5714285714285714, val loss 1.781040847595102\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.19704433497536947, val loss 1.7399233321250953\n",
            "({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.645320197044335, val loss 1.4839234064365256\n",
            "({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.6403940886699507, val loss 2.0090413158163063\n",
            "({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.645320197044335, val loss 2.2277551008562737\n",
            "({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}), val accuracy 0.7389162561576355, val loss 1.4728715255526192\n",
            "\n",
            "\n",
            "({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 1}), best val accuracy 0.7389162561576355, best val loss 1.4728715255526192\n",
            "\n",
            "\n",
            "val_accuracies\n",
            "[0.6798029556650246, 0.6600985221674877, 0.5714285714285714, 0.19704433497536947, 0.645320197044335, 0.6403940886699507, 0.645320197044335, 0.7389162561576355]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-mel'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}