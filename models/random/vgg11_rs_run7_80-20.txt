training set 506
validation set 506
-------------------------------------
{'lr': 0.0008377019231346562, 'batch_size': 8, 'weight_decay': 2.4427015675775187e-06, 'gamma': 0.00903130010323455}
train_acc: 0.17786561264822134, val_acc: 0.21541501976284586, train_loss: 1.7863152342822712, val_loss: 1.7722297741961572 (1 / 60)
train_acc: 0.18379446640316205, val_acc: 0.18181818181818182, train_loss: 1.7704359589829275, val_loss: 1.7523967682608503 (2 / 60)
train_acc: 0.18774703557312253, val_acc: 0.18181818181818182, train_loss: 1.7528877253588953, val_loss: 1.7411301805096653 (3 / 60)
train_acc: 0.20948616600790515, val_acc: 0.18181818181818182, train_loss: 1.7504995048281704, val_loss: 1.7216323750763542 (4 / 60)
train_acc: 0.22332015810276679, val_acc: 0.30632411067193677, train_loss: 1.737266372786209, val_loss: 1.7086612023854915 (5 / 60)
train_acc: 0.2885375494071146, val_acc: 0.2727272727272727, train_loss: 1.702369820459087, val_loss: 1.6933222542638364 (6 / 60)
train_acc: 0.2845849802371542, val_acc: 0.2984189723320158, train_loss: 1.6792372483980986, val_loss: 1.6299347905773418 (7 / 60)
train_acc: 0.3102766798418972, val_acc: 0.37549407114624506, train_loss: 1.625590267388717, val_loss: 1.5310549123485098 (8 / 60)
train_acc: 0.32806324110671936, val_acc: 0.37549407114624506, train_loss: 1.5982566525342436, val_loss: 1.5546836801197217 (9 / 60)
train_acc: 0.2924901185770751, val_acc: 0.30434782608695654, train_loss: 1.6062405406250784, val_loss: 1.588579886515621 (10 / 60)
train_acc: 0.308300395256917, val_acc: 0.37549407114624506, train_loss: 1.5723007799608435, val_loss: 1.4867907541071472 (11 / 60)
train_acc: 0.35968379446640314, val_acc: 0.3339920948616601, train_loss: 1.5215614124720276, val_loss: 1.501301684398425 (12 / 60)
train_acc: 0.34980237154150196, val_acc: 0.3893280632411067, train_loss: 1.5198279265829697, val_loss: 1.4489812615360667 (13 / 60)
train_acc: 0.3557312252964427, val_acc: 0.33794466403162055, train_loss: 1.4925839142365889, val_loss: 1.4222116993350002 (14 / 60)
train_acc: 0.35177865612648224, val_acc: 0.3675889328063241, train_loss: 1.4452084185106482, val_loss: 1.420514835906123 (15 / 60)
train_acc: 0.3616600790513834, val_acc: 0.37549407114624506, train_loss: 1.4834058294183181, val_loss: 1.4798739239161194 (16 / 60)
train_acc: 0.41304347826086957, val_acc: 0.41106719367588934, train_loss: 1.4148132490075154, val_loss: 1.3247306761534319 (17 / 60)
train_acc: 0.39920948616600793, val_acc: 0.4525691699604743, train_loss: 1.4059491732374954, val_loss: 1.3218183757759365 (18 / 60)
train_acc: 0.41106719367588934, val_acc: 0.4308300395256917, train_loss: 1.39776557094966, val_loss: 1.3157423588598198 (19 / 60)
train_acc: 0.3932806324110672, val_acc: 0.4209486166007905, train_loss: 1.3800065913219226, val_loss: 1.3212138638194841 (20 / 60)
train_acc: 0.38537549407114624, val_acc: 0.4407114624505929, train_loss: 1.3856624741799275, val_loss: 1.324563325158221 (21 / 60)
train_acc: 0.424901185770751, val_acc: 0.46047430830039526, train_loss: 1.343120737038111, val_loss: 1.2506876929475386 (22 / 60)
train_acc: 0.4367588932806324, val_acc: 0.4525691699604743, train_loss: 1.333543907512318, val_loss: 1.2445742339484775 (23 / 60)
train_acc: 0.4308300395256917, val_acc: 0.4782608695652174, train_loss: 1.3293834302736365, val_loss: 1.2551392500579592 (24 / 60)
train_acc: 0.41699604743083, val_acc: 0.4901185770750988, train_loss: 1.3342969982991577, val_loss: 1.2261804243321475 (25 / 60)
train_acc: 0.45652173913043476, val_acc: 0.4505928853754941, train_loss: 1.2546910667136724, val_loss: 1.2541880296624226 (26 / 60)
train_acc: 0.44466403162055335, val_acc: 0.5039525691699605, train_loss: 1.2291747911174307, val_loss: 1.2281511499005344 (27 / 60)
train_acc: 0.466403162055336, val_acc: 0.5059288537549407, train_loss: 1.2280169306065254, val_loss: 1.2008126517058362 (28 / 60)
train_acc: 0.4308300395256917, val_acc: 0.5138339920948617, train_loss: 1.2860843176427095, val_loss: 1.1727960180388137 (29 / 60)
train_acc: 0.48616600790513836, val_acc: 0.44466403162055335, train_loss: 1.259400883446569, val_loss: 1.2940740797359482 (30 / 60)
train_acc: 0.49209486166007904, val_acc: 0.48616600790513836, train_loss: 1.1975280673136353, val_loss: 1.192459461952858 (31 / 60)
train_acc: 0.5158102766798419, val_acc: 0.4841897233201581, train_loss: 1.2047635175493867, val_loss: 1.2160567789680874 (32 / 60)
train_acc: 0.4901185770750988, val_acc: 0.4683794466403162, train_loss: 1.1676724871156716, val_loss: 1.2605916037861067 (33 / 60)
train_acc: 0.5217391304347826, val_acc: 0.46047430830039526, train_loss: 1.1726326221533916, val_loss: 1.2269139836428193 (34 / 60)
train_acc: 0.5197628458498024, val_acc: 0.48221343873517786, train_loss: 1.169487161598658, val_loss: 1.1801939133127688 (35 / 60)
train_acc: 0.5158102766798419, val_acc: 0.5158102766798419, train_loss: 1.1354140792439578, val_loss: 1.1322201561079666 (36 / 60)
train_acc: 0.5810276679841897, val_acc: 0.5316205533596838, train_loss: 1.0294583135913955, val_loss: 1.1067883685643494 (37 / 60)
train_acc: 0.5810276679841897, val_acc: 0.5474308300395256, train_loss: 1.014867725108452, val_loss: 1.0937723340724297 (38 / 60)
train_acc: 0.5849802371541502, val_acc: 0.5553359683794467, train_loss: 1.0099362886470298, val_loss: 1.0830000389234822 (39 / 60)
train_acc: 0.5968379446640316, val_acc: 0.567193675889328, train_loss: 0.9764750187576052, val_loss: 1.079740791452732 (40 / 60)
train_acc: 0.6146245059288538, val_acc: 0.5632411067193676, train_loss: 0.9907858715698182, val_loss: 1.0763620244184502 (41 / 60)
train_acc: 0.5968379446640316, val_acc: 0.5731225296442688, train_loss: 0.9855212859014277, val_loss: 1.0766124404937383 (42 / 60)
train_acc: 0.5830039525691699, val_acc: 0.567193675889328, train_loss: 1.0002818150011448, val_loss: 1.0767021360604658 (43 / 60)
train_acc: 0.650197628458498, val_acc: 0.5652173913043478, train_loss: 0.9504847517126633, val_loss: 1.0775317768805583 (44 / 60)
train_acc: 0.6086956521739131, val_acc: 0.5711462450592886, train_loss: 0.9778515491560985, val_loss: 1.0752314760279749 (45 / 60)
train_acc: 0.5948616600790514, val_acc: 0.5770750988142292, train_loss: 0.966463010301703, val_loss: 1.0753799771131733 (46 / 60)
train_acc: 0.5988142292490118, val_acc: 0.5770750988142292, train_loss: 0.9787839267093673, val_loss: 1.0752787255486953 (47 / 60)
train_acc: 0.6205533596837944, val_acc: 0.5790513833992095, train_loss: 0.960312223717158, val_loss: 1.0753314306613484 (48 / 60)
train_acc: 0.616600790513834, val_acc: 0.5770750988142292, train_loss: 0.9316253697448097, val_loss: 1.0747325632411973 (49 / 60)
train_acc: 0.6185770750988142, val_acc: 0.5830039525691699, train_loss: 0.9550398501011694, val_loss: 1.0774791165302864 (50 / 60)
train_acc: 0.6086956521739131, val_acc: 0.5790513833992095, train_loss: 0.9494425458870387, val_loss: 1.0773781990345288 (51 / 60)
train_acc: 0.6067193675889329, val_acc: 0.5790513833992095, train_loss: 0.9794326483496564, val_loss: 1.072993805757153 (52 / 60)
train_acc: 0.6067193675889329, val_acc: 0.5810276679841897, train_loss: 0.9503637420330123, val_loss: 1.0757572782840654 (53 / 60)
train_acc: 0.6363636363636364, val_acc: 0.5790513833992095, train_loss: 0.9297431038302395, val_loss: 1.0760086152864539 (54 / 60)
train_acc: 0.6146245059288538, val_acc: 0.5810276679841897, train_loss: 0.9526236151518087, val_loss: 1.0717799715373828 (55 / 60)
train_acc: 0.6007905138339921, val_acc: 0.5830039525691699, train_loss: 0.9701217954809015, val_loss: 1.0713261196264636 (56 / 60)
train_acc: 0.6185770750988142, val_acc: 0.5849802371541502, train_loss: 0.9724332864576649, val_loss: 1.0701400147596367 (57 / 60)
train_acc: 0.6264822134387352, val_acc: 0.5830039525691699, train_loss: 0.9338316130543886, val_loss: 1.0716456631897937 (58 / 60)
train_acc: 0.6225296442687747, val_acc: 0.5830039525691699, train_loss: 0.96036979049562, val_loss: 1.0727701879772744 (59 / 60)
train_acc: 0.6225296442687747, val_acc: 0.5849802371541502, train_loss: 0.94164197576847, val_loss: 1.0732556713428423 (60 / 60)
lr 0.0008377019231346562, batch 8, decay 2.4427015675775187e-06, gamma 0.00903130010323455, val accuracy 0.5849802371541502, val loss 1.0701400147596367 [1 / 50]
-------------------------------------
{'lr': 0.0030494781805484286, 'batch_size': 8, 'weight_decay': 8.884486518195432e-06, 'gamma': 0.013544572840448658}
train_acc: 0.18181818181818182, val_acc: 0.18181818181818182, train_loss: 1.7775946346667444, val_loss: 1.757834677639686 (1 / 60)
train_acc: 0.17984189723320157, val_acc: 0.2964426877470356, train_loss: 1.7588307376906807, val_loss: 1.7320203639773042 (2 / 60)
train_acc: 0.22924901185770752, val_acc: 0.3577075098814229, train_loss: 1.7416578978889072, val_loss: 1.6825788812675024 (3 / 60)
train_acc: 0.2608695652173913, val_acc: 0.3577075098814229, train_loss: 1.676741929864695, val_loss: 1.5727304243758733 (4 / 60)
train_acc: 0.30237154150197626, val_acc: 0.1976284584980237, train_loss: 1.6855697170076633, val_loss: 1.7233095753334255 (5 / 60)
train_acc: 0.22529644268774704, val_acc: 0.22727272727272727, train_loss: 1.7107386650304077, val_loss: 1.790085272826696 (6 / 60)
train_acc: 0.30434782608695654, val_acc: 0.38537549407114624, train_loss: 1.6427124884759956, val_loss: 1.5130483105248613 (7 / 60)
train_acc: 0.3695652173913043, val_acc: 0.40118577075098816, train_loss: 1.5235662469750808, val_loss: 1.4754026407309673 (8 / 60)
train_acc: 0.3300395256916996, val_acc: 0.37351778656126483, train_loss: 1.602314402463408, val_loss: 1.4610896657106904 (9 / 60)
train_acc: 0.34980237154150196, val_acc: 0.31620553359683795, train_loss: 1.498915571469092, val_loss: 1.5673151614637715 (10 / 60)
train_acc: 0.35177865612648224, val_acc: 0.37549407114624506, train_loss: 1.462336137831918, val_loss: 1.3604751754655198 (11 / 60)
train_acc: 0.36561264822134387, val_acc: 0.3438735177865613, train_loss: 1.4180185205851619, val_loss: 1.440333491728711 (12 / 60)
train_acc: 0.3557312252964427, val_acc: 0.31225296442687744, train_loss: 1.4189011023449805, val_loss: 1.5192030465649993 (13 / 60)
train_acc: 0.3715415019762846, val_acc: 0.38735177865612647, train_loss: 1.3903956526352954, val_loss: 1.2985522973207617 (14 / 60)
train_acc: 0.40118577075098816, val_acc: 0.4209486166007905, train_loss: 1.4141894352765894, val_loss: 1.2772575235178347 (15 / 60)
train_acc: 0.4090909090909091, val_acc: 0.3715415019762846, train_loss: 1.401716564248202, val_loss: 1.4073375251453384 (16 / 60)
train_acc: 0.40711462450592883, val_acc: 0.4268774703557312, train_loss: 1.3309905580852344, val_loss: 1.2438103464752317 (17 / 60)
train_acc: 0.37351778656126483, val_acc: 0.4505928853754941, train_loss: 1.378432627251968, val_loss: 1.2397226891498792 (18 / 60)
train_acc: 0.44664031620553357, val_acc: 0.4841897233201581, train_loss: 1.2732874885378147, val_loss: 1.240540003116894 (19 / 60)
train_acc: 0.3952569169960474, val_acc: 0.40118577075098816, train_loss: 1.2576321090162978, val_loss: 1.3274956698945388 (20 / 60)
train_acc: 0.424901185770751, val_acc: 0.4723320158102767, train_loss: 1.2575317776721457, val_loss: 1.2432048132297078 (21 / 60)
train_acc: 0.47035573122529645, val_acc: 0.4782608695652174, train_loss: 1.2395727445956746, val_loss: 1.1852021763918428 (22 / 60)
train_acc: 0.44664031620553357, val_acc: 0.4762845849802372, train_loss: 1.2034218207649563, val_loss: 1.216505525611606 (23 / 60)
train_acc: 0.5138339920948617, val_acc: 0.45454545454545453, train_loss: 1.1690979720104353, val_loss: 1.297414111525645 (24 / 60)
train_acc: 0.5316205533596838, val_acc: 0.49209486166007904, train_loss: 1.1574806453211035, val_loss: 1.1764484125634898 (25 / 60)
train_acc: 0.5395256916996047, val_acc: 0.5513833992094862, train_loss: 1.0755979746226736, val_loss: 1.0750684078503032 (26 / 60)
train_acc: 0.5474308300395256, val_acc: 0.5296442687747036, train_loss: 1.0762569753548845, val_loss: 1.137261429794221 (27 / 60)
train_acc: 0.5652173913043478, val_acc: 0.5632411067193676, train_loss: 1.0281814230760566, val_loss: 1.0843890551993027 (28 / 60)
train_acc: 0.5889328063241107, val_acc: 0.4782608695652174, train_loss: 1.0291389311726384, val_loss: 1.2733205844291113 (29 / 60)
train_acc: 0.5039525691699605, val_acc: 0.5098814229249012, train_loss: 1.164934263398996, val_loss: 1.2516776662570215 (30 / 60)
train_acc: 0.5869565217391305, val_acc: 0.5573122529644269, train_loss: 1.005023211829747, val_loss: 1.0836131252318975 (31 / 60)
train_acc: 0.6264822134387352, val_acc: 0.5237154150197628, train_loss: 0.858666901531898, val_loss: 1.1388668302490776 (32 / 60)
train_acc: 0.6284584980237155, val_acc: 0.541501976284585, train_loss: 0.9025580619163664, val_loss: 1.246612031469232 (33 / 60)
train_acc: 0.6600790513833992, val_acc: 0.5652173913043478, train_loss: 0.832449173738834, val_loss: 1.1186287907272459 (34 / 60)
train_acc: 0.650197628458498, val_acc: 0.5079051383399209, train_loss: 0.8450223282863029, val_loss: 1.354988164110146 (35 / 60)
train_acc: 0.6877470355731226, val_acc: 0.5513833992094862, train_loss: 0.761791014388616, val_loss: 1.3449139491371487 (36 / 60)
train_acc: 0.7391304347826086, val_acc: 0.6126482213438735, train_loss: 0.6698476594427357, val_loss: 1.0941034416436206 (37 / 60)
train_acc: 0.7905138339920948, val_acc: 0.6126482213438735, train_loss: 0.5435424967716805, val_loss: 1.0522701608333662 (38 / 60)
train_acc: 0.808300395256917, val_acc: 0.616600790513834, train_loss: 0.4985483484305883, val_loss: 1.0547898828747715 (39 / 60)
train_acc: 0.7924901185770751, val_acc: 0.616600790513834, train_loss: 0.5010345950428206, val_loss: 1.0586035279888408 (40 / 60)
train_acc: 0.7964426877470355, val_acc: 0.6284584980237155, train_loss: 0.5320548596589462, val_loss: 1.0414478595077756 (41 / 60)
train_acc: 0.8221343873517787, val_acc: 0.6185770750988142, train_loss: 0.44994466530946875, val_loss: 1.0489352187620322 (42 / 60)
train_acc: 0.8300395256916996, val_acc: 0.6225296442687747, train_loss: 0.4708433587089358, val_loss: 1.0548737473167449 (43 / 60)
train_acc: 0.8221343873517787, val_acc: 0.6205533596837944, train_loss: 0.448896997059758, val_loss: 1.0607472573344416 (44 / 60)
train_acc: 0.8102766798418972, val_acc: 0.6225296442687747, train_loss: 0.4767470199600039, val_loss: 1.0590296682161775 (45 / 60)
train_acc: 0.849802371541502, val_acc: 0.6205533596837944, train_loss: 0.4447382561302939, val_loss: 1.0663727993079326 (46 / 60)
train_acc: 0.8280632411067194, val_acc: 0.6264822134387352, train_loss: 0.41864706829131354, val_loss: 1.0690500604305342 (47 / 60)
train_acc: 0.8438735177865613, val_acc: 0.6343873517786561, train_loss: 0.4138432439608065, val_loss: 1.0666744035223257 (48 / 60)
train_acc: 0.8359683794466403, val_acc: 0.6284584980237155, train_loss: 0.43323862646879413, val_loss: 1.0821836022991436 (49 / 60)
train_acc: 0.8478260869565217, val_acc: 0.6225296442687747, train_loss: 0.4055187591450959, val_loss: 1.0920799697340713 (50 / 60)
train_acc: 0.8438735177865613, val_acc: 0.6304347826086957, train_loss: 0.39504383863667725, val_loss: 1.0954729205534863 (51 / 60)
train_acc: 0.8438735177865613, val_acc: 0.6304347826086957, train_loss: 0.40165772998757043, val_loss: 1.1108669758785383 (52 / 60)
train_acc: 0.8596837944664032, val_acc: 0.6284584980237155, train_loss: 0.3922447460913375, val_loss: 1.110174991396576 (53 / 60)
train_acc: 0.8517786561264822, val_acc: 0.6284584980237155, train_loss: 0.39078396817912225, val_loss: 1.131504481489008 (54 / 60)
train_acc: 0.841897233201581, val_acc: 0.6264822134387352, train_loss: 0.38908597626704944, val_loss: 1.1284977593440784 (55 / 60)
train_acc: 0.8458498023715415, val_acc: 0.6324110671936759, train_loss: 0.3694910145559801, val_loss: 1.135844842247341 (56 / 60)
train_acc: 0.8596837944664032, val_acc: 0.6284584980237155, train_loss: 0.3876773832814967, val_loss: 1.144598719630788 (57 / 60)
train_acc: 0.8715415019762845, val_acc: 0.6284584980237155, train_loss: 0.3684511191760127, val_loss: 1.140835190950175 (58 / 60)
train_acc: 0.8478260869565217, val_acc: 0.6245059288537549, train_loss: 0.357839236853151, val_loss: 1.1618573265113379 (59 / 60)
train_acc: 0.8616600790513834, val_acc: 0.6284584980237155, train_loss: 0.3576290807705152, val_loss: 1.163291637134175 (60 / 60)
lr 0.0030494781805484286, batch 8, decay 8.884486518195432e-06, gamma 0.013544572840448658, val accuracy 0.6343873517786561, val loss 1.0666744035223257 [2 / 50]
-------------------------------------
{'lr': 0.00212061237381847, 'batch_size': 8, 'weight_decay': 9.321442446976307e-06, 'gamma': 0.011378541186777249}
train_acc: 0.18774703557312253, val_acc: 0.18181818181818182, train_loss: 1.7797906012403164, val_loss: 1.7565025830928516 (1 / 60)
train_acc: 0.18181818181818182, val_acc: 0.21739130434782608, train_loss: 1.7603711629573535, val_loss: 1.7341642832096387 (2 / 60)
train_acc: 0.23122529644268774, val_acc: 0.191699604743083, train_loss: 1.7425581984840364, val_loss: 1.706185324861127 (3 / 60)
train_acc: 0.2648221343873518, val_acc: 0.274703557312253, train_loss: 1.7246662251091758, val_loss: 1.682378912160519 (4 / 60)
train_acc: 0.26679841897233203, val_acc: 0.3675889328063241, train_loss: 1.6673594727346548, val_loss: 1.461360734442006 (5 / 60)
train_acc: 0.2707509881422925, val_acc: 0.35177865612648224, train_loss: 1.6534141042958135, val_loss: 1.5421196980909868 (6 / 60)
train_acc: 0.3142292490118577, val_acc: 0.39920948616600793, train_loss: 1.55307492625572, val_loss: 1.3931591868871758 (7 / 60)
train_acc: 0.35177865612648224, val_acc: 0.391304347826087, train_loss: 1.507545095187402, val_loss: 1.4187923768763486 (8 / 60)
train_acc: 0.3339920948616601, val_acc: 0.40118577075098816, train_loss: 1.5053267667416057, val_loss: 1.3827255102014353 (9 / 60)
train_acc: 0.32608695652173914, val_acc: 0.36561264822134387, train_loss: 1.5129046949002112, val_loss: 1.348844113086052 (10 / 60)
train_acc: 0.38735177865612647, val_acc: 0.4288537549407115, train_loss: 1.4116160695260693, val_loss: 1.3243773539546921 (11 / 60)
train_acc: 0.3300395256916996, val_acc: 0.4209486166007905, train_loss: 1.4277676207274788, val_loss: 1.3200953553316621 (12 / 60)
train_acc: 0.39723320158102765, val_acc: 0.37549407114624506, train_loss: 1.3753991979855322, val_loss: 1.4283534019832083 (13 / 60)
train_acc: 0.38735177865612647, val_acc: 0.4426877470355731, train_loss: 1.401501406794009, val_loss: 1.2910674579529895 (14 / 60)
train_acc: 0.4150197628458498, val_acc: 0.41304347826086957, train_loss: 1.3465154896611753, val_loss: 1.3005058393176836 (15 / 60)
train_acc: 0.4288537549407115, val_acc: 0.4090909090909091, train_loss: 1.3414590895882708, val_loss: 1.3103349859064275 (16 / 60)
train_acc: 0.40711462450592883, val_acc: 0.424901185770751, train_loss: 1.3490210170802392, val_loss: 1.30313883845514 (17 / 60)
train_acc: 0.4288537549407115, val_acc: 0.4209486166007905, train_loss: 1.3065939533851834, val_loss: 1.3343538719674815 (18 / 60)
train_acc: 0.3715415019762846, val_acc: 0.424901185770751, train_loss: 1.3594517227218086, val_loss: 1.2547533462641267 (19 / 60)
train_acc: 0.44466403162055335, val_acc: 0.41699604743083, train_loss: 1.2604551305883958, val_loss: 1.3544642246758984 (20 / 60)
train_acc: 0.4288537549407115, val_acc: 0.4189723320158103, train_loss: 1.242434568084747, val_loss: 1.2289051152029526 (21 / 60)
train_acc: 0.4268774703557312, val_acc: 0.44466403162055335, train_loss: 1.2677952461091897, val_loss: 1.2471792928786145 (22 / 60)
train_acc: 0.4841897233201581, val_acc: 0.47035573122529645, train_loss: 1.2194250694847861, val_loss: 1.2560856719262044 (23 / 60)
train_acc: 0.4841897233201581, val_acc: 0.5059288537549407, train_loss: 1.1970155978862476, val_loss: 1.1550560282624287 (24 / 60)
train_acc: 0.5098814229249012, val_acc: 0.45652173913043476, train_loss: 1.198044864556535, val_loss: 1.2143742091099736 (25 / 60)
train_acc: 0.5098814229249012, val_acc: 0.49604743083003955, train_loss: 1.1819307144451519, val_loss: 1.2026460330948057 (26 / 60)
train_acc: 0.48023715415019763, val_acc: 0.4762845849802372, train_loss: 1.2242142951535613, val_loss: 1.218399105807067 (27 / 60)
train_acc: 0.4980237154150198, val_acc: 0.4644268774703557, train_loss: 1.122103166203254, val_loss: 1.247508407110282 (28 / 60)
train_acc: 0.5553359683794467, val_acc: 0.5197628458498024, train_loss: 1.0383494969884397, val_loss: 1.143355522702334 (29 / 60)
train_acc: 0.5592885375494071, val_acc: 0.45652173913043476, train_loss: 1.0523017072394902, val_loss: 1.5562384637448157 (30 / 60)
train_acc: 0.5118577075098815, val_acc: 0.5533596837944664, train_loss: 1.0871383380512947, val_loss: 1.0443860118096997 (31 / 60)
train_acc: 0.5731225296442688, val_acc: 0.5849802371541502, train_loss: 0.9722714160270842, val_loss: 1.027472000348238 (32 / 60)
train_acc: 0.5632411067193676, val_acc: 0.4881422924901186, train_loss: 1.0101378213746746, val_loss: 1.109278488536126 (33 / 60)
train_acc: 0.6007905138339921, val_acc: 0.5474308300395256, train_loss: 0.9424340482285842, val_loss: 1.1221016400416377 (34 / 60)
train_acc: 0.6324110671936759, val_acc: 0.5513833992094862, train_loss: 0.893340345427924, val_loss: 1.1564818210752585 (35 / 60)
train_acc: 0.6521739130434783, val_acc: 0.5553359683794467, train_loss: 0.862223454614873, val_loss: 1.1033582988935027 (36 / 60)
train_acc: 0.7055335968379447, val_acc: 0.5711462450592886, train_loss: 0.7171668808450812, val_loss: 1.056753951099079 (37 / 60)
train_acc: 0.7312252964426877, val_acc: 0.5849802371541502, train_loss: 0.6594407226257173, val_loss: 1.0260913593495788 (38 / 60)
train_acc: 0.733201581027668, val_acc: 0.6027667984189723, train_loss: 0.6574371049526652, val_loss: 1.0201743600867954 (39 / 60)
train_acc: 0.7312252964426877, val_acc: 0.6027667984189723, train_loss: 0.6543545788927041, val_loss: 1.0128447811594123 (40 / 60)
train_acc: 0.7450592885375494, val_acc: 0.5988142292490118, train_loss: 0.6225627981155757, val_loss: 1.0136268595932971 (41 / 60)
train_acc: 0.7786561264822134, val_acc: 0.6047430830039525, train_loss: 0.5821151431841342, val_loss: 1.023439795603394 (42 / 60)
train_acc: 0.7984189723320159, val_acc: 0.6047430830039525, train_loss: 0.5600446585138796, val_loss: 1.029696908392925 (43 / 60)
train_acc: 0.7470355731225297, val_acc: 0.6047430830039525, train_loss: 0.613130743795704, val_loss: 1.0307748204634595 (44 / 60)
train_acc: 0.7608695652173914, val_acc: 0.6047430830039525, train_loss: 0.595252160969459, val_loss: 1.028103512266408 (45 / 60)
train_acc: 0.7707509881422925, val_acc: 0.6047430830039525, train_loss: 0.5839124114617057, val_loss: 1.0304204037066975 (46 / 60)
train_acc: 0.7806324110671937, val_acc: 0.6047430830039525, train_loss: 0.5904718910752549, val_loss: 1.034696669917804 (47 / 60)
train_acc: 0.7707509881422925, val_acc: 0.6086956521739131, train_loss: 0.5761507846150002, val_loss: 1.04090623186511 (48 / 60)
train_acc: 0.7865612648221344, val_acc: 0.6086956521739131, train_loss: 0.5691652825698551, val_loss: 1.0489384539042537 (49 / 60)
train_acc: 0.8063241106719368, val_acc: 0.6067193675889329, train_loss: 0.5355992067472737, val_loss: 1.054022602648603 (50 / 60)
train_acc: 0.7786561264822134, val_acc: 0.6067193675889329, train_loss: 0.5342233006662059, val_loss: 1.0601894747127185 (51 / 60)
train_acc: 0.782608695652174, val_acc: 0.6106719367588933, train_loss: 0.5339216672384692, val_loss: 1.0622138878102358 (52 / 60)
train_acc: 0.8043478260869565, val_acc: 0.6067193675889329, train_loss: 0.5117529128851156, val_loss: 1.0721584991975264 (53 / 60)
train_acc: 0.7905138339920948, val_acc: 0.6007905138339921, train_loss: 0.5287567878900309, val_loss: 1.076290197523215 (54 / 60)
train_acc: 0.7964426877470355, val_acc: 0.6047430830039525, train_loss: 0.5163701115389586, val_loss: 1.0757411016305916 (55 / 60)
train_acc: 0.7905138339920948, val_acc: 0.6067193675889329, train_loss: 0.5118104304249579, val_loss: 1.0829841346137608 (56 / 60)
train_acc: 0.7865612648221344, val_acc: 0.6086956521739131, train_loss: 0.5485404576708677, val_loss: 1.0759556253436997 (57 / 60)
train_acc: 0.8063241106719368, val_acc: 0.6067193675889329, train_loss: 0.4859414854539713, val_loss: 1.0852690251919592 (58 / 60)
train_acc: 0.8003952569169961, val_acc: 0.6027667984189723, train_loss: 0.5166564421220259, val_loss: 1.082440454969293 (59 / 60)
train_acc: 0.8023715415019763, val_acc: 0.6067193675889329, train_loss: 0.5275069204243746, val_loss: 1.0859321186193835 (60 / 60)
lr 0.00212061237381847, batch 8, decay 9.321442446976307e-06, gamma 0.011378541186777249, val accuracy 0.6106719367588933, val loss 1.0622138878102358 [3 / 50]
-------------------------------------
{'lr': 0.002712726773730524, 'batch_size': 8, 'weight_decay': 5.8854060643094e-06, 'gamma': 0.026493660813106813}
train_acc: 0.20948616600790515, val_acc: 0.18774703557312253, train_loss: 1.7777206511365566, val_loss: 1.7578480974016453 (1 / 60)
train_acc: 0.191699604743083, val_acc: 0.2608695652173913, train_loss: 1.7636380073110105, val_loss: 1.7394952519609053 (2 / 60)
train_acc: 0.2075098814229249, val_acc: 0.18181818181818182, train_loss: 1.7568707593344888, val_loss: 1.7276538869609004 (3 / 60)
train_acc: 0.2826086956521739, val_acc: 0.23715415019762845, train_loss: 1.7046636451374402, val_loss: 1.6295605761260383 (4 / 60)
train_acc: 0.22529644268774704, val_acc: 0.3695652173913043, train_loss: 1.6949876589266208, val_loss: 1.5134209102321519 (5 / 60)
train_acc: 0.2707509881422925, val_acc: 0.23517786561264822, train_loss: 1.6503775515575183, val_loss: 1.6639738007496467 (6 / 60)
train_acc: 0.2608695652173913, val_acc: 0.3221343873517787, train_loss: 1.6213545403461682, val_loss: 1.532377351649665 (7 / 60)
train_acc: 0.32806324110671936, val_acc: 0.3695652173913043, train_loss: 1.5819370539292046, val_loss: 1.4539444100244243 (8 / 60)
train_acc: 0.33794466403162055, val_acc: 0.2826086956521739, train_loss: 1.5094945840684793, val_loss: 1.6672482382167468 (9 / 60)
train_acc: 0.34980237154150196, val_acc: 0.41699604743083, train_loss: 1.54929676946444, val_loss: 1.3966552200524702 (10 / 60)
train_acc: 0.38537549407114624, val_acc: 0.40711462450592883, train_loss: 1.462496263000805, val_loss: 1.3833346267933901 (11 / 60)
train_acc: 0.33201581027667987, val_acc: 0.39723320158102765, train_loss: 1.4820886016363213, val_loss: 1.3435262363889944 (12 / 60)
train_acc: 0.33201581027667987, val_acc: 0.4189723320158103, train_loss: 1.504361162072585, val_loss: 1.4177819570533843 (13 / 60)
train_acc: 0.3359683794466403, val_acc: 0.391304347826087, train_loss: 1.4347147800234468, val_loss: 1.40906254905957 (14 / 60)
train_acc: 0.3952569169960474, val_acc: 0.42292490118577075, train_loss: 1.3893333103345789, val_loss: 1.301289892479365 (15 / 60)
train_acc: 0.39723320158102765, val_acc: 0.43873517786561267, train_loss: 1.3507341212434731, val_loss: 1.3054183992472561 (16 / 60)
train_acc: 0.3814229249011858, val_acc: 0.41699604743083, train_loss: 1.3465446266732197, val_loss: 1.2611516257048596 (17 / 60)
train_acc: 0.34980237154150196, val_acc: 0.3675889328063241, train_loss: 1.5039075664851977, val_loss: 1.386007823491756 (18 / 60)
train_acc: 0.41304347826086957, val_acc: 0.45652173913043476, train_loss: 1.3139781066080327, val_loss: 1.2161605134311873 (19 / 60)
train_acc: 0.4367588932806324, val_acc: 0.42292490118577075, train_loss: 1.2634731243721582, val_loss: 1.35602935830595 (20 / 60)
train_acc: 0.49209486166007904, val_acc: 0.4901185770750988, train_loss: 1.2383972335709885, val_loss: 1.2091776749833298 (21 / 60)
train_acc: 0.4683794466403162, val_acc: 0.41106719367588934, train_loss: 1.2384047786237693, val_loss: 1.2994136810302734 (22 / 60)
train_acc: 0.4426877470355731, val_acc: 0.44861660079051385, train_loss: 1.2927544917984914, val_loss: 1.2631974335715705 (23 / 60)
train_acc: 0.4505928853754941, val_acc: 0.4901185770750988, train_loss: 1.2512181728724905, val_loss: 1.1793140394414368 (24 / 60)
train_acc: 0.5, val_acc: 0.5138339920948617, train_loss: 1.1960657747837866, val_loss: 1.148833547185061 (25 / 60)
train_acc: 0.5, val_acc: 0.4525691699604743, train_loss: 1.1791272695827861, val_loss: 1.1604611199835073 (26 / 60)
train_acc: 0.5098814229249012, val_acc: 0.525691699604743, train_loss: 1.1696789132747725, val_loss: 1.1219409275431877 (27 / 60)
train_acc: 0.5454545454545454, val_acc: 0.5474308300395256, train_loss: 1.1066294211172776, val_loss: 1.04255599890773 (28 / 60)
train_acc: 0.5474308300395256, val_acc: 0.46047430830039526, train_loss: 1.0154104864173257, val_loss: 1.4143630153105664 (29 / 60)
train_acc: 0.5434782608695652, val_acc: 0.5296442687747036, train_loss: 1.0855611360120208, val_loss: 1.0771952994727334 (30 / 60)
train_acc: 0.6245059288537549, val_acc: 0.49604743083003955, train_loss: 0.9166464751416986, val_loss: 1.3278064463920745 (31 / 60)
train_acc: 0.5513833992094862, val_acc: 0.466403162055336, train_loss: 1.0916921696644055, val_loss: 1.1815513706961167 (32 / 60)
train_acc: 0.6225296442687747, val_acc: 0.5592885375494071, train_loss: 0.9528079494657252, val_loss: 1.089926497267169 (33 / 60)
train_acc: 0.6482213438735178, val_acc: 0.5177865612648221, train_loss: 0.8811509868373042, val_loss: 1.3089400171762398 (34 / 60)
train_acc: 0.6877470355731226, val_acc: 0.5711462450592886, train_loss: 0.7769109552556818, val_loss: 1.0898515315866282 (35 / 60)
train_acc: 0.6758893280632411, val_acc: 0.6047430830039525, train_loss: 0.7764245507274221, val_loss: 1.0634075181757507 (36 / 60)
train_acc: 0.7747035573122529, val_acc: 0.6324110671936759, train_loss: 0.5867789941342924, val_loss: 0.9648411306939106 (37 / 60)
train_acc: 0.7865612648221344, val_acc: 0.6363636363636364, train_loss: 0.5285565877856002, val_loss: 0.9649690229430972 (38 / 60)
train_acc: 0.8063241106719368, val_acc: 0.6343873517786561, train_loss: 0.4900270610929949, val_loss: 0.9638542045246471 (39 / 60)
train_acc: 0.7727272727272727, val_acc: 0.6561264822134387, train_loss: 0.5261042586899558, val_loss: 0.9747214453964836 (40 / 60)
train_acc: 0.83399209486166, val_acc: 0.6521739130434783, train_loss: 0.4458505900009819, val_loss: 0.983853936430965 (41 / 60)
train_acc: 0.8260869565217391, val_acc: 0.6383399209486166, train_loss: 0.45991452432903845, val_loss: 1.0172283093448684 (42 / 60)
train_acc: 0.8221343873517787, val_acc: 0.6482213438735178, train_loss: 0.4593596533824333, val_loss: 1.0089006522898618 (43 / 60)
train_acc: 0.8181818181818182, val_acc: 0.650197628458498, train_loss: 0.4515140049542363, val_loss: 1.0008070530156372 (44 / 60)
train_acc: 0.7944664031620553, val_acc: 0.6442687747035574, train_loss: 0.5021069386731023, val_loss: 1.0181460990736135 (45 / 60)
train_acc: 0.8241106719367589, val_acc: 0.642292490118577, train_loss: 0.43829305770368915, val_loss: 1.0207611270572827 (46 / 60)
train_acc: 0.8438735177865613, val_acc: 0.650197628458498, train_loss: 0.4169529813080437, val_loss: 1.0419103321821794 (47 / 60)
train_acc: 0.841897233201581, val_acc: 0.650197628458498, train_loss: 0.4185962005566231, val_loss: 1.0518511241603745 (48 / 60)
train_acc: 0.83399209486166, val_acc: 0.6442687747035574, train_loss: 0.4081472288007322, val_loss: 1.0684784108942205 (49 / 60)
train_acc: 0.8221343873517787, val_acc: 0.6541501976284585, train_loss: 0.41312206568925275, val_loss: 1.053737935812577 (50 / 60)
train_acc: 0.849802371541502, val_acc: 0.6521739130434783, train_loss: 0.41194108446596167, val_loss: 1.0775199073105461 (51 / 60)
train_acc: 0.8438735177865613, val_acc: 0.6699604743083004, train_loss: 0.40742246624038153, val_loss: 1.0580583695366448 (52 / 60)
train_acc: 0.8675889328063241, val_acc: 0.6600790513833992, train_loss: 0.37312237217492267, val_loss: 1.0747776615761013 (53 / 60)
train_acc: 0.857707509881423, val_acc: 0.66600790513834, train_loss: 0.3842005626015041, val_loss: 1.089523989692507 (54 / 60)
train_acc: 0.849802371541502, val_acc: 0.6758893280632411, train_loss: 0.3824360848886693, val_loss: 1.0874813352177737 (55 / 60)
train_acc: 0.8774703557312253, val_acc: 0.6679841897233202, train_loss: 0.37116674684253137, val_loss: 1.0955687473885156 (56 / 60)
train_acc: 0.8557312252964426, val_acc: 0.650197628458498, train_loss: 0.3693434563078899, val_loss: 1.1246785476744883 (57 / 60)
train_acc: 0.8596837944664032, val_acc: 0.6640316205533597, train_loss: 0.3432714277105369, val_loss: 1.1076289283428267 (58 / 60)
train_acc: 0.8537549407114624, val_acc: 0.6758893280632411, train_loss: 0.34280849115650647, val_loss: 1.123028545040387 (59 / 60)
train_acc: 0.8478260869565217, val_acc: 0.6541501976284585, train_loss: 0.37042506504435785, val_loss: 1.1351790126604524 (60 / 60)
lr 0.002712726773730524, batch 8, decay 5.8854060643094e-06, gamma 0.026493660813106813, val accuracy 0.6758893280632411, val loss 1.0874813352177737 [4 / 50]
-------------------------------------
{'lr': 0.0010316163585472981, 'batch_size': 8, 'weight_decay': 1.8309942558988887e-05, 'gamma': 0.002673690056313373}
train_acc: 0.16798418972332016, val_acc: 0.2391304347826087, train_loss: 1.7823962222917278, val_loss: 1.7641021413765405 (1 / 60)
train_acc: 0.20948616600790515, val_acc: 0.18181818181818182, train_loss: 1.7652267420244783, val_loss: 1.7514882167808623 (2 / 60)
train_acc: 0.17786561264822134, val_acc: 0.2509881422924901, train_loss: 1.7606581722794785, val_loss: 1.7418893080926223 (3 / 60)
train_acc: 0.2075098814229249, val_acc: 0.23122529644268774, train_loss: 1.7523407097390518, val_loss: 1.7267038784479436 (4 / 60)
train_acc: 0.2608695652173913, val_acc: 0.2865612648221344, train_loss: 1.732841136427265, val_loss: 1.6880603991007146 (5 / 60)
train_acc: 0.274703557312253, val_acc: 0.30039525691699603, train_loss: 1.6956197508710176, val_loss: 1.656539442510944 (6 / 60)
train_acc: 0.2964426877470356, val_acc: 0.34189723320158105, train_loss: 1.6436311953623775, val_loss: 1.547678423493276 (7 / 60)
train_acc: 0.3102766798418972, val_acc: 0.37351778656126483, train_loss: 1.618991201574152, val_loss: 1.5855746796950991 (8 / 60)
train_acc: 0.3557312252964427, val_acc: 0.33992094861660077, train_loss: 1.5592877403078342, val_loss: 1.5523335219843115 (9 / 60)
train_acc: 0.2964426877470356, val_acc: 0.2628458498023715, train_loss: 1.5481644609700078, val_loss: 1.772428854652073 (10 / 60)
train_acc: 0.34782608695652173, val_acc: 0.35375494071146246, train_loss: 1.5312189678900798, val_loss: 1.4123868574738032 (11 / 60)
train_acc: 0.35968379446640314, val_acc: 0.38537549407114624, train_loss: 1.5036470428285862, val_loss: 1.365391919735392 (12 / 60)
train_acc: 0.32806324110671936, val_acc: 0.4051383399209486, train_loss: 1.4878864179957996, val_loss: 1.3363853174707163 (13 / 60)
train_acc: 0.4031620553359684, val_acc: 0.40118577075098816, train_loss: 1.4064886829127436, val_loss: 1.3706859920335852 (14 / 60)
train_acc: 0.3300395256916996, val_acc: 0.4209486166007905, train_loss: 1.4642956558423552, val_loss: 1.3390208902095146 (15 / 60)
train_acc: 0.37351778656126483, val_acc: 0.37549407114624506, train_loss: 1.3909692556961724, val_loss: 1.4829176864605176 (16 / 60)
train_acc: 0.40711462450592883, val_acc: 0.3952569169960474, train_loss: 1.3725942368563928, val_loss: 1.3121487792772737 (17 / 60)
train_acc: 0.40118577075098816, val_acc: 0.4150197628458498, train_loss: 1.4135410634896501, val_loss: 1.3497082659378354 (18 / 60)
train_acc: 0.383399209486166, val_acc: 0.4268774703557312, train_loss: 1.3616663014935881, val_loss: 1.302069850589918 (19 / 60)
train_acc: 0.391304347826087, val_acc: 0.40118577075098816, train_loss: 1.3720440567717722, val_loss: 1.336023867837054 (20 / 60)
train_acc: 0.4209486166007905, val_acc: 0.4150197628458498, train_loss: 1.3260235692201396, val_loss: 1.2865854063524087 (21 / 60)
train_acc: 0.4407114624505929, val_acc: 0.46047430830039526, train_loss: 1.3198023728231196, val_loss: 1.2306164385301794 (22 / 60)
train_acc: 0.42292490118577075, val_acc: 0.4782608695652174, train_loss: 1.2980286316438154, val_loss: 1.2277814281787798 (23 / 60)
train_acc: 0.44861660079051385, val_acc: 0.45454545454545453, train_loss: 1.2621938541472666, val_loss: 1.2769301498360313 (24 / 60)
train_acc: 0.4407114624505929, val_acc: 0.4367588932806324, train_loss: 1.3171944384989531, val_loss: 1.236891887875885 (25 / 60)
train_acc: 0.4150197628458498, val_acc: 0.3952569169960474, train_loss: 1.303622690585291, val_loss: 1.3808909833666836 (26 / 60)
train_acc: 0.4525691699604743, val_acc: 0.4723320158102767, train_loss: 1.2576826876802407, val_loss: 1.251111929595706 (27 / 60)
train_acc: 0.45652173913043476, val_acc: 0.466403162055336, train_loss: 1.2288127635778645, val_loss: 1.192153431210122 (28 / 60)
train_acc: 0.5039525691699605, val_acc: 0.4881422924901186, train_loss: 1.1932284949796472, val_loss: 1.230263063558948 (29 / 60)
train_acc: 0.4980237154150198, val_acc: 0.4644268774703557, train_loss: 1.2230818111434756, val_loss: 1.209880213256881 (30 / 60)
train_acc: 0.525691699604743, val_acc: 0.525691699604743, train_loss: 1.1598109727791646, val_loss: 1.2367427452750828 (31 / 60)
train_acc: 0.5098814229249012, val_acc: 0.45454545454545453, train_loss: 1.1708647891466797, val_loss: 1.3340794257966897 (32 / 60)
train_acc: 0.4723320158102767, val_acc: 0.5019762845849802, train_loss: 1.2284919433442971, val_loss: 1.149225753522202 (33 / 60)
train_acc: 0.5395256916996047, val_acc: 0.48023715415019763, train_loss: 1.133814179379007, val_loss: 1.2144293113659492 (34 / 60)
train_acc: 0.5474308300395256, val_acc: 0.5039525691699605, train_loss: 1.0852217087632583, val_loss: 1.183186561693787 (35 / 60)
train_acc: 0.5988142292490118, val_acc: 0.5079051383399209, train_loss: 1.0253848874050637, val_loss: 1.0756015433624329 (36 / 60)
train_acc: 0.5869565217391305, val_acc: 0.5197628458498024, train_loss: 0.9693899969809612, val_loss: 1.0695679861566294 (37 / 60)
train_acc: 0.575098814229249, val_acc: 0.5079051383399209, train_loss: 0.9407979433715579, val_loss: 1.064878378461001 (38 / 60)
train_acc: 0.5869565217391305, val_acc: 0.5197628458498024, train_loss: 0.9715416026209654, val_loss: 1.0613532645900259 (39 / 60)
train_acc: 0.5711462450592886, val_acc: 0.5177865612648221, train_loss: 0.9600608699877743, val_loss: 1.0587740408573225 (40 / 60)
train_acc: 0.6106719367588933, val_acc: 0.5217391304347826, train_loss: 0.9633878742753281, val_loss: 1.055327614776702 (41 / 60)
train_acc: 0.6264822134387352, val_acc: 0.5197628458498024, train_loss: 0.936892431008486, val_loss: 1.0535226560864053 (42 / 60)
train_acc: 0.6205533596837944, val_acc: 0.5177865612648221, train_loss: 0.9479860543262346, val_loss: 1.0516867868513928 (43 / 60)
train_acc: 0.616600790513834, val_acc: 0.5237154150197628, train_loss: 0.9541117313351084, val_loss: 1.0504843557305015 (44 / 60)
train_acc: 0.6245059288537549, val_acc: 0.5296442687747036, train_loss: 0.9269657761683106, val_loss: 1.049768557661607 (45 / 60)
train_acc: 0.6126482213438735, val_acc: 0.5316205533596838, train_loss: 0.937791891248801, val_loss: 1.0488712832390554 (46 / 60)
train_acc: 0.6126482213438735, val_acc: 0.5355731225296443, train_loss: 0.9154932239781255, val_loss: 1.0488932196330647 (47 / 60)
train_acc: 0.6304347826086957, val_acc: 0.5375494071146245, train_loss: 0.8904790138538647, val_loss: 1.0487863847860706 (48 / 60)
train_acc: 0.6086956521739131, val_acc: 0.5395256916996047, train_loss: 0.94146281928413, val_loss: 1.0484043371536045 (49 / 60)
train_acc: 0.6245059288537549, val_acc: 0.5434782608695652, train_loss: 0.9181554472964742, val_loss: 1.0469105983440112 (50 / 60)
train_acc: 0.616600790513834, val_acc: 0.5533596837944664, train_loss: 0.8987572876361047, val_loss: 1.0477815758098254 (51 / 60)
train_acc: 0.6264822134387352, val_acc: 0.5533596837944664, train_loss: 0.9098680598933706, val_loss: 1.0478468878938276 (52 / 60)
train_acc: 0.6264822134387352, val_acc: 0.5533596837944664, train_loss: 0.8942669257816118, val_loss: 1.0477094391117925 (53 / 60)
train_acc: 0.6304347826086957, val_acc: 0.5553359683794467, train_loss: 0.905107174937433, val_loss: 1.0471057496052014 (54 / 60)
train_acc: 0.6482213438735178, val_acc: 0.5533596837944664, train_loss: 0.8980162303909482, val_loss: 1.047002867512081 (55 / 60)
train_acc: 0.6106719367588933, val_acc: 0.5553359683794467, train_loss: 0.9344749003059779, val_loss: 1.0477915022212998 (56 / 60)
train_acc: 0.6403162055335968, val_acc: 0.5553359683794467, train_loss: 0.8861634344922695, val_loss: 1.0482388748952993 (57 / 60)
train_acc: 0.6343873517786561, val_acc: 0.5573122529644269, train_loss: 0.8856743663667219, val_loss: 1.0483091212072861 (58 / 60)
train_acc: 0.6403162055335968, val_acc: 0.5592885375494071, train_loss: 0.9096247546757634, val_loss: 1.0480610431418589 (59 / 60)
train_acc: 0.6304347826086957, val_acc: 0.5592885375494071, train_loss: 0.9025573626808499, val_loss: 1.049374477665415 (60 / 60)
lr 0.0010316163585472981, batch 8, decay 1.8309942558988887e-05, gamma 0.002673690056313373, val accuracy 0.5592885375494071, val loss 1.0480610431418589 [5 / 50]
-------------------------------------
{'lr': 0.0016661746592012004, 'batch_size': 8, 'weight_decay': 3.3763075569909223e-06, 'gamma': 0.006052773438030023}
train_acc: 0.18379446640316205, val_acc: 0.26679841897233203, train_loss: 1.7838231117829033, val_loss: 1.7631690605827 (1 / 60)
train_acc: 0.18379446640316205, val_acc: 0.233201581027668, train_loss: 1.7676597301196675, val_loss: 1.7576641249562441 (2 / 60)
train_acc: 0.20355731225296442, val_acc: 0.20355731225296442, train_loss: 1.7593263147376743, val_loss: 1.7336803415547246 (3 / 60)
train_acc: 0.22134387351778656, val_acc: 0.18972332015810275, train_loss: 1.750813768786404, val_loss: 1.710713305492175 (4 / 60)
train_acc: 0.27865612648221344, val_acc: 0.30632411067193677, train_loss: 1.7171610353492466, val_loss: 1.694306465948052 (5 / 60)
train_acc: 0.29051383399209485, val_acc: 0.37351778656126483, train_loss: 1.6572669249749465, val_loss: 1.5748348900451963 (6 / 60)
train_acc: 0.3181818181818182, val_acc: 0.29051383399209485, train_loss: 1.6036947207017378, val_loss: 1.5998120020500757 (7 / 60)
train_acc: 0.31225296442687744, val_acc: 0.21739130434782608, train_loss: 1.5964779128199038, val_loss: 1.7372781716787769 (8 / 60)
train_acc: 0.33992094861660077, val_acc: 0.3557312252964427, train_loss: 1.583963409714077, val_loss: 1.4369545067723088 (9 / 60)
train_acc: 0.33794466403162055, val_acc: 0.35968379446640314, train_loss: 1.5238658637397373, val_loss: 1.4409087392181277 (10 / 60)
train_acc: 0.34980237154150196, val_acc: 0.424901185770751, train_loss: 1.4609663439362417, val_loss: 1.3374867590048567 (11 / 60)
train_acc: 0.3893280632411067, val_acc: 0.3359683794466403, train_loss: 1.4974941665476018, val_loss: 1.5974099113064792 (12 / 60)
train_acc: 0.3577075098814229, val_acc: 0.3577075098814229, train_loss: 1.4456129964632478, val_loss: 1.5143135927411406 (13 / 60)
train_acc: 0.3557312252964427, val_acc: 0.39723320158102765, train_loss: 1.4700697771174163, val_loss: 1.350370432548372 (14 / 60)
train_acc: 0.3932806324110672, val_acc: 0.44466403162055335, train_loss: 1.3753936469790493, val_loss: 1.328543264404116 (15 / 60)
train_acc: 0.35968379446640314, val_acc: 0.424901185770751, train_loss: 1.3605298595466162, val_loss: 1.3019270439864148 (16 / 60)
train_acc: 0.4189723320158103, val_acc: 0.4051383399209486, train_loss: 1.3799828870494375, val_loss: 1.3404793501371453 (17 / 60)
train_acc: 0.391304347826087, val_acc: 0.4150197628458498, train_loss: 1.357124773881181, val_loss: 1.3158204027786558 (18 / 60)
train_acc: 0.43478260869565216, val_acc: 0.466403162055336, train_loss: 1.2740800701111201, val_loss: 1.2321560194369832 (19 / 60)
train_acc: 0.4367588932806324, val_acc: 0.45454545454545453, train_loss: 1.2930089664082283, val_loss: 1.274469251924824 (20 / 60)
train_acc: 0.41304347826086957, val_acc: 0.45652173913043476, train_loss: 1.3013488614983237, val_loss: 1.2170031895279414 (21 / 60)
train_acc: 0.4367588932806324, val_acc: 0.4209486166007905, train_loss: 1.2641097349611667, val_loss: 1.291283687584014 (22 / 60)
train_acc: 0.4505928853754941, val_acc: 0.48616600790513836, train_loss: 1.2482588903706064, val_loss: 1.2469726890443342 (23 / 60)
train_acc: 0.4505928853754941, val_acc: 0.4407114624505929, train_loss: 1.2236561751648372, val_loss: 1.2542661701737656 (24 / 60)
train_acc: 0.4723320158102767, val_acc: 0.4743083003952569, train_loss: 1.2518829234503945, val_loss: 1.2089248568172983 (25 / 60)
train_acc: 0.5019762845849802, val_acc: 0.4407114624505929, train_loss: 1.176956649825507, val_loss: 1.2915419571013318 (26 / 60)
train_acc: 0.49604743083003955, val_acc: 0.45454545454545453, train_loss: 1.1893896010553413, val_loss: 1.2974431802161597 (27 / 60)
train_acc: 0.5, val_acc: 0.5098814229249012, train_loss: 1.175304285622397, val_loss: 1.1168525902178918 (28 / 60)
train_acc: 0.5197628458498024, val_acc: 0.5316205533596838, train_loss: 1.119547868199028, val_loss: 1.0759339195937507 (29 / 60)
train_acc: 0.549407114624506, val_acc: 0.5335968379446641, train_loss: 1.0361273717503303, val_loss: 1.1483518182053396 (30 / 60)
train_acc: 0.541501976284585, val_acc: 0.5335968379446641, train_loss: 1.0648610846327227, val_loss: 1.2130384657222764 (31 / 60)
train_acc: 0.5612648221343873, val_acc: 0.541501976284585, train_loss: 1.023298245644852, val_loss: 1.1267558423426782 (32 / 60)
train_acc: 0.5533596837944664, val_acc: 0.5098814229249012, train_loss: 0.9856541797577628, val_loss: 1.1843657333389102 (33 / 60)
train_acc: 0.5830039525691699, val_acc: 0.5474308300395256, train_loss: 0.9595875165208055, val_loss: 1.0336129844424282 (34 / 60)
train_acc: 0.5889328063241107, val_acc: 0.5632411067193676, train_loss: 0.9647402466521433, val_loss: 1.0315343367723608 (35 / 60)
train_acc: 0.6363636363636364, val_acc: 0.5731225296442688, train_loss: 0.9251785834316208, val_loss: 1.0739603805918938 (36 / 60)
train_acc: 0.717391304347826, val_acc: 0.5889328063241107, train_loss: 0.7397268979916931, val_loss: 1.047825811408725 (37 / 60)
train_acc: 0.7213438735177866, val_acc: 0.5909090909090909, train_loss: 0.7204989303242076, val_loss: 1.0381914593956687 (38 / 60)
train_acc: 0.7114624505928854, val_acc: 0.5909090909090909, train_loss: 0.7250851355051334, val_loss: 1.0308933182667366 (39 / 60)
train_acc: 0.7213438735177866, val_acc: 0.5928853754940712, train_loss: 0.6925742809951541, val_loss: 1.0333290279147183 (40 / 60)
train_acc: 0.7055335968379447, val_acc: 0.5928853754940712, train_loss: 0.7015867303953811, val_loss: 1.0350754171492083 (41 / 60)
train_acc: 0.7233201581027668, val_acc: 0.5948616600790514, train_loss: 0.6706341806607755, val_loss: 1.0378658719684766 (42 / 60)
train_acc: 0.7094861660079052, val_acc: 0.5968379446640316, train_loss: 0.7182595074883563, val_loss: 1.0376253933774624 (43 / 60)
train_acc: 0.7371541501976284, val_acc: 0.5988142292490118, train_loss: 0.6765190353506638, val_loss: 1.039376254138268 (44 / 60)
train_acc: 0.7569169960474308, val_acc: 0.5968379446640316, train_loss: 0.6504866855417787, val_loss: 1.039945309105598 (45 / 60)
train_acc: 0.7075098814229249, val_acc: 0.5988142292490118, train_loss: 0.7072761803276454, val_loss: 1.041557676236149 (46 / 60)
train_acc: 0.7292490118577075, val_acc: 0.5968379446640316, train_loss: 0.6807989518161819, val_loss: 1.0441785311039258 (47 / 60)
train_acc: 0.7272727272727273, val_acc: 0.6007905138339921, train_loss: 0.6674980608370935, val_loss: 1.043277362354188 (48 / 60)
train_acc: 0.7193675889328063, val_acc: 0.5988142292490118, train_loss: 0.670485989378375, val_loss: 1.044449402880763 (49 / 60)
train_acc: 0.7766798418972332, val_acc: 0.5968379446640316, train_loss: 0.6055522926240099, val_loss: 1.0490673865254216 (50 / 60)
train_acc: 0.7252964426877471, val_acc: 0.6007905138339921, train_loss: 0.6903296181335751, val_loss: 1.0443362381618484 (51 / 60)
train_acc: 0.733201581027668, val_acc: 0.6007905138339921, train_loss: 0.6446159234631202, val_loss: 1.045059877893199 (52 / 60)
train_acc: 0.7549407114624506, val_acc: 0.6007905138339921, train_loss: 0.649030315546179, val_loss: 1.0422907370352463 (53 / 60)
train_acc: 0.7272727272727273, val_acc: 0.6027667984189723, train_loss: 0.65270381718285, val_loss: 1.0457178373110625 (54 / 60)
train_acc: 0.7569169960474308, val_acc: 0.6067193675889329, train_loss: 0.6723669729685123, val_loss: 1.0441360360548901 (55 / 60)
train_acc: 0.7608695652173914, val_acc: 0.6067193675889329, train_loss: 0.6241449433353108, val_loss: 1.0454078936294133 (56 / 60)
train_acc: 0.733201581027668, val_acc: 0.6007905138339921, train_loss: 0.6815374943578667, val_loss: 1.0463825393571213 (57 / 60)
train_acc: 0.7371541501976284, val_acc: 0.6027667984189723, train_loss: 0.644745541184316, val_loss: 1.049457514710106 (58 / 60)
train_acc: 0.7608695652173914, val_acc: 0.6067193675889329, train_loss: 0.6403603360586958, val_loss: 1.0491420091847656 (59 / 60)
train_acc: 0.7727272727272727, val_acc: 0.6027667984189723, train_loss: 0.5955290358528318, val_loss: 1.0487755357983555 (60 / 60)
lr 0.0016661746592012004, batch 8, decay 3.3763075569909223e-06, gamma 0.006052773438030023, val accuracy 0.6067193675889329, val loss 1.0441360360548901 [6 / 50]
-------------------------------------
{'lr': 0.002257902637477237, 'batch_size': 8, 'weight_decay': 2.1782988426701316e-06, 'gamma': 0.05463232441247336}
train_acc: 0.18972332015810275, val_acc: 0.22134387351778656, train_loss: 1.7825825087166587, val_loss: 1.7609012254142007 (1 / 60)
train_acc: 0.18774703557312253, val_acc: 0.18181818181818182, train_loss: 1.7650143657277224, val_loss: 1.750250033710314 (2 / 60)
train_acc: 0.20355731225296442, val_acc: 0.24308300395256918, train_loss: 1.7541311828515276, val_loss: 1.7234749850548303 (3 / 60)
train_acc: 0.23517786561264822, val_acc: 0.24308300395256918, train_loss: 1.746469700289338, val_loss: 1.6874491678396233 (4 / 60)
train_acc: 0.2391304347826087, val_acc: 0.31225296442687744, train_loss: 1.7002036364182183, val_loss: 1.6232141383551797 (5 / 60)
train_acc: 0.2885375494071146, val_acc: 0.3181818181818182, train_loss: 1.6924305376799211, val_loss: 1.6088158575442468 (6 / 60)
train_acc: 0.3300395256916996, val_acc: 0.38735177865612647, train_loss: 1.5724217128376716, val_loss: 1.4689947418544604 (7 / 60)
train_acc: 0.3438735177865613, val_acc: 0.4031620553359684, train_loss: 1.5478192511283362, val_loss: 1.395864372196876 (8 / 60)
train_acc: 0.3102766798418972, val_acc: 0.383399209486166, train_loss: 1.4975329302987563, val_loss: 1.3860667456280102 (9 / 60)
train_acc: 0.36363636363636365, val_acc: 0.38537549407114624, train_loss: 1.4512943382790908, val_loss: 1.3587964309062883 (10 / 60)
train_acc: 0.3557312252964427, val_acc: 0.36561264822134387, train_loss: 1.4425342488194643, val_loss: 1.3500955649044202 (11 / 60)
train_acc: 0.3794466403162055, val_acc: 0.4288537549407115, train_loss: 1.4013010894828164, val_loss: 1.3102353834823186 (12 / 60)
train_acc: 0.37351778656126483, val_acc: 0.4426877470355731, train_loss: 1.450145782689332, val_loss: 1.291519102136137 (13 / 60)
train_acc: 0.41304347826086957, val_acc: 0.41106719367588934, train_loss: 1.3536756726592898, val_loss: 1.282610321233395 (14 / 60)
train_acc: 0.41699604743083, val_acc: 0.4683794466403162, train_loss: 1.337321312531181, val_loss: 1.2512721808060356 (15 / 60)
train_acc: 0.4189723320158103, val_acc: 0.4209486166007905, train_loss: 1.3117836699655405, val_loss: 1.3150609693979558 (16 / 60)
train_acc: 0.3794466403162055, val_acc: 0.41699604743083, train_loss: 1.3440110509103467, val_loss: 1.303056948740963 (17 / 60)
train_acc: 0.3814229249011858, val_acc: 0.42292490118577075, train_loss: 1.3336974632127483, val_loss: 1.2968213459248599 (18 / 60)
train_acc: 0.40711462450592883, val_acc: 0.44664031620553357, train_loss: 1.3037597511125647, val_loss: 1.2298624826514202 (19 / 60)
train_acc: 0.39920948616600793, val_acc: 0.43280632411067194, train_loss: 1.3102360007319998, val_loss: 1.272614078559423 (20 / 60)