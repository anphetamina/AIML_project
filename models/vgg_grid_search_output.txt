{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.1}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.05}
{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.1}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.05}
{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.1}
training set 809
validation set 203
train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.78373383488437, val_loss: 1.7685335005445433 (1 / 100)
train_acc: 0.1915945611866502, val_acc: 0.18226600985221675, train_loss: 1.7591753850319183, val_loss: 1.7403155025002992 (2 / 100)
train_acc: 0.19777503090234858, val_acc: 0.22660098522167488, train_loss: 1.744106983961664, val_loss: 1.7206945889101828 (3 / 100)
train_acc: 0.2249690976514215, val_acc: 0.2561576354679803, train_loss: 1.7316292724739046, val_loss: 1.7059643556331765 (4 / 100)
train_acc: 0.26452410383189123, val_acc: 0.23645320197044334, train_loss: 1.6886965863047483, val_loss: 1.6405535777801363 (5 / 100)
train_acc: 0.2954264524103832, val_acc: 0.35467980295566504, train_loss: 1.6677118656219747, val_loss: 1.5781844431543586 (6 / 100)
train_acc: 0.3411619283065513, val_acc: 0.2857142857142857, train_loss: 1.6157246720510892, val_loss: 1.672465663238112 (7 / 100)
train_acc: 0.3288009888751545, val_acc: 0.39901477832512317, train_loss: 1.5780016092493743, val_loss: 1.4462852219642677 (8 / 100)
train_acc: 0.35970333745364647, val_acc: 0.3694581280788177, train_loss: 1.5130871963147328, val_loss: 1.5083793994828398 (9 / 100)
train_acc: 0.3621755253399258, val_acc: 0.3793103448275862, train_loss: 1.4855279285916587, val_loss: 1.4945245711087005 (10 / 100)
train_acc: 0.3819530284301607, val_acc: 0.3891625615763547, train_loss: 1.4494802842770873, val_loss: 1.4610776871883224 (11 / 100)
train_acc: 0.37082818294190356, val_acc: 0.3694581280788177, train_loss: 1.4268492022609829, val_loss: 1.3766332694462367 (12 / 100)
train_acc: 0.3930778739184178, val_acc: 0.4236453201970443, train_loss: 1.4145337064717107, val_loss: 1.330364547926804 (13 / 100)
train_acc: 0.415327564894932, val_acc: 0.4630541871921182, train_loss: 1.3620626835062712, val_loss: 1.2550151941224272 (14 / 100)
train_acc: 0.41409147095179233, val_acc: 0.4433497536945813, train_loss: 1.3534568816386578, val_loss: 1.3153020895173397 (15 / 100)
train_acc: 0.43016069221260816, val_acc: 0.458128078817734, train_loss: 1.3038736656952847, val_loss: 1.2371725716027133 (16 / 100)
train_acc: 0.415327564894932, val_acc: 0.5024630541871922, train_loss: 1.301666410508645, val_loss: 1.186180835286972 (17 / 100)
train_acc: 0.41903584672435107, val_acc: 0.4433497536945813, train_loss: 1.3121248370195349, val_loss: 1.2594843630133004 (18 / 100)
train_acc: 0.48331273176761436, val_acc: 0.4630541871921182, train_loss: 1.2533173805703635, val_loss: 1.2994039281835696 (19 / 100)
train_acc: 0.4758961681087763, val_acc: 0.5024630541871922, train_loss: 1.269942855952844, val_loss: 1.262349520998048 (20 / 100)
train_acc: 0.4796044499381953, val_acc: 0.5221674876847291, train_loss: 1.2272651214682126, val_loss: 1.1525027164684727 (21 / 100)
train_acc: 0.47095179233621753, val_acc: 0.4187192118226601, train_loss: 1.2258059014790728, val_loss: 1.257804590786619 (22 / 100)
train_acc: 0.49814585908529047, val_acc: 0.4729064039408867, train_loss: 1.1554269392793937, val_loss: 1.1893765386102235 (23 / 100)
train_acc: 0.5092707045735476, val_acc: 0.458128078817734, train_loss: 1.1806158600985193, val_loss: 1.1806066573547025 (24 / 100)
train_acc: 0.522867737948084, val_acc: 0.5467980295566502, train_loss: 1.1481974172061689, val_loss: 1.0868582666801114 (25 / 100)
train_acc: 0.5315203955500618, val_acc: 0.45320197044334976, train_loss: 1.0985861632084228, val_loss: 1.4302576621764986 (26 / 100)
train_acc: 0.5302843016069221, val_acc: 0.5073891625615764, train_loss: 1.0957239089701762, val_loss: 1.1519955495014567 (27 / 100)
train_acc: 0.5525339925834364, val_acc: 0.5221674876847291, train_loss: 1.0485507926186466, val_loss: 1.3735314137829935 (28 / 100)
train_acc: 0.5488257107540173, val_acc: 0.5270935960591133, train_loss: 1.0503360069873748, val_loss: 1.2819593457752847 (29 / 100)
train_acc: 0.5735475896168108, val_acc: 0.5270935960591133, train_loss: 1.0089199177561643, val_loss: 1.145402090302829 (30 / 100)
train_acc: 0.5550061804697157, val_acc: 0.5369458128078818, train_loss: 1.0493555493348903, val_loss: 1.1409553001666892 (31 / 100)
train_acc: 0.619283065512979, val_acc: 0.5911330049261084, train_loss: 0.9332560962445952, val_loss: 1.017917294807622 (32 / 100)
train_acc: 0.6291718170580964, val_acc: 0.5812807881773399, train_loss: 0.900799279454612, val_loss: 1.129364417691536 (33 / 100)
train_acc: 0.6143386897404203, val_acc: 0.5566502463054187, train_loss: 0.9232618882423278, val_loss: 1.1204004002909356 (34 / 100)
train_acc: 0.6365883807169345, val_acc: 0.541871921182266, train_loss: 0.9190937417694016, val_loss: 1.0148128911192194 (35 / 100)
train_acc: 0.6266996291718171, val_acc: 0.5615763546798029, train_loss: 0.8882167863904766, val_loss: 1.1216303380252106 (36 / 100)
train_acc: 0.6823238566131026, val_acc: 0.5714285714285714, train_loss: 0.8083949066947211, val_loss: 1.2078805812473954 (37 / 100)
train_acc: 0.6909765142150803, val_acc: 0.6157635467980296, train_loss: 0.7784091129585898, val_loss: 1.0325541152742697 (38 / 100)
train_acc: 0.7070457354758962, val_acc: 0.5812807881773399, train_loss: 0.7140360190930266, val_loss: 1.0717352799006872 (39 / 100)
train_acc: 0.7107540173053152, val_acc: 0.6206896551724138, train_loss: 0.7227502564711977, val_loss: 1.0377472515763908 (40 / 100)
train_acc: 0.7330037082818294, val_acc: 0.6157635467980296, train_loss: 0.7050815044139018, val_loss: 1.0168454046613478 (41 / 100)
train_acc: 0.7107540173053152, val_acc: 0.6157635467980296, train_loss: 0.7150252873287507, val_loss: 1.3187641554278107 (42 / 100)
train_acc: 0.7527812113720643, val_acc: 0.6059113300492611, train_loss: 0.6126328554966836, val_loss: 1.3502651340708944 (43 / 100)
train_acc: 0.6773794808405439, val_acc: 0.645320197044335, train_loss: 0.8108952592123572, val_loss: 1.1171635007623382 (44 / 100)
train_acc: 0.7725587144622992, val_acc: 0.6157635467980296, train_loss: 0.5690765827341634, val_loss: 1.0725170814345035 (45 / 100)
train_acc: 0.7948084054388134, val_acc: 0.6354679802955665, train_loss: 0.5098226926530101, val_loss: 1.0795075526378426 (46 / 100)
train_acc: 0.7873918417799752, val_acc: 0.6551724137931034, train_loss: 0.548065011374588, val_loss: 1.0642458956523482 (47 / 100)
train_acc: 0.8096415327564895, val_acc: 0.6502463054187192, train_loss: 0.49149149236337214, val_loss: 1.1301951446556693 (48 / 100)
train_acc: 0.830655129789864, val_acc: 0.6600985221674877, train_loss: 0.42063818299136735, val_loss: 1.363823467581143 (49 / 100)
train_acc: 0.8467243510506799, val_acc: 0.6600985221674877, train_loss: 0.4218120778299527, val_loss: 1.1632297764270765 (50 / 100)
train_acc: 0.8355995055624228, val_acc: 0.6354679802955665, train_loss: 0.44429056326155314, val_loss: 1.4594083575192343 (51 / 100)
train_acc: 0.7218788627935723, val_acc: 0.6995073891625616, train_loss: 0.7073465802318822, val_loss: 1.2190375210616389 (52 / 100)
train_acc: 0.8257107540173053, val_acc: 0.6847290640394089, train_loss: 0.4458410415720144, val_loss: 1.1707994130444643 (53 / 100)
train_acc: 0.8417799752781211, val_acc: 0.6798029556650246, train_loss: 0.4121690959069873, val_loss: 1.0205895486723613 (54 / 100)
train_acc: 0.8603213844252163, val_acc: 0.6600985221674877, train_loss: 0.37352726132377556, val_loss: 1.207179679365581 (55 / 100)
train_acc: 0.8677379480840544, val_acc: 0.6650246305418719, train_loss: 0.34558123755366604, val_loss: 1.6535105034341953 (56 / 100)
train_acc: 0.861557478368356, val_acc: 0.6847290640394089, train_loss: 0.3679037079380823, val_loss: 1.139225322771542 (57 / 100)
train_acc: 0.8825710754017305, val_acc: 0.645320197044335, train_loss: 0.3138643249740412, val_loss: 1.2116599494013294 (58 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6748768472906403, train_loss: 0.2798436766649206, val_loss: 1.2507030344361743 (59 / 100)
train_acc: 0.9110012360939431, val_acc: 0.6896551724137931, train_loss: 0.23642536500475758, val_loss: 1.3558491439067673 (60 / 100)
train_acc: 0.9443757725587144, val_acc: 0.7438423645320197, train_loss: 0.17392502476464686, val_loss: 1.1848883557642622 (61 / 100)
train_acc: 0.957972805933251, val_acc: 0.7438423645320197, train_loss: 0.15073673230019136, val_loss: 1.2302069595001015 (62 / 100)
train_acc: 0.9431396786155748, val_acc: 0.729064039408867, train_loss: 0.13937576547983402, val_loss: 1.2848408173751362 (63 / 100)
train_acc: 0.9567367119901112, val_acc: 0.7339901477832512, train_loss: 0.10456823182783846, val_loss: 1.299033915614847 (64 / 100)
train_acc: 0.9616810877626699, val_acc: 0.7438423645320197, train_loss: 0.11547666574438069, val_loss: 1.3156936710397598 (65 / 100)
train_acc: 0.9542645241038319, val_acc: 0.7389162561576355, train_loss: 0.12036131338961192, val_loss: 1.3614150560254534 (66 / 100)
train_acc: 0.9468479604449939, val_acc: 0.7438423645320197, train_loss: 0.13936495471501675, val_loss: 1.3456075354456314 (67 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7438423645320197, train_loss: 0.0959784862284902, val_loss: 1.3696311765116425 (68 / 100)
train_acc: 0.9555006180469716, val_acc: 0.7586206896551724, train_loss: 0.13473185930028098, val_loss: 1.3178652379606746 (69 / 100)
train_acc: 0.965389369592089, val_acc: 0.7536945812807881, train_loss: 0.10577929712491219, val_loss: 1.4150441807185488 (70 / 100)
train_acc: 0.965389369592089, val_acc: 0.7438423645320197, train_loss: 0.0970323240506487, val_loss: 1.4057781625851034 (71 / 100)
train_acc: 0.9530284301606922, val_acc: 0.7536945812807881, train_loss: 0.1009780223054261, val_loss: 1.4293723162171876 (72 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7389162561576355, train_loss: 0.07237879012806896, val_loss: 1.4640146866807797 (73 / 100)
train_acc: 0.9666254635352287, val_acc: 0.7241379310344828, train_loss: 0.10341844408414862, val_loss: 1.4986663862989453 (74 / 100)
train_acc: 0.9629171817058096, val_acc: 0.7389162561576355, train_loss: 0.09607517910828844, val_loss: 1.4947347852396848 (75 / 100)
train_acc: 0.9703337453646477, val_acc: 0.7389162561576355, train_loss: 0.098310959648585, val_loss: 1.4613136881090738 (76 / 100)
train_acc: 0.9666254635352287, val_acc: 0.7339901477832512, train_loss: 0.0882847982519784, val_loss: 1.5054220930108884 (77 / 100)
train_acc: 0.9629171817058096, val_acc: 0.7438423645320197, train_loss: 0.08725621894793988, val_loss: 1.496209300503942 (78 / 100)
train_acc: 0.969097651421508, val_acc: 0.729064039408867, train_loss: 0.08901232488370502, val_loss: 1.5293833842418465 (79 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7536945812807881, train_loss: 0.07757288092293757, val_loss: 1.5217512932610628 (80 / 100)
train_acc: 0.965389369592089, val_acc: 0.7586206896551724, train_loss: 0.09169566719729468, val_loss: 1.5278293522707935 (81 / 100)
train_acc: 0.9752781211372065, val_acc: 0.7438423645320197, train_loss: 0.07371234982211157, val_loss: 1.5192823713929782 (82 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7635467980295566, train_loss: 0.07704800551547698, val_loss: 1.4869063125161701 (83 / 100)
train_acc: 0.9567367119901112, val_acc: 0.7339901477832512, train_loss: 0.10360821834748106, val_loss: 1.4953251977272222 (84 / 100)
train_acc: 0.969097651421508, val_acc: 0.7487684729064039, train_loss: 0.09746902554822057, val_loss: 1.4749785385695584 (85 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7586206896551724, train_loss: 0.06043395698438911, val_loss: 1.4974648305054368 (86 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7536945812807881, train_loss: 0.06924164707787399, val_loss: 1.5231841736532785 (87 / 100)
train_acc: 0.9641532756489494, val_acc: 0.7487684729064039, train_loss: 0.08718352883648961, val_loss: 1.5591367287882443 (88 / 100)
train_acc: 0.9851668726823238, val_acc: 0.7487684729064039, train_loss: 0.048029029914563606, val_loss: 1.5867895751163876 (89 / 100)
train_acc: 0.9703337453646477, val_acc: 0.7487684729064039, train_loss: 0.0792457923311533, val_loss: 1.6006375745012256 (90 / 100)
train_acc: 0.965389369592089, val_acc: 0.7389162561576355, train_loss: 0.09129807695617487, val_loss: 1.622169793826606 (91 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7635467980295566, train_loss: 0.080816844190449, val_loss: 1.5736170563791774 (92 / 100)
train_acc: 0.9715698393077874, val_acc: 0.7586206896551724, train_loss: 0.07245363676356444, val_loss: 1.5628343898380919 (93 / 100)
train_acc: 0.9814585908529048, val_acc: 0.7635467980295566, train_loss: 0.060810725827446975, val_loss: 1.5828983796934777 (94 / 100)
train_acc: 0.9777503090234858, val_acc: 0.7487684729064039, train_loss: 0.06913261493145315, val_loss: 1.5900617773309718 (95 / 100)
train_acc: 0.969097651421508, val_acc: 0.7487684729064039, train_loss: 0.08122996479383358, val_loss: 1.597121342062363 (96 / 100)
train_acc: 0.9740420271940667, val_acc: 0.7389162561576355, train_loss: 0.0702357115350636, val_loss: 1.5828301238602605 (97 / 100)
train_acc: 0.9728059332509271, val_acc: 0.7635467980295566, train_loss: 0.07719301440659795, val_loss: 1.5754121983873433 (98 / 100)
train_acc: 0.9678615574783683, val_acc: 0.7635467980295566, train_loss: 0.08986866547828552, val_loss: 1.575839596869323 (99 / 100)
train_acc: 0.9765142150803461, val_acc: 0.7487684729064039, train_loss: 0.06889708640401532, val_loss: 1.5847745859270612 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}), val accuracy 0.7635467980295566, val loss 1.4869063125161701
train_acc: 0.17181705809641531, val_acc: 0.21182266009852216, train_loss: 1.784361404747839, val_loss: 1.7642770218731734 (1 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.766925573348999, val_loss: 1.7531924670552972 (2 / 100)
train_acc: 0.22620519159456118, val_acc: 0.2561576354679803, train_loss: 1.7576426865880657, val_loss: 1.7382822242276421 (3 / 100)
train_acc: 0.23856613102595797, val_acc: 0.2315270935960591, train_loss: 1.7471613552425935, val_loss: 1.7220872734567803 (4 / 100)
train_acc: 0.2595797280593325, val_acc: 0.33004926108374383, train_loss: 1.7158655118293904, val_loss: 1.6193340922811348 (5 / 100)
train_acc: 0.25339925834363414, val_acc: 0.35467980295566504, train_loss: 1.713133012997942, val_loss: 1.6003223880758426 (6 / 100)
train_acc: 0.2843016069221261, val_acc: 0.3054187192118227, train_loss: 1.67195953868965, val_loss: 1.6007734096696224 (7 / 100)
train_acc: 0.36093943139678614, val_acc: 0.3399014778325123, train_loss: 1.561879686431036, val_loss: 1.5899436467974057 (8 / 100)
train_acc: 0.3263288009888752, val_acc: 0.35467980295566504, train_loss: 1.5805941249885134, val_loss: 1.49422952048297 (9 / 100)
train_acc: 0.3572311495673671, val_acc: 0.3448275862068966, train_loss: 1.5032355272578368, val_loss: 1.4546788038291367 (10 / 100)
train_acc: 0.37453646477132263, val_acc: 0.43842364532019706, train_loss: 1.4788648392567676, val_loss: 1.465018196646216 (11 / 100)
train_acc: 0.34857849196538937, val_acc: 0.3891625615763547, train_loss: 1.4724658371049482, val_loss: 1.4341557031781802 (12 / 100)
train_acc: 0.37082818294190356, val_acc: 0.3251231527093596, train_loss: 1.4437153908171967, val_loss: 1.63305669876155 (13 / 100)
train_acc: 0.3683559950556242, val_acc: 0.4039408866995074, train_loss: 1.4667615312875717, val_loss: 1.445153016762193 (14 / 100)
train_acc: 0.3943139678615575, val_acc: 0.458128078817734, train_loss: 1.3949429054637479, val_loss: 1.3602121780658591 (15 / 100)
train_acc: 0.38813349814585907, val_acc: 0.4039408866995074, train_loss: 1.3866008325619221, val_loss: 1.3289326141620506 (16 / 100)
train_acc: 0.40667490729295425, val_acc: 0.39408866995073893, train_loss: 1.3840013941374638, val_loss: 1.3159581522636226 (17 / 100)
train_acc: 0.44128553770086526, val_acc: 0.4975369458128079, train_loss: 1.3321049793983715, val_loss: 1.2944574632080905 (18 / 100)
train_acc: 0.4276885043263288, val_acc: 0.43349753694581283, train_loss: 1.3421970009067004, val_loss: 1.3620289646345993 (19 / 100)
train_acc: 0.43139678615574784, val_acc: 0.46798029556650245, train_loss: 1.368697890981903, val_loss: 1.2580579789401276 (20 / 100)
train_acc: 0.44499381953028433, val_acc: 0.4630541871921182, train_loss: 1.2987654828023263, val_loss: 1.2446271275064629 (21 / 100)
train_acc: 0.4388133498145859, val_acc: 0.4630541871921182, train_loss: 1.306820211658077, val_loss: 1.2424459645313581 (22 / 100)
train_acc: 0.4758961681087763, val_acc: 0.4630541871921182, train_loss: 1.2632981053978316, val_loss: 1.224477032135273 (23 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4630541871921182, train_loss: 1.2645783478898378, val_loss: 1.2030680649386252 (24 / 100)
train_acc: 0.4907292954264524, val_acc: 0.4630541871921182, train_loss: 1.2322985028159632, val_loss: 1.196917113118571 (25 / 100)
train_acc: 0.5030902348578492, val_acc: 0.4482758620689655, train_loss: 1.201461157486377, val_loss: 1.2674795033896498 (26 / 100)
train_acc: 0.5203955500618047, val_acc: 0.3842364532019704, train_loss: 1.192048879135377, val_loss: 1.3550262929770747 (27 / 100)
train_acc: 0.5377008652657602, val_acc: 0.5073891625615764, train_loss: 1.186145384762579, val_loss: 1.1494043516408046 (28 / 100)
train_acc: 0.5364647713226205, val_acc: 0.4827586206896552, train_loss: 1.1477680778031885, val_loss: 1.1942138116935204 (29 / 100)
train_acc: 0.5339925834363412, val_acc: 0.5714285714285714, train_loss: 1.1408783968063752, val_loss: 1.1324468122914506 (30 / 100)
train_acc: 0.5673671199011124, val_acc: 0.5517241379310345, train_loss: 1.0726224229715957, val_loss: 1.1401977010548408 (31 / 100)
train_acc: 0.5648949320148331, val_acc: 0.4876847290640394, train_loss: 1.0545946403840563, val_loss: 1.207767148616866 (32 / 100)
train_acc: 0.5710754017305315, val_acc: 0.4482758620689655, train_loss: 1.0361261907113055, val_loss: 1.2728984816908249 (33 / 100)
train_acc: 0.5859085290482077, val_acc: 0.47783251231527096, train_loss: 0.9921169787903209, val_loss: 1.1980525167117566 (34 / 100)
train_acc: 0.5896168108776267, val_acc: 0.5911330049261084, train_loss: 0.9952731232707963, val_loss: 1.0271065176414151 (35 / 100)
train_acc: 0.6378244746600742, val_acc: 0.5812807881773399, train_loss: 0.929920085428377, val_loss: 1.1085625704873372 (36 / 100)
train_acc: 0.6168108776266996, val_acc: 0.4630541871921182, train_loss: 0.9464848191835382, val_loss: 1.312536914947585 (37 / 100)
train_acc: 0.6724351050679852, val_acc: 0.5763546798029556, train_loss: 0.8586398532570366, val_loss: 1.100383582079939 (38 / 100)
train_acc: 0.6724351050679852, val_acc: 0.5467980295566502, train_loss: 0.8761506393017668, val_loss: 1.1371152864888383 (39 / 100)
train_acc: 0.6934487021013597, val_acc: 0.5714285714285714, train_loss: 0.7881700164455419, val_loss: 1.0968423471074973 (40 / 100)
train_acc: 0.7144622991347342, val_acc: 0.5369458128078818, train_loss: 0.7268828580936484, val_loss: 1.1820532353640778 (41 / 100)
train_acc: 0.7317676143386898, val_acc: 0.5714285714285714, train_loss: 0.7118231184845065, val_loss: 1.2685390740192581 (42 / 100)
train_acc: 0.7404202719406675, val_acc: 0.5862068965517241, train_loss: 0.7130141900702667, val_loss: 1.0530330500579232 (43 / 100)
train_acc: 0.7737948084054388, val_acc: 0.5665024630541872, train_loss: 0.6292958386306857, val_loss: 1.175454576614455 (44 / 100)
train_acc: 0.7824474660074165, val_acc: 0.5763546798029556, train_loss: 0.58251512139041, val_loss: 1.1369039982997726 (45 / 100)
train_acc: 0.7503090234857849, val_acc: 0.5467980295566502, train_loss: 0.6340557824548596, val_loss: 1.2110897919227337 (46 / 100)
train_acc: 0.7849196538936959, val_acc: 0.5812807881773399, train_loss: 0.596162891063761, val_loss: 1.1673362685248183 (47 / 100)
train_acc: 0.788627935723115, val_acc: 0.6551724137931034, train_loss: 0.5810532530099706, val_loss: 1.0665241635491696 (48 / 100)
train_acc: 0.8195302843016069, val_acc: 0.5960591133004927, train_loss: 0.48339614172653744, val_loss: 1.3444474277825191 (49 / 100)
train_acc: 0.8529048207663782, val_acc: 0.6108374384236454, train_loss: 0.3781543772653832, val_loss: 1.421452060635454 (50 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5566502463054187, train_loss: 0.3557807612330716, val_loss: 1.4056067490225355 (51 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6108374384236454, train_loss: 0.3494974835988765, val_loss: 1.7603676524655572 (52 / 100)
train_acc: 0.8800988875154512, val_acc: 0.645320197044335, train_loss: 0.34615789753544907, val_loss: 1.101978027027816 (53 / 100)
train_acc: 0.8504326328800988, val_acc: 0.6157635467980296, train_loss: 0.42364104539708536, val_loss: 1.5226379427416572 (54 / 100)
train_acc: 0.899876390605686, val_acc: 0.6403940886699507, train_loss: 0.2896549798944235, val_loss: 1.3372012884746045 (55 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6650246305418719, train_loss: 0.2293389679032881, val_loss: 1.1813663896081483 (56 / 100)
train_acc: 0.9221260815822002, val_acc: 0.6354679802955665, train_loss: 0.22531891767999299, val_loss: 2.166120241428244 (57 / 100)
train_acc: 0.907292954264524, val_acc: 0.6403940886699507, train_loss: 0.28814430510894623, val_loss: 1.2511681603093452 (58 / 100)
train_acc: 0.8936959208899876, val_acc: 0.5320197044334976, train_loss: 0.28790176121059835, val_loss: 1.616968880072603 (59 / 100)
train_acc: 0.9134734239802225, val_acc: 0.625615763546798, train_loss: 0.24483985305569228, val_loss: 1.5444904162085116 (60 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6600985221674877, train_loss: 0.14654318024997215, val_loss: 1.4372705271091368 (61 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6600985221674877, train_loss: 0.09201892830974828, val_loss: 1.5129883315762862 (62 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6748768472906403, train_loss: 0.08014525648100562, val_loss: 1.6631151931039219 (63 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6748768472906403, train_loss: 0.07908427140621378, val_loss: 1.7420732176362588 (64 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6600985221674877, train_loss: 0.08322204927578845, val_loss: 1.7954089541740605 (65 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6748768472906403, train_loss: 0.055183452345679514, val_loss: 1.7982734418267687 (66 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6600985221674877, train_loss: 0.04767672962547086, val_loss: 1.985860453450621 (67 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6847290640394089, train_loss: 0.06361225184757718, val_loss: 1.9847033951670079 (68 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.04938634526449611, val_loss: 2.0113645169535292 (69 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6798029556650246, train_loss: 0.03977053981776291, val_loss: 2.131243826133277 (70 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6798029556650246, train_loss: 0.061296846574846985, val_loss: 2.138686766765388 (71 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6798029556650246, train_loss: 0.04338561236047921, val_loss: 2.1515172479187914 (72 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6748768472906403, train_loss: 0.04200774129153182, val_loss: 2.1457340124205415 (73 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6798029556650246, train_loss: 0.03715569657654638, val_loss: 2.1897675961696454 (74 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.03290504032955476, val_loss: 2.1348195246287753 (75 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6748768472906403, train_loss: 0.04886827348041888, val_loss: 2.1383886765963926 (76 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6600985221674877, train_loss: 0.04572392998283961, val_loss: 2.2607418639319286 (77 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6748768472906403, train_loss: 0.04128748053231257, val_loss: 2.256043868699097 (78 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6699507389162561, train_loss: 0.046727414184211946, val_loss: 2.2030920536060052 (79 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6748768472906403, train_loss: 0.05670898158117042, val_loss: 2.1223957876266515 (80 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6748768472906403, train_loss: 0.05207846662759486, val_loss: 2.184562521027814 (81 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6699507389162561, train_loss: 0.039389598354863, val_loss: 2.170117300132225 (82 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6600985221674877, train_loss: 0.05842442329793395, val_loss: 2.0433699415235096 (83 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6650246305418719, train_loss: 0.028148641250336864, val_loss: 2.238167628278873 (84 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6699507389162561, train_loss: 0.04450215087980216, val_loss: 2.2522780460677123 (85 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6650246305418719, train_loss: 0.04113083333697985, val_loss: 2.195215009409806 (86 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6650246305418719, train_loss: 0.019868418371721604, val_loss: 2.3690920416357484 (87 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6748768472906403, train_loss: 0.036123196333094194, val_loss: 2.4030740860060518 (88 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6748768472906403, train_loss: 0.0338847466246012, val_loss: 2.4827363079991835 (89 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6798029556650246, train_loss: 0.02622190246770644, val_loss: 2.570009220409863 (90 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6847290640394089, train_loss: 0.02586098683926614, val_loss: 2.435141711399473 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6748768472906403, train_loss: 0.028552846354518744, val_loss: 2.550051899966348 (92 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6847290640394089, train_loss: 0.03419529905425309, val_loss: 2.3714167825106918 (93 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6896551724137931, train_loss: 0.027762692849921944, val_loss: 2.331142272855261 (94 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6847290640394089, train_loss: 0.02822194906925536, val_loss: 2.422904704591911 (95 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6847290640394089, train_loss: 0.021782379362580213, val_loss: 2.3505594078543153 (96 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6896551724137931, train_loss: 0.018172311399716826, val_loss: 2.4447800566997433 (97 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6945812807881774, train_loss: 0.033632485474585305, val_loss: 2.382970290231 (98 / 100)
train_acc: 0.992583436341162, val_acc: 0.6748768472906403, train_loss: 0.02485905265336573, val_loss: 2.485448380996441 (99 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6847290640394089, train_loss: 0.021002554480902786, val_loss: 2.518056775548775 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.1}), val accuracy 0.6945812807881774, val loss 2.382970290231
train_acc: 0.1903584672435105, val_acc: 0.18719211822660098, train_loss: 1.7802917099706321, val_loss: 1.7550017052683338 (1 / 100)
train_acc: 0.21013597033374537, val_acc: 0.3103448275862069, train_loss: 1.7606686957834383, val_loss: 1.742342155555199 (2 / 100)
train_acc: 0.24103831891223734, val_acc: 0.22167487684729065, train_loss: 1.744329983283327, val_loss: 1.7066170153359475 (3 / 100)
train_acc: 0.2521631644004944, val_acc: 0.3251231527093596, train_loss: 1.7033872042951832, val_loss: 1.5980333230765582 (4 / 100)
train_acc: 0.32014833127317677, val_acc: 0.3497536945812808, train_loss: 1.6489227684525536, val_loss: 1.5922433026318479 (5 / 100)
train_acc: 0.2954264524103832, val_acc: 0.33497536945812806, train_loss: 1.642521990539117, val_loss: 1.560525747942807 (6 / 100)
train_acc: 0.32138442521631644, val_acc: 0.37438423645320196, train_loss: 1.5807261932618244, val_loss: 1.4477067692526455 (7 / 100)
train_acc: 0.34857849196538937, val_acc: 0.3694581280788177, train_loss: 1.5347427770734865, val_loss: 1.4325491201701424 (8 / 100)
train_acc: 0.3473423980222497, val_acc: 0.35960591133004927, train_loss: 1.527747131690696, val_loss: 1.4899539518826113 (9 / 100)
train_acc: 0.34610630407911, val_acc: 0.3448275862068966, train_loss: 1.475723144887257, val_loss: 1.4426588871208905 (10 / 100)
train_acc: 0.39555006180469715, val_acc: 0.3793103448275862, train_loss: 1.4402727615111248, val_loss: 1.39484624616031 (11 / 100)
train_acc: 0.3757725587144623, val_acc: 0.4088669950738916, train_loss: 1.43104218581993, val_loss: 1.397059611499016 (12 / 100)
train_acc: 0.4054388133498146, val_acc: 0.37438423645320196, train_loss: 1.4137783616376012, val_loss: 1.5516478375261054 (13 / 100)
train_acc: 0.411619283065513, val_acc: 0.43842364532019706, train_loss: 1.404482913400393, val_loss: 1.3259181970445981 (14 / 100)
train_acc: 0.411619283065513, val_acc: 0.4236453201970443, train_loss: 1.3893038866988514, val_loss: 1.473584849258949 (15 / 100)
train_acc: 0.4264524103831891, val_acc: 0.41379310344827586, train_loss: 1.3923581011952517, val_loss: 1.3377968900896646 (16 / 100)
train_acc: 0.4400494437577256, val_acc: 0.41379310344827586, train_loss: 1.346884015906137, val_loss: 1.3069236384236753 (17 / 100)
train_acc: 0.4338689740420272, val_acc: 0.4433497536945813, train_loss: 1.354652256694506, val_loss: 1.330927951582547 (18 / 100)
train_acc: 0.4437577255871446, val_acc: 0.4876847290640394, train_loss: 1.3197717519272096, val_loss: 1.2718502858589436 (19 / 100)
train_acc: 0.43016069221260816, val_acc: 0.4088669950738916, train_loss: 1.2917202809832447, val_loss: 1.3177432767276107 (20 / 100)
train_acc: 0.4561186650185414, val_acc: 0.4433497536945813, train_loss: 1.2793013200771677, val_loss: 1.4287691257270099 (21 / 100)
train_acc: 0.4610630407911001, val_acc: 0.49261083743842365, train_loss: 1.2812711874251017, val_loss: 1.2129236078027434 (22 / 100)
train_acc: 0.4857849196538937, val_acc: 0.4975369458128079, train_loss: 1.2228589858053935, val_loss: 1.1823146419572126 (23 / 100)
train_acc: 0.49814585908529047, val_acc: 0.4630541871921182, train_loss: 1.1920867159281143, val_loss: 1.174452129255962 (24 / 100)
train_acc: 0.5043263288009888, val_acc: 0.45320197044334976, train_loss: 1.1712899405523047, val_loss: 1.243650295757895 (25 / 100)
train_acc: 0.4721878862793572, val_acc: 0.5073891625615764, train_loss: 1.2450520310030584, val_loss: 1.15791585351446 (26 / 100)
train_acc: 0.5302843016069221, val_acc: 0.4236453201970443, train_loss: 1.1761995472925701, val_loss: 1.3148603868014708 (27 / 100)
train_acc: 0.5203955500618047, val_acc: 0.5221674876847291, train_loss: 1.1618508019465008, val_loss: 1.176203927970285 (28 / 100)
train_acc: 0.5451174289245982, val_acc: 0.5467980295566502, train_loss: 1.1035093545029573, val_loss: 1.1250573916388262 (29 / 100)
train_acc: 0.5599505562422744, val_acc: 0.5369458128078818, train_loss: 1.0737101224208496, val_loss: 1.1460143421671074 (30 / 100)
train_acc: 0.5377008652657602, val_acc: 0.4433497536945813, train_loss: 1.0727192521537336, val_loss: 1.5360845550527713 (31 / 100)
train_acc: 0.595797280593325, val_acc: 0.5665024630541872, train_loss: 1.0497298788818057, val_loss: 1.0892694918392913 (32 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5862068965517241, train_loss: 1.0200572998178905, val_loss: 1.057923952640571 (33 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5714285714285714, train_loss: 0.9994178083535326, val_loss: 1.1132606341333813 (34 / 100)
train_acc: 0.6378244746600742, val_acc: 0.5467980295566502, train_loss: 0.9025711079021025, val_loss: 1.1281529342012453 (35 / 100)
train_acc: 0.5970333745364648, val_acc: 0.5911330049261084, train_loss: 0.9521632294719682, val_loss: 1.0001714499713166 (36 / 100)
train_acc: 0.646477132262052, val_acc: 0.6206896551724138, train_loss: 0.86444861072545, val_loss: 1.0360106570380074 (37 / 100)
train_acc: 0.6872682323856613, val_acc: 0.5615763546798029, train_loss: 0.7815758960945497, val_loss: 1.1234036736887665 (38 / 100)
train_acc: 0.6835599505562423, val_acc: 0.541871921182266, train_loss: 0.8039133548736572, val_loss: 1.292360291105186 (39 / 100)
train_acc: 0.7206427688504327, val_acc: 0.5911330049261084, train_loss: 0.7194221569374848, val_loss: 1.151142398712083 (40 / 100)
train_acc: 0.6983930778739185, val_acc: 0.5517241379310345, train_loss: 0.7223634133380187, val_loss: 1.535969267925018 (41 / 100)
train_acc: 0.7194066749072929, val_acc: 0.5517241379310345, train_loss: 0.7095816692404163, val_loss: 1.1026959486782844 (42 / 100)
train_acc: 0.7725587144622992, val_acc: 0.5911330049261084, train_loss: 0.6013774090850603, val_loss: 1.2366480974141012 (43 / 100)
train_acc: 0.799752781211372, val_acc: 0.6305418719211823, train_loss: 0.5740004231225427, val_loss: 1.219193258309012 (44 / 100)
train_acc: 0.7836835599505563, val_acc: 0.645320197044335, train_loss: 0.5735913880528567, val_loss: 1.0381434292628848 (45 / 100)
train_acc: 0.7169344870210136, val_acc: 0.625615763546798, train_loss: 0.7548026248757418, val_loss: 1.0479087204181503 (46 / 100)
train_acc: 0.8182941903584673, val_acc: 0.5615763546798029, train_loss: 0.4633676059755908, val_loss: 1.686431936295749 (47 / 100)
train_acc: 0.7812113720642769, val_acc: 0.625615763546798, train_loss: 0.6002130545261322, val_loss: 1.2077961666830654 (48 / 100)
train_acc: 0.8294190358467244, val_acc: 0.625615763546798, train_loss: 0.43452977986801394, val_loss: 1.3321759573050909 (49 / 100)
train_acc: 0.8603213844252163, val_acc: 0.645320197044335, train_loss: 0.36783617167596616, val_loss: 1.1286644853394607 (50 / 100)
train_acc: 0.8689740420271941, val_acc: 0.6403940886699507, train_loss: 0.35492478032931407, val_loss: 1.3160814801460416 (51 / 100)
train_acc: 0.8281829419035847, val_acc: 0.6059113300492611, train_loss: 0.5016483591572464, val_loss: 1.4620805467878069 (52 / 100)
train_acc: 0.8640296662546354, val_acc: 0.5911330049261084, train_loss: 0.3607119083109833, val_loss: 1.5388852428332926 (53 / 100)
train_acc: 0.8899876390605687, val_acc: 0.6354679802955665, train_loss: 0.284395733044675, val_loss: 1.5258153425208454 (54 / 100)
train_acc: 0.5648949320148331, val_acc: 0.5911330049261084, train_loss: 1.0984972310154635, val_loss: 1.2321084356073089 (55 / 100)
train_acc: 0.799752781211372, val_acc: 0.625615763546798, train_loss: 0.5175953972324895, val_loss: 1.2252592617655036 (56 / 100)
train_acc: 0.8603213844252163, val_acc: 0.6206896551724138, train_loss: 0.37476993181796836, val_loss: 1.6315551153544723 (57 / 100)
train_acc: 0.8887515451174289, val_acc: 0.645320197044335, train_loss: 0.31677921784970314, val_loss: 1.6614157959745435 (58 / 100)
train_acc: 0.9134734239802225, val_acc: 0.645320197044335, train_loss: 0.2578839916823379, val_loss: 1.3747265127492068 (59 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6108374384236454, train_loss: 0.19152593347433913, val_loss: 1.9139833741000134 (60 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6403940886699507, train_loss: 0.14367968042937138, val_loss: 1.5704651664336915 (61 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6502463054187192, train_loss: 0.07675840857591854, val_loss: 1.6483866710380968 (62 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6403940886699507, train_loss: 0.08550155442783652, val_loss: 1.6767743009651823 (63 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6305418719211823, train_loss: 0.06758400786792391, val_loss: 1.7048859386314899 (64 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6354679802955665, train_loss: 0.10324416187107195, val_loss: 1.6668834204744236 (65 / 100)
train_acc: 0.9789864029666254, val_acc: 0.645320197044335, train_loss: 0.07266708431196743, val_loss: 1.7472999951815957 (66 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6502463054187192, train_loss: 0.0802251913933583, val_loss: 1.7875163635890472 (67 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6600985221674877, train_loss: 0.08249868465442445, val_loss: 1.8337557841404317 (68 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6551724137931034, train_loss: 0.06404276124037094, val_loss: 1.8685219252638041 (69 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6600985221674877, train_loss: 0.06462162917270355, val_loss: 1.8860435907183022 (70 / 100)
train_acc: 0.9814585908529048, val_acc: 0.645320197044335, train_loss: 0.059976821482107874, val_loss: 1.899600329804303 (71 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.06760666013795454, val_loss: 1.9487235484452083 (72 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6403940886699507, train_loss: 0.05035990572388299, val_loss: 1.9638090013283227 (73 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.0499923354468328, val_loss: 1.9800524033349136 (74 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.06381634448750499, val_loss: 1.9782643647029483 (75 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6551724137931034, train_loss: 0.06334621030998466, val_loss: 1.9715670038913857 (76 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6650246305418719, train_loss: 0.08616977907965888, val_loss: 1.9410701593741995 (77 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6600985221674877, train_loss: 0.05959910883744361, val_loss: 1.9802100414713029 (78 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6650246305418719, train_loss: 0.04024693520903145, val_loss: 2.0525342939522466 (79 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.05127278688664195, val_loss: 2.0334990479676005 (80 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.04982811470408964, val_loss: 2.0681655445122367 (81 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6502463054187192, train_loss: 0.047011445420339464, val_loss: 2.056621800208914 (82 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6354679802955665, train_loss: 0.05786443007154429, val_loss: 2.0968810252368155 (83 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6551724137931034, train_loss: 0.04585717797132004, val_loss: 2.0686201297590885 (84 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6600985221674877, train_loss: 0.04845309714304355, val_loss: 2.1148313818306756 (85 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6650246305418719, train_loss: 0.05354637357006851, val_loss: 2.1458175778388977 (86 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6600985221674877, train_loss: 0.03895192933170993, val_loss: 2.200171543165968 (87 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.05398323877780193, val_loss: 2.1789375311635397 (88 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6699507389162561, train_loss: 0.03054168300958735, val_loss: 2.239895169958105 (89 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6600985221674877, train_loss: 0.03616975529674252, val_loss: 2.330162925085998 (90 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6650246305418719, train_loss: 0.029777096140075232, val_loss: 2.3546106965083795 (91 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6650246305418719, train_loss: 0.04006298554989846, val_loss: 2.320199875115174 (92 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.04451572570871511, val_loss: 2.3043625293106866 (93 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6748768472906403, train_loss: 0.04519947468129312, val_loss: 2.3527262028802203 (94 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6699507389162561, train_loss: 0.04379329206916988, val_loss: 2.331494937976593 (95 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6748768472906403, train_loss: 0.060130589677317915, val_loss: 2.375539594095916 (96 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6699507389162561, train_loss: 0.057621635524245214, val_loss: 2.31642453365138 (97 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6748768472906403, train_loss: 0.04225212961840541, val_loss: 2.3627748906318775 (98 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6699507389162561, train_loss: 0.0445089278321331, val_loss: 2.421446453174347 (99 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.03755956866095771, val_loss: 2.4103085865528127 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.05}), val accuracy 0.6798029556650246, val loss 2.4103085865528127
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7761770797748353, val_loss: 1.7523032591260712 (1 / 100)
train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.763675312323977, val_loss: 1.7430592258575515 (2 / 100)
train_acc: 0.2249690976514215, val_acc: 0.29064039408866993, train_loss: 1.737621975622896, val_loss: 1.736579603162305 (3 / 100)
train_acc: 0.2484548825710754, val_acc: 0.3103448275862069, train_loss: 1.7165320709402982, val_loss: 1.640741604302317 (4 / 100)
train_acc: 0.2843016069221261, val_acc: 0.2561576354679803, train_loss: 1.667753151969061, val_loss: 1.6117521007659987 (5 / 100)
train_acc: 0.3374536464771323, val_acc: 0.3103448275862069, train_loss: 1.6139834699288875, val_loss: 1.5677423013254927 (6 / 100)
train_acc: 0.3374536464771323, val_acc: 0.30049261083743845, train_loss: 1.5707768658625034, val_loss: 1.6389580947424978 (7 / 100)
train_acc: 0.3572311495673671, val_acc: 0.4187192118226601, train_loss: 1.5445162701813047, val_loss: 1.5012876294516577 (8 / 100)
train_acc: 0.34363411619283063, val_acc: 0.3103448275862069, train_loss: 1.5083576373028371, val_loss: 1.5924437527586086 (9 / 100)
train_acc: 0.3856613102595797, val_acc: 0.3399014778325123, train_loss: 1.4808991901364699, val_loss: 1.457246813574448 (10 / 100)
train_acc: 0.3794808405438813, val_acc: 0.35467980295566504, train_loss: 1.4776602360167816, val_loss: 1.4019290126603225 (11 / 100)
train_acc: 0.40173053152039556, val_acc: 0.3645320197044335, train_loss: 1.4461971099945465, val_loss: 1.4003686581926393 (12 / 100)
train_acc: 0.39555006180469715, val_acc: 0.3694581280788177, train_loss: 1.414133751642866, val_loss: 1.4759686856434262 (13 / 100)
train_acc: 0.415327564894932, val_acc: 0.45320197044334976, train_loss: 1.3804527705325773, val_loss: 1.3674742735078182 (14 / 100)
train_acc: 0.4326328800988875, val_acc: 0.46798029556650245, train_loss: 1.3667268764840068, val_loss: 1.3823110534639782 (15 / 100)
train_acc: 0.4338689740420272, val_acc: 0.47783251231527096, train_loss: 1.35214987467187, val_loss: 1.291908036899097 (16 / 100)
train_acc: 0.44128553770086526, val_acc: 0.4187192118226601, train_loss: 1.3321546982186392, val_loss: 1.3186463669603095 (17 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4236453201970443, train_loss: 1.3428641131840766, val_loss: 1.321784789632694 (18 / 100)
train_acc: 0.453646477132262, val_acc: 0.43842364532019706, train_loss: 1.3031875930993606, val_loss: 1.305860425744738 (19 / 100)
train_acc: 0.4400494437577256, val_acc: 0.5073891625615764, train_loss: 1.3262761617620442, val_loss: 1.2284348075613012 (20 / 100)
train_acc: 0.45488257107540175, val_acc: 0.4975369458128079, train_loss: 1.3040157532957193, val_loss: 1.2515232827275844 (21 / 100)
train_acc: 0.4622991347342398, val_acc: 0.4729064039408867, train_loss: 1.269902616260373, val_loss: 1.1940573668245025 (22 / 100)
train_acc: 0.46971569839307786, val_acc: 0.5024630541871922, train_loss: 1.2503423229578252, val_loss: 1.211716471047237 (23 / 100)
train_acc: 0.5018541409147095, val_acc: 0.4630541871921182, train_loss: 1.2176432780488606, val_loss: 1.1879400778286562 (24 / 100)
train_acc: 0.47713226205191595, val_acc: 0.4630541871921182, train_loss: 1.1984081701530955, val_loss: 1.2538204028688629 (25 / 100)
train_acc: 0.5352286773794809, val_acc: 0.4039408866995074, train_loss: 1.1460416187314668, val_loss: 1.320281270102327 (26 / 100)
train_acc: 0.5142150803461063, val_acc: 0.5172413793103449, train_loss: 1.1738257081016474, val_loss: 1.133832203343584 (27 / 100)
train_acc: 0.5352286773794809, val_acc: 0.5320197044334976, train_loss: 1.1183652659723873, val_loss: 1.121002358462423 (28 / 100)
train_acc: 0.5451174289245982, val_acc: 0.49261083743842365, train_loss: 1.1111136290287353, val_loss: 1.1832656502136456 (29 / 100)
train_acc: 0.584672435105068, val_acc: 0.5073891625615764, train_loss: 1.036487243378855, val_loss: 1.1585325516503433 (30 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5812807881773399, train_loss: 1.0142986550466682, val_loss: 1.0409710721429346 (31 / 100)
train_acc: 0.5772558714462299, val_acc: 0.5270935960591133, train_loss: 1.0440882755298402, val_loss: 1.3250831735545192 (32 / 100)
train_acc: 0.6279357231149567, val_acc: 0.5665024630541872, train_loss: 0.9572591563532468, val_loss: 1.0984589113977743 (33 / 100)
train_acc: 0.6588380716934487, val_acc: 0.5172413793103449, train_loss: 0.9042403143916937, val_loss: 1.2745202641768996 (34 / 100)
train_acc: 0.6106304079110012, val_acc: 0.5714285714285714, train_loss: 0.95850663161543, val_loss: 1.124686754689428 (35 / 100)
train_acc: 0.6724351050679852, val_acc: 0.5911330049261084, train_loss: 0.8801800677154503, val_loss: 1.045541217468055 (36 / 100)
train_acc: 0.681087762669963, val_acc: 0.5566502463054187, train_loss: 0.8316371280271722, val_loss: 1.1234774307664392 (37 / 100)
train_acc: 0.6440049443757726, val_acc: 0.5714285714285714, train_loss: 0.9058380779730817, val_loss: 1.059775812872525 (38 / 100)
train_acc: 0.6847960444993819, val_acc: 0.5665024630541872, train_loss: 0.8128616174749744, val_loss: 1.11329992974333 (39 / 100)
train_acc: 0.7206427688504327, val_acc: 0.5763546798029556, train_loss: 0.740440401659613, val_loss: 1.1354931443195624 (40 / 100)
train_acc: 0.7552533992583437, val_acc: 0.5221674876847291, train_loss: 0.6461030888763729, val_loss: 1.3819274673320976 (41 / 100)
train_acc: 0.7082818294190358, val_acc: 0.6403940886699507, train_loss: 0.7747244780378967, val_loss: 1.0034258116055004 (42 / 100)
train_acc: 0.757725587144623, val_acc: 0.5467980295566502, train_loss: 0.598588752363462, val_loss: 1.2262857408065515 (43 / 100)
train_acc: 0.7898640296662547, val_acc: 0.5960591133004927, train_loss: 0.5280212367273527, val_loss: 1.1660183829627013 (44 / 100)
train_acc: 0.7799752781211372, val_acc: 0.5714285714285714, train_loss: 0.5495916485639084, val_loss: 1.2743532293535806 (45 / 100)
train_acc: 0.8170580964153276, val_acc: 0.6403940886699507, train_loss: 0.4773473337347929, val_loss: 1.0683577210445123 (46 / 100)
train_acc: 0.823238566131026, val_acc: 0.645320197044335, train_loss: 0.5097835921533912, val_loss: 1.0974046673093523 (47 / 100)
train_acc: 0.857849196538937, val_acc: 0.5862068965517241, train_loss: 0.38019685264865605, val_loss: 1.1799184724027887 (48 / 100)
train_acc: 0.8702101359703337, val_acc: 0.6305418719211823, train_loss: 0.36127450675398515, val_loss: 1.34804679578161 (49 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6305418719211823, train_loss: 0.37289710201055953, val_loss: 1.168285218072055 (50 / 100)
train_acc: 0.8640296662546354, val_acc: 0.6502463054187192, train_loss: 0.361205554126367, val_loss: 1.3932546045392604 (51 / 100)
train_acc: 0.8887515451174289, val_acc: 0.5763546798029556, train_loss: 0.30603227877646355, val_loss: 1.330662494222519 (52 / 100)
train_acc: 0.899876390605686, val_acc: 0.6108374384236454, train_loss: 0.28831181110646137, val_loss: 1.4213312787228618 (53 / 100)
train_acc: 0.9221260815822002, val_acc: 0.6206896551724138, train_loss: 0.22642887670118522, val_loss: 1.557025447850267 (54 / 100)
train_acc: 0.9060568603213844, val_acc: 0.5221674876847291, train_loss: 0.24244077199763803, val_loss: 2.541313206474182 (55 / 100)
train_acc: 0.8986402966625463, val_acc: 0.6354679802955665, train_loss: 0.2858858693515415, val_loss: 1.704751534708615 (56 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6650246305418719, train_loss: 0.24985001378949404, val_loss: 1.323801743573156 (57 / 100)
train_acc: 0.9085290482076638, val_acc: 0.5862068965517241, train_loss: 0.25363707380330164, val_loss: 1.1230083639398585 (58 / 100)
train_acc: 0.899876390605686, val_acc: 0.6798029556650246, train_loss: 0.2892750482476686, val_loss: 1.4046068793447146 (59 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6206896551724138, train_loss: 0.21856480033789635, val_loss: 1.2807389315713216 (60 / 100)
train_acc: 0.957972805933251, val_acc: 0.6748768472906403, train_loss: 0.1249027754673999, val_loss: 1.435417378770894 (61 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6748768472906403, train_loss: 0.11010197066553444, val_loss: 1.4270406538629767 (62 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6896551724137931, train_loss: 0.08922649431876994, val_loss: 1.4662814680578673 (63 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6847290640394089, train_loss: 0.06884433798795872, val_loss: 1.4415936379009866 (64 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6650246305418719, train_loss: 0.04147968186141534, val_loss: 1.5525748597577287 (65 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6798029556650246, train_loss: 0.06792074154569723, val_loss: 1.626547404991582 (66 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6748768472906403, train_loss: 0.06986702033704231, val_loss: 1.6191803742512105 (67 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6600985221674877, train_loss: 0.055029255498030276, val_loss: 1.6065440647707785 (68 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6699507389162561, train_loss: 0.07637244912396256, val_loss: 1.6377662153079593 (69 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6945812807881774, train_loss: 0.05826743571513663, val_loss: 1.727535083376128 (70 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6896551724137931, train_loss: 0.038835632049551115, val_loss: 1.7598296809079024 (71 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6995073891625616, train_loss: 0.05732220006077487, val_loss: 1.769244699348957 (72 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6896551724137931, train_loss: 0.042092393296316026, val_loss: 1.8278221611318917 (73 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.037434993774546094, val_loss: 1.8312079281055282 (74 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6847290640394089, train_loss: 0.05101681993387833, val_loss: 1.8020402366304633 (75 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6650246305418719, train_loss: 0.042715595590758826, val_loss: 1.9054022284564127 (76 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6748768472906403, train_loss: 0.037762753748333794, val_loss: 1.8703224133388163 (77 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6847290640394089, train_loss: 0.045077824622061106, val_loss: 1.819984798067309 (78 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6945812807881774, train_loss: 0.04840157500598281, val_loss: 1.7572949577141277 (79 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6847290640394089, train_loss: 0.03309222956375669, val_loss: 1.7864535314402556 (80 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6847290640394089, train_loss: 0.04195780202985842, val_loss: 1.8977523269911705 (81 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6798029556650246, train_loss: 0.036295725329697354, val_loss: 1.9093948843443922 (82 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6748768472906403, train_loss: 0.036119519853768746, val_loss: 1.9575519417894298 (83 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6798029556650246, train_loss: 0.027347891528173195, val_loss: 2.0809678144642874 (84 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6847290640394089, train_loss: 0.026563972566272184, val_loss: 2.0761067368126853 (85 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6995073891625616, train_loss: 0.03982419387077077, val_loss: 2.156247888879823 (86 / 100)
train_acc: 0.992583436341162, val_acc: 0.6798029556650246, train_loss: 0.024609537884979812, val_loss: 2.0539305456753434 (87 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.0464735396565554, val_loss: 2.0732113639709397 (88 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6699507389162561, train_loss: 0.03202277974528347, val_loss: 2.1508406136423495 (89 / 100)
train_acc: 0.992583436341162, val_acc: 0.6748768472906403, train_loss: 0.030073359958615674, val_loss: 2.1176841593728275 (90 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6748768472906403, train_loss: 0.038388290275602026, val_loss: 2.140389942770521 (91 / 100)
train_acc: 0.992583436341162, val_acc: 0.6798029556650246, train_loss: 0.031249152420477756, val_loss: 2.189601905827452 (92 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6847290640394089, train_loss: 0.03379299805691864, val_loss: 2.1561623306697224 (93 / 100)
train_acc: 0.992583436341162, val_acc: 0.6847290640394089, train_loss: 0.03299475320337435, val_loss: 2.1345168827789758 (94 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6798029556650246, train_loss: 0.027340762694774954, val_loss: 2.15826400497864 (95 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6699507389162561, train_loss: 0.032893426191379464, val_loss: 2.24660271875964 (96 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6699507389162561, train_loss: 0.017919134592685772, val_loss: 2.223163961776959 (97 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6699507389162561, train_loss: 0.019473741906240342, val_loss: 2.1980306341730316 (98 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6798029556650246, train_loss: 0.019049164391271262, val_loss: 2.3518697449139188 (99 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6748768472906403, train_loss: 0.04588226128567577, val_loss: 2.092450952295012 (100 / 100)
({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.1}), val accuracy 0.6995073891625616, val loss 1.769244699348957
train_acc: 0.17552533992583436, val_acc: 0.18226600985221675, train_loss: 1.7867061913529196, val_loss: 1.7791771178175075 (1 / 100)
train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7720697596577102, val_loss: 1.7614627694848723 (2 / 100)
train_acc: 0.20395550061804696, val_acc: 0.21182266009852216, train_loss: 1.7664495644669598, val_loss: 1.7573017275392129 (3 / 100)
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7659737813310659, val_loss: 1.7498102505218807 (4 / 100)
train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.760421065081772, val_loss: 1.7454664683694323 (5 / 100)
train_acc: 0.2200247218788628, val_acc: 0.21674876847290642, train_loss: 1.750442646489892, val_loss: 1.731674015815622 (6 / 100)
train_acc: 0.23362175525339926, val_acc: 0.22167487684729065, train_loss: 1.74693813680571, val_loss: 1.7249166642503786 (7 / 100)
train_acc: 0.2719406674907293, val_acc: 0.2955665024630542, train_loss: 1.7270258645928835, val_loss: 1.6690115875798492 (8 / 100)
train_acc: 0.2978986402966625, val_acc: 0.2561576354679803, train_loss: 1.6576331276239364, val_loss: 1.70579773275723 (9 / 100)
train_acc: 0.32014833127317677, val_acc: 0.26108374384236455, train_loss: 1.6355017615189806, val_loss: 1.604662971543561 (10 / 100)
train_acc: 0.3003708281829419, val_acc: 0.28078817733990147, train_loss: 1.601203126429922, val_loss: 1.5613761024522077 (11 / 100)
train_acc: 0.3288009888751545, val_acc: 0.3645320197044335, train_loss: 1.5696446093994254, val_loss: 1.505413718411488 (12 / 100)
train_acc: 0.3411619283065513, val_acc: 0.3399014778325123, train_loss: 1.5446122242287446, val_loss: 1.488220132630447 (13 / 100)
train_acc: 0.34239802224969096, val_acc: 0.3399014778325123, train_loss: 1.5430579537661615, val_loss: 1.500946936936214 (14 / 100)
train_acc: 0.3683559950556242, val_acc: 0.3448275862068966, train_loss: 1.4966775345419188, val_loss: 1.4993030819399604 (15 / 100)
train_acc: 0.377008652657602, val_acc: 0.3793103448275862, train_loss: 1.5006215747708296, val_loss: 1.3990886387566628 (16 / 100)
train_acc: 0.3683559950556242, val_acc: 0.39901477832512317, train_loss: 1.469282195506196, val_loss: 1.4177656432090722 (17 / 100)
train_acc: 0.3967861557478368, val_acc: 0.3645320197044335, train_loss: 1.4385593073035052, val_loss: 1.4859479812565695 (18 / 100)
train_acc: 0.3831891223733004, val_acc: 0.4630541871921182, train_loss: 1.4326753396775724, val_loss: 1.4042026127500487 (19 / 100)
train_acc: 0.38936959208899874, val_acc: 0.35467980295566504, train_loss: 1.4499045140368976, val_loss: 1.4209468352970818 (20 / 100)
train_acc: 0.38936959208899874, val_acc: 0.39408866995073893, train_loss: 1.396391005244921, val_loss: 1.4266862775304634 (21 / 100)
train_acc: 0.3967861557478368, val_acc: 0.4039408866995074, train_loss: 1.3956549357719563, val_loss: 1.4264585102720213 (22 / 100)
train_acc: 0.4103831891223733, val_acc: 0.4482758620689655, train_loss: 1.3828928025602851, val_loss: 1.3465086433100584 (23 / 100)
train_acc: 0.40914709517923364, val_acc: 0.3891625615763547, train_loss: 1.4008320253181221, val_loss: 1.345886016126924 (24 / 100)
train_acc: 0.4227441285537701, val_acc: 0.45320197044334976, train_loss: 1.3455022557262142, val_loss: 1.3319464499140021 (25 / 100)
train_acc: 0.43139678615574784, val_acc: 0.4088669950738916, train_loss: 1.328508162380591, val_loss: 1.3394833447897962 (26 / 100)
train_acc: 0.446229913473424, val_acc: 0.43842364532019706, train_loss: 1.3123493850304848, val_loss: 1.3016286113579285 (27 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4039408866995074, train_loss: 1.3228467029458366, val_loss: 1.3226266262566515 (28 / 100)
train_acc: 0.45982694684796044, val_acc: 0.47783251231527096, train_loss: 1.3006151792292837, val_loss: 1.3117484729278264 (29 / 100)
train_acc: 0.45241038318912236, val_acc: 0.42857142857142855, train_loss: 1.2864911405942938, val_loss: 1.2555958520015473 (30 / 100)
train_acc: 0.46600741656365885, val_acc: 0.4630541871921182, train_loss: 1.3370155972809667, val_loss: 1.2945422110299172 (31 / 100)
train_acc: 0.45982694684796044, val_acc: 0.46798029556650245, train_loss: 1.272229936715257, val_loss: 1.2673285741524156 (32 / 100)
train_acc: 0.4684796044499382, val_acc: 0.47783251231527096, train_loss: 1.2663371651370092, val_loss: 1.3187076945610234 (33 / 100)
train_acc: 0.5006180469715699, val_acc: 0.43349753694581283, train_loss: 1.254769768791529, val_loss: 1.2367622811218788 (34 / 100)
train_acc: 0.4820766378244747, val_acc: 0.5172413793103449, train_loss: 1.2586540495067355, val_loss: 1.2603292932064074 (35 / 100)
train_acc: 0.47713226205191595, val_acc: 0.4876847290640394, train_loss: 1.2310883649642153, val_loss: 1.2222722387078948 (36 / 100)
train_acc: 0.4721878862793572, val_acc: 0.47783251231527096, train_loss: 1.2333804078685633, val_loss: 1.255423502969037 (37 / 100)
train_acc: 0.5129789864029666, val_acc: 0.4482758620689655, train_loss: 1.2032629041500822, val_loss: 1.2001735024851532 (38 / 100)
train_acc: 0.4857849196538937, val_acc: 0.5024630541871922, train_loss: 1.2149709860974984, val_loss: 1.2068492300404703 (39 / 100)
train_acc: 0.515451174289246, val_acc: 0.4630541871921182, train_loss: 1.1833696530392792, val_loss: 1.236448057619809 (40 / 100)
train_acc: 0.5018541409147095, val_acc: 0.47783251231527096, train_loss: 1.1853578470103967, val_loss: 1.1723746542860134 (41 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5369458128078818, train_loss: 1.120998598147087, val_loss: 1.1161465098705199 (42 / 100)
train_acc: 0.522867737948084, val_acc: 0.49261083743842365, train_loss: 1.114392774214114, val_loss: 1.1793885985618742 (43 / 100)
train_acc: 0.5562422744128553, val_acc: 0.4975369458128079, train_loss: 1.1130529779144211, val_loss: 1.1684427361182979 (44 / 100)
train_acc: 0.5364647713226205, val_acc: 0.541871921182266, train_loss: 1.1141966344841625, val_loss: 1.134100947474024 (45 / 100)
train_acc: 0.5772558714462299, val_acc: 0.49261083743842365, train_loss: 1.0509094344670753, val_loss: 1.1838229157654523 (46 / 100)
train_acc: 0.5500618046971569, val_acc: 0.5320197044334976, train_loss: 1.0849164381015433, val_loss: 1.2440890693312208 (47 / 100)
train_acc: 0.5636588380716935, val_acc: 0.4876847290640394, train_loss: 1.0332722192346977, val_loss: 1.3864203148287506 (48 / 100)
train_acc: 0.5834363411619283, val_acc: 0.5665024630541872, train_loss: 1.0056097283498908, val_loss: 1.063759797605975 (49 / 100)
train_acc: 0.630407911001236, val_acc: 0.5123152709359606, train_loss: 0.9219692154926776, val_loss: 1.096938664396408 (50 / 100)
train_acc: 0.630407911001236, val_acc: 0.5320197044334976, train_loss: 0.9297880701287863, val_loss: 1.2912816352444916 (51 / 100)
train_acc: 0.584672435105068, val_acc: 0.5862068965517241, train_loss: 1.0464417449623458, val_loss: 1.107157943577602 (52 / 100)
train_acc: 0.619283065512979, val_acc: 0.4827586206896552, train_loss: 0.9670158443403775, val_loss: 1.3208740051156782 (53 / 100)
train_acc: 0.6563658838071693, val_acc: 0.5714285714285714, train_loss: 0.8825650866453079, val_loss: 1.1135601592181352 (54 / 100)
train_acc: 0.6711990111248455, val_acc: 0.5270935960591133, train_loss: 0.8735643067524961, val_loss: 1.2401824464351672 (55 / 100)
train_acc: 0.6971569839307787, val_acc: 0.5467980295566502, train_loss: 0.8067885930517548, val_loss: 1.196848145553044 (56 / 100)
train_acc: 0.6909765142150803, val_acc: 0.5911330049261084, train_loss: 0.7814809393381749, val_loss: 1.0750915968946635 (57 / 100)
train_acc: 0.7095179233621756, val_acc: 0.5960591133004927, train_loss: 0.7632226355659357, val_loss: 0.9929653861252545 (58 / 100)
train_acc: 0.715698393077874, val_acc: 0.5911330049261084, train_loss: 0.7356826056656054, val_loss: 1.0308979403209217 (59 / 100)
train_acc: 0.7404202719406675, val_acc: 0.5615763546798029, train_loss: 0.6882686417536034, val_loss: 1.0941929042045706 (60 / 100)
train_acc: 0.7626699629171817, val_acc: 0.5714285714285714, train_loss: 0.6229946158725045, val_loss: 1.0588257315710847 (61 / 100)
train_acc: 0.7948084054388134, val_acc: 0.5763546798029556, train_loss: 0.5374221288229538, val_loss: 1.0818868308818985 (62 / 100)
train_acc: 0.8207663782447466, val_acc: 0.6009852216748769, train_loss: 0.47850792345732485, val_loss: 1.0911050556328497 (63 / 100)
train_acc: 0.8220024721878862, val_acc: 0.5960591133004927, train_loss: 0.4859554612518683, val_loss: 1.0781594300504975 (64 / 100)
train_acc: 0.8467243510506799, val_acc: 0.5960591133004927, train_loss: 0.4502160026057542, val_loss: 1.1288301571836612 (65 / 100)
train_acc: 0.8343634116192831, val_acc: 0.5911330049261084, train_loss: 0.43685992428634607, val_loss: 1.1312250189593274 (66 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5960591133004927, train_loss: 0.4350547468927499, val_loss: 1.129136641037288 (67 / 100)
train_acc: 0.8689740420271941, val_acc: 0.6009852216748769, train_loss: 0.37153786641852965, val_loss: 1.1601834194413547 (68 / 100)
train_acc: 0.8590852904820766, val_acc: 0.5812807881773399, train_loss: 0.3830832622401941, val_loss: 1.1607770990268351 (69 / 100)
train_acc: 0.857849196538937, val_acc: 0.5911330049261084, train_loss: 0.4073346132695749, val_loss: 1.1730335005398453 (70 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5862068965517241, train_loss: 0.34137476212604084, val_loss: 1.1524767338348727 (71 / 100)
train_acc: 0.8677379480840544, val_acc: 0.5862068965517241, train_loss: 0.36262630299194193, val_loss: 1.1709032587229913 (72 / 100)
train_acc: 0.8665018541409147, val_acc: 0.6009852216748769, train_loss: 0.35522270515763715, val_loss: 1.1934796968117136 (73 / 100)
train_acc: 0.8702101359703337, val_acc: 0.5960591133004927, train_loss: 0.33860316209504276, val_loss: 1.1809903568234936 (74 / 100)
train_acc: 0.8776266996291718, val_acc: 0.6059113300492611, train_loss: 0.332035284807125, val_loss: 1.2076430631975823 (75 / 100)
train_acc: 0.8862793572311496, val_acc: 0.6059113300492611, train_loss: 0.32872251136635966, val_loss: 1.1761481331780625 (76 / 100)
train_acc: 0.857849196538937, val_acc: 0.6206896551724138, train_loss: 0.3500476162719491, val_loss: 1.1709582884910659 (77 / 100)
train_acc: 0.8974042027194067, val_acc: 0.6108374384236454, train_loss: 0.292691414045315, val_loss: 1.2080847644453565 (78 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6108374384236454, train_loss: 0.2665395858629672, val_loss: 1.229655185062897 (79 / 100)
train_acc: 0.9085290482076638, val_acc: 0.5862068965517241, train_loss: 0.2680315102539192, val_loss: 1.2235180992504646 (80 / 100)
train_acc: 0.8838071693448702, val_acc: 0.6206896551724138, train_loss: 0.2948787060597329, val_loss: 1.2275345136085754 (81 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6157635467980296, train_loss: 0.26230429722587906, val_loss: 1.2566347315980884 (82 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6206896551724138, train_loss: 0.3069091743532895, val_loss: 1.2438168879506624 (83 / 100)
train_acc: 0.9097651421508035, val_acc: 0.6009852216748769, train_loss: 0.2645287722607036, val_loss: 1.267398925250387 (84 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6059113300492611, train_loss: 0.29874491750530907, val_loss: 1.2604633764974003 (85 / 100)
train_acc: 0.9221260815822002, val_acc: 0.6059113300492611, train_loss: 0.24895509202562835, val_loss: 1.3823545384289595 (86 / 100)
train_acc: 0.892459826946848, val_acc: 0.6305418719211823, train_loss: 0.26489595300776997, val_loss: 1.2895299554458393 (87 / 100)
train_acc: 0.9048207663782447, val_acc: 0.6157635467980296, train_loss: 0.2761364952880977, val_loss: 1.3012558177774176 (88 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6059113300492611, train_loss: 0.22071441569640698, val_loss: 1.3154685059791715 (89 / 100)
train_acc: 0.92336217552534, val_acc: 0.6206896551724138, train_loss: 0.21897461726382025, val_loss: 1.3614792227745056 (90 / 100)
train_acc: 0.9159456118665018, val_acc: 0.6157635467980296, train_loss: 0.22278431275276966, val_loss: 1.3214189824212361 (91 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6108374384236454, train_loss: 0.22428327259159794, val_loss: 1.386951793003552 (92 / 100)
train_acc: 0.9258343634116193, val_acc: 0.6206896551724138, train_loss: 0.2181726547305752, val_loss: 1.353686641149333 (93 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6157635467980296, train_loss: 0.18654921251189133, val_loss: 1.4066446959385144 (94 / 100)
train_acc: 0.9258343634116193, val_acc: 0.6157635467980296, train_loss: 0.20479241536633194, val_loss: 1.4080676895937896 (95 / 100)
train_acc: 0.9159456118665018, val_acc: 0.6354679802955665, train_loss: 0.2201563859604787, val_loss: 1.358423742167468 (96 / 100)
train_acc: 0.9196538936959209, val_acc: 0.6108374384236454, train_loss: 0.24322783448750657, val_loss: 1.4080765830178565 (97 / 100)
train_acc: 0.9208899876390606, val_acc: 0.6157635467980296, train_loss: 0.2165315687859014, val_loss: 1.3669103313549398 (98 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6108374384236454, train_loss: 0.23265955522564344, val_loss: 1.39363078002272 (99 / 100)
train_acc: 0.927070457354759, val_acc: 0.6206896551724138, train_loss: 0.2056829401548625, val_loss: 1.4008251697265457 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.05}), val accuracy 0.6354679802955665, val loss 1.358423742167468
train_acc: 0.19283065512978986, val_acc: 0.33497536945812806, train_loss: 1.7881716809549792, val_loss: 1.7779768288429147 (1 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7734147214476936, val_loss: 1.7583331591977274 (2 / 100)
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7631002272604717, val_loss: 1.7497676041325911 (3 / 100)
train_acc: 0.20148331273176762, val_acc: 0.21182266009852216, train_loss: 1.761546286281166, val_loss: 1.7403714310359486 (4 / 100)
train_acc: 0.2373300370828183, val_acc: 0.2857142857142857, train_loss: 1.7535580490958704, val_loss: 1.727417577076428 (5 / 100)
train_acc: 0.22249690976514216, val_acc: 0.3103448275862069, train_loss: 1.7354290900920024, val_loss: 1.7050834136643434 (6 / 100)
train_acc: 0.27935723114956734, val_acc: 0.2660098522167488, train_loss: 1.7142355845796753, val_loss: 1.6951643909726823 (7 / 100)
train_acc: 0.315203955500618, val_acc: 0.31527093596059114, train_loss: 1.6588046513912262, val_loss: 1.6063124757682161 (8 / 100)
train_acc: 0.28182941903584674, val_acc: 0.3103448275862069, train_loss: 1.6548274804104686, val_loss: 1.5538728566005313 (9 / 100)
train_acc: 0.3374536464771323, val_acc: 0.2955665024630542, train_loss: 1.5986272764146991, val_loss: 1.5790962145246308 (10 / 100)
train_acc: 0.33250927070457353, val_acc: 0.37438423645320196, train_loss: 1.5502133575741235, val_loss: 1.4930586715049932 (11 / 100)
train_acc: 0.33127317676143386, val_acc: 0.3399014778325123, train_loss: 1.561934000187368, val_loss: 1.5445310229738358 (12 / 100)
train_acc: 0.34857849196538937, val_acc: 0.35467980295566504, train_loss: 1.5348186510602388, val_loss: 1.4349320686509457 (13 / 100)
train_acc: 0.36093943139678614, val_acc: 0.3694581280788177, train_loss: 1.5088818967710762, val_loss: 1.4566901886991679 (14 / 100)
train_acc: 0.380716934487021, val_acc: 0.4236453201970443, train_loss: 1.4648187889893654, val_loss: 1.4202055707940915 (15 / 100)
train_acc: 0.3868974042027194, val_acc: 0.3448275862068966, train_loss: 1.4487018480583822, val_loss: 1.485700742364517 (16 / 100)
train_acc: 0.35599505562422745, val_acc: 0.4088669950738916, train_loss: 1.4959891680881325, val_loss: 1.4378071929433662 (17 / 100)
train_acc: 0.40914709517923364, val_acc: 0.3793103448275862, train_loss: 1.4267218865923887, val_loss: 1.4076308417202803 (18 / 100)
train_acc: 0.38936959208899874, val_acc: 0.4039408866995074, train_loss: 1.4248939478500517, val_loss: 1.411674170658506 (19 / 100)
train_acc: 0.42027194066749074, val_acc: 0.3448275862068966, train_loss: 1.4081092977111214, val_loss: 1.468852196420942 (20 / 100)
train_acc: 0.41656365883807167, val_acc: 0.4088669950738916, train_loss: 1.3822018216065923, val_loss: 1.3848294865321644 (21 / 100)
train_acc: 0.39184177997527814, val_acc: 0.4039408866995074, train_loss: 1.4133257221969302, val_loss: 1.4318008276042093 (22 / 100)
train_acc: 0.41409147095179233, val_acc: 0.3793103448275862, train_loss: 1.3843383708017865, val_loss: 1.4365125583310432 (23 / 100)
train_acc: 0.3930778739184178, val_acc: 0.45320197044334976, train_loss: 1.3970913030897878, val_loss: 1.333253586233543 (24 / 100)
train_acc: 0.3930778739184178, val_acc: 0.39901477832512317, train_loss: 1.3616378787716181, val_loss: 1.3256547644807788 (25 / 100)
train_acc: 0.43757725587144625, val_acc: 0.43842364532019706, train_loss: 1.3408546771932444, val_loss: 1.3316951579061047 (26 / 100)
train_acc: 0.44252163164400493, val_acc: 0.458128078817734, train_loss: 1.318897257481871, val_loss: 1.3378781080245972 (27 / 100)
train_acc: 0.44746600741656367, val_acc: 0.4433497536945813, train_loss: 1.3189381002937761, val_loss: 1.2844100403668257 (28 / 100)
train_acc: 0.4264524103831891, val_acc: 0.43842364532019706, train_loss: 1.323630181466988, val_loss: 1.2848032660084991 (29 / 100)
train_acc: 0.45488257107540175, val_acc: 0.43842364532019706, train_loss: 1.3023898420286708, val_loss: 1.3630911041363118 (30 / 100)
train_acc: 0.44746600741656367, val_acc: 0.41379310344827586, train_loss: 1.3076156170023387, val_loss: 1.3195855623395571 (31 / 100)
train_acc: 0.4363411619283066, val_acc: 0.4876847290640394, train_loss: 1.3391347083232017, val_loss: 1.2600826958717384 (32 / 100)
train_acc: 0.47713226205191595, val_acc: 0.43349753694581283, train_loss: 1.2605528722440063, val_loss: 1.262712636604685 (33 / 100)
train_acc: 0.4783683559950556, val_acc: 0.45320197044334976, train_loss: 1.2518303472415184, val_loss: 1.3437247164730954 (34 / 100)
train_acc: 0.4894932014833127, val_acc: 0.4729064039408867, train_loss: 1.25080969041888, val_loss: 1.1931246196107912 (35 / 100)
train_acc: 0.4894932014833127, val_acc: 0.47783251231527096, train_loss: 1.2251961077983653, val_loss: 1.2056321428327137 (36 / 100)
train_acc: 0.5080346106304079, val_acc: 0.4482758620689655, train_loss: 1.2078783833346938, val_loss: 1.269682253816445 (37 / 100)
train_acc: 0.48825710754017304, val_acc: 0.4630541871921182, train_loss: 1.2414368508920093, val_loss: 1.264318249495746 (38 / 100)
train_acc: 0.511742892459827, val_acc: 0.4827586206896552, train_loss: 1.1690988487602016, val_loss: 1.1597017590048277 (39 / 100)
train_acc: 0.5574783683559951, val_acc: 0.4827586206896552, train_loss: 1.1609088667243608, val_loss: 1.2080183481347972 (40 / 100)
train_acc: 0.5142150803461063, val_acc: 0.458128078817734, train_loss: 1.1940429357279954, val_loss: 1.2926069054697535 (41 / 100)
train_acc: 0.5265760197775031, val_acc: 0.4975369458128079, train_loss: 1.138552622683116, val_loss: 1.146689494255141 (42 / 100)
train_acc: 0.5488257107540173, val_acc: 0.5172413793103449, train_loss: 1.135077241324671, val_loss: 1.1679491016077879 (43 / 100)
train_acc: 0.5624227441285538, val_acc: 0.46798029556650245, train_loss: 1.1035882181525967, val_loss: 1.2205086746826548 (44 / 100)
train_acc: 0.5512978986402967, val_acc: 0.5172413793103449, train_loss: 1.099695562432222, val_loss: 1.1848316685906772 (45 / 100)
train_acc: 0.5661310259579728, val_acc: 0.4876847290640394, train_loss: 1.0399584373820698, val_loss: 1.1969605848707001 (46 / 100)
train_acc: 0.5587144622991347, val_acc: 0.4876847290640394, train_loss: 1.0789792754299414, val_loss: 1.278105392244649 (47 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5467980295566502, train_loss: 1.005557960573911, val_loss: 1.1506430330534874 (48 / 100)
train_acc: 0.6007416563658838, val_acc: 0.5320197044334976, train_loss: 1.011663081472088, val_loss: 1.091199424172857 (49 / 100)
train_acc: 0.5896168108776267, val_acc: 0.5517241379310345, train_loss: 0.9906982232083201, val_loss: 1.087663529541692 (50 / 100)
train_acc: 0.6266996291718171, val_acc: 0.5517241379310345, train_loss: 0.9540937812572946, val_loss: 1.0762777451811165 (51 / 100)
train_acc: 0.6106304079110012, val_acc: 0.5862068965517241, train_loss: 0.9327894114740699, val_loss: 1.0285662741496646 (52 / 100)
train_acc: 0.6440049443757726, val_acc: 0.5467980295566502, train_loss: 0.9088691694038024, val_loss: 1.1537557288343683 (53 / 100)
train_acc: 0.6477132262051916, val_acc: 0.5566502463054187, train_loss: 0.9138181623628614, val_loss: 1.097275420949964 (54 / 100)
train_acc: 0.6427688504326329, val_acc: 0.5714285714285714, train_loss: 0.8923869119733756, val_loss: 1.0661568183617052 (55 / 100)
train_acc: 0.688504326328801, val_acc: 0.5172413793103449, train_loss: 0.8679714138045151, val_loss: 1.1385827874902434 (56 / 100)
train_acc: 0.6860321384425216, val_acc: 0.5665024630541872, train_loss: 0.7727720128148978, val_loss: 1.1353192940134134 (57 / 100)
train_acc: 0.6897404202719407, val_acc: 0.5467980295566502, train_loss: 0.797271771763989, val_loss: 1.2765797687868767 (58 / 100)
train_acc: 0.7058096415327565, val_acc: 0.541871921182266, train_loss: 0.7713309604541039, val_loss: 1.1246428947730605 (59 / 100)
train_acc: 0.723114956736712, val_acc: 0.6059113300492611, train_loss: 0.7205950556638362, val_loss: 1.1215850367334677 (60 / 100)
train_acc: 0.7601977750309024, val_acc: 0.6108374384236454, train_loss: 0.6041977638367227, val_loss: 1.0954970053851312 (61 / 100)
train_acc: 0.8121137206427689, val_acc: 0.625615763546798, train_loss: 0.5147940539311714, val_loss: 1.081510189425182 (62 / 100)
train_acc: 0.8454882571075402, val_acc: 0.6059113300492611, train_loss: 0.42254629007302347, val_loss: 1.1745587023608204 (63 / 100)
train_acc: 0.8430160692212608, val_acc: 0.6059113300492611, train_loss: 0.4095366046072084, val_loss: 1.1686384918654493 (64 / 100)
train_acc: 0.8541409147095179, val_acc: 0.6009852216748769, train_loss: 0.41736568376071964, val_loss: 1.1648910016261886 (65 / 100)
train_acc: 0.8380716934487021, val_acc: 0.6059113300492611, train_loss: 0.4053583110145055, val_loss: 1.187702827559316 (66 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6009852216748769, train_loss: 0.32018363225297963, val_loss: 1.2942142283975198 (67 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5911330049261084, train_loss: 0.3117759752700886, val_loss: 1.3193764225602738 (68 / 100)
train_acc: 0.8726823238566132, val_acc: 0.6354679802955665, train_loss: 0.32688103282849484, val_loss: 1.2678606107904407 (69 / 100)
train_acc: 0.8739184177997528, val_acc: 0.6157635467980296, train_loss: 0.33774629835734704, val_loss: 1.2432995206616781 (70 / 100)
train_acc: 0.8763906056860321, val_acc: 0.5911330049261084, train_loss: 0.32009298375569406, val_loss: 1.2903834017626759 (71 / 100)
train_acc: 0.899876390605686, val_acc: 0.6009852216748769, train_loss: 0.3108402561345707, val_loss: 1.3460353689240705 (72 / 100)
train_acc: 0.8813349814585909, val_acc: 0.6059113300492611, train_loss: 0.3140381436670666, val_loss: 1.3171994098888828 (73 / 100)
train_acc: 0.9011124845488258, val_acc: 0.6009852216748769, train_loss: 0.2682632165137858, val_loss: 1.3950019408329366 (74 / 100)
train_acc: 0.8986402966625463, val_acc: 0.6009852216748769, train_loss: 0.2805325145774483, val_loss: 1.3370464649693719 (75 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6009852216748769, train_loss: 0.27302038220156843, val_loss: 1.4200451042264552 (76 / 100)
train_acc: 0.899876390605686, val_acc: 0.6059113300492611, train_loss: 0.27446294074005484, val_loss: 1.4049768459620735 (77 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6059113300492611, train_loss: 0.260730195435959, val_loss: 1.421966187178795 (78 / 100)
train_acc: 0.9159456118665018, val_acc: 0.6108374384236454, train_loss: 0.23466148393226346, val_loss: 1.3987187931103071 (79 / 100)
train_acc: 0.9085290482076638, val_acc: 0.6009852216748769, train_loss: 0.24342338790557588, val_loss: 1.5780774258040442 (80 / 100)
train_acc: 0.9097651421508035, val_acc: 0.5960591133004927, train_loss: 0.2480047591794996, val_loss: 1.5392199079391404 (81 / 100)
train_acc: 0.9147095179233622, val_acc: 0.5862068965517241, train_loss: 0.22350144430497668, val_loss: 1.4937385253131097 (82 / 100)
train_acc: 0.927070457354759, val_acc: 0.5960591133004927, train_loss: 0.20687665015790607, val_loss: 1.5024953737047506 (83 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6157635467980296, train_loss: 0.17436108413084475, val_loss: 1.6208384031145444 (84 / 100)
train_acc: 0.9283065512978986, val_acc: 0.625615763546798, train_loss: 0.22057282884129784, val_loss: 1.5294289189606465 (85 / 100)
train_acc: 0.9295426452410384, val_acc: 0.5960591133004927, train_loss: 0.20536529855763513, val_loss: 1.690246874182095 (86 / 100)
train_acc: 0.9381953028430161, val_acc: 0.6206896551724138, train_loss: 0.17078344019219666, val_loss: 1.6129020320370866 (87 / 100)
train_acc: 0.9406674907292955, val_acc: 0.5960591133004927, train_loss: 0.1969515495140414, val_loss: 1.6860187649726868 (88 / 100)
train_acc: 0.930778739184178, val_acc: 0.6059113300492611, train_loss: 0.17904302406001593, val_loss: 1.6627946026219522 (89 / 100)
train_acc: 0.927070457354759, val_acc: 0.6305418719211823, train_loss: 0.1841702125367924, val_loss: 1.6803060294372107 (90 / 100)
train_acc: 0.9295426452410384, val_acc: 0.6305418719211823, train_loss: 0.17105760586497515, val_loss: 1.6454603551643823 (91 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6059113300492611, train_loss: 0.1592800717142368, val_loss: 1.7576656071423309 (92 / 100)
train_acc: 0.9381953028430161, val_acc: 0.6059113300492611, train_loss: 0.165865289045058, val_loss: 1.8225454373899939 (93 / 100)
train_acc: 0.9357231149567367, val_acc: 0.6354679802955665, train_loss: 0.1795586397403987, val_loss: 1.8138018256337771 (94 / 100)
train_acc: 0.9480840543881335, val_acc: 0.6157635467980296, train_loss: 0.15449895493096782, val_loss: 1.672611162286674 (95 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6157635467980296, train_loss: 0.15337616920802738, val_loss: 1.7379259951596189 (96 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6206896551724138, train_loss: 0.1500540520853106, val_loss: 1.7616617876320637 (97 / 100)
train_acc: 0.9480840543881335, val_acc: 0.625615763546798, train_loss: 0.13927228041499742, val_loss: 1.7599373932542473 (98 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6206896551724138, train_loss: 0.13107198896749941, val_loss: 1.8928195634498972 (99 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6354679802955665, train_loss: 0.13742026215135977, val_loss: 1.846150853950989 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.1}), val accuracy 0.6354679802955665, val loss 1.2678606107904407
train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.789575855723123, val_loss: 1.7863755748776966 (1 / 100)
train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7830148908794294, val_loss: 1.7777192827516002 (2 / 100)
train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7758423204917106, val_loss: 1.7657733580161785 (3 / 100)
train_acc: 0.1841779975278121, val_acc: 0.18226600985221675, train_loss: 1.7664340015394873, val_loss: 1.7543755534834462 (4 / 100)
train_acc: 0.19901112484548825, val_acc: 0.18226600985221675, train_loss: 1.7618015440197015, val_loss: 1.7484107733947303 (5 / 100)
train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7565816310781188, val_loss: 1.743395360232574 (6 / 100)
train_acc: 0.18788627935723115, val_acc: 0.18719211822660098, train_loss: 1.7514766161462432, val_loss: 1.7302689787202281 (7 / 100)
train_acc: 0.22744128553770088, val_acc: 0.3448275862068966, train_loss: 1.729438145611578, val_loss: 1.7165056208671607 (8 / 100)
train_acc: 0.26081582200247216, val_acc: 0.3103448275862069, train_loss: 1.704325728274983, val_loss: 1.6538423599280747 (9 / 100)
train_acc: 0.30407911001236093, val_acc: 0.33497536945812806, train_loss: 1.6523603390998982, val_loss: 1.5966727616164484 (10 / 100)
train_acc: 0.34239802224969096, val_acc: 0.2955665024630542, train_loss: 1.5998822721768957, val_loss: 1.5318813576486898 (11 / 100)
train_acc: 0.3053152039555006, val_acc: 0.2955665024630542, train_loss: 1.6136718979577347, val_loss: 1.5778710906728735 (12 / 100)
train_acc: 0.3510506798516687, val_acc: 0.35467980295566504, train_loss: 1.5493165310587371, val_loss: 1.5179059493717888 (13 / 100)
train_acc: 0.3572311495673671, val_acc: 0.32019704433497537, train_loss: 1.520216054468426, val_loss: 1.5122115817563286 (14 / 100)
train_acc: 0.3535228677379481, val_acc: 0.3103448275862069, train_loss: 1.503285859659664, val_loss: 1.5595973178083673 (15 / 100)
train_acc: 0.34857849196538937, val_acc: 0.3103448275862069, train_loss: 1.5102339865103345, val_loss: 1.5086308588535327 (16 / 100)
train_acc: 0.377008652657602, val_acc: 0.4088669950738916, train_loss: 1.4743757843234484, val_loss: 1.4465991757773413 (17 / 100)
train_acc: 0.3720642768850433, val_acc: 0.4039408866995074, train_loss: 1.5010449489940083, val_loss: 1.4338858568022403 (18 / 100)
train_acc: 0.3794808405438813, val_acc: 0.39408866995073893, train_loss: 1.4610646108466998, val_loss: 1.3862347931697452 (19 / 100)
train_acc: 0.38936959208899874, val_acc: 0.35467980295566504, train_loss: 1.4188565089469787, val_loss: 1.5072164852630916 (20 / 100)
train_acc: 0.380716934487021, val_acc: 0.3645320197044335, train_loss: 1.4254937789348796, val_loss: 1.4126931687293969 (21 / 100)
train_acc: 0.3831891223733004, val_acc: 0.45320197044334976, train_loss: 1.4122310781066292, val_loss: 1.3672625108305456 (22 / 100)
train_acc: 0.415327564894932, val_acc: 0.4039408866995074, train_loss: 1.389946107221917, val_loss: 1.3374344004786074 (23 / 100)
train_acc: 0.4004944375772559, val_acc: 0.4088669950738916, train_loss: 1.3772097485616563, val_loss: 1.3576608896255493 (24 / 100)
train_acc: 0.42398022249690975, val_acc: 0.4236453201970443, train_loss: 1.385506671644996, val_loss: 1.3425419512640666 (25 / 100)
train_acc: 0.4054388133498146, val_acc: 0.4236453201970443, train_loss: 1.36810480472626, val_loss: 1.3575198192314561 (26 / 100)
train_acc: 0.4276885043263288, val_acc: 0.4482758620689655, train_loss: 1.3438532390759519, val_loss: 1.3338259191348636 (27 / 100)
train_acc: 0.41656365883807167, val_acc: 0.49261083743842365, train_loss: 1.3431519409929424, val_loss: 1.2938078958999935 (28 / 100)
train_acc: 0.44746600741656367, val_acc: 0.3793103448275862, train_loss: 1.3265417868775697, val_loss: 1.3908077190662254 (29 / 100)
train_acc: 0.42398022249690975, val_acc: 0.458128078817734, train_loss: 1.3269846508617895, val_loss: 1.3113992475523737 (30 / 100)
train_acc: 0.44870210135970334, val_acc: 0.5123152709359606, train_loss: 1.3102759336511638, val_loss: 1.298353403659877 (31 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4827586206896552, train_loss: 1.2866363702215282, val_loss: 1.2468543915913022 (32 / 100)
train_acc: 0.45859085290482077, val_acc: 0.46798029556650245, train_loss: 1.291524701640102, val_loss: 1.252133670698833 (33 / 100)
train_acc: 0.43757725587144625, val_acc: 0.4876847290640394, train_loss: 1.3269593889545304, val_loss: 1.239396119352632 (34 / 100)
train_acc: 0.4932014833127318, val_acc: 0.5024630541871922, train_loss: 1.250757382443573, val_loss: 1.2225021540825003 (35 / 100)
train_acc: 0.4684796044499382, val_acc: 0.5024630541871922, train_loss: 1.2460908338666994, val_loss: 1.17262791001738 (36 / 100)
train_acc: 0.5129789864029666, val_acc: 0.4482758620689655, train_loss: 1.2254703156143538, val_loss: 1.2555073053378778 (37 / 100)
train_acc: 0.5030902348578492, val_acc: 0.5172413793103449, train_loss: 1.2198702071888927, val_loss: 1.1784195961623356 (38 / 100)
train_acc: 0.4796044499381953, val_acc: 0.541871921182266, train_loss: 1.2180566089262332, val_loss: 1.140502173325111 (39 / 100)
train_acc: 0.5216316440049443, val_acc: 0.5073891625615764, train_loss: 1.1797583646915752, val_loss: 1.1422660509353788 (40 / 100)
train_acc: 0.5067985166872683, val_acc: 0.5172413793103449, train_loss: 1.1553284004975308, val_loss: 1.1726168141576456 (41 / 100)
train_acc: 0.5265760197775031, val_acc: 0.4876847290640394, train_loss: 1.1137269399369456, val_loss: 1.168400043337216 (42 / 100)
train_acc: 0.5290482076637825, val_acc: 0.5320197044334976, train_loss: 1.1468439690114836, val_loss: 1.131948953778873 (43 / 100)
train_acc: 0.5166872682323856, val_acc: 0.5024630541871922, train_loss: 1.1311975545140516, val_loss: 1.1599651492875198 (44 / 100)
train_acc: 0.5500618046971569, val_acc: 0.46798029556650245, train_loss: 1.1000684552787998, val_loss: 1.3247084852509898 (45 / 100)
train_acc: 0.5302843016069221, val_acc: 0.5024630541871922, train_loss: 1.1096454625960777, val_loss: 1.1404862521317205 (46 / 100)
train_acc: 0.584672435105068, val_acc: 0.5073891625615764, train_loss: 1.0622549552115876, val_loss: 1.2330677356626012 (47 / 100)
train_acc: 0.5710754017305315, val_acc: 0.5172413793103449, train_loss: 1.0734078587943456, val_loss: 1.1611638967626787 (48 / 100)
train_acc: 0.5970333745364648, val_acc: 0.5369458128078818, train_loss: 1.027104963772966, val_loss: 1.1278773337749426 (49 / 100)
train_acc: 0.6106304079110012, val_acc: 0.5566502463054187, train_loss: 0.975310797154977, val_loss: 1.077500952875673 (50 / 100)
train_acc: 0.61557478368356, val_acc: 0.5665024630541872, train_loss: 0.9977686358028643, val_loss: 1.1091162967564436 (51 / 100)
train_acc: 0.619283065512979, val_acc: 0.541871921182266, train_loss: 0.97513398288649, val_loss: 1.1566370925292593 (52 / 100)
train_acc: 0.6254635352286774, val_acc: 0.5566502463054187, train_loss: 0.9567216978821678, val_loss: 1.0337940378142108 (53 / 100)
train_acc: 0.657601977750309, val_acc: 0.5862068965517241, train_loss: 0.890862897609456, val_loss: 1.1782524653256232 (54 / 100)
train_acc: 0.6588380716934487, val_acc: 0.6206896551724138, train_loss: 0.9054778444457555, val_loss: 1.0397945683577965 (55 / 100)
train_acc: 0.6662546353522868, val_acc: 0.5862068965517241, train_loss: 0.84894519653839, val_loss: 1.0239554153287351 (56 / 100)
train_acc: 0.7132262051915945, val_acc: 0.5566502463054187, train_loss: 0.7779270322862161, val_loss: 1.0968305923668622 (57 / 100)
train_acc: 0.6835599505562423, val_acc: 0.5615763546798029, train_loss: 0.7961198938055003, val_loss: 1.0819378286746923 (58 / 100)
train_acc: 0.7132262051915945, val_acc: 0.6059113300492611, train_loss: 0.7576521993862242, val_loss: 1.0149756675870547 (59 / 100)
train_acc: 0.7428924598269468, val_acc: 0.5911330049261084, train_loss: 0.6763121847463921, val_loss: 1.0511740998094306 (60 / 100)
train_acc: 0.7775030902348579, val_acc: 0.6206896551724138, train_loss: 0.5852553992542554, val_loss: 1.0427535610833192 (61 / 100)
train_acc: 0.8182941903584673, val_acc: 0.6206896551724138, train_loss: 0.46920297452339577, val_loss: 1.041386896459927 (62 / 100)
train_acc: 0.8244746600741656, val_acc: 0.6305418719211823, train_loss: 0.46754158257848694, val_loss: 1.0386985135195879 (63 / 100)
train_acc: 0.8491965389369592, val_acc: 0.6305418719211823, train_loss: 0.4791653483406133, val_loss: 1.048466730881207 (64 / 100)
train_acc: 0.8244746600741656, val_acc: 0.6305418719211823, train_loss: 0.4466899086724695, val_loss: 1.0657895430555484 (65 / 100)
train_acc: 0.8430160692212608, val_acc: 0.6108374384236454, train_loss: 0.4305742257752436, val_loss: 1.0893711606269987 (66 / 100)
train_acc: 0.8442521631644005, val_acc: 0.6157635467980296, train_loss: 0.44785939906671995, val_loss: 1.1140025275681407 (67 / 100)
train_acc: 0.861557478368356, val_acc: 0.625615763546798, train_loss: 0.39017212505098914, val_loss: 1.117974471869727 (68 / 100)
train_acc: 0.8640296662546354, val_acc: 0.6157635467980296, train_loss: 0.3831923614694692, val_loss: 1.125124629495179 (69 / 100)
train_acc: 0.8541409147095179, val_acc: 0.645320197044335, train_loss: 0.3918643675569551, val_loss: 1.1126060973247285 (70 / 100)
train_acc: 0.8788627935723115, val_acc: 0.6206896551724138, train_loss: 0.3704494236426241, val_loss: 1.124507549361055 (71 / 100)
train_acc: 0.8491965389369592, val_acc: 0.6157635467980296, train_loss: 0.37659663993437004, val_loss: 1.12116534222523 (72 / 100)
train_acc: 0.8776266996291718, val_acc: 0.6354679802955665, train_loss: 0.3483384258225468, val_loss: 1.142818760108478 (73 / 100)
train_acc: 0.8788627935723115, val_acc: 0.6157635467980296, train_loss: 0.3206241101358081, val_loss: 1.2048840158678629 (74 / 100)
train_acc: 0.8714462299134734, val_acc: 0.6354679802955665, train_loss: 0.33039566961074496, val_loss: 1.2120699218928521 (75 / 100)
train_acc: 0.8800988875154512, val_acc: 0.625615763546798, train_loss: 0.35065066475969164, val_loss: 1.1751325905616647 (76 / 100)
train_acc: 0.8912237330037083, val_acc: 0.6305418719211823, train_loss: 0.30376007567230057, val_loss: 1.192779784132107 (77 / 100)
train_acc: 0.8838071693448702, val_acc: 0.625615763546798, train_loss: 0.31017835745852723, val_loss: 1.1959079915079578 (78 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6059113300492611, train_loss: 0.33991507907733043, val_loss: 1.1895771160207946 (79 / 100)
train_acc: 0.8677379480840544, val_acc: 0.6305418719211823, train_loss: 0.33122406631008217, val_loss: 1.2201595649930643 (80 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6108374384236454, train_loss: 0.2815208190082767, val_loss: 1.277238632070607 (81 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6108374384236454, train_loss: 0.32906102658939007, val_loss: 1.2530471735399933 (82 / 100)
train_acc: 0.8776266996291718, val_acc: 0.6108374384236454, train_loss: 0.3083384231524945, val_loss: 1.2991282094288341 (83 / 100)
train_acc: 0.8912237330037083, val_acc: 0.6305418719211823, train_loss: 0.30885015838815194, val_loss: 1.2462493830126495 (84 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6206896551724138, train_loss: 0.2699255311518576, val_loss: 1.2692280300145078 (85 / 100)
train_acc: 0.8899876390605687, val_acc: 0.625615763546798, train_loss: 0.3024872248009197, val_loss: 1.2662653509031963 (86 / 100)
train_acc: 0.9060568603213844, val_acc: 0.6009852216748769, train_loss: 0.26714869773726824, val_loss: 1.250855379210317 (87 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6157635467980296, train_loss: 0.24084221121333585, val_loss: 1.3069189710570086 (88 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6157635467980296, train_loss: 0.23049256194507237, val_loss: 1.3399947103608418 (89 / 100)
train_acc: 0.907292954264524, val_acc: 0.6354679802955665, train_loss: 0.2580780697196759, val_loss: 1.375244399009667 (90 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6108374384236454, train_loss: 0.25486493623632434, val_loss: 1.3348052713084104 (91 / 100)
train_acc: 0.9221260815822002, val_acc: 0.625615763546798, train_loss: 0.22797150152870102, val_loss: 1.3578178715236082 (92 / 100)
train_acc: 0.9035846724351051, val_acc: 0.6157635467980296, train_loss: 0.2512942733443417, val_loss: 1.368195419534674 (93 / 100)
train_acc: 0.9184177997527813, val_acc: 0.6305418719211823, train_loss: 0.21454428057146013, val_loss: 1.3842737577818884 (94 / 100)
train_acc: 0.9085290482076638, val_acc: 0.6354679802955665, train_loss: 0.24378241162070238, val_loss: 1.4029077655576132 (95 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6305418719211823, train_loss: 0.21526200942262289, val_loss: 1.355099808993598 (96 / 100)
train_acc: 0.9394313967861557, val_acc: 0.6108374384236454, train_loss: 0.18855613759259507, val_loss: 1.443725131709 (97 / 100)
train_acc: 0.92336217552534, val_acc: 0.6206896551724138, train_loss: 0.2144348170465533, val_loss: 1.437174994370033 (98 / 100)
train_acc: 0.9283065512978986, val_acc: 0.645320197044335, train_loss: 0.20770391567675822, val_loss: 1.3892739779256247 (99 / 100)
train_acc: 0.934487021013597, val_acc: 0.645320197044335, train_loss: 0.2053926445276687, val_loss: 1.4028686760681603 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.05}), val accuracy 0.645320197044335, val loss 1.1126060973247285
train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.790036370344598, val_loss: 1.783659152796703 (1 / 100)
train_acc: 0.2027194066749073, val_acc: 0.21182266009852216, train_loss: 1.7808054184589457, val_loss: 1.772779097110767 (2 / 100)
train_acc: 0.19283065512978986, val_acc: 0.18226600985221675, train_loss: 1.7701850027324832, val_loss: 1.758118505548374 (3 / 100)
train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.7643645506706755, val_loss: 1.751966938596641 (4 / 100)
train_acc: 0.20642768850432633, val_acc: 0.18226600985221675, train_loss: 1.761258115285112, val_loss: 1.7459762619046741 (5 / 100)
train_acc: 0.23980222496909764, val_acc: 0.24630541871921183, train_loss: 1.7489700946583884, val_loss: 1.7312449745356744 (6 / 100)
train_acc: 0.207663782447466, val_acc: 0.23645320197044334, train_loss: 1.735748231484657, val_loss: 1.7153491709619908 (7 / 100)
train_acc: 0.26452410383189123, val_acc: 0.32019704433497537, train_loss: 1.7158710501249994, val_loss: 1.6688362735832853 (8 / 100)
train_acc: 0.2843016069221261, val_acc: 0.3399014778325123, train_loss: 1.6656891271122012, val_loss: 1.5538220411450991 (9 / 100)
train_acc: 0.2978986402966625, val_acc: 0.3399014778325123, train_loss: 1.6318226218665632, val_loss: 1.5650260037389294 (10 / 100)
train_acc: 0.3300370828182942, val_acc: 0.33497536945812806, train_loss: 1.5807168161029133, val_loss: 1.5135651128045444 (11 / 100)
train_acc: 0.3473423980222497, val_acc: 0.3842364532019704, train_loss: 1.5446540086319478, val_loss: 1.4849861390484964 (12 / 100)
train_acc: 0.34981458590852904, val_acc: 0.3793103448275862, train_loss: 1.5513836101194838, val_loss: 1.4612098820691037 (13 / 100)
train_acc: 0.3621755253399258, val_acc: 0.33497536945812806, train_loss: 1.502500392008476, val_loss: 1.4806333386839317 (14 / 100)
train_acc: 0.38442521631644005, val_acc: 0.3251231527093596, train_loss: 1.4884502214318596, val_loss: 1.605460285553204 (15 / 100)
train_acc: 0.3794808405438813, val_acc: 0.3891625615763547, train_loss: 1.4817977997811675, val_loss: 1.415337714655646 (16 / 100)
train_acc: 0.3794808405438813, val_acc: 0.35960591133004927, train_loss: 1.4398403979644492, val_loss: 1.4682486967500208 (17 / 100)
train_acc: 0.40296662546353523, val_acc: 0.35960591133004927, train_loss: 1.4315319224842105, val_loss: 1.3602283987505683 (18 / 100)
train_acc: 0.39060568603213847, val_acc: 0.39901477832512317, train_loss: 1.4391407201847128, val_loss: 1.3795887501956208 (19 / 100)
train_acc: 0.415327564894932, val_acc: 0.39901477832512317, train_loss: 1.3807057518010086, val_loss: 1.4266910946427895 (20 / 100)
train_acc: 0.40667490729295425, val_acc: 0.41379310344827586, train_loss: 1.37841539816155, val_loss: 1.367876975407154 (21 / 100)
train_acc: 0.415327564894932, val_acc: 0.37438423645320196, train_loss: 1.3749969752668891, val_loss: 1.4106353674028895 (22 / 100)
train_acc: 0.42398022249690975, val_acc: 0.45320197044334976, train_loss: 1.3752392014702701, val_loss: 1.309876381470065 (23 / 100)
train_acc: 0.4276885043263288, val_acc: 0.43842364532019706, train_loss: 1.3851672820608754, val_loss: 1.343464712204017 (24 / 100)
train_acc: 0.43757725587144625, val_acc: 0.43842364532019706, train_loss: 1.33687121847504, val_loss: 1.3158688075436746 (25 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4975369458128079, train_loss: 1.3238935892013153, val_loss: 1.3025257540453832 (26 / 100)
train_acc: 0.4672435105067985, val_acc: 0.4236453201970443, train_loss: 1.2989814294725472, val_loss: 1.3567772757243641 (27 / 100)
train_acc: 0.4561186650185414, val_acc: 0.46798029556650245, train_loss: 1.3020845188935402, val_loss: 1.267742862842353 (28 / 100)
train_acc: 0.4338689740420272, val_acc: 0.49261083743842365, train_loss: 1.291667332607972, val_loss: 1.254759975842067 (29 / 100)
train_acc: 0.47095179233621753, val_acc: 0.4729064039408867, train_loss: 1.2562577108517565, val_loss: 1.2339682103377845 (30 / 100)
train_acc: 0.46971569839307786, val_acc: 0.4729064039408867, train_loss: 1.3014311878878637, val_loss: 1.4110103974788648 (31 / 100)
train_acc: 0.48702101359703337, val_acc: 0.4433497536945813, train_loss: 1.2554876777828108, val_loss: 1.268451984292768 (32 / 100)
train_acc: 0.48084054388133496, val_acc: 0.49261083743842365, train_loss: 1.2641153731953227, val_loss: 1.1994943107877458 (33 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4630541871921182, train_loss: 1.241727095157166, val_loss: 1.2431951347243022 (34 / 100)
train_acc: 0.4956736711990111, val_acc: 0.4039408866995074, train_loss: 1.23685399976148, val_loss: 1.2677123869581175 (35 / 100)
train_acc: 0.519159456118665, val_acc: 0.45320197044334976, train_loss: 1.1704028622329015, val_loss: 1.2650268066105583 (36 / 100)
train_acc: 0.519159456118665, val_acc: 0.47783251231527096, train_loss: 1.1797258721293862, val_loss: 1.2453192977482461 (37 / 100)
train_acc: 0.5092707045735476, val_acc: 0.4876847290640394, train_loss: 1.1525350617537244, val_loss: 1.1201293606476244 (38 / 100)
train_acc: 0.5611866501854141, val_acc: 0.5369458128078818, train_loss: 1.1162945485969704, val_loss: 1.144227633922558 (39 / 100)
train_acc: 0.5784919653893696, val_acc: 0.5073891625615764, train_loss: 1.0787605287412778, val_loss: 1.1213501691818237 (40 / 100)
train_acc: 0.5686032138442522, val_acc: 0.5221674876847291, train_loss: 1.0537998070675598, val_loss: 1.1751152033289078 (41 / 100)
train_acc: 0.5611866501854141, val_acc: 0.5566502463054187, train_loss: 1.107048320902882, val_loss: 1.086316958730444 (42 / 100)
train_acc: 0.5686032138442522, val_acc: 0.5024630541871922, train_loss: 1.0521436676990854, val_loss: 1.1908996774645275 (43 / 100)
train_acc: 0.5784919653893696, val_acc: 0.5024630541871922, train_loss: 1.03633896396835, val_loss: 1.1980781966242298 (44 / 100)
train_acc: 0.6093943139678616, val_acc: 0.5172413793103449, train_loss: 0.9990160457136015, val_loss: 1.1491580720018284 (45 / 100)
train_acc: 0.6341161928306551, val_acc: 0.5270935960591133, train_loss: 0.9399209090304758, val_loss: 1.1792124251426734 (46 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5665024630541872, train_loss: 0.9591627025191657, val_loss: 1.0701323797550109 (47 / 100)
train_acc: 0.6637824474660075, val_acc: 0.4975369458128079, train_loss: 0.8974430769571415, val_loss: 1.1691559162633172 (48 / 100)
train_acc: 0.6341161928306551, val_acc: 0.49261083743842365, train_loss: 0.9087460892014804, val_loss: 1.173809425584201 (49 / 100)
train_acc: 0.6415327564894932, val_acc: 0.49261083743842365, train_loss: 0.9051232978941042, val_loss: 1.2516306606419567 (50 / 100)
train_acc: 0.6934487021013597, val_acc: 0.5862068965517241, train_loss: 0.8228797867654722, val_loss: 1.0722250042877761 (51 / 100)
train_acc: 0.6724351050679852, val_acc: 0.6157635467980296, train_loss: 0.8299549008329365, val_loss: 1.1391889394210477 (52 / 100)
train_acc: 0.7070457354758962, val_acc: 0.5763546798029556, train_loss: 0.7671191246606806, val_loss: 1.231499210073443 (53 / 100)
train_acc: 0.7021013597033374, val_acc: 0.5665024630541872, train_loss: 0.7780830299456423, val_loss: 1.14063037263936 (54 / 100)
train_acc: 0.7243510506798516, val_acc: 0.541871921182266, train_loss: 0.7348408000578249, val_loss: 1.3710498933134407 (55 / 100)
train_acc: 0.7354758961681088, val_acc: 0.5812807881773399, train_loss: 0.7000017825177927, val_loss: 1.0882153111725605 (56 / 100)
train_acc: 0.7194066749072929, val_acc: 0.5812807881773399, train_loss: 0.7181576513242073, val_loss: 1.0382346841208454 (57 / 100)
train_acc: 0.7280593325092707, val_acc: 0.5862068965517241, train_loss: 0.6853815878572217, val_loss: 1.23256132344307 (58 / 100)
train_acc: 0.7713226205191595, val_acc: 0.5073891625615764, train_loss: 0.6064157986965109, val_loss: 1.5712362903679533 (59 / 100)
train_acc: 0.7787391841779975, val_acc: 0.5812807881773399, train_loss: 0.607849069704084, val_loss: 1.370203415748521 (60 / 100)
train_acc: 0.8541409147095179, val_acc: 0.6059113300492611, train_loss: 0.3943688147810687, val_loss: 1.107720550645161 (61 / 100)
train_acc: 0.8689740420271941, val_acc: 0.645320197044335, train_loss: 0.3362807743849949, val_loss: 1.2011404187221246 (62 / 100)
train_acc: 0.8850432632880099, val_acc: 0.6157635467980296, train_loss: 0.3102692358278668, val_loss: 1.2312219944493523 (63 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6157635467980296, train_loss: 0.26703268444287614, val_loss: 1.2273976864485905 (64 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6206896551724138, train_loss: 0.23459388254894167, val_loss: 1.309953149609965 (65 / 100)
train_acc: 0.9060568603213844, val_acc: 0.625615763546798, train_loss: 0.24370424694419643, val_loss: 1.297863312836351 (66 / 100)
train_acc: 0.9122373300370828, val_acc: 0.6059113300492611, train_loss: 0.2253769216932384, val_loss: 1.2960992368864896 (67 / 100)
train_acc: 0.9184177997527813, val_acc: 0.6157635467980296, train_loss: 0.2158598499038753, val_loss: 1.4464360739797206 (68 / 100)
train_acc: 0.9295426452410384, val_acc: 0.625615763546798, train_loss: 0.19553997151194455, val_loss: 1.3698900042496291 (69 / 100)
train_acc: 0.9332509270704573, val_acc: 0.625615763546798, train_loss: 0.21250759000683891, val_loss: 1.3933430406553993 (70 / 100)
train_acc: 0.9456118665018541, val_acc: 0.6403940886699507, train_loss: 0.16224811961977975, val_loss: 1.48300426934153 (71 / 100)
train_acc: 0.9320148331273177, val_acc: 0.6206896551724138, train_loss: 0.1803308997869639, val_loss: 1.4837565755315603 (72 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6354679802955665, train_loss: 0.16793237484724471, val_loss: 1.5631447965875636 (73 / 100)
train_acc: 0.930778739184178, val_acc: 0.6108374384236454, train_loss: 0.17246076026965942, val_loss: 1.5106852326193467 (74 / 100)
train_acc: 0.9283065512978986, val_acc: 0.625615763546798, train_loss: 0.18038434932199485, val_loss: 1.6161598994814117 (75 / 100)
train_acc: 0.9468479604449939, val_acc: 0.6403940886699507, train_loss: 0.15550983906234297, val_loss: 1.729526839820035 (76 / 100)
train_acc: 0.9357231149567367, val_acc: 0.6403940886699507, train_loss: 0.17165772111255248, val_loss: 1.591974268552705 (77 / 100)
train_acc: 0.9245982694684796, val_acc: 0.6403940886699507, train_loss: 0.1911587460295784, val_loss: 1.6096720616218492 (78 / 100)
train_acc: 0.9406674907292955, val_acc: 0.6305418719211823, train_loss: 0.16392651891936771, val_loss: 1.5240792366377827 (79 / 100)
train_acc: 0.9419035846724351, val_acc: 0.6354679802955665, train_loss: 0.14309879904440218, val_loss: 1.6225027016230993 (80 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6305418719211823, train_loss: 0.10977120412000177, val_loss: 1.7124007720078154 (81 / 100)
train_acc: 0.9456118665018541, val_acc: 0.625615763546798, train_loss: 0.1518749112150504, val_loss: 1.7082997181732666 (82 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6009852216748769, train_loss: 0.13691466475741382, val_loss: 1.6626794399886295 (83 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6305418719211823, train_loss: 0.12224676081051933, val_loss: 1.6691927613295945 (84 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6502463054187192, train_loss: 0.12575173967406245, val_loss: 1.6566329690916786 (85 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6305418719211823, train_loss: 0.1102468239509573, val_loss: 1.7386083806970436 (86 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6305418719211823, train_loss: 0.11482894876960328, val_loss: 1.835993166627555 (87 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6502463054187192, train_loss: 0.11361911344918686, val_loss: 1.7083652097309752 (88 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6206896551724138, train_loss: 0.1334752171531743, val_loss: 1.8429296204609236 (89 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6403940886699507, train_loss: 0.12426507251975512, val_loss: 1.7754663261286732 (90 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6305418719211823, train_loss: 0.11444958090368884, val_loss: 1.8175491373527226 (91 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6206896551724138, train_loss: 0.12099441521362446, val_loss: 1.8335086430234862 (92 / 100)
train_acc: 0.9555006180469716, val_acc: 0.625615763546798, train_loss: 0.10772527251346554, val_loss: 1.961489537079346 (93 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6354679802955665, train_loss: 0.10363551532234927, val_loss: 1.914489648318643 (94 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6305418719211823, train_loss: 0.1254790153340592, val_loss: 1.8282695952894652 (95 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6502463054187192, train_loss: 0.09640213968842411, val_loss: 1.9138829995845925 (96 / 100)
train_acc: 0.9567367119901112, val_acc: 0.625615763546798, train_loss: 0.09542724994895922, val_loss: 1.907483242709061 (97 / 100)
train_acc: 0.9517923362175525, val_acc: 0.6403940886699507, train_loss: 0.11935730722395539, val_loss: 1.9492870281482566 (98 / 100)
train_acc: 0.9542645241038319, val_acc: 0.6305418719211823, train_loss: 0.1268505957092726, val_loss: 1.7848305452633373 (99 / 100)
train_acc: 0.9641532756489494, val_acc: 0.645320197044335, train_loss: 0.10740260405832043, val_loss: 1.9490951866351913 (100 / 100)
({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.1}), val accuracy 0.6502463054187192, val loss 1.6566329690916786
train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.782881315323272, val_loss: 1.7616474734151304 (1 / 100)
train_acc: 0.20024721878862795, val_acc: 0.18226600985221675, train_loss: 1.7627461886376474, val_loss: 1.749805768135146 (2 / 100)
train_acc: 0.23485784919653893, val_acc: 0.2660098522167488, train_loss: 1.7530899529698754, val_loss: 1.7153229155563956 (3 / 100)
train_acc: 0.2249690976514215, val_acc: 0.18719211822660098, train_loss: 1.741901600464018, val_loss: 1.7552979027696431 (4 / 100)
train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7712897629614077, val_loss: 1.7523370094487232 (5 / 100)
train_acc: 0.22620519159456118, val_acc: 0.22660098522167488, train_loss: 1.7425021748018206, val_loss: 1.7039266219867275 (6 / 100)
train_acc: 0.27070457354758964, val_acc: 0.2561576354679803, train_loss: 1.6740298377273994, val_loss: 1.7125173836506058 (7 / 100)
train_acc: 0.32014833127317677, val_acc: 0.3694581280788177, train_loss: 1.5839541919151843, val_loss: 1.4635233379937158 (8 / 100)
train_acc: 0.34363411619283063, val_acc: 0.3694581280788177, train_loss: 1.5110865467411037, val_loss: 1.5641622772357735 (9 / 100)
train_acc: 0.34487021013597036, val_acc: 0.35960591133004927, train_loss: 1.5464277500275185, val_loss: 1.4020688504421066 (10 / 100)
train_acc: 0.3621755253399258, val_acc: 0.3793103448275862, train_loss: 1.4956206420738116, val_loss: 1.387225291411865 (11 / 100)
train_acc: 0.37082818294190356, val_acc: 0.43842364532019706, train_loss: 1.4513616491159786, val_loss: 1.3531718612304462 (12 / 100)
train_acc: 0.40296662546353523, val_acc: 0.4236453201970443, train_loss: 1.4125532443797486, val_loss: 1.321752969267333 (13 / 100)
train_acc: 0.415327564894932, val_acc: 0.4630541871921182, train_loss: 1.3817537638401367, val_loss: 1.3545908114593017 (14 / 100)
train_acc: 0.415327564894932, val_acc: 0.4088669950738916, train_loss: 1.3726256795513025, val_loss: 1.3470290828808187 (15 / 100)
train_acc: 0.4227441285537701, val_acc: 0.3793103448275862, train_loss: 1.3760291230398587, val_loss: 1.348023684741241 (16 / 100)
train_acc: 0.453646477132262, val_acc: 0.4039408866995074, train_loss: 1.3056324207591186, val_loss: 1.406610155340486 (17 / 100)
train_acc: 0.44499381953028433, val_acc: 0.4729064039408867, train_loss: 1.352841689648528, val_loss: 1.2371691917550975 (18 / 100)
train_acc: 0.43139678615574784, val_acc: 0.4482758620689655, train_loss: 1.3176255768397536, val_loss: 1.2787332981090827 (19 / 100)
train_acc: 0.449938195302843, val_acc: 0.4039408866995074, train_loss: 1.2981361516179202, val_loss: 1.3744321929410173 (20 / 100)
train_acc: 0.4820766378244747, val_acc: 0.458128078817734, train_loss: 1.2575165205744494, val_loss: 1.2252734664625722 (21 / 100)
train_acc: 0.5067985166872683, val_acc: 0.458128078817734, train_loss: 1.188004083185467, val_loss: 1.1978967316044962 (22 / 100)
train_acc: 0.5105067985166872, val_acc: 0.4975369458128079, train_loss: 1.1608989210741776, val_loss: 1.1408153889801702 (23 / 100)
train_acc: 0.5055624227441285, val_acc: 0.5221674876847291, train_loss: 1.181423401508402, val_loss: 1.2111586802111471 (24 / 100)
train_acc: 0.5253399258343634, val_acc: 0.5073891625615764, train_loss: 1.1277038662041663, val_loss: 1.1704561322780664 (25 / 100)
train_acc: 0.5389369592088998, val_acc: 0.4827586206896552, train_loss: 1.0812205649424247, val_loss: 1.261010960405096 (26 / 100)
train_acc: 0.5203955500618047, val_acc: 0.46798029556650245, train_loss: 1.1001774863937435, val_loss: 1.2102816416124993 (27 / 100)
train_acc: 0.5587144622991347, val_acc: 0.5467980295566502, train_loss: 1.0469135852030977, val_loss: 1.1183714314634576 (28 / 100)
train_acc: 0.6131025957972805, val_acc: 0.5320197044334976, train_loss: 0.9512963533696197, val_loss: 1.383552074432373 (29 / 100)
train_acc: 0.6118665018541409, val_acc: 0.541871921182266, train_loss: 0.9718651890902054, val_loss: 1.1133185754268629 (30 / 100)
train_acc: 0.6106304079110012, val_acc: 0.458128078817734, train_loss: 0.9541620833912061, val_loss: 1.2096222445295362 (31 / 100)
train_acc: 0.6032138442521632, val_acc: 0.5221674876847291, train_loss: 0.9275260779117919, val_loss: 1.2025150295548839 (32 / 100)
train_acc: 0.6477132262051916, val_acc: 0.5665024630541872, train_loss: 0.841917237186314, val_loss: 1.2161457115793464 (33 / 100)
train_acc: 0.6613102595797281, val_acc: 0.5270935960591133, train_loss: 0.8311119943083585, val_loss: 1.1437478682090496 (34 / 100)
train_acc: 0.6909765142150803, val_acc: 0.5812807881773399, train_loss: 0.7819828609895647, val_loss: 1.18491270095844 (35 / 100)
train_acc: 0.7119901112484549, val_acc: 0.5812807881773399, train_loss: 0.7068677395029622, val_loss: 1.3472842148372106 (36 / 100)
train_acc: 0.7330037082818294, val_acc: 0.5714285714285714, train_loss: 0.6721510680850563, val_loss: 1.493814093138784 (37 / 100)
train_acc: 0.7478368355995055, val_acc: 0.541871921182266, train_loss: 0.6418719461143975, val_loss: 1.4240675201556954 (38 / 100)
train_acc: 0.6563658838071693, val_acc: 0.6009852216748769, train_loss: 0.8965257515276613, val_loss: 1.317479782210195 (39 / 100)
train_acc: 0.7688504326328801, val_acc: 0.6009852216748769, train_loss: 0.591836364513864, val_loss: 1.1379343829131479 (40 / 100)
train_acc: 0.7911001236093943, val_acc: 0.6009852216748769, train_loss: 0.5420543835101228, val_loss: 1.2556331275131902 (41 / 100)
train_acc: 0.830655129789864, val_acc: 0.5714285714285714, train_loss: 0.4880018808933065, val_loss: 1.5658398590651639 (42 / 100)
train_acc: 0.8355995055624228, val_acc: 0.5566502463054187, train_loss: 0.46705365063086135, val_loss: 1.170225100270633 (43 / 100)
train_acc: 0.8393077873918418, val_acc: 0.6206896551724138, train_loss: 0.44754072349652074, val_loss: 1.2612554477940638 (44 / 100)
train_acc: 0.8393077873918418, val_acc: 0.5615763546798029, train_loss: 0.42676417936648076, val_loss: 1.2434127832868416 (45 / 100)
train_acc: 0.8504326328800988, val_acc: 0.5517241379310345, train_loss: 0.43158295216460163, val_loss: 1.3686379147280614 (46 / 100)
train_acc: 0.8121137206427689, val_acc: 0.5270935960591133, train_loss: 0.47962329797308584, val_loss: 1.3694749542057807 (47 / 100)
train_acc: 0.8603213844252163, val_acc: 0.5517241379310345, train_loss: 0.35158658337092075, val_loss: 1.218914138272478 (48 / 100)
train_acc: 0.892459826946848, val_acc: 0.5763546798029556, train_loss: 0.29011826963153553, val_loss: 1.6818435579685156 (49 / 100)
train_acc: 0.8763906056860321, val_acc: 0.6502463054187192, train_loss: 0.3408468099695496, val_loss: 1.3579412293551592 (50 / 100)
train_acc: 0.9048207663782447, val_acc: 0.6354679802955665, train_loss: 0.28613367142577106, val_loss: 1.5230607678150307 (51 / 100)
train_acc: 0.9134734239802225, val_acc: 0.6354679802955665, train_loss: 0.2485086895774115, val_loss: 1.6251519108053498 (52 / 100)
train_acc: 0.9110012360939431, val_acc: 0.5862068965517241, train_loss: 0.25393048205098645, val_loss: 1.6672952644930685 (53 / 100)
train_acc: 0.9011124845488258, val_acc: 0.5369458128078818, train_loss: 0.2974778748265892, val_loss: 2.154646849397368 (54 / 100)
train_acc: 0.9196538936959209, val_acc: 0.6108374384236454, train_loss: 0.22059579773797977, val_loss: 1.5509395385023408 (55 / 100)
train_acc: 0.9258343634116193, val_acc: 0.5812807881773399, train_loss: 0.18585714495226244, val_loss: 1.4594049838376162 (56 / 100)
train_acc: 0.9406674907292955, val_acc: 0.5960591133004927, train_loss: 0.17293981509686107, val_loss: 2.461033284957773 (57 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5517241379310345, train_loss: 0.2970237780560374, val_loss: 2.183263268964044 (58 / 100)
train_acc: 0.9085290482076638, val_acc: 0.6059113300492611, train_loss: 0.24908862700421083, val_loss: 2.0696091251860698 (59 / 100)
train_acc: 0.9369592088998764, val_acc: 0.6305418719211823, train_loss: 0.16812519929907083, val_loss: 1.9920062455050465 (60 / 100)
train_acc: 0.9542645241038319, val_acc: 0.6305418719211823, train_loss: 0.12291042221196649, val_loss: 1.9132861245441906 (61 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6305418719211823, train_loss: 0.10066253366812197, val_loss: 1.9036951194255811 (62 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6354679802955665, train_loss: 0.07833236610638933, val_loss: 1.8927486829569775 (63 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6403940886699507, train_loss: 0.096893712233554, val_loss: 1.9971208751495249 (64 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6502463054187192, train_loss: 0.08067589784582112, val_loss: 2.0029537666020136 (65 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6354679802955665, train_loss: 0.0952027374498629, val_loss: 2.0926983033494997 (66 / 100)
train_acc: 0.9752781211372065, val_acc: 0.625615763546798, train_loss: 0.07151697194767824, val_loss: 2.0493830316172446 (67 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6403940886699507, train_loss: 0.06607367656434275, val_loss: 2.0219075917610394 (68 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6206896551724138, train_loss: 0.0821464932598496, val_loss: 2.079676838343954 (69 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6157635467980296, train_loss: 0.06095280885991119, val_loss: 2.1578694344154132 (70 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6305418719211823, train_loss: 0.04830947956726489, val_loss: 2.1991110059428096 (71 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6206896551724138, train_loss: 0.06723993537747226, val_loss: 2.195874654013535 (72 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6009852216748769, train_loss: 0.08108539295432299, val_loss: 2.2399850784264173 (73 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6059113300492611, train_loss: 0.07576344747036437, val_loss: 2.2059775452895707 (74 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6059113300492611, train_loss: 0.06625888668857192, val_loss: 2.2242922169234367 (75 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6059113300492611, train_loss: 0.06407549958883316, val_loss: 2.271850263837523 (76 / 100)
train_acc: 0.9740420271940667, val_acc: 0.5960591133004927, train_loss: 0.0720906645170101, val_loss: 2.26259573809619 (77 / 100)
train_acc: 0.9789864029666254, val_acc: 0.5960591133004927, train_loss: 0.0565322970577754, val_loss: 2.2915802048932155 (78 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6059113300492611, train_loss: 0.06272224899570196, val_loss: 2.3501938930873214 (79 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6009852216748769, train_loss: 0.06624108044561851, val_loss: 2.343161399728559 (80 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6157635467980296, train_loss: 0.052980653877164, val_loss: 2.38551939355916 (81 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6206896551724138, train_loss: 0.07270181341135899, val_loss: 2.3295334192919612 (82 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6059113300492611, train_loss: 0.04802965469501811, val_loss: 2.4228000212185488 (83 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6157635467980296, train_loss: 0.06471413926524197, val_loss: 2.4131171644614837 (84 / 100)
train_acc: 0.9752781211372065, val_acc: 0.5960591133004927, train_loss: 0.066273981620119, val_loss: 2.428780642049066 (85 / 100)
train_acc: 0.9851668726823238, val_acc: 0.5911330049261084, train_loss: 0.05008179885053222, val_loss: 2.4942433511095095 (86 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6009852216748769, train_loss: 0.06307580017188866, val_loss: 2.4841029191839286 (87 / 100)
train_acc: 0.9814585908529048, val_acc: 0.5911330049261084, train_loss: 0.04185305640782944, val_loss: 2.5695150620831644 (88 / 100)
train_acc: 0.9888751545117429, val_acc: 0.5911330049261084, train_loss: 0.04618625293113982, val_loss: 2.6540827522136894 (89 / 100)
train_acc: 0.9851668726823238, val_acc: 0.5960591133004927, train_loss: 0.048252180863369826, val_loss: 2.6055621319803697 (90 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6059113300492611, train_loss: 0.0361861105460319, val_loss: 2.6402859881593677 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6108374384236454, train_loss: 0.03213508358991927, val_loss: 2.6413110418272723 (92 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6108374384236454, train_loss: 0.04315941383871071, val_loss: 2.6067734936188005 (93 / 100)
train_acc: 0.9703337453646477, val_acc: 0.5960591133004927, train_loss: 0.06671104737648416, val_loss: 2.631737849688882 (94 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6009852216748769, train_loss: 0.06437077097898655, val_loss: 2.578400541115277 (95 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5960591133004927, train_loss: 0.042280172093394956, val_loss: 2.630060510975974 (96 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5911330049261084, train_loss: 0.052316891395559416, val_loss: 2.6882299175990627 (97 / 100)
train_acc: 0.9777503090234858, val_acc: 0.5960591133004927, train_loss: 0.06409127323235511, val_loss: 2.6082129924755377 (98 / 100)
train_acc: 0.9765142150803461, val_acc: 0.5911330049261084, train_loss: 0.05072733056265285, val_loss: 2.704536243318924 (99 / 100)
train_acc: 0.9888751545117429, val_acc: 0.5911330049261084, train_loss: 0.03849921621409865, val_loss: 2.780947189025691 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}), val accuracy 0.6502463054187192, val loss 1.3579412293551592
train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.776161844267686, val_loss: 1.7748959692828175 (1 / 100)
train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7650602848185009, val_loss: 1.7271266470988984 (2 / 100)
train_acc: 0.22249690976514216, val_acc: 0.2413793103448276, train_loss: 1.7041137869779495, val_loss: 1.7549225661554948 (3 / 100)
train_acc: 0.29666254635352285, val_acc: 0.33004926108374383, train_loss: 1.6633937968901267, val_loss: 1.6002815873752088 (4 / 100)
train_acc: 0.2669962917181706, val_acc: 0.23645320197044334, train_loss: 1.6891572080524948, val_loss: 1.744096542814095 (5 / 100)
train_acc: 0.32014833127317677, val_acc: 0.32019704433497537, train_loss: 1.6227412795548974, val_loss: 1.6127175574232204 (6 / 100)
train_acc: 0.2694684796044499, val_acc: 0.33004926108374383, train_loss: 1.6718000559635893, val_loss: 1.618563810005564 (7 / 100)
train_acc: 0.2558714462299135, val_acc: 0.3448275862068966, train_loss: 1.6936152379209237, val_loss: 1.5750968914313856 (8 / 100)
train_acc: 0.30284301606922126, val_acc: 0.3497536945812808, train_loss: 1.584800211843955, val_loss: 1.783346526728475 (9 / 100)
train_acc: 0.3176761433868974, val_acc: 0.2857142857142857, train_loss: 1.5961880436344407, val_loss: 1.6227654371355555 (10 / 100)
train_acc: 0.34981458590852904, val_acc: 0.1921182266009852, train_loss: 1.5624870092818706, val_loss: 1.7770118449121861 (11 / 100)
train_acc: 0.3362175525339926, val_acc: 0.35467980295566504, train_loss: 1.588651460829123, val_loss: 1.514542261955186 (12 / 100)
train_acc: 0.36711990111248455, val_acc: 0.32019704433497537, train_loss: 1.5115779737017505, val_loss: 1.5438968001915316 (13 / 100)
train_acc: 0.3757725587144623, val_acc: 0.35467980295566504, train_loss: 1.481964731835317, val_loss: 1.4847759783561594 (14 / 100)
train_acc: 0.37453646477132263, val_acc: 0.3891625615763547, train_loss: 1.460916026266308, val_loss: 1.4356425636507608 (15 / 100)
train_acc: 0.3720642768850433, val_acc: 0.4088669950738916, train_loss: 1.4506589097646612, val_loss: 1.4119974245578784 (16 / 100)
train_acc: 0.39555006180469715, val_acc: 0.37438423645320196, train_loss: 1.419062790970867, val_loss: 1.3782921759365814 (17 / 100)
train_acc: 0.35970333745364647, val_acc: 0.3645320197044335, train_loss: 1.4780874611862804, val_loss: 1.431219770990569 (18 / 100)
train_acc: 0.41285537700865266, val_acc: 0.4236453201970443, train_loss: 1.367166550109354, val_loss: 1.3122546766779106 (19 / 100)
train_acc: 0.4289245982694685, val_acc: 0.4236453201970443, train_loss: 1.3242196131990336, val_loss: 1.2724427971346626 (20 / 100)
train_acc: 0.41409147095179233, val_acc: 0.3891625615763547, train_loss: 1.3136464935003311, val_loss: 1.28390526888993 (21 / 100)
train_acc: 0.45859085290482077, val_acc: 0.4729064039408867, train_loss: 1.2768386639240203, val_loss: 1.2099098404640047 (22 / 100)
train_acc: 0.4721878862793572, val_acc: 0.4236453201970443, train_loss: 1.2242332310847506, val_loss: 1.4042892068477686 (23 / 100)
train_acc: 0.4721878862793572, val_acc: 0.41379310344827586, train_loss: 1.2248399646674157, val_loss: 1.339648981399724 (24 / 100)
train_acc: 0.4932014833127318, val_acc: 0.4482758620689655, train_loss: 1.1755931465823217, val_loss: 1.3043095745476596 (25 / 100)
train_acc: 0.47713226205191595, val_acc: 0.5073891625615764, train_loss: 1.1747096498463445, val_loss: 1.1514149642930243 (26 / 100)
train_acc: 0.5166872682323856, val_acc: 0.49261083743842365, train_loss: 1.112547199127848, val_loss: 1.1310657447782055 (27 / 100)
train_acc: 0.5105067985166872, val_acc: 0.4630541871921182, train_loss: 1.0948514192743855, val_loss: 1.3470302605863862 (28 / 100)
train_acc: 0.5562422744128553, val_acc: 0.45320197044334976, train_loss: 1.0360146296775827, val_loss: 1.2551728334332921 (29 / 100)
train_acc: 0.5611866501854141, val_acc: 0.5123152709359606, train_loss: 1.0479497971434528, val_loss: 1.0867785685168112 (30 / 100)
train_acc: 0.553770086526576, val_acc: 0.49261083743842365, train_loss: 1.0332376426465726, val_loss: 1.4571324651464452 (31 / 100)
train_acc: 0.5488257107540173, val_acc: 0.541871921182266, train_loss: 0.9997686523442215, val_loss: 1.237691990847658 (32 / 100)
train_acc: 0.6019777503090235, val_acc: 0.5024630541871922, train_loss: 0.91807540518097, val_loss: 1.1704226644168347 (33 / 100)
train_acc: 0.6279357231149567, val_acc: 0.41379310344827586, train_loss: 0.9037937858638126, val_loss: 1.3709430406833518 (34 / 100)
train_acc: 0.6291718170580964, val_acc: 0.5270935960591133, train_loss: 0.8893562477215553, val_loss: 1.4866380268717048 (35 / 100)
train_acc: 0.6217552533992583, val_acc: 0.5369458128078818, train_loss: 0.8765463098165278, val_loss: 1.1742351824426887 (36 / 100)
train_acc: 0.657601977750309, val_acc: 0.5320197044334976, train_loss: 0.8075024306553109, val_loss: 1.1492360043408247 (37 / 100)
train_acc: 0.6971569839307787, val_acc: 0.5172413793103449, train_loss: 0.7442240293594756, val_loss: 2.228500323342572 (38 / 100)
train_acc: 0.7058096415327565, val_acc: 0.46798029556650245, train_loss: 0.7287138248108815, val_loss: 1.2125111976867826 (39 / 100)
train_acc: 0.7033374536464772, val_acc: 0.5517241379310345, train_loss: 0.712916081267028, val_loss: 1.282698397565945 (40 / 100)
train_acc: 0.7441285537700866, val_acc: 0.5763546798029556, train_loss: 0.6423395876536705, val_loss: 1.3371237034868138 (41 / 100)
train_acc: 0.7280593325092707, val_acc: 0.5615763546798029, train_loss: 0.6819353379189452, val_loss: 1.610154151622885 (42 / 100)
train_acc: 0.7663782447466008, val_acc: 0.5763546798029556, train_loss: 0.5787705183029175, val_loss: 1.3413369532289177 (43 / 100)
train_acc: 0.7527812113720643, val_acc: 0.5369458128078818, train_loss: 0.6222781099111984, val_loss: 1.1965417803214689 (44 / 100)
train_acc: 0.7824474660074165, val_acc: 0.5665024630541872, train_loss: 0.5492763989345989, val_loss: 1.4989940286269916 (45 / 100)
train_acc: 0.7873918417799752, val_acc: 0.5763546798029556, train_loss: 0.50672099381059, val_loss: 1.6139875949897202 (46 / 100)
train_acc: 0.7812113720642769, val_acc: 0.5270935960591133, train_loss: 0.5527455081751085, val_loss: 2.057492254990075 (47 / 100)
train_acc: 0.8331273176761433, val_acc: 0.6059113300492611, train_loss: 0.4481331469544079, val_loss: 1.1607159006184544 (48 / 100)
train_acc: 0.826946847960445, val_acc: 0.5665024630541872, train_loss: 0.43444221114051357, val_loss: 1.2147139686669035 (49 / 100)
train_acc: 0.8355995055624228, val_acc: 0.5369458128078818, train_loss: 0.424743882215804, val_loss: 1.498170271295632 (50 / 100)
train_acc: 0.8665018541409147, val_acc: 0.5369458128078818, train_loss: 0.3687011146427527, val_loss: 2.373682717971614 (51 / 100)
train_acc: 0.8702101359703337, val_acc: 0.5467980295566502, train_loss: 0.3878139450464614, val_loss: 1.8121903347851607 (52 / 100)
train_acc: 0.8776266996291718, val_acc: 0.5714285714285714, train_loss: 0.33790076898850674, val_loss: 1.9895601689521902 (53 / 100)
train_acc: 0.8763906056860321, val_acc: 0.5763546798029556, train_loss: 0.3579512091885391, val_loss: 2.1988414837221795 (54 / 100)
train_acc: 0.8714462299134734, val_acc: 0.5369458128078818, train_loss: 0.30443016796088485, val_loss: 2.3398136822460907 (55 / 100)
train_acc: 0.8405438813349815, val_acc: 0.5714285714285714, train_loss: 0.40789248460008126, val_loss: 2.8357464151429426 (56 / 100)
train_acc: 0.8726823238566132, val_acc: 0.5566502463054187, train_loss: 0.37543489081308484, val_loss: 2.385440692525779 (57 / 100)
train_acc: 0.8800988875154512, val_acc: 0.6009852216748769, train_loss: 0.3260406249827891, val_loss: 1.3941974076144215 (58 / 100)
train_acc: 0.934487021013597, val_acc: 0.5714285714285714, train_loss: 0.1633495665598564, val_loss: 2.628448506147403 (59 / 100)
train_acc: 0.9295426452410384, val_acc: 0.5862068965517241, train_loss: 0.21435840860727542, val_loss: 2.15069896892961 (60 / 100)
train_acc: 0.9678615574783683, val_acc: 0.5911330049261084, train_loss: 0.11136407124244681, val_loss: 2.068101933143409 (61 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6009852216748769, train_loss: 0.06477826973711162, val_loss: 2.1494226065175286 (62 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6009852216748769, train_loss: 0.06955563432648686, val_loss: 2.2880654076637303 (63 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6009852216748769, train_loss: 0.05703650932524201, val_loss: 2.2909903523369963 (64 / 100)
train_acc: 0.9752781211372065, val_acc: 0.5960591133004927, train_loss: 0.08217674221184994, val_loss: 2.186065123879851 (65 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6009852216748769, train_loss: 0.061576074958584366, val_loss: 2.2925187005785297 (66 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6157635467980296, train_loss: 0.06539345686456328, val_loss: 2.2596824668311135 (67 / 100)
train_acc: 0.9851668726823238, val_acc: 0.625615763546798, train_loss: 0.04589277734273149, val_loss: 2.227667583326988 (68 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6305418719211823, train_loss: 0.056409827121550724, val_loss: 2.309740585646606 (69 / 100)
train_acc: 0.969097651421508, val_acc: 0.6059113300492611, train_loss: 0.08036033302656063, val_loss: 2.4858311661358536 (70 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6009852216748769, train_loss: 0.06359901431169734, val_loss: 2.512324630920523 (71 / 100)
train_acc: 0.9740420271940667, val_acc: 0.5960591133004927, train_loss: 0.06421315611071876, val_loss: 2.3603664950784204 (72 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6059113300492611, train_loss: 0.056905196093216225, val_loss: 2.416540479718758 (73 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6059113300492611, train_loss: 0.036791685337778664, val_loss: 2.571221536309848 (74 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6059113300492611, train_loss: 0.046858833363678014, val_loss: 2.6504929177279544 (75 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6009852216748769, train_loss: 0.03508801852227436, val_loss: 2.8284334836922254 (76 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6059113300492611, train_loss: 0.041339959290767336, val_loss: 2.883956371857028 (77 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6157635467980296, train_loss: 0.03803020295754941, val_loss: 2.746489129630216 (78 / 100)
train_acc: 0.9864029666254636, val_acc: 0.5911330049261084, train_loss: 0.03857137319920826, val_loss: 2.769432660394114 (79 / 100)
train_acc: 0.9864029666254636, val_acc: 0.5862068965517241, train_loss: 0.04686769964668453, val_loss: 2.8826332620799247 (80 / 100)
train_acc: 0.9876390605686032, val_acc: 0.5911330049261084, train_loss: 0.04082533146159169, val_loss: 2.879913175047325 (81 / 100)
train_acc: 0.9901112484548825, val_acc: 0.5911330049261084, train_loss: 0.03392728046964214, val_loss: 3.004744695912441 (82 / 100)
train_acc: 0.9839307787391842, val_acc: 0.5911330049261084, train_loss: 0.04635793316938969, val_loss: 2.9506860337233896 (83 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5960591133004927, train_loss: 0.03091476609002527, val_loss: 2.962198960370031 (84 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6059113300492611, train_loss: 0.04923775921056533, val_loss: 2.8565292329036542 (85 / 100)
train_acc: 0.9789864029666254, val_acc: 0.5862068965517241, train_loss: 0.05256450146768238, val_loss: 2.733476843152727 (86 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6157635467980296, train_loss: 0.04343448286445533, val_loss: 2.754196096523642 (87 / 100)
train_acc: 0.9839307787391842, val_acc: 0.5911330049261084, train_loss: 0.05052425613804123, val_loss: 2.827568061833311 (88 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6157635467980296, train_loss: 0.03277486805862785, val_loss: 2.767855534999829 (89 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5763546798029556, train_loss: 0.04195796986592862, val_loss: 2.890530340190004 (90 / 100)
train_acc: 0.9876390605686032, val_acc: 0.5911330049261084, train_loss: 0.03364660816522699, val_loss: 2.956975247472378 (91 / 100)
train_acc: 0.9950556242274413, val_acc: 0.5862068965517241, train_loss: 0.019507511731868033, val_loss: 2.999526096682243 (92 / 100)
train_acc: 0.9876390605686032, val_acc: 0.5960591133004927, train_loss: 0.03796489733848053, val_loss: 3.09351716135523 (93 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5911330049261084, train_loss: 0.027082824147086505, val_loss: 3.3059717281698595 (94 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5911330049261084, train_loss: 0.02287135268613346, val_loss: 3.2251143678655767 (95 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6009852216748769, train_loss: 0.027580624899846515, val_loss: 3.274923928265501 (96 / 100)
train_acc: 0.9913473423980222, val_acc: 0.5862068965517241, train_loss: 0.027910671216448395, val_loss: 3.21521171677876 (97 / 100)
train_acc: 0.9864029666254636, val_acc: 0.5862068965517241, train_loss: 0.04106507578355862, val_loss: 3.1884713337339203 (98 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6009852216748769, train_loss: 0.03204203035097629, val_loss: 3.0961247271504897 (99 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6157635467980296, train_loss: 0.03201655831708307, val_loss: 3.1107122322608687 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.1}), val accuracy 0.6305418719211823, val loss 2.309740585646606
train_acc: 0.17428924598269468, val_acc: 0.18226600985221675, train_loss: 1.7834432752819085, val_loss: 1.7614808928203114 (1 / 100)
train_acc: 0.18665018541409148, val_acc: 0.2660098522167488, train_loss: 1.7619402891920581, val_loss: 1.7518073238175491 (2 / 100)
train_acc: 0.24103831891223734, val_acc: 0.1921182266009852, train_loss: 1.7311492390626735, val_loss: 1.6811388889557035 (3 / 100)
train_acc: 0.2719406674907293, val_acc: 0.26108374384236455, train_loss: 1.6963911305546613, val_loss: 1.6426037121288881 (4 / 100)
train_acc: 0.27441285537700866, val_acc: 0.26108374384236455, train_loss: 1.6765215688641788, val_loss: 1.6082694418911863 (5 / 100)
train_acc: 0.26823238566131025, val_acc: 0.18226600985221675, train_loss: 1.6919795992347897, val_loss: 1.787228939568468 (6 / 100)
train_acc: 0.18788627935723115, val_acc: 0.1921182266009852, train_loss: 1.7762166161472335, val_loss: 1.7614710571730665 (7 / 100)
train_acc: 0.1668726823238566, val_acc: 0.18226600985221675, train_loss: 1.7755433873576199, val_loss: 1.7587465905203608 (8 / 100)
train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7693841679871303, val_loss: 1.7616883974357191 (9 / 100)
train_acc: 0.20148331273176762, val_acc: 0.22167487684729065, train_loss: 1.7547679672429823, val_loss: 1.7377729721257251 (10 / 100)
train_acc: 0.21631644004944375, val_acc: 0.22167487684729065, train_loss: 1.7589652128655773, val_loss: 1.7250173197591245 (11 / 100)
train_acc: 0.24351050679851668, val_acc: 0.22660098522167488, train_loss: 1.7416500642950956, val_loss: 1.7488684436957824 (12 / 100)
train_acc: 0.2620519159456119, val_acc: 0.18226600985221675, train_loss: 1.7261633084642578, val_loss: 1.7788329453303897 (13 / 100)
train_acc: 0.18788627935723115, val_acc: 0.27586206896551724, train_loss: 1.7724843848915712, val_loss: 1.7569236966776731 (14 / 100)
train_acc: 0.28182941903584674, val_acc: 0.2561576354679803, train_loss: 1.6981672455265437, val_loss: 1.6782376214201227 (15 / 100)
train_acc: 0.3164400494437577, val_acc: 0.21674876847290642, train_loss: 1.639331555926461, val_loss: 1.803441145149945 (16 / 100)
train_acc: 0.32756489493201485, val_acc: 0.3251231527093596, train_loss: 1.596221421940807, val_loss: 1.5674130851999293 (17 / 100)
train_acc: 0.3411619283065513, val_acc: 0.35467980295566504, train_loss: 1.524483628561824, val_loss: 1.4669693138799056 (18 / 100)
train_acc: 0.37824474660074164, val_acc: 0.3251231527093596, train_loss: 1.4733200851270678, val_loss: 1.5393050362911131 (19 / 100)
train_acc: 0.3831891223733004, val_acc: 0.33004926108374383, train_loss: 1.4679459816740528, val_loss: 1.6414922211557774 (20 / 100)
train_acc: 0.4042027194066749, val_acc: 0.39901477832512317, train_loss: 1.4650970645829096, val_loss: 1.3530303371950911 (21 / 100)
train_acc: 0.37330037082818296, val_acc: 0.3842364532019704, train_loss: 1.4270686263354364, val_loss: 1.3827215949890062 (22 / 100)
train_acc: 0.411619283065513, val_acc: 0.43349753694581283, train_loss: 1.3812657849603, val_loss: 1.352374324070409 (23 / 100)
train_acc: 0.39184177997527814, val_acc: 0.4187192118226601, train_loss: 1.4169881473512969, val_loss: 1.3482976646846152 (24 / 100)
train_acc: 0.4276885043263288, val_acc: 0.45320197044334976, train_loss: 1.3614332929382513, val_loss: 1.2811444566167633 (25 / 100)
train_acc: 0.46971569839307786, val_acc: 0.3842364532019704, train_loss: 1.3122887275422312, val_loss: 1.4293286392254194 (26 / 100)
train_acc: 0.40914709517923364, val_acc: 0.4482758620689655, train_loss: 1.376066824709087, val_loss: 1.2825472428293652 (27 / 100)
train_acc: 0.4796044499381953, val_acc: 0.4039408866995074, train_loss: 1.2643061462232592, val_loss: 1.2893943883515344 (28 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4827586206896552, train_loss: 1.2808228941871445, val_loss: 1.2609846953100758 (29 / 100)
train_acc: 0.4647713226205192, val_acc: 0.4236453201970443, train_loss: 1.2574245932665096, val_loss: 1.2877892020887929 (30 / 100)
train_acc: 0.49938195302843014, val_acc: 0.43842364532019706, train_loss: 1.2094563814559296, val_loss: 1.3242423352349568 (31 / 100)
train_acc: 0.522867737948084, val_acc: 0.4975369458128079, train_loss: 1.201468224873207, val_loss: 1.201506071196401 (32 / 100)
train_acc: 0.4907292954264524, val_acc: 0.43842364532019706, train_loss: 1.1827514047823082, val_loss: 1.3842360803059168 (33 / 100)
train_acc: 0.5339925834363412, val_acc: 0.4876847290640394, train_loss: 1.126331831233021, val_loss: 1.2452590421502814 (34 / 100)
train_acc: 0.5587144622991347, val_acc: 0.5024630541871922, train_loss: 1.097945052702141, val_loss: 1.1551126614580014 (35 / 100)
train_acc: 0.5698393077873919, val_acc: 0.49261083743842365, train_loss: 1.0648354302230665, val_loss: 1.2334885943699352 (36 / 100)
train_acc: 0.5784919653893696, val_acc: 0.4236453201970443, train_loss: 1.023963096852061, val_loss: 1.786777035943393 (37 / 100)
train_acc: 0.5698393077873919, val_acc: 0.5024630541871922, train_loss: 1.0402617666718397, val_loss: 1.1702555188991752 (38 / 100)
train_acc: 0.6205191594561187, val_acc: 0.4433497536945813, train_loss: 0.9476532538240713, val_loss: 1.246508402777423 (39 / 100)
train_acc: 0.6427688504326329, val_acc: 0.5812807881773399, train_loss: 0.9086059660493075, val_loss: 1.0877515007122396 (40 / 100)
train_acc: 0.6118665018541409, val_acc: 0.5024630541871922, train_loss: 1.0039234918775901, val_loss: 1.2465763473745637 (41 / 100)
train_acc: 0.6909765142150803, val_acc: 0.5369458128078818, train_loss: 0.8007299459466828, val_loss: 1.1983140542589386 (42 / 100)
train_acc: 0.7045735475896168, val_acc: 0.5517241379310345, train_loss: 0.7925974361976086, val_loss: 1.4731532276557584 (43 / 100)
train_acc: 0.7045735475896168, val_acc: 0.5467980295566502, train_loss: 0.7332053470375806, val_loss: 1.7818738639061087 (44 / 100)
train_acc: 0.7367119901112484, val_acc: 0.5172413793103449, train_loss: 0.6961054109377678, val_loss: 1.4673192342513888 (45 / 100)
train_acc: 0.7663782447466008, val_acc: 0.5467980295566502, train_loss: 0.675393639300456, val_loss: 1.3497084250003832 (46 / 100)
train_acc: 0.7589616810877626, val_acc: 0.5812807881773399, train_loss: 0.6067326338535776, val_loss: 1.4354594452627774 (47 / 100)
train_acc: 0.7725587144622992, val_acc: 0.5517241379310345, train_loss: 0.5953981618504, val_loss: 1.1200755358916785 (48 / 100)
train_acc: 0.8034610630407911, val_acc: 0.4876847290640394, train_loss: 0.5298173989000073, val_loss: 1.5359079977268069 (49 / 100)
train_acc: 0.7948084054388134, val_acc: 0.6059113300492611, train_loss: 0.511688317739772, val_loss: 1.376879744929046 (50 / 100)
train_acc: 0.8491965389369592, val_acc: 0.6108374384236454, train_loss: 0.42505098302815253, val_loss: 1.8307266622928564 (51 / 100)
train_acc: 0.8726823238566132, val_acc: 0.4876847290640394, train_loss: 0.38311347560623227, val_loss: 1.6856683614512382 (52 / 100)
train_acc: 0.8714462299134734, val_acc: 0.5665024630541872, train_loss: 0.38566134916100425, val_loss: 1.3984739102166275 (53 / 100)
train_acc: 0.8566131025957973, val_acc: 0.5467980295566502, train_loss: 0.40439465638291555, val_loss: 1.450434387317432 (54 / 100)
train_acc: 0.8862793572311496, val_acc: 0.5517241379310345, train_loss: 0.27381420179704213, val_loss: 1.7850651030469997 (55 / 100)
train_acc: 0.9060568603213844, val_acc: 0.5911330049261084, train_loss: 0.29632094366146694, val_loss: 2.5134614430037625 (56 / 100)
train_acc: 0.8986402966625463, val_acc: 0.6157635467980296, train_loss: 0.29658966792381297, val_loss: 1.3580342606077054 (57 / 100)
train_acc: 0.9196538936959209, val_acc: 0.5665024630541872, train_loss: 0.24347730900065417, val_loss: 2.846316261244525 (58 / 100)
train_acc: 0.9332509270704573, val_acc: 0.5960591133004927, train_loss: 0.20222875479567332, val_loss: 2.1814553373552896 (59 / 100)
train_acc: 0.9184177997527813, val_acc: 0.6206896551724138, train_loss: 0.23048123720991892, val_loss: 1.617329190223675 (60 / 100)
train_acc: 0.965389369592089, val_acc: 0.6551724137931034, train_loss: 0.11982141599077524, val_loss: 1.661638236985418 (61 / 100)
train_acc: 0.9641532756489494, val_acc: 0.645320197044335, train_loss: 0.10589225080016222, val_loss: 1.692011136139555 (62 / 100)
train_acc: 0.9728059332509271, val_acc: 0.645320197044335, train_loss: 0.08137721567425062, val_loss: 1.7604998890402281 (63 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6502463054187192, train_loss: 0.05254736745313307, val_loss: 1.8657757895333427 (64 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6403940886699507, train_loss: 0.058268369054617485, val_loss: 1.8884013773772517 (65 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6354679802955665, train_loss: 0.06448851704450119, val_loss: 1.945303231037309 (66 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6305418719211823, train_loss: 0.05842897314371078, val_loss: 1.9988579814657201 (67 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6206896551724138, train_loss: 0.058215193607014395, val_loss: 2.005243030674939 (68 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6305418719211823, train_loss: 0.055141578940732225, val_loss: 2.014126543341012 (69 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6108374384236454, train_loss: 0.0625312366650632, val_loss: 2.033091519853752 (70 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6108374384236454, train_loss: 0.07365659243980945, val_loss: 2.087424331697924 (71 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6305418719211823, train_loss: 0.05119431284066331, val_loss: 2.049771805114934 (72 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6009852216748769, train_loss: 0.04124562142069172, val_loss: 2.124727731267807 (73 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.05278884347790693, val_loss: 2.1463177626943355 (74 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6502463054187192, train_loss: 0.06623352458067376, val_loss: 2.233510060263385 (75 / 100)
train_acc: 0.9888751545117429, val_acc: 0.645320197044335, train_loss: 0.044546551698512585, val_loss: 2.2280121771572845 (76 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6206896551724138, train_loss: 0.041961811086892786, val_loss: 2.3251772649182474 (77 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6354679802955665, train_loss: 0.046207732853694956, val_loss: 2.3284799347957366 (78 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6305418719211823, train_loss: 0.0504510336370197, val_loss: 2.3297907892119123 (79 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6108374384236454, train_loss: 0.05379646714449813, val_loss: 2.358989655677908 (80 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6206896551724138, train_loss: 0.04557949356154547, val_loss: 2.3587735345210934 (81 / 100)
train_acc: 0.9826946847960445, val_acc: 0.625615763546798, train_loss: 0.046328820168456276, val_loss: 2.3121276732736034 (82 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6157635467980296, train_loss: 0.03654387574850113, val_loss: 2.278150942525253 (83 / 100)
train_acc: 0.9826946847960445, val_acc: 0.625615763546798, train_loss: 0.04361380561173183, val_loss: 2.287012151603041 (84 / 100)
train_acc: 0.9851668726823238, val_acc: 0.625615763546798, train_loss: 0.03889089476487545, val_loss: 2.359956179639976 (85 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6403940886699507, train_loss: 0.06833754835376339, val_loss: 2.3259364064103862 (86 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6305418719211823, train_loss: 0.04422017346206495, val_loss: 2.3791646751864204 (87 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6206896551724138, train_loss: 0.026760266207351967, val_loss: 2.3854758848110444 (88 / 100)
train_acc: 0.992583436341162, val_acc: 0.6206896551724138, train_loss: 0.025481609979872356, val_loss: 2.3844849760896465 (89 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6305418719211823, train_loss: 0.03168672389536175, val_loss: 2.431873387303846 (90 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6403940886699507, train_loss: 0.03760918507027832, val_loss: 2.5197138372313215 (91 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6305418719211823, train_loss: 0.03448619432885508, val_loss: 2.4605904098214775 (92 / 100)
train_acc: 0.9839307787391842, val_acc: 0.625615763546798, train_loss: 0.041919078461466676, val_loss: 2.436519393779961 (93 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6157635467980296, train_loss: 0.047358505216016165, val_loss: 2.4650697611235635 (94 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6108374384236454, train_loss: 0.040657399021945574, val_loss: 2.4972932520758344 (95 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6206896551724138, train_loss: 0.04763817183019499, val_loss: 2.511592266007597 (96 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6354679802955665, train_loss: 0.023426986153252487, val_loss: 2.5867209980640506 (97 / 100)
train_acc: 0.9913473423980222, val_acc: 0.645320197044335, train_loss: 0.031427139257471114, val_loss: 2.662269934057602 (98 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6551724137931034, train_loss: 0.04001201304281303, val_loss: 2.68223340464343 (99 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.039776884139099876, val_loss: 2.6620672497843287 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.05}), val accuracy 0.6551724137931034, val loss 1.661638236985418
train_acc: 0.1792336217552534, val_acc: 0.1921182266009852, train_loss: 1.7727910782704395, val_loss: 1.7787025632529423 (1 / 100)
train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7657721797084927, val_loss: 1.7435122810561081 (2 / 100)
train_acc: 0.2027194066749073, val_acc: 0.28078817733990147, train_loss: 1.7477506889843086, val_loss: 1.720449569190077 (3 / 100)
train_acc: 0.24598269468479605, val_acc: 0.26108374384236455, train_loss: 1.7279260547553064, val_loss: 1.7385558988073189 (4 / 100)
train_acc: 0.26081582200247216, val_acc: 0.29064039408866993, train_loss: 1.7342421650444475, val_loss: 1.6655045923928322 (5 / 100)
train_acc: 0.2830655129789864, val_acc: 0.32019704433497537, train_loss: 1.6927475590346328, val_loss: 1.6508340312929577 (6 / 100)
train_acc: 0.32014833127317677, val_acc: 0.29064039408866993, train_loss: 1.613093926084351, val_loss: 1.4781100791076134 (7 / 100)
train_acc: 0.3164400494437577, val_acc: 0.27586206896551724, train_loss: 1.628039315398161, val_loss: 1.5758587392092926 (8 / 100)
train_acc: 0.35599505562422745, val_acc: 0.458128078817734, train_loss: 1.5122769524346766, val_loss: 1.3364846882561745 (9 / 100)
train_acc: 0.37453646477132263, val_acc: 0.43349753694581283, train_loss: 1.4651927143445858, val_loss: 1.3559628161303516 (10 / 100)
train_acc: 0.3757725587144623, val_acc: 0.4236453201970443, train_loss: 1.4518716747887497, val_loss: 1.3385731733491268 (11 / 100)
train_acc: 0.3831891223733004, val_acc: 0.4482758620689655, train_loss: 1.3877006540781782, val_loss: 1.2693437279151578 (12 / 100)
train_acc: 0.411619283065513, val_acc: 0.4236453201970443, train_loss: 1.3466089157887235, val_loss: 1.2902693648643682 (13 / 100)
train_acc: 0.41409147095179233, val_acc: 0.4630541871921182, train_loss: 1.328338275733778, val_loss: 1.256711541138259 (14 / 100)
train_acc: 0.44870210135970334, val_acc: 0.46798029556650245, train_loss: 1.2829181641082386, val_loss: 1.267885207542645 (15 / 100)
train_acc: 0.46600741656365885, val_acc: 0.47783251231527096, train_loss: 1.247659779596977, val_loss: 1.2520383954635395 (16 / 100)
train_acc: 0.4647713226205192, val_acc: 0.4039408866995074, train_loss: 1.2317509433100338, val_loss: 1.393817775061565 (17 / 100)
train_acc: 0.48084054388133496, val_acc: 0.4975369458128079, train_loss: 1.2257503070701627, val_loss: 1.1941900047762641 (18 / 100)
train_acc: 0.4969097651421508, val_acc: 0.5123152709359606, train_loss: 1.1530950244778608, val_loss: 1.1302594078585433 (19 / 100)
train_acc: 0.5030902348578492, val_acc: 0.4876847290640394, train_loss: 1.165955651675815, val_loss: 1.1459585856921568 (20 / 100)
train_acc: 0.5364647713226205, val_acc: 0.5467980295566502, train_loss: 1.1106738761270003, val_loss: 1.0720049791735382 (21 / 100)
train_acc: 0.5574783683559951, val_acc: 0.5123152709359606, train_loss: 1.0998479320917496, val_loss: 1.1311706695063362 (22 / 100)
train_acc: 0.5500618046971569, val_acc: 0.5320197044334976, train_loss: 1.071355936406422, val_loss: 1.2770753124077332 (23 / 100)
train_acc: 0.5859085290482077, val_acc: 0.4827586206896552, train_loss: 0.997863982015546, val_loss: 1.4159774046226088 (24 / 100)
train_acc: 0.5784919653893696, val_acc: 0.5517241379310345, train_loss: 0.9971866327693643, val_loss: 1.110081438654162 (25 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5172413793103449, train_loss: 0.9748490509497663, val_loss: 1.4899200606228682 (26 / 100)
train_acc: 0.6341161928306551, val_acc: 0.49261083743842365, train_loss: 0.9100432611071725, val_loss: 1.4449528347095246 (27 / 100)
train_acc: 0.6402966625463535, val_acc: 0.541871921182266, train_loss: 0.9248699384507791, val_loss: 1.1492546638244479 (28 / 100)
train_acc: 0.6266996291718171, val_acc: 0.541871921182266, train_loss: 0.9144450073925909, val_loss: 1.1602623679955018 (29 / 100)
train_acc: 0.6761433868974042, val_acc: 0.5073891625615764, train_loss: 0.828600457925879, val_loss: 1.687030100470106 (30 / 100)
train_acc: 0.69221260815822, val_acc: 0.5270935960591133, train_loss: 0.7636397733676566, val_loss: 1.5336248263936911 (31 / 100)
train_acc: 0.7107540173053152, val_acc: 0.5123152709359606, train_loss: 0.7469976601111432, val_loss: 1.7191274130872904 (32 / 100)
train_acc: 0.7206427688504327, val_acc: 0.5615763546798029, train_loss: 0.690856229094846, val_loss: 1.4498775246108107 (33 / 100)
train_acc: 0.73053152039555, val_acc: 0.541871921182266, train_loss: 0.6665461328621995, val_loss: 1.2686917576296577 (34 / 100)
train_acc: 0.7787391841779975, val_acc: 0.5960591133004927, train_loss: 0.5925575749688449, val_loss: 1.3940192895569825 (35 / 100)
train_acc: 0.7428924598269468, val_acc: 0.4876847290640394, train_loss: 0.629541956450058, val_loss: 1.3439480624175424 (36 / 100)
train_acc: 0.7787391841779975, val_acc: 0.5566502463054187, train_loss: 0.5967750474165927, val_loss: 1.3998248553628405 (37 / 100)
train_acc: 0.8182941903584673, val_acc: 0.5960591133004927, train_loss: 0.48476531935858047, val_loss: 1.9569936045284928 (38 / 100)
train_acc: 0.8220024721878862, val_acc: 0.5024630541871922, train_loss: 0.4927492554314499, val_loss: 1.3334912949888578 (39 / 100)
train_acc: 0.8022249690976514, val_acc: 0.6059113300492611, train_loss: 0.506501287258747, val_loss: 1.8142997408148103 (40 / 100)
train_acc: 0.8405438813349815, val_acc: 0.6059113300492611, train_loss: 0.42669815863902844, val_loss: 1.3552285221409914 (41 / 100)
train_acc: 0.8133498145859085, val_acc: 0.5763546798029556, train_loss: 0.5263565227628786, val_loss: 1.6193206606827346 (42 / 100)
train_acc: 0.8454882571075402, val_acc: 0.541871921182266, train_loss: 0.42733485383362646, val_loss: 1.9970645141131773 (43 / 100)
train_acc: 0.8380716934487021, val_acc: 0.6403940886699507, train_loss: 0.41092723998504754, val_loss: 2.3548815361971926 (44 / 100)
train_acc: 0.8553770086526576, val_acc: 0.5665024630541872, train_loss: 0.3860694759413692, val_loss: 2.3114598396376436 (45 / 100)
train_acc: 0.8813349814585909, val_acc: 0.4975369458128079, train_loss: 0.3663758264925925, val_loss: 2.935842461186677 (46 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5320197044334976, train_loss: 0.3316151152729841, val_loss: 2.0240486243675493 (47 / 100)
train_acc: 0.8912237330037083, val_acc: 0.6009852216748769, train_loss: 0.32555463361209636, val_loss: 2.4720486490597278 (48 / 100)
train_acc: 0.9060568603213844, val_acc: 0.5665024630541872, train_loss: 0.2718780276507176, val_loss: 2.8482806999695125 (49 / 100)
train_acc: 0.8912237330037083, val_acc: 0.5960591133004927, train_loss: 0.3131481999961938, val_loss: 2.305279546183318 (50 / 100)
train_acc: 0.92336217552534, val_acc: 0.645320197044335, train_loss: 0.20832140778729, val_loss: 2.1001954361282547 (51 / 100)
train_acc: 0.9147095179233622, val_acc: 0.6157635467980296, train_loss: 0.2299972784386577, val_loss: 1.965979175614606 (52 / 100)
train_acc: 0.9171817058096415, val_acc: 0.5862068965517241, train_loss: 0.21900170636265476, val_loss: 2.1339386871882846 (53 / 100)
train_acc: 0.907292954264524, val_acc: 0.6009852216748769, train_loss: 0.2554233395419693, val_loss: 1.6827529991788817 (54 / 100)
train_acc: 0.930778739184178, val_acc: 0.5812807881773399, train_loss: 0.19063158825095122, val_loss: 2.614736650964897 (55 / 100)
train_acc: 0.9097651421508035, val_acc: 0.5517241379310345, train_loss: 0.23956616154707258, val_loss: 1.4199787724781505 (56 / 100)
train_acc: 0.9332509270704573, val_acc: 0.6206896551724138, train_loss: 0.18820206712291326, val_loss: 2.2667982255296755 (57 / 100)
train_acc: 0.9493201483312732, val_acc: 0.6108374384236454, train_loss: 0.12814599194544354, val_loss: 2.58874107111851 (58 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6354679802955665, train_loss: 0.13289546819198853, val_loss: 2.9451583242181485 (59 / 100)
train_acc: 0.9035846724351051, val_acc: 0.5467980295566502, train_loss: 0.2675964487497827, val_loss: 2.9340403796416785 (60 / 100)
train_acc: 0.9666254635352287, val_acc: 0.5714285714285714, train_loss: 0.10274416525078056, val_loss: 2.52878909980135 (61 / 100)
train_acc: 0.9703337453646477, val_acc: 0.5812807881773399, train_loss: 0.07449627408875228, val_loss: 2.6770895631442517 (62 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6059113300492611, train_loss: 0.06196342587323654, val_loss: 2.625586562555999 (63 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5960591133004927, train_loss: 0.04961812393037586, val_loss: 2.768040720465148 (64 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6059113300492611, train_loss: 0.06447267915468723, val_loss: 2.909442692554643 (65 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6009852216748769, train_loss: 0.04559037844536478, val_loss: 2.8837241374800358 (66 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6059113300492611, train_loss: 0.06077460084474278, val_loss: 3.0868928902254904 (67 / 100)
train_acc: 0.9826946847960445, val_acc: 0.5960591133004927, train_loss: 0.049511893865351916, val_loss: 3.2912160164029727 (68 / 100)
train_acc: 0.9888751545117429, val_acc: 0.5960591133004927, train_loss: 0.032521270703621055, val_loss: 3.3938420347392264 (69 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6108374384236454, train_loss: 0.04378673835796833, val_loss: 3.5022786990762342 (70 / 100)
train_acc: 0.9839307787391842, val_acc: 0.625615763546798, train_loss: 0.041570118242789555, val_loss: 3.2908778120144246 (71 / 100)
train_acc: 0.9888751545117429, val_acc: 0.625615763546798, train_loss: 0.03754236966334698, val_loss: 3.3298100626527383 (72 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6157635467980296, train_loss: 0.03705735097562132, val_loss: 3.3281776470503783 (73 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6157635467980296, train_loss: 0.03665551605861178, val_loss: 3.3833632962457063 (74 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6108374384236454, train_loss: 0.0281858637247451, val_loss: 3.5485973311175267 (75 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6009852216748769, train_loss: 0.024211329494330143, val_loss: 3.577732299936229 (76 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6108374384236454, train_loss: 0.046799956647073676, val_loss: 3.3829457853815237 (77 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6206896551724138, train_loss: 0.05299854720626095, val_loss: 3.3995541633643542 (78 / 100)
train_acc: 0.992583436341162, val_acc: 0.6305418719211823, train_loss: 0.026042063097723923, val_loss: 3.4984687913227552 (79 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6403940886699507, train_loss: 0.02216991122779799, val_loss: 3.647458262044221 (80 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6206896551724138, train_loss: 0.026764850975998546, val_loss: 3.5573671580535438 (81 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6206896551724138, train_loss: 0.03438425771385542, val_loss: 3.5805592959737544 (82 / 100)
train_acc: 0.9876390605686032, val_acc: 0.6354679802955665, train_loss: 0.03429327582841456, val_loss: 3.6362740652901784 (83 / 100)
train_acc: 0.9913473423980222, val_acc: 0.625615763546798, train_loss: 0.022312848618062965, val_loss: 3.800560356948176 (84 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6354679802955665, train_loss: 0.0310688487384169, val_loss: 3.815177010785183 (85 / 100)
train_acc: 0.9901112484548825, val_acc: 0.625615763546798, train_loss: 0.0246221824688434, val_loss: 3.874892011651852 (86 / 100)
train_acc: 0.9913473423980222, val_acc: 0.625615763546798, train_loss: 0.024877407789525054, val_loss: 4.0222052306377245 (87 / 100)
train_acc: 0.992583436341162, val_acc: 0.6502463054187192, train_loss: 0.023034415522081447, val_loss: 3.985223145320498 (88 / 100)
train_acc: 0.9938195302843016, val_acc: 0.625615763546798, train_loss: 0.019148220385255568, val_loss: 3.94203638913009 (89 / 100)
train_acc: 0.9888751545117429, val_acc: 0.625615763546798, train_loss: 0.029150261719825096, val_loss: 3.674558780463458 (90 / 100)
train_acc: 0.992583436341162, val_acc: 0.6305418719211823, train_loss: 0.026465249739412323, val_loss: 3.7035218530100553 (91 / 100)
train_acc: 0.9913473423980222, val_acc: 0.6206896551724138, train_loss: 0.027051641855605307, val_loss: 3.6889150459778133 (92 / 100)
train_acc: 0.9962917181705809, val_acc: 0.6206896551724138, train_loss: 0.0176967706609568, val_loss: 3.967735866020466 (93 / 100)
train_acc: 0.992583436341162, val_acc: 0.6403940886699507, train_loss: 0.027850197920545806, val_loss: 3.800979367617903 (94 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6305418719211823, train_loss: 0.02554599257423203, val_loss: 3.88763540718943 (95 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6206896551724138, train_loss: 0.019502421244702615, val_loss: 3.964420283369243 (96 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6059113300492611, train_loss: 0.038039761803795584, val_loss: 3.926831036365678 (97 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6206896551724138, train_loss: 0.018328631322080333, val_loss: 4.264985176142801 (98 / 100)
train_acc: 0.9950556242274413, val_acc: 0.6157635467980296, train_loss: 0.01637260846066092, val_loss: 4.451314484544575 (99 / 100)
train_acc: 0.9901112484548825, val_acc: 0.5911330049261084, train_loss: 0.02360446064080237, val_loss: 4.2186449079090735 (100 / 100)
({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.001, 'gamma': 0.1}), val accuracy 0.6502463054187192, val loss 3.985223145320498
train_acc: 0.17552533992583436, val_acc: 0.28078817733990147, train_loss: 1.7902324289562381, val_loss: 1.7831851196993749 (1 / 100)
train_acc: 0.2027194066749073, val_acc: 0.18226600985221675, train_loss: 1.7772075885305887, val_loss: 1.759437391910647 (2 / 100)
train_acc: 0.17058096415327564, val_acc: 0.18226600985221675, train_loss: 1.7591117599838597, val_loss: 1.7458137373618892 (3 / 100)
train_acc: 0.2138442521631644, val_acc: 0.1921182266009852, train_loss: 1.754427653160614, val_loss: 1.7250228967572667 (4 / 100)
train_acc: 0.22126081582200247, val_acc: 0.2857142857142857, train_loss: 1.7434814913458523, val_loss: 1.7127279366178465 (5 / 100)
train_acc: 0.2880098887515451, val_acc: 0.2857142857142857, train_loss: 1.6841005010274785, val_loss: 1.640125358045982 (6 / 100)
train_acc: 0.3065512978986403, val_acc: 0.2955665024630542, train_loss: 1.6261284006540795, val_loss: 1.5399653441800272 (7 / 100)
train_acc: 0.3547589616810878, val_acc: 0.31527093596059114, train_loss: 1.5798544748162457, val_loss: 1.578779594064346 (8 / 100)
train_acc: 0.34610630407911, val_acc: 0.33497536945812806, train_loss: 1.5520578027508314, val_loss: 1.496783615920344 (9 / 100)
train_acc: 0.37453646477132263, val_acc: 0.2955665024630542, train_loss: 1.5230262397393604, val_loss: 1.5087274900210903 (10 / 100)
train_acc: 0.3584672435105068, val_acc: 0.3645320197044335, train_loss: 1.4859952343114375, val_loss: 1.3949919786359288 (11 / 100)
train_acc: 0.37824474660074164, val_acc: 0.4088669950738916, train_loss: 1.4470586275730204, val_loss: 1.4021579737733738 (12 / 100)
train_acc: 0.3868974042027194, val_acc: 0.4236453201970443, train_loss: 1.4130148150864874, val_loss: 1.4025394035677605 (13 / 100)
train_acc: 0.40914709517923364, val_acc: 0.3694581280788177, train_loss: 1.389194562054977, val_loss: 1.5094088597837927 (14 / 100)
train_acc: 0.3819530284301607, val_acc: 0.43349753694581283, train_loss: 1.4505159175587525, val_loss: 1.3496663646744977 (15 / 100)
train_acc: 0.40914709517923364, val_acc: 0.43349753694581283, train_loss: 1.3785042798121279, val_loss: 1.3469225767210786 (16 / 100)
train_acc: 0.415327564894932, val_acc: 0.33004926108374383, train_loss: 1.3846423692255292, val_loss: 1.5028875725609916 (17 / 100)
train_acc: 0.411619283065513, val_acc: 0.43842364532019706, train_loss: 1.3581837383277338, val_loss: 1.3255954011907718 (18 / 100)
train_acc: 0.3943139678615575, val_acc: 0.3842364532019704, train_loss: 1.395244651436069, val_loss: 1.3398964728040648 (19 / 100)
train_acc: 0.4326328800988875, val_acc: 0.4630541871921182, train_loss: 1.333203825431937, val_loss: 1.2588482002906611 (20 / 100)
train_acc: 0.4684796044499382, val_acc: 0.458128078817734, train_loss: 1.3331238566281916, val_loss: 1.2923288685934884 (21 / 100)
train_acc: 0.4363411619283066, val_acc: 0.4630541871921182, train_loss: 1.3168329706298112, val_loss: 1.2877141254876048 (22 / 100)
train_acc: 0.449938195302843, val_acc: 0.35467980295566504, train_loss: 1.317410268653898, val_loss: 1.3283290243501147 (23 / 100)
train_acc: 0.4622991347342398, val_acc: 0.5172413793103449, train_loss: 1.2347385766921732, val_loss: 1.2616076393080462 (24 / 100)
train_acc: 0.47713226205191595, val_acc: 0.4876847290640394, train_loss: 1.3227594840364492, val_loss: 1.2107269593647547 (25 / 100)
train_acc: 0.4672435105067985, val_acc: 0.4827586206896552, train_loss: 1.2359931725359377, val_loss: 1.240966909624673 (26 / 100)
train_acc: 0.4684796044499382, val_acc: 0.5123152709359606, train_loss: 1.2486102560394627, val_loss: 1.2105556550284324 (27 / 100)
train_acc: 0.48331273176761436, val_acc: 0.5172413793103449, train_loss: 1.2115459941668327, val_loss: 1.1821187029918427 (28 / 100)
train_acc: 0.5265760197775031, val_acc: 0.5123152709359606, train_loss: 1.1548319290241293, val_loss: 1.2409529286652363 (29 / 100)
train_acc: 0.5129789864029666, val_acc: 0.5221674876847291, train_loss: 1.1636625743472238, val_loss: 1.1411777802288825 (30 / 100)
train_acc: 0.5080346106304079, val_acc: 0.5566502463054187, train_loss: 1.1828400785165605, val_loss: 1.0955397119663033 (31 / 100)
train_acc: 0.5253399258343634, val_acc: 0.5172413793103449, train_loss: 1.1318982034295393, val_loss: 1.1427238997567464 (32 / 100)
train_acc: 0.5426452410383189, val_acc: 0.541871921182266, train_loss: 1.1339853628456813, val_loss: 1.138973525005021 (33 / 100)
train_acc: 0.5426452410383189, val_acc: 0.541871921182266, train_loss: 1.0991657888344104, val_loss: 1.1206553158501686 (34 / 100)
train_acc: 0.5698393077873919, val_acc: 0.5369458128078818, train_loss: 1.0430758932170232, val_loss: 1.0727338503146995 (35 / 100)
train_acc: 0.5661310259579728, val_acc: 0.5517241379310345, train_loss: 1.012071308305738, val_loss: 1.0851863828198662 (36 / 100)
train_acc: 0.5908529048207664, val_acc: 0.5763546798029556, train_loss: 1.02722768391608, val_loss: 1.0340461901256017 (37 / 100)
train_acc: 0.6032138442521632, val_acc: 0.5615763546798029, train_loss: 0.981523906049976, val_loss: 1.09841973088645 (38 / 100)
train_acc: 0.6242274412855378, val_acc: 0.541871921182266, train_loss: 0.9435644683201322, val_loss: 1.1124424247318887 (39 / 100)
train_acc: 0.6526576019777504, val_acc: 0.5714285714285714, train_loss: 0.8663245971476928, val_loss: 1.2045295423474804 (40 / 100)
train_acc: 0.6254635352286774, val_acc: 0.5911330049261084, train_loss: 0.8835400870468177, val_loss: 1.011004573312299 (41 / 100)
train_acc: 0.6650185414091471, val_acc: 0.5812807881773399, train_loss: 0.8316270224243513, val_loss: 1.0143939274285227 (42 / 100)
train_acc: 0.7033374536464772, val_acc: 0.5467980295566502, train_loss: 0.7598995717405831, val_loss: 1.076921932215761 (43 / 100)
train_acc: 0.7008652657601978, val_acc: 0.5911330049261084, train_loss: 0.7674669623374939, val_loss: 1.340899308179987 (44 / 100)
train_acc: 0.6909765142150803, val_acc: 0.5172413793103449, train_loss: 0.7766417101375547, val_loss: 1.2751825683809854 (45 / 100)
train_acc: 0.695920889987639, val_acc: 0.5714285714285714, train_loss: 0.7859187650371099, val_loss: 1.2556720948571642 (46 / 100)
train_acc: 0.715698393077874, val_acc: 0.6009852216748769, train_loss: 0.7276496212326258, val_loss: 0.9640660561951511 (47 / 100)
train_acc: 0.7775030902348579, val_acc: 0.5714285714285714, train_loss: 0.5830795697140311, val_loss: 1.207246011847933 (48 / 100)
train_acc: 0.8046971569839307, val_acc: 0.6206896551724138, train_loss: 0.5068560102298322, val_loss: 1.3167539174333582 (49 / 100)
train_acc: 0.7515451174289246, val_acc: 0.5862068965517241, train_loss: 0.6694267193967539, val_loss: 1.2973083521932216 (50 / 100)
train_acc: 0.7898640296662547, val_acc: 0.5566502463054187, train_loss: 0.5425842058452305, val_loss: 1.3382137304015935 (51 / 100)
train_acc: 0.8380716934487021, val_acc: 0.5960591133004927, train_loss: 0.4685095314705475, val_loss: 1.2430525460266715 (52 / 100)
train_acc: 0.823238566131026, val_acc: 0.5714285714285714, train_loss: 0.45926096597030225, val_loss: 1.3789362326044168 (53 / 100)
train_acc: 0.8244746600741656, val_acc: 0.6354679802955665, train_loss: 0.47539113205943917, val_loss: 1.1855713208320693 (54 / 100)
train_acc: 0.8491965389369592, val_acc: 0.645320197044335, train_loss: 0.4020744338171149, val_loss: 1.175062914200017 (55 / 100)
train_acc: 0.8665018541409147, val_acc: 0.6502463054187192, train_loss: 0.39468755135577455, val_loss: 1.1186855846437915 (56 / 100)
train_acc: 0.8566131025957973, val_acc: 0.5665024630541872, train_loss: 0.38590913160032925, val_loss: 1.371974571585068 (57 / 100)
train_acc: 0.8640296662546354, val_acc: 0.625615763546798, train_loss: 0.35152187416668434, val_loss: 1.1723287046836515 (58 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6502463054187192, train_loss: 0.3168216425055184, val_loss: 1.2734666111434034 (59 / 100)
train_acc: 0.9184177997527813, val_acc: 0.6502463054187192, train_loss: 0.22288896132384892, val_loss: 1.8503675325750717 (60 / 100)
train_acc: 0.9283065512978986, val_acc: 0.6896551724137931, train_loss: 0.1981514898786144, val_loss: 1.506265538666636 (61 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6650246305418719, train_loss: 0.13958557311109324, val_loss: 1.5340897702231195 (62 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6650246305418719, train_loss: 0.12613498148069763, val_loss: 1.533096134956247 (63 / 100)
train_acc: 0.9542645241038319, val_acc: 0.6551724137931034, train_loss: 0.12126362086613335, val_loss: 1.5495809525104578 (64 / 100)
train_acc: 0.9505562422744128, val_acc: 0.6798029556650246, train_loss: 0.12289714401562517, val_loss: 1.6670926116370215 (65 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6650246305418719, train_loss: 0.11174500813734044, val_loss: 1.6495411390154233 (66 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6896551724137931, train_loss: 0.1052793494252458, val_loss: 1.6778288915239532 (67 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6650246305418719, train_loss: 0.11550404319288704, val_loss: 1.6620369668077366 (68 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6600985221674877, train_loss: 0.09871293425707352, val_loss: 1.7123375620160783 (69 / 100)
train_acc: 0.969097651421508, val_acc: 0.6600985221674877, train_loss: 0.07544083132671034, val_loss: 1.7472752215239802 (70 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6600985221674877, train_loss: 0.11137404355907764, val_loss: 1.819397855274783 (71 / 100)
train_acc: 0.9530284301606922, val_acc: 0.6600985221674877, train_loss: 0.11025902352840335, val_loss: 1.803329513871611 (72 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6650246305418719, train_loss: 0.10108322396929685, val_loss: 1.845137270213348 (73 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6650246305418719, train_loss: 0.07553694775841477, val_loss: 1.855618241972524 (74 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6650246305418719, train_loss: 0.08864656895656962, val_loss: 1.848500399753965 (75 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6699507389162561, train_loss: 0.0765363664742748, val_loss: 1.9200792054237403 (76 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6650246305418719, train_loss: 0.07300834370631959, val_loss: 1.8740544677367938 (77 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.07807734088997538, val_loss: 1.871677679968585 (78 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6600985221674877, train_loss: 0.08311606809377155, val_loss: 1.8779518786322307 (79 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.06732259736809654, val_loss: 1.9612147391136057 (80 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6600985221674877, train_loss: 0.11851052846414196, val_loss: 1.8628940623382042 (81 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6600985221674877, train_loss: 0.0680172351754198, val_loss: 1.9023638311865294 (82 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6551724137931034, train_loss: 0.08815738401284766, val_loss: 1.979225555076975 (83 / 100)
train_acc: 0.9567367119901112, val_acc: 0.6650246305418719, train_loss: 0.10630664078355277, val_loss: 1.9896595795166316 (84 / 100)
train_acc: 0.9666254635352287, val_acc: 0.6502463054187192, train_loss: 0.08407784732258954, val_loss: 1.9673650393932325 (85 / 100)
train_acc: 0.969097651421508, val_acc: 0.6551724137931034, train_loss: 0.0801396508469754, val_loss: 2.0345205708677545 (86 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6650246305418719, train_loss: 0.0762269295034274, val_loss: 2.024752492387894 (87 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6650246305418719, train_loss: 0.06849909728975467, val_loss: 2.1314910849914175 (88 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.07680436368796822, val_loss: 2.100995264029855 (89 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.08435834618688219, val_loss: 2.1633840159242377 (90 / 100)
train_acc: 0.969097651421508, val_acc: 0.6748768472906403, train_loss: 0.08045362527378604, val_loss: 2.192467528023743 (91 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6699507389162561, train_loss: 0.09462899536960011, val_loss: 2.146125654281654 (92 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.05340742346530202, val_loss: 2.2015877545173534 (93 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6551724137931034, train_loss: 0.07039212650528502, val_loss: 2.171542665641296 (94 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.04517215259179786, val_loss: 2.190579146587203 (95 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6650246305418719, train_loss: 0.06968326282967227, val_loss: 2.235206336810671 (96 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6600985221674877, train_loss: 0.058537418377322084, val_loss: 2.1540049020879963 (97 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6650246305418719, train_loss: 0.06912334386733612, val_loss: 2.232070584602544 (98 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.058878566171831195, val_loss: 2.2059399382821443 (99 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.05782336930483027, val_loss: 2.3262458194065565 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.05}), val accuracy 0.6896551724137931, val loss 1.506265538666636
train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7841880709043392, val_loss: 1.7739881400404305 (1 / 100)
train_acc: 0.17058096415327564, val_acc: 0.19704433497536947, train_loss: 1.7736082601606182, val_loss: 1.756652729851859 (2 / 100)
train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7633950275602683, val_loss: 1.7506777506156508 (3 / 100)
train_acc: 0.20395550061804696, val_acc: 0.18226600985221675, train_loss: 1.7596479841451562, val_loss: 1.740795163685465 (4 / 100)
train_acc: 0.24721878862793573, val_acc: 0.2315270935960591, train_loss: 1.7331343302768005, val_loss: 1.6949066276033524 (5 / 100)
train_acc: 0.2880098887515451, val_acc: 0.2955665024630542, train_loss: 1.6916895708430684, val_loss: 1.6076822498161805 (6 / 100)
train_acc: 0.29913473423980225, val_acc: 0.37438423645320196, train_loss: 1.6339118268492785, val_loss: 1.5572883800920008 (7 / 100)
train_acc: 0.34363411619283063, val_acc: 0.28078817733990147, train_loss: 1.5678360724478628, val_loss: 1.599644261627949 (8 / 100)
train_acc: 0.34363411619283063, val_acc: 0.30049261083743845, train_loss: 1.613428169481539, val_loss: 1.6070480158763567 (9 / 100)
train_acc: 0.34363411619283063, val_acc: 0.23645320197044334, train_loss: 1.5675158259011022, val_loss: 1.5924095940120115 (10 / 100)
train_acc: 0.34610630407911, val_acc: 0.35467980295566504, train_loss: 1.5258345200193237, val_loss: 1.4393238357722467 (11 / 100)
train_acc: 0.3831891223733004, val_acc: 0.29064039408866993, train_loss: 1.4781518505589186, val_loss: 1.541627468733952 (12 / 100)
train_acc: 0.3695920889987639, val_acc: 0.39408866995073893, train_loss: 1.4601331101949195, val_loss: 1.4462276826351148 (13 / 100)
train_acc: 0.380716934487021, val_acc: 0.35467980295566504, train_loss: 1.4623422299975666, val_loss: 1.5141282522032413 (14 / 100)
train_acc: 0.38442521631644005, val_acc: 0.4630541871921182, train_loss: 1.446262398815273, val_loss: 1.383483437775391 (15 / 100)
train_acc: 0.3720642768850433, val_acc: 0.4039408866995074, train_loss: 1.464873066201935, val_loss: 1.402455912434996 (16 / 100)
train_acc: 0.4042027194066749, val_acc: 0.39408866995073893, train_loss: 1.4074349540420457, val_loss: 1.373695257849294 (17 / 100)
train_acc: 0.3868974042027194, val_acc: 0.37438423645320196, train_loss: 1.4251198454751957, val_loss: 1.4811132447472934 (18 / 100)
train_acc: 0.41656365883807167, val_acc: 0.47783251231527096, train_loss: 1.3729226863281099, val_loss: 1.3504145503631366 (19 / 100)
train_acc: 0.41656365883807167, val_acc: 0.45320197044334976, train_loss: 1.3526217221329622, val_loss: 1.313427634133494 (20 / 100)
train_acc: 0.42027194066749074, val_acc: 0.4039408866995074, train_loss: 1.3936786775388588, val_loss: 1.3808027059573846 (21 / 100)
train_acc: 0.43016069221260816, val_acc: 0.46798029556650245, train_loss: 1.317288386070242, val_loss: 1.3792884026842165 (22 / 100)
train_acc: 0.45241038318912236, val_acc: 0.4236453201970443, train_loss: 1.3186112555349419, val_loss: 1.3770210860398016 (23 / 100)
train_acc: 0.44252163164400493, val_acc: 0.43349753694581283, train_loss: 1.3496094463192783, val_loss: 1.4463787583881997 (24 / 100)
train_acc: 0.44128553770086526, val_acc: 0.4482758620689655, train_loss: 1.3365887735034392, val_loss: 1.2739695240124105 (25 / 100)
train_acc: 0.4610630407911001, val_acc: 0.47783251231527096, train_loss: 1.2728945858251621, val_loss: 1.2374595855844432 (26 / 100)
train_acc: 0.44870210135970334, val_acc: 0.4088669950738916, train_loss: 1.2609790445700269, val_loss: 1.3180155067021035 (27 / 100)
train_acc: 0.46600741656365885, val_acc: 0.4876847290640394, train_loss: 1.2278818646526455, val_loss: 1.2446118640194972 (28 / 100)
train_acc: 0.5006180469715699, val_acc: 0.4039408866995074, train_loss: 1.2230288142474237, val_loss: 1.3107438337039479 (29 / 100)
train_acc: 0.4857849196538937, val_acc: 0.43842364532019706, train_loss: 1.1892061575381512, val_loss: 1.3373286183831727 (30 / 100)
train_acc: 0.5043263288009888, val_acc: 0.46798029556650245, train_loss: 1.1893803217944463, val_loss: 1.2888086030048689 (31 / 100)
train_acc: 0.5166872682323856, val_acc: 0.46798029556650245, train_loss: 1.1722391684653586, val_loss: 1.2098256719523464 (32 / 100)
train_acc: 0.5377008652657602, val_acc: 0.4975369458128079, train_loss: 1.1076346010301257, val_loss: 1.1810872105542074 (33 / 100)
train_acc: 0.5364647713226205, val_acc: 0.5467980295566502, train_loss: 1.1119948279282956, val_loss: 1.1109554908545733 (34 / 100)
train_acc: 0.5661310259579728, val_acc: 0.43842364532019706, train_loss: 1.063453614048669, val_loss: 1.340432355850201 (35 / 100)
train_acc: 0.5636588380716935, val_acc: 0.5270935960591133, train_loss: 1.0799030912821312, val_loss: 1.1919463693801993 (36 / 100)
train_acc: 0.5859085290482077, val_acc: 0.5615763546798029, train_loss: 1.0258674550115399, val_loss: 1.1223627240787 (37 / 100)
train_acc: 0.6093943139678616, val_acc: 0.46798029556650245, train_loss: 0.9507650926764433, val_loss: 1.262927376578007 (38 / 100)
train_acc: 0.584672435105068, val_acc: 0.4876847290640394, train_loss: 1.0171812665182522, val_loss: 1.1597252326645875 (39 / 100)
train_acc: 0.6378244746600742, val_acc: 0.5566502463054187, train_loss: 0.9025413643002362, val_loss: 1.0797137494744926 (40 / 100)
train_acc: 0.6501854140914709, val_acc: 0.5812807881773399, train_loss: 0.8778074462569982, val_loss: 1.1052001030574292 (41 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5320197044334976, train_loss: 0.9383847786042245, val_loss: 1.3139599039049572 (42 / 100)
train_acc: 0.7021013597033374, val_acc: 0.4975369458128079, train_loss: 0.7787504076810349, val_loss: 1.2536556139368142 (43 / 100)
train_acc: 0.6983930778739185, val_acc: 0.49261083743842365, train_loss: 0.7527857386726974, val_loss: 1.1727508782165978 (44 / 100)
train_acc: 0.7107540173053152, val_acc: 0.4827586206896552, train_loss: 0.7493545905179235, val_loss: 1.2253646219305216 (45 / 100)
train_acc: 0.7243510506798516, val_acc: 0.5862068965517241, train_loss: 0.6869368658519646, val_loss: 1.1435968658606994 (46 / 100)
train_acc: 0.7713226205191595, val_acc: 0.5763546798029556, train_loss: 0.6376128515000691, val_loss: 1.1375616225115772 (47 / 100)
train_acc: 0.7639060568603214, val_acc: 0.5517241379310345, train_loss: 0.5967512858665476, val_loss: 1.255990255642407 (48 / 100)
train_acc: 0.788627935723115, val_acc: 0.5714285714285714, train_loss: 0.5349405740004387, val_loss: 1.3301133393066857 (49 / 100)
train_acc: 0.7935723114956736, val_acc: 0.5615763546798029, train_loss: 0.5530817340714086, val_loss: 1.2229744213555247 (50 / 100)
train_acc: 0.8046971569839307, val_acc: 0.49261083743842365, train_loss: 0.5109994351053415, val_loss: 1.1970506787593729 (51 / 100)
train_acc: 0.8182941903584673, val_acc: 0.6009852216748769, train_loss: 0.460841009510757, val_loss: 1.5524489282093612 (52 / 100)
train_acc: 0.8145859085290482, val_acc: 0.6009852216748769, train_loss: 0.4917443971183008, val_loss: 1.1387971903890224 (53 / 100)
train_acc: 0.8368355995055624, val_acc: 0.6059113300492611, train_loss: 0.4308929453305762, val_loss: 1.509889430600434 (54 / 100)
train_acc: 0.8244746600741656, val_acc: 0.6108374384236454, train_loss: 0.4727052369503804, val_loss: 1.4776286529790004 (55 / 100)
train_acc: 0.8590852904820766, val_acc: 0.6108374384236454, train_loss: 0.3471510104549535, val_loss: 1.2665232555032364 (56 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6403940886699507, train_loss: 0.3106890932296498, val_loss: 1.0692152219452882 (57 / 100)
train_acc: 0.8936959208899876, val_acc: 0.6108374384236454, train_loss: 0.2895925848092078, val_loss: 1.5593960696253284 (58 / 100)
train_acc: 0.8467243510506799, val_acc: 0.6157635467980296, train_loss: 0.40870870471148024, val_loss: 1.155804151971939 (59 / 100)
train_acc: 0.8862793572311496, val_acc: 0.6206896551724138, train_loss: 0.30334262673286044, val_loss: 1.6196881691223295 (60 / 100)
train_acc: 0.930778739184178, val_acc: 0.6502463054187192, train_loss: 0.19895654908935131, val_loss: 1.466872737325471 (61 / 100)
train_acc: 0.9555006180469716, val_acc: 0.6551724137931034, train_loss: 0.1284004113854488, val_loss: 1.4976085066208111 (62 / 100)
train_acc: 0.9419035846724351, val_acc: 0.6600985221674877, train_loss: 0.1399857658796169, val_loss: 1.5069911397736648 (63 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6699507389162561, train_loss: 0.10702224197361171, val_loss: 1.6346570229882678 (64 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6650246305418719, train_loss: 0.10716731144502133, val_loss: 1.6504517118331834 (65 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6748768472906403, train_loss: 0.07673982237966452, val_loss: 1.7572315531998433 (66 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6502463054187192, train_loss: 0.1100878747656702, val_loss: 1.7801022940668567 (67 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6847290640394089, train_loss: 0.08533622188164365, val_loss: 1.722552746387538 (68 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6650246305418719, train_loss: 0.09462484045987961, val_loss: 1.7178171180151953 (69 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6896551724137931, train_loss: 0.09042448991603404, val_loss: 1.7598839463858769 (70 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6847290640394089, train_loss: 0.08594987728047025, val_loss: 1.7460551784543568 (71 / 100)
train_acc: 0.965389369592089, val_acc: 0.6945812807881774, train_loss: 0.10766244354589907, val_loss: 1.8404957754858609 (72 / 100)
train_acc: 0.969097651421508, val_acc: 0.6847290640394089, train_loss: 0.08691272835767562, val_loss: 1.7615350211782408 (73 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6699507389162561, train_loss: 0.06774866566055067, val_loss: 1.9096000329614273 (74 / 100)
train_acc: 0.965389369592089, val_acc: 0.6748768472906403, train_loss: 0.08643725333932202, val_loss: 1.9587731966244175 (75 / 100)
train_acc: 0.969097651421508, val_acc: 0.6798029556650246, train_loss: 0.0828707570276869, val_loss: 1.9759152558049544 (76 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6748768472906403, train_loss: 0.07905176747935665, val_loss: 1.9695899938714916 (77 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6847290640394089, train_loss: 0.09022805614141363, val_loss: 1.9204748739749926 (78 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6945812807881774, train_loss: 0.06665858409133808, val_loss: 1.823059764988904 (79 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6847290640394089, train_loss: 0.07082848232446701, val_loss: 1.862157896821722 (80 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6995073891625616, train_loss: 0.05167390980811879, val_loss: 1.9537365324978757 (81 / 100)
train_acc: 0.9604449938195303, val_acc: 0.6847290640394089, train_loss: 0.0981361656386419, val_loss: 1.9441161478681517 (82 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6748768472906403, train_loss: 0.06426758553927168, val_loss: 2.0166720286965956 (83 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6798029556650246, train_loss: 0.0886814321479927, val_loss: 1.9821416585903449 (84 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6748768472906403, train_loss: 0.051826592426567494, val_loss: 1.9942022291897552 (85 / 100)
train_acc: 0.969097651421508, val_acc: 0.6896551724137931, train_loss: 0.07439307509262427, val_loss: 1.9492201993030867 (86 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6847290640394089, train_loss: 0.06431830149461666, val_loss: 1.9841942652105697 (87 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6748768472906403, train_loss: 0.06190505531721268, val_loss: 1.9705117494601923 (88 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6699507389162561, train_loss: 0.05959133829631381, val_loss: 1.9507587566751565 (89 / 100)
train_acc: 0.969097651421508, val_acc: 0.6748768472906403, train_loss: 0.08889030115345058, val_loss: 1.9196075623845819 (90 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6798029556650246, train_loss: 0.041463987788845115, val_loss: 1.9813429093713244 (91 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6650246305418719, train_loss: 0.0638764781373172, val_loss: 1.9432598287836085 (92 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6748768472906403, train_loss: 0.051735701451563865, val_loss: 2.051260568238244 (93 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6699507389162561, train_loss: 0.06016335281807059, val_loss: 2.0592323341980356 (94 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6847290640394089, train_loss: 0.06435864968559209, val_loss: 2.1125612059250254 (95 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6748768472906403, train_loss: 0.06391498700419743, val_loss: 2.094337347693044 (96 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6798029556650246, train_loss: 0.06963940648123094, val_loss: 2.1031951176121906 (97 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6699507389162561, train_loss: 0.06590437152416058, val_loss: 2.0948653632196885 (98 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6847290640394089, train_loss: 0.06180818576011139, val_loss: 2.1176699811014634 (99 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.049955400017496515, val_loss: 2.172750768403114 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 1e-05, 'gamma': 0.1}), val accuracy 0.6995073891625616, val loss 1.9537365324978757
train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7831404161983722, val_loss: 1.7705621983617397 (1 / 100)
train_acc: 0.18170580964153277, val_acc: 0.18226600985221675, train_loss: 1.7682728026205, val_loss: 1.7516744189661713 (2 / 100)
train_acc: 0.2126081582200247, val_acc: 0.2561576354679803, train_loss: 1.7600891570962405, val_loss: 1.754685591594339 (3 / 100)
train_acc: 0.23485784919653893, val_acc: 0.2512315270935961, train_loss: 1.7531537106364266, val_loss: 1.7364868553988453 (4 / 100)
train_acc: 0.27935723114956734, val_acc: 0.3103448275862069, train_loss: 1.7047248926976113, val_loss: 1.6237360855628704 (5 / 100)
train_acc: 0.3164400494437577, val_acc: 0.2413793103448276, train_loss: 1.6816647225168933, val_loss: 1.5830282589484905 (6 / 100)
train_acc: 0.29295426452410384, val_acc: 0.2413793103448276, train_loss: 1.6278915875332318, val_loss: 1.6416205044450431 (7 / 100)
train_acc: 0.34239802224969096, val_acc: 0.30049261083743845, train_loss: 1.5837083584888019, val_loss: 1.6597708363838384 (8 / 100)
train_acc: 0.3362175525339926, val_acc: 0.35960591133004927, train_loss: 1.5676575442327114, val_loss: 1.4988961337235174 (9 / 100)
train_acc: 0.35970333745364647, val_acc: 0.3054187192118227, train_loss: 1.5137566120279735, val_loss: 1.648766269824775 (10 / 100)
train_acc: 0.37330037082818296, val_acc: 0.458128078817734, train_loss: 1.4773683570076714, val_loss: 1.4263457142073532 (11 / 100)
train_acc: 0.38936959208899874, val_acc: 0.3694581280788177, train_loss: 1.459747477721225, val_loss: 1.4248015099558338 (12 / 100)
train_acc: 0.3683559950556242, val_acc: 0.39901477832512317, train_loss: 1.429874653279855, val_loss: 1.3713982939132916 (13 / 100)
train_acc: 0.4079110012360939, val_acc: 0.3891625615763547, train_loss: 1.4384183039329255, val_loss: 1.362556317756916 (14 / 100)
train_acc: 0.36093943139678614, val_acc: 0.37438423645320196, train_loss: 1.437684490889937, val_loss: 1.4632418044094968 (15 / 100)
train_acc: 0.39184177997527814, val_acc: 0.3793103448275862, train_loss: 1.3964696018893286, val_loss: 1.3803424735374639 (16 / 100)
train_acc: 0.3992583436341162, val_acc: 0.4187192118226601, train_loss: 1.3885958875507596, val_loss: 1.3453176506047178 (17 / 100)
train_acc: 0.3943139678615575, val_acc: 0.4482758620689655, train_loss: 1.3882736554104553, val_loss: 1.425066293166776 (18 / 100)
train_acc: 0.40296662546353523, val_acc: 0.4827586206896552, train_loss: 1.3873857616346759, val_loss: 1.4194481930709237 (19 / 100)
train_acc: 0.3967861557478368, val_acc: 0.4187192118226601, train_loss: 1.3880404516851945, val_loss: 1.340086808345588 (20 / 100)
train_acc: 0.45982694684796044, val_acc: 0.4827586206896552, train_loss: 1.30467900151228, val_loss: 1.2806376905864096 (21 / 100)
train_acc: 0.446229913473424, val_acc: 0.458128078817734, train_loss: 1.3113855348971335, val_loss: 1.3635989345353225 (22 / 100)
train_acc: 0.4573547589616811, val_acc: 0.35960591133004927, train_loss: 1.2859186077000038, val_loss: 1.4230306524361296 (23 / 100)
train_acc: 0.4721878862793572, val_acc: 0.49261083743842365, train_loss: 1.2690815710461478, val_loss: 1.195765158812988 (24 / 100)
train_acc: 0.4721878862793572, val_acc: 0.49261083743842365, train_loss: 1.2575254791009853, val_loss: 1.2158611014558764 (25 / 100)
train_acc: 0.4956736711990111, val_acc: 0.49261083743842365, train_loss: 1.1937289716876187, val_loss: 1.170752451337617 (26 / 100)
train_acc: 0.4796044499381953, val_acc: 0.4433497536945813, train_loss: 1.2377553055401342, val_loss: 1.2278347097594162 (27 / 100)
train_acc: 0.515451174289246, val_acc: 0.5172413793103449, train_loss: 1.1923300873658567, val_loss: 1.1495513187840654 (28 / 100)
train_acc: 0.5241038318912238, val_acc: 0.5024630541871922, train_loss: 1.171164071604112, val_loss: 1.1429874098359658 (29 / 100)
train_acc: 0.519159456118665, val_acc: 0.4975369458128079, train_loss: 1.1592178751423274, val_loss: 1.2097807459056085 (30 / 100)
train_acc: 0.5784919653893696, val_acc: 0.5467980295566502, train_loss: 1.065443887698783, val_loss: 1.1093724919070165 (31 / 100)
train_acc: 0.5624227441285538, val_acc: 0.5270935960591133, train_loss: 1.0834863123993939, val_loss: 1.1602535362314121 (32 / 100)
train_acc: 0.5747836835599506, val_acc: 0.5615763546798029, train_loss: 1.04491612024154, val_loss: 1.1155296490697437 (33 / 100)
train_acc: 0.5859085290482077, val_acc: 0.5270935960591133, train_loss: 1.0381728197794466, val_loss: 1.1273985243783209 (34 / 100)
train_acc: 0.5760197775030902, val_acc: 0.5369458128078818, train_loss: 0.9932363501143249, val_loss: 1.1510787336109893 (35 / 100)
train_acc: 0.6328800988875154, val_acc: 0.5172413793103449, train_loss: 0.9202169386948584, val_loss: 1.1662526433103777 (36 / 100)
train_acc: 0.6316440049443758, val_acc: 0.5172413793103449, train_loss: 0.9177990037814354, val_loss: 1.2102517338809122 (37 / 100)
train_acc: 0.6056860321384425, val_acc: 0.5714285714285714, train_loss: 0.9593724945124943, val_loss: 1.071578031103012 (38 / 100)
train_acc: 0.69221260815822, val_acc: 0.5320197044334976, train_loss: 0.7982118671992506, val_loss: 1.3423616342943878 (39 / 100)
train_acc: 0.6390605686032138, val_acc: 0.5517241379310345, train_loss: 0.8982314202929899, val_loss: 1.1026394123514298 (40 / 100)
train_acc: 0.7058096415327565, val_acc: 0.5073891625615764, train_loss: 0.7491900935695405, val_loss: 1.4454392047938456 (41 / 100)
train_acc: 0.7218788627935723, val_acc: 0.5862068965517241, train_loss: 0.7026038631078486, val_loss: 1.0651068106073465 (42 / 100)
train_acc: 0.7404202719406675, val_acc: 0.5911330049261084, train_loss: 0.6838866758110791, val_loss: 1.0567239734339597 (43 / 100)
train_acc: 0.7218788627935723, val_acc: 0.6059113300492611, train_loss: 0.7358938476579593, val_loss: 1.1037945671034564 (44 / 100)
train_acc: 0.7688504326328801, val_acc: 0.5517241379310345, train_loss: 0.5923467042714321, val_loss: 1.101405455561107 (45 / 100)
train_acc: 0.7799752781211372, val_acc: 0.6009852216748769, train_loss: 0.5879717210240948, val_loss: 1.270216011648695 (46 / 100)
train_acc: 0.7948084054388134, val_acc: 0.5467980295566502, train_loss: 0.5521385159863824, val_loss: 1.3849222721724674 (47 / 100)
train_acc: 0.7750309023485785, val_acc: 0.5665024630541872, train_loss: 0.5560365664796865, val_loss: 1.2456552629987594 (48 / 100)
train_acc: 0.8590852904820766, val_acc: 0.5270935960591133, train_loss: 0.4281946413670246, val_loss: 1.873525101563026 (49 / 100)
train_acc: 0.8158220024721878, val_acc: 0.5714285714285714, train_loss: 0.4810503103824422, val_loss: 1.6627089965519646 (50 / 100)
train_acc: 0.8207663782447466, val_acc: 0.5615763546798029, train_loss: 0.4710262078326771, val_loss: 1.4578336829622391 (51 / 100)
train_acc: 0.8899876390605687, val_acc: 0.5665024630541872, train_loss: 0.3027664215772497, val_loss: 1.661786505741439 (52 / 100)
train_acc: 0.8739184177997528, val_acc: 0.6059113300492611, train_loss: 0.35234901192972184, val_loss: 1.5895998125593063 (53 / 100)
train_acc: 0.8491965389369592, val_acc: 0.5911330049261084, train_loss: 0.38813326458995806, val_loss: 1.5604634032460856 (54 / 100)
train_acc: 0.8949320148331273, val_acc: 0.6206896551724138, train_loss: 0.28840299803482733, val_loss: 1.683601600195974 (55 / 100)
train_acc: 0.8726823238566132, val_acc: 0.5615763546798029, train_loss: 0.3344923246776218, val_loss: 2.0200357031939653 (56 / 100)
train_acc: 0.9097651421508035, val_acc: 0.5763546798029556, train_loss: 0.26048933144552894, val_loss: 1.6870829304450838 (57 / 100)
train_acc: 0.9048207663782447, val_acc: 0.6157635467980296, train_loss: 0.2677128919122835, val_loss: 1.3865154917016993 (58 / 100)
train_acc: 0.9184177997527813, val_acc: 0.625615763546798, train_loss: 0.264824509031251, val_loss: 1.6024512551688208 (59 / 100)
train_acc: 0.9110012360939431, val_acc: 0.6009852216748769, train_loss: 0.24082680269431125, val_loss: 1.6917385632181403 (60 / 100)
train_acc: 0.9592088998763906, val_acc: 0.6650246305418719, train_loss: 0.1183023128948636, val_loss: 1.6425495687963927 (61 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6600985221674877, train_loss: 0.10498065118331402, val_loss: 1.7021234114769057 (62 / 100)
train_acc: 0.965389369592089, val_acc: 0.6600985221674877, train_loss: 0.10194993034760354, val_loss: 1.7629617528962385 (63 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6600985221674877, train_loss: 0.08574113447785525, val_loss: 1.730633448497415 (64 / 100)
train_acc: 0.9678615574783683, val_acc: 0.645320197044335, train_loss: 0.08136918708884672, val_loss: 1.8116523908276863 (65 / 100)
train_acc: 0.9604449938195303, val_acc: 0.645320197044335, train_loss: 0.11271703272265911, val_loss: 1.7596244773841256 (66 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6699507389162561, train_loss: 0.09386901266421611, val_loss: 1.7874652355762537 (67 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6699507389162561, train_loss: 0.08477819584855725, val_loss: 1.7938506409452466 (68 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6699507389162561, train_loss: 0.08552226899440685, val_loss: 1.8427916219081786 (69 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6748768472906403, train_loss: 0.07851963608936673, val_loss: 1.899099320613692 (70 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.06482917490577594, val_loss: 1.9425382549539576 (71 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6650246305418719, train_loss: 0.064441224110741, val_loss: 1.9299999264073489 (72 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.05831695561457255, val_loss: 1.9769619779633771 (73 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6699507389162561, train_loss: 0.08032967902637088, val_loss: 1.968437091176733 (74 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6699507389162561, train_loss: 0.06273104175027316, val_loss: 1.9807367982535526 (75 / 100)
train_acc: 0.969097651421508, val_acc: 0.6699507389162561, train_loss: 0.07784015389230696, val_loss: 1.9982910696508849 (76 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6650246305418719, train_loss: 0.0619279576536862, val_loss: 2.0838503038941933 (77 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.045443727258404044, val_loss: 2.118516559084061 (78 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6551724137931034, train_loss: 0.06448804595385654, val_loss: 2.0884812688592618 (79 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6600985221674877, train_loss: 0.04103385370825642, val_loss: 2.121659063940565 (80 / 100)
train_acc: 0.9901112484548825, val_acc: 0.6650246305418719, train_loss: 0.04260682882882116, val_loss: 2.180244135151943 (81 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6650246305418719, train_loss: 0.046264333210710544, val_loss: 2.2209863051992333 (82 / 100)
train_acc: 0.9802224969097652, val_acc: 0.645320197044335, train_loss: 0.06153793483788357, val_loss: 2.1850925478441963 (83 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6699507389162561, train_loss: 0.0582988749894835, val_loss: 2.257726914776957 (84 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6551724137931034, train_loss: 0.05725004926452825, val_loss: 2.287060201461679 (85 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6600985221674877, train_loss: 0.05188360202445088, val_loss: 2.2703502078361697 (86 / 100)
train_acc: 0.9938195302843016, val_acc: 0.6600985221674877, train_loss: 0.026964445638931408, val_loss: 2.30942202965027 (87 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6551724137931034, train_loss: 0.055833553648997, val_loss: 2.3568775301496383 (88 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6551724137931034, train_loss: 0.040698854384005036, val_loss: 2.3593940617415705 (89 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6600985221674877, train_loss: 0.04915179796644247, val_loss: 2.370829969204118 (90 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6502463054187192, train_loss: 0.059410169776051326, val_loss: 2.399216923220404 (91 / 100)
train_acc: 0.9826946847960445, val_acc: 0.645320197044335, train_loss: 0.04649731314140147, val_loss: 2.4706736527053006 (92 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6551724137931034, train_loss: 0.0356550428858637, val_loss: 2.467560160923474 (93 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6798029556650246, train_loss: 0.07053460830037467, val_loss: 2.406967087332251 (94 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6650246305418719, train_loss: 0.0501769649966278, val_loss: 2.340714565638838 (95 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6650246305418719, train_loss: 0.06778342228000626, val_loss: 2.3905783979763537 (96 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6502463054187192, train_loss: 0.03994192771512292, val_loss: 2.3585257817958962 (97 / 100)
train_acc: 0.9826946847960445, val_acc: 0.645320197044335, train_loss: 0.0445087459882346, val_loss: 2.395776771559504 (98 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6650246305418719, train_loss: 0.07648252999716253, val_loss: 2.363981010878615 (99 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6600985221674877, train_loss: 0.03679075347644142, val_loss: 2.427178770450536 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.05}), val accuracy 0.6798029556650246, val loss 2.406967087332251
train_acc: 0.19530284301606923, val_acc: 0.22660098522167488, train_loss: 1.7855405201870667, val_loss: 1.7686893393840697 (1 / 100)
train_acc: 0.18665018541409148, val_acc: 0.18226600985221675, train_loss: 1.7655226863064195, val_loss: 1.750889197946182 (2 / 100)
train_acc: 0.20148331273176762, val_acc: 0.32019704433497537, train_loss: 1.75630616699662, val_loss: 1.741050796555768 (3 / 100)
train_acc: 0.19901112484548825, val_acc: 0.2413793103448276, train_loss: 1.7517467278927308, val_loss: 1.7161011895522695 (4 / 100)
train_acc: 0.23856613102595797, val_acc: 0.2512315270935961, train_loss: 1.7116753813362828, val_loss: 1.6764515849757078 (5 / 100)
train_acc: 0.2904820766378245, val_acc: 0.3103448275862069, train_loss: 1.6592213456209275, val_loss: 1.5889328271884637 (6 / 100)
train_acc: 0.28059332509270707, val_acc: 0.28078817733990147, train_loss: 1.687496948301129, val_loss: 1.5733275460492213 (7 / 100)
train_acc: 0.3300370828182942, val_acc: 0.3251231527093596, train_loss: 1.5912676573683806, val_loss: 1.5713328786671454 (8 / 100)
train_acc: 0.33498145859085293, val_acc: 0.45320197044334976, train_loss: 1.5371168873955499, val_loss: 1.476784875240232 (9 / 100)
train_acc: 0.3362175525339926, val_acc: 0.27586206896551724, train_loss: 1.5416137299814685, val_loss: 1.5711522607380533 (10 / 100)
train_acc: 0.3572311495673671, val_acc: 0.3891625615763547, train_loss: 1.4981150721442713, val_loss: 1.3992841924939836 (11 / 100)
train_acc: 0.34487021013597036, val_acc: 0.3842364532019704, train_loss: 1.4859829656273238, val_loss: 1.464575834755827 (12 / 100)
train_acc: 0.3547589616810878, val_acc: 0.3399014778325123, train_loss: 1.4810713270243963, val_loss: 1.3994745870529137 (13 / 100)
train_acc: 0.377008652657602, val_acc: 0.3891625615763547, train_loss: 1.4494740572494393, val_loss: 1.4333257387424339 (14 / 100)
train_acc: 0.38936959208899874, val_acc: 0.4236453201970443, train_loss: 1.4222113981529867, val_loss: 1.3236381843172271 (15 / 100)
train_acc: 0.39184177997527814, val_acc: 0.43349753694581283, train_loss: 1.4214078448022105, val_loss: 1.3051769140318696 (16 / 100)
train_acc: 0.41409147095179233, val_acc: 0.3251231527093596, train_loss: 1.3640280506666864, val_loss: 1.4269531941766223 (17 / 100)
train_acc: 0.41409147095179233, val_acc: 0.4433497536945813, train_loss: 1.3994272461043595, val_loss: 1.2608409620858179 (18 / 100)
train_acc: 0.4276885043263288, val_acc: 0.4433497536945813, train_loss: 1.3398996529679363, val_loss: 1.2888420083252667 (19 / 100)
train_acc: 0.44746600741656367, val_acc: 0.4433497536945813, train_loss: 1.3268917190424443, val_loss: 1.2409324381739049 (20 / 100)
train_acc: 0.45859085290482077, val_acc: 0.49261083743842365, train_loss: 1.3083020579829647, val_loss: 1.3015951834288724 (21 / 100)
train_acc: 0.4746600741656366, val_acc: 0.4827586206896552, train_loss: 1.287365431691277, val_loss: 1.2136395059782883 (22 / 100)
train_acc: 0.4684796044499382, val_acc: 0.4482758620689655, train_loss: 1.2943029898058793, val_loss: 1.2534116283426144 (23 / 100)
train_acc: 0.4511742892459827, val_acc: 0.4975369458128079, train_loss: 1.2814833367858152, val_loss: 1.1769659536812693 (24 / 100)
train_acc: 0.48702101359703337, val_acc: 0.5221674876847291, train_loss: 1.1976273223407778, val_loss: 1.2088796511072244 (25 / 100)
train_acc: 0.5129789864029666, val_acc: 0.4876847290640394, train_loss: 1.1675606992542376, val_loss: 1.317612458332419 (26 / 100)
train_acc: 0.522867737948084, val_acc: 0.5221674876847291, train_loss: 1.1773173698536104, val_loss: 1.186978963501935 (27 / 100)
train_acc: 0.5030902348578492, val_acc: 0.4088669950738916, train_loss: 1.1849176768761482, val_loss: 1.370314096582347 (28 / 100)
train_acc: 0.5216316440049443, val_acc: 0.4827586206896552, train_loss: 1.1449236223665245, val_loss: 1.1714074482471484 (29 / 100)
train_acc: 0.5438813349814586, val_acc: 0.5024630541871922, train_loss: 1.0941994082647732, val_loss: 1.1656810846822014 (30 / 100)
train_acc: 0.5673671199011124, val_acc: 0.5615763546798029, train_loss: 1.0305360725105766, val_loss: 1.1333928924475984 (31 / 100)
train_acc: 0.5834363411619283, val_acc: 0.5123152709359606, train_loss: 0.9945916865753155, val_loss: 1.2679693607861184 (32 / 100)
train_acc: 0.5624227441285538, val_acc: 0.5320197044334976, train_loss: 1.0854253076357658, val_loss: 1.0924386637551444 (33 / 100)
train_acc: 0.622991347342398, val_acc: 0.5270935960591133, train_loss: 0.9368780404881877, val_loss: 1.2761254140308924 (34 / 100)
train_acc: 0.6180469715698393, val_acc: 0.5763546798029556, train_loss: 0.9583623260443821, val_loss: 1.09542571265122 (35 / 100)
train_acc: 0.6316440049443758, val_acc: 0.43349753694581283, train_loss: 0.9018494822038856, val_loss: 1.5097757624875148 (36 / 100)
train_acc: 0.6402966625463535, val_acc: 0.5566502463054187, train_loss: 0.9349391710920298, val_loss: 1.1145448038730714 (37 / 100)
train_acc: 0.6613102595797281, val_acc: 0.5123152709359606, train_loss: 0.8330687910723598, val_loss: 1.2098380896845475 (38 / 100)
train_acc: 0.6749072929542645, val_acc: 0.5665024630541872, train_loss: 0.7994468487679443, val_loss: 1.1908471293637317 (39 / 100)
train_acc: 0.7021013597033374, val_acc: 0.5763546798029556, train_loss: 0.7308433553933803, val_loss: 1.247300153295395 (40 / 100)
train_acc: 0.723114956736712, val_acc: 0.5960591133004927, train_loss: 0.726198678110969, val_loss: 1.336607545467433 (41 / 100)
train_acc: 0.7243510506798516, val_acc: 0.5172413793103449, train_loss: 0.720011999639504, val_loss: 1.1705042896012368 (42 / 100)
train_acc: 0.7416563658838071, val_acc: 0.5812807881773399, train_loss: 0.649172165190481, val_loss: 1.2904558299210271 (43 / 100)
train_acc: 0.7750309023485785, val_acc: 0.5517241379310345, train_loss: 0.6106315297897725, val_loss: 1.456777771705477 (44 / 100)
train_acc: 0.7812113720642769, val_acc: 0.5763546798029556, train_loss: 0.6290738063925424, val_loss: 1.2661514892953958 (45 / 100)
train_acc: 0.7750309023485785, val_acc: 0.49261083743842365, train_loss: 0.5995451040630435, val_loss: 1.4171956752615023 (46 / 100)
train_acc: 0.8343634116192831, val_acc: 0.6108374384236454, train_loss: 0.46275841158311654, val_loss: 1.3333669272549633 (47 / 100)
train_acc: 0.8158220024721878, val_acc: 0.5566502463054187, train_loss: 0.49458448347556133, val_loss: 1.43542285505774 (48 / 100)
train_acc: 0.8133498145859085, val_acc: 0.5665024630541872, train_loss: 0.48703586694189294, val_loss: 1.0378757591905265 (49 / 100)
train_acc: 0.8467243510506799, val_acc: 0.5960591133004927, train_loss: 0.40137341185685876, val_loss: 1.3847280934526416 (50 / 100)
train_acc: 0.8714462299134734, val_acc: 0.6305418719211823, train_loss: 0.38729592719390454, val_loss: 1.536653264402756 (51 / 100)
train_acc: 0.8417799752781211, val_acc: 0.6059113300492611, train_loss: 0.3887831102342924, val_loss: 1.5809046693623359 (52 / 100)
train_acc: 0.8751545117428925, val_acc: 0.6009852216748769, train_loss: 0.3418375129163339, val_loss: 1.3487470044291079 (53 / 100)
train_acc: 0.8936959208899876, val_acc: 0.5714285714285714, train_loss: 0.33722624374261156, val_loss: 1.6024963164270805 (54 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5911330049261084, train_loss: 0.35095195066096313, val_loss: 1.6853223369626575 (55 / 100)
train_acc: 0.8751545117428925, val_acc: 0.5270935960591133, train_loss: 0.3639157072206952, val_loss: 1.904931391401244 (56 / 100)
train_acc: 0.8875154511742892, val_acc: 0.4975369458128079, train_loss: 0.3296270721922404, val_loss: 1.6219433205468314 (57 / 100)
train_acc: 0.8887515451174289, val_acc: 0.6354679802955665, train_loss: 0.33583577903740486, val_loss: 1.651530242905828 (58 / 100)
train_acc: 0.896168108776267, val_acc: 0.5960591133004927, train_loss: 0.2898525775436713, val_loss: 1.7380783014696808 (59 / 100)
train_acc: 0.896168108776267, val_acc: 0.5615763546798029, train_loss: 0.3047105884651466, val_loss: 1.9847855098141824 (60 / 100)
train_acc: 0.9555006180469716, val_acc: 0.645320197044335, train_loss: 0.1407252059436699, val_loss: 1.693721218062152 (61 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6157635467980296, train_loss: 0.11601406564229204, val_loss: 1.8737029254142874 (62 / 100)
train_acc: 0.9629171817058096, val_acc: 0.6305418719211823, train_loss: 0.10627642992253061, val_loss: 1.8853151187520896 (63 / 100)
train_acc: 0.969097651421508, val_acc: 0.625615763546798, train_loss: 0.09605264014878732, val_loss: 2.0235647932062006 (64 / 100)
train_acc: 0.9616810877626699, val_acc: 0.6305418719211823, train_loss: 0.10041153431053841, val_loss: 2.0979122704473037 (65 / 100)
train_acc: 0.9728059332509271, val_acc: 0.6551724137931034, train_loss: 0.07685511338965431, val_loss: 2.118677528033703 (66 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.08336904272897576, val_loss: 2.104407903596098 (67 / 100)
train_acc: 0.965389369592089, val_acc: 0.6403940886699507, train_loss: 0.08602097357896114, val_loss: 2.057441581058972 (68 / 100)
train_acc: 0.9678615574783683, val_acc: 0.6600985221674877, train_loss: 0.08502200226517041, val_loss: 2.0422752537750846 (69 / 100)
train_acc: 0.9641532756489494, val_acc: 0.6600985221674877, train_loss: 0.0882945800452218, val_loss: 2.0453447602652566 (70 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6551724137931034, train_loss: 0.08711730593951288, val_loss: 2.2291803066366414 (71 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6551724137931034, train_loss: 0.06572199324364641, val_loss: 2.239701152435077 (72 / 100)
train_acc: 0.9703337453646477, val_acc: 0.6600985221674877, train_loss: 0.07292569037273582, val_loss: 2.2240016037607426 (73 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.05419270821319771, val_loss: 2.376876365962287 (74 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6502463054187192, train_loss: 0.06421944771620487, val_loss: 2.423926644724578 (75 / 100)
train_acc: 0.9839307787391842, val_acc: 0.6551724137931034, train_loss: 0.06284186704491802, val_loss: 2.301781446475701 (76 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6650246305418719, train_loss: 0.07452228352685351, val_loss: 2.4512285892599324 (77 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6600985221674877, train_loss: 0.06406678698671468, val_loss: 2.4466741554842795 (78 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6502463054187192, train_loss: 0.07632313626277294, val_loss: 2.4347962041206546 (79 / 100)
train_acc: 0.9752781211372065, val_acc: 0.6551724137931034, train_loss: 0.06768154125771174, val_loss: 2.485454417214605 (80 / 100)
train_acc: 0.9814585908529048, val_acc: 0.6650246305418719, train_loss: 0.05634338525728275, val_loss: 2.4742644737506736 (81 / 100)
train_acc: 0.9777503090234858, val_acc: 0.6600985221674877, train_loss: 0.060442436611028307, val_loss: 2.5553863624046587 (82 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6600985221674877, train_loss: 0.04272156062378227, val_loss: 2.6642406691471345 (83 / 100)
train_acc: 0.9851668726823238, val_acc: 0.6551724137931034, train_loss: 0.05700274671765208, val_loss: 2.678679021121246 (84 / 100)
train_acc: 0.9826946847960445, val_acc: 0.6650246305418719, train_loss: 0.05848134654410481, val_loss: 2.728360578931611 (85 / 100)
train_acc: 0.969097651421508, val_acc: 0.645320197044335, train_loss: 0.07279764161513122, val_loss: 2.4878352874605527 (86 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6699507389162561, train_loss: 0.06204288218133566, val_loss: 2.3763108300458033 (87 / 100)
train_acc: 0.9765142150803461, val_acc: 0.6403940886699507, train_loss: 0.07321777669033692, val_loss: 2.468250327509612 (88 / 100)
train_acc: 0.9789864029666254, val_acc: 0.6354679802955665, train_loss: 0.0627627234597436, val_loss: 2.5111611288756572 (89 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6403940886699507, train_loss: 0.03419416325514484, val_loss: 2.6224009168559106 (90 / 100)
train_acc: 0.9715698393077874, val_acc: 0.6305418719211823, train_loss: 0.0579918220418198, val_loss: 2.6117232256922227 (91 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6403940886699507, train_loss: 0.05301909570579909, val_loss: 2.6734777777065784 (92 / 100)
train_acc: 0.992583436341162, val_acc: 0.6650246305418719, train_loss: 0.029834985438900067, val_loss: 2.521628756828496 (93 / 100)
train_acc: 0.9864029666254636, val_acc: 0.6551724137931034, train_loss: 0.044227909246026174, val_loss: 2.6390926098001413 (94 / 100)
train_acc: 0.9740420271940667, val_acc: 0.6551724137931034, train_loss: 0.06593744565441523, val_loss: 2.714348930443449 (95 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6502463054187192, train_loss: 0.053520994369174145, val_loss: 2.576184107165031 (96 / 100)
train_acc: 0.9851668726823238, val_acc: 0.645320197044335, train_loss: 0.04101192038299053, val_loss: 2.6387774227875207 (97 / 100)
train_acc: 0.9888751545117429, val_acc: 0.6502463054187192, train_loss: 0.03380941680652102, val_loss: 2.905695945758538 (98 / 100)
train_acc: 0.9839307787391842, val_acc: 0.645320197044335, train_loss: 0.04463958650901085, val_loss: 2.827765424850539 (99 / 100)
train_acc: 0.9802224969097652, val_acc: 0.6502463054187192, train_loss: 0.04744047360962121, val_loss: 2.639707820168857 (100 / 100)
({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.001, 'gamma': 0.1}), val accuracy 0.6699507389162561, val loss 2.3763108300458033

({'lr': 0.0005, 'batch_size': 8, 'weight_decay': 1e-05, 'gamma': 0.05}), best val accuracy 0.7635467980295566, best val loss 1.4869063125161701

val_accuracies
[0.7635467980295566, 0.6945812807881774, 0.6798029556650246, 0.6995073891625616, 0.6354679802955665, 0.6354679802955665, 0.645320197044335, 0.6502463054187192, 0.6502463054187192, 0.6305418719211823, 0.6551724137931034, 0.6502463054187192, 0.6896551724137931, 0.6995073891625616, 0.6798029556650246, 0.6699507389162561]