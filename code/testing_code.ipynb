{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testing_code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPaMDHUbl6zzKeZGVHd9/wk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NmNXzlktIZYy","colab_type":"text"},"source":["Testing functions and classes"]},{"cell_type":"code","metadata":{"id":"rjCHX7OYJOhk","colab_type":"code","colab":{}},"source":["# Serve per il mapping fra label sul file con le labels per canzone di test e l'indice della label che la rete considera.\n","LABELS_FROM_FILE = {'angry' : 0, 'calming' : 1, 'happy' : 3, 'normal' : 4, 'sad' : 5}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"luRrXt95IVME","colab_type":"code","colab":{}},"source":["class ImageFolderWithPaths(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0]\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path\n","\n","def test_network_with_songs_data_return(net, test_dataset, batch_size):\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    net.train(False)\n","    net = net.to(DEVICE)\n","\n","    test_songs_data = dict()\n","    for images, labels, paths in test_dataloader:\n","      torch.cuda.empty_cache()\n","      images = images.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      # Forward Pass\n","      outputs = net(images)\n","\n","      # Get predictions\n","      _, preds = torch.max(outputs.data, 1)\n","\n","      idx = 0;\n","      for pred in preds:\n","\n","        image_name = paths[idx].split(\"/\")[-1]\n","        song_idx = image_name.split(\"_\")[0]\n","      \n","        if song_idx not in test_songs_data:\n","          test_songs_data[song_idx] = dict()\n","          test_songs_data[song_idx][\"preds\"] = np.zeros(NUM_CLASSES, dtype=int)\n","          # test_songs_data[song_idx][\"outputs\"] = []\n","\n","        test_songs_data[song_idx][\"preds\"][pred] += 1\n","        # test_songs_data[song_idx][\"outputs\"].append(outputs[idx])\n","\n","        idx += 1\n","\n","      del labels\n","      del images\n","      del outputs\n","\n","    return test_songs_data\n","\n","def read_songs_labels(path):\n","  f = open(path,\"r\")\n","  lines = f.readlines()\n","\n","  song_labels = dict()\n","\n","  for line in lines:\n","    names = line.split(\":\")\n","\n","    if names[0] not in song_labels:\n","      song_labels[names[0]] = []\n","\n","    labels = names[1].replace(\" \", \"\").split(\",\")\n","    labels[-1] = labels[-1][:-2]\n","\n","    for label in labels:\n","      song_labels[names[0]].append(LABELS_FROM_FILE[label])\n","  \n","  return song_labels\n","\n","def major_voting_analyze(songs_data, songs_labels):\n","\n","  ordered_keys = sorted(songs_labels.keys())\n","  print(ordered_keys)\n","  prediction = dict()\n","  avg_outputs = dict()\n","  corrects = 0\n","\n","  for key in songs_data.keys():\n","    num_slices = 0\n","    for value in songs_data[key][\"preds\"]:\n","      num_slices += value\n","\n","\n","    for value in songs_data[key][\"preds\"]:\n","      value = (float) (value/num_slices)\n","      # if value > 0.5:\n","      #   prediction[key] = idx_pred\n","\n","    max = 0\n","    idx_pred = 0\n","    idx_max = 0\n","    for value in songs_data[key][\"preds\"]:\n","      if value > max:\n","        max = value\n","        idx_max = idx_pred\n","      idx_pred += 1\n","\n","    prediction[key] = idx_max\n","\n","    # for output in songs_data[key][\"outputs\"]:\n","    #   if sum_outputs is None:\n","    #     sum_outputs = output\n","    #   else:\n","    #     sum_outputs += output\n","\n","    # avg_ouputs = sum_outputs/num_slices\n","\n","  idx = 0\n","  for song in prediction:\n","    if prediction[song] in songs_labels[ordered_keys[idx]]:\n","      corrects += 1\n","    print(\"Prediction for song {} - {}: ; labels: {}\".format(song, ordered_keys[idx], prediction, songs_labels[ordered_keys[idx]]))\n","  idx += 1\n","\n","  test_accuracy = (float) (corrects / idx)\n","  print(\"Test accuracy: {}\".format(test_accuracy))\n","\n","def get_test_dataset(test_data_dir):\n","    eval_transform = transforms.Compose([\n","          transforms.Resize(224),\n","          transforms.CenterCrop(224),\n","          transforms.ToTensor()\n","          ])\n","    \n","    if not os.path.isdir('./AIML_project'):\n","        !git clone https://github.com/anphetamina/AIML_project.git\n","    \n","    test_dataset = ImageFolderWithPaths(test_data_dir, transform=eval_transform)\n","\n","    return test_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DRWBeVNJVHZ","colab_type":"text"},"source":["Code example"]},{"cell_type":"code","metadata":{"id":"WdTvcMOJJUpx","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache()\n","\n","TEST_DATA_DIR = 'AIML_project/CAL500_test_sliced_spectrograms'\n","test_dataset = get_test_dataset(TEST_DATA_DIR)\n","print('test set {}'.format(len(test_dataset_copy)))\n","\n","# net extracted by training\n","songs_data = test_network_with_songs_data_return(net, test_dataset, 1)\n","\n","print(songs_data)\n","\n","songs_labels = read_songs_labels(\"AIML_project/songs_filtered_with_labels.txt\")\n","\n","print(songs_labels)\n","\n","major_voting_analyze(songs_data, songs_labels)"],"execution_count":0,"outputs":[]}]}